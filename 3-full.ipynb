{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN_NAME = 'close'\n",
    "DATE_COLUMN_NAME = 'date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df = pd.read_csv(\"BTC-ETH-filtered_with_indicators.csv\",\n",
    "                 #read dates as dates\n",
    "                 parse_dates=[DATE_COLUMN_NAME], date_parser=lambda x: datetime.fromtimestamp(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_mfi</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>momentum_stoch</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-08 13:00:00</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>305.268381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.167981</td>\n",
       "      <td>45.157443</td>\n",
       "      <td>28.591248</td>\n",
       "      <td>35.263099</td>\n",
       "      <td>50.670902</td>\n",
       "      <td>3.022479</td>\n",
       "      <td>35.313687</td>\n",
       "      <td>-96.977521</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.021977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-08 14:00:00</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>136.451949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>...</td>\n",
       "      <td>998.683014</td>\n",
       "      <td>43.532803</td>\n",
       "      <td>29.578064</td>\n",
       "      <td>33.326024</td>\n",
       "      <td>50.240787</td>\n",
       "      <td>12.782255</td>\n",
       "      <td>19.826985</td>\n",
       "      <td>-87.217745</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.021955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-08 15:00:00</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>288.438229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>...</td>\n",
       "      <td>998.683014</td>\n",
       "      <td>43.717932</td>\n",
       "      <td>20.524735</td>\n",
       "      <td>31.591883</td>\n",
       "      <td>47.917554</td>\n",
       "      <td>13.526088</td>\n",
       "      <td>9.776940</td>\n",
       "      <td>-86.473912</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.021939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-08 16:00:00</td>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>92.436833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.537481</td>\n",
       "      <td>47.884700</td>\n",
       "      <td>25.320718</td>\n",
       "      <td>30.209204</td>\n",
       "      <td>49.308124</td>\n",
       "      <td>34.472678</td>\n",
       "      <td>20.260340</td>\n",
       "      <td>-65.527322</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.021939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-08 17:00:00</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>69.129320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.911531</td>\n",
       "      <td>48.423552</td>\n",
       "      <td>30.578143</td>\n",
       "      <td>28.984263</td>\n",
       "      <td>55.993278</td>\n",
       "      <td>36.710383</td>\n",
       "      <td>28.236383</td>\n",
       "      <td>-63.289617</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.021939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date      open      high       low     close      volume  \\\n",
       "0 2019-10-08 13:00:00  0.022053  0.022053  0.021884  0.021896  305.268381   \n",
       "1 2019-10-08 14:00:00  0.021882  0.021907  0.021803  0.021864  136.451949   \n",
       "2 2019-10-08 15:00:00  0.021853  0.021882  0.021817  0.021867  288.438229   \n",
       "3 2019-10-08 16:00:00  0.021874  0.021967  0.021828  0.021929   92.436833   \n",
       "4 2019-10-08 17:00:00  0.021909  0.021938  0.021862  0.021937   69.129320   \n",
       "\n",
       "   fake  volatility_atr  volatility_bbh  volatility_bbl  ...   volume_nvi  \\\n",
       "0     0        0.000128        0.022258        0.021808  ...  1000.167981   \n",
       "1     0        0.000126        0.022256        0.021811  ...   998.683014   \n",
       "2     0        0.000122        0.022261        0.021801  ...   998.683014   \n",
       "3     0        0.000123        0.022252        0.021820  ...  1001.537481   \n",
       "4     0        0.000120        0.022247        0.021831  ...  1001.911531   \n",
       "\n",
       "   momentum_rsi  momentum_mfi  momentum_tsi  momentum_uo  momentum_stoch  \\\n",
       "0     45.157443     28.591248     35.263099    50.670902        3.022479   \n",
       "1     43.532803     29.578064     33.326024    50.240787       12.782255   \n",
       "2     43.717932     20.524735     31.591883    47.917554       13.526088   \n",
       "3     47.884700     25.320718     30.209204    49.308124       34.472678   \n",
       "4     48.423552     30.578143     28.984263    55.993278       36.710383   \n",
       "\n",
       "   momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama  \n",
       "0              35.313687   -96.977521     0.000107       0.021977  \n",
       "1              19.826985   -87.217745     0.000059       0.021955  \n",
       "2               9.776940   -86.473912     0.000008       0.021939  \n",
       "3              20.260340   -65.527322    -0.000037       0.021939  \n",
       "4              28.236383   -63.289617    -0.000065       0.021939  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELAPSED = 'Elapsed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>...</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>305.268381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1570539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>136.451949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1570543200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>288.438229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1570546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>92.436833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1570550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>69.129320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1570554000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close      volume  fake  volatility_atr  \\\n",
       "0  0.022053  0.022053  0.021884  0.021896  305.268381     0        0.000128   \n",
       "1  0.021882  0.021907  0.021803  0.021864  136.451949     0        0.000126   \n",
       "2  0.021853  0.021882  0.021817  0.021867  288.438229     0        0.000122   \n",
       "3  0.021874  0.021967  0.021828  0.021929   92.436833     0        0.000123   \n",
       "4  0.021909  0.021938  0.021862  0.021937   69.129320     0        0.000120   \n",
       "\n",
       "   volatility_bbh  volatility_bbl  volatility_bbm  ...  Is_month_end  \\\n",
       "0        0.022258        0.021808        0.022033  ...         False   \n",
       "1        0.022256        0.021811        0.022034  ...         False   \n",
       "2        0.022261        0.021801        0.022031  ...         False   \n",
       "3        0.022252        0.021820        0.022036  ...         False   \n",
       "4        0.022247        0.021831        0.022039  ...         False   \n",
       "\n",
       "   Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  \\\n",
       "0           False           False             False        False   \n",
       "1           False           False             False        False   \n",
       "2           False           False             False        False   \n",
       "3           False           False             False        False   \n",
       "4           False           False             False        False   \n",
       "\n",
       "   Is_year_start  Hour  Minute  Second     Elapsed  \n",
       "0          False    13       0       0  1570539600  \n",
       "1          False    14       0       0  1570543200  \n",
       "2          False    15       0       0  1570546800  \n",
       "3          False    16       0       0  1570550400  \n",
       "4          False    17       0       0  1570554000  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_datepart(df, DATE_COLUMN_NAME, time=True);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>...</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>305.268381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570540e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>136.451949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570543e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>288.438229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570547e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>92.436833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570550e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>69.129320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570554e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close      volume  fake  volatility_atr  \\\n",
       "0  0.022053  0.022053  0.021884  0.021896  305.268381   0.0        0.000128   \n",
       "1  0.021882  0.021907  0.021803  0.021864  136.451949   0.0        0.000126   \n",
       "2  0.021853  0.021882  0.021817  0.021867  288.438229   0.0        0.000122   \n",
       "3  0.021874  0.021967  0.021828  0.021929   92.436833   0.0        0.000123   \n",
       "4  0.021909  0.021938  0.021862  0.021937   69.129320   0.0        0.000120   \n",
       "\n",
       "   volatility_bbh  volatility_bbl  volatility_bbm  ...  Is_month_end  \\\n",
       "0        0.022258        0.021808        0.022033  ...           0.0   \n",
       "1        0.022256        0.021811        0.022034  ...           0.0   \n",
       "2        0.022261        0.021801        0.022031  ...           0.0   \n",
       "3        0.022252        0.021820        0.022036  ...           0.0   \n",
       "4        0.022247        0.021831        0.022039  ...           0.0   \n",
       "\n",
       "   Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  \\\n",
       "0             0.0             0.0               0.0          0.0   \n",
       "1             0.0             0.0               0.0          0.0   \n",
       "2             0.0             0.0               0.0          0.0   \n",
       "3             0.0             0.0               0.0          0.0   \n",
       "4             0.0             0.0               0.0          0.0   \n",
       "\n",
       "   Is_year_start  Hour  Minute  Second       Elapsed  \n",
       "0            0.0  13.0     0.0     0.0  1.570540e+09  \n",
       "1            0.0  14.0     0.0     0.0  1.570543e+09  \n",
       "2            0.0  15.0     0.0     0.0  1.570547e+09  \n",
       "3            0.0  16.0     0.0     0.0  1.570550e+09  \n",
       "4            0.0  17.0     0.0     0.0  1.570554e+09  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('open', 0),\n",
       " ('high', 0),\n",
       " ('low', 0),\n",
       " ('close', 0),\n",
       " ('volume', 0),\n",
       " ('fake', 0),\n",
       " ('volatility_atr', 0),\n",
       " ('volatility_bbh', 0),\n",
       " ('volatility_bbl', 0),\n",
       " ('volatility_bbm', 0),\n",
       " ('volatility_kcc', 0),\n",
       " ('volatility_kch', 0),\n",
       " ('volatility_kcl', 0),\n",
       " ('volatility_dch', 0),\n",
       " ('volatility_dcl', 0),\n",
       " ('trend_macd', 0),\n",
       " ('trend_macd_signal', 0),\n",
       " ('trend_macd_diff', 0),\n",
       " ('trend_ema_fast', 0),\n",
       " ('trend_ema_slow', 0),\n",
       " ('trend_adx', 0),\n",
       " ('trend_adx_pos', 0),\n",
       " ('trend_adx_neg', 0),\n",
       " ('trend_vortex_ind_pos', 0),\n",
       " ('trend_vortex_ind_neg', 0),\n",
       " ('trend_vortex_diff', 0),\n",
       " ('trend_trix', 0),\n",
       " ('trend_mass_index', 0),\n",
       " ('trend_cci', 0),\n",
       " ('trend_dpo', 0),\n",
       " ('trend_kst', 0),\n",
       " ('trend_kst_sig', 0),\n",
       " ('trend_kst_diff', 0),\n",
       " ('trend_ichimoku_a', 0),\n",
       " ('trend_ichimoku_b', 0),\n",
       " ('trend_visual_ichimoku_a', 0),\n",
       " ('trend_visual_ichimoku_b', 0),\n",
       " ('trend_aroon_up', 0),\n",
       " ('trend_aroon_down', 0),\n",
       " ('trend_aroon_ind', 0),\n",
       " ('others_dr', 0),\n",
       " ('others_dlr', 0),\n",
       " ('others_cr', 0),\n",
       " ('volume_adi', 0),\n",
       " ('volume_cmf', 0),\n",
       " ('volume_fi', 0),\n",
       " ('volume_em', 0),\n",
       " ('volume_vpt', 0),\n",
       " ('volume_nvi', 0),\n",
       " ('momentum_rsi', 0),\n",
       " ('momentum_mfi', 0),\n",
       " ('momentum_tsi', 0),\n",
       " ('momentum_uo', 0),\n",
       " ('momentum_stoch', 0),\n",
       " ('momentum_stoch_signal', 0),\n",
       " ('momentum_wr', 0),\n",
       " ('momentum_ao', 0),\n",
       " ('momentum_kama', 0),\n",
       " ('Year', 0),\n",
       " ('Month', 0),\n",
       " ('Week', 0),\n",
       " ('Day', 0),\n",
       " ('Dayofweek', 0),\n",
       " ('Dayofyear', 0),\n",
       " ('Is_month_end', 0),\n",
       " ('Is_month_start', 0),\n",
       " ('Is_quarter_end', 0),\n",
       " ('Is_quarter_start', 0),\n",
       " ('Is_year_end', 0),\n",
       " ('Is_year_start', 0),\n",
       " ('Hour', 0),\n",
       " ('Minute', 0),\n",
       " ('Second', 0),\n",
       " ('Elapsed', 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(column, sum(df[column].isna())) for column in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>volatility_kcc</th>\n",
       "      <th>volatility_kch</th>\n",
       "      <th>volatility_kcl</th>\n",
       "      <th>volatility_dch</th>\n",
       "      <th>volatility_dcl</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>trend_macd_signal</th>\n",
       "      <th>trend_macd_diff</th>\n",
       "      <th>trend_ema_fast</th>\n",
       "      <th>trend_ema_slow</th>\n",
       "      <th>trend_adx</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "      <th>trend_adx_neg</th>\n",
       "      <th>trend_vortex_ind_pos</th>\n",
       "      <th>trend_vortex_ind_neg</th>\n",
       "      <th>trend_vortex_diff</th>\n",
       "      <th>trend_trix</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>trend_dpo</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>trend_kst_diff</th>\n",
       "      <th>trend_ichimoku_a</th>\n",
       "      <th>trend_ichimoku_b</th>\n",
       "      <th>trend_visual_ichimoku_a</th>\n",
       "      <th>trend_visual_ichimoku_b</th>\n",
       "      <th>trend_aroon_up</th>\n",
       "      <th>trend_aroon_down</th>\n",
       "      <th>trend_aroon_ind</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_vpt</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_mfi</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>momentum_stoch</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1.397000e+03</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1.397000e+03</td>\n",
       "      <td>1.397000e+03</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1.397000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.020861</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>153.582367</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.020814</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-3.143768e-07</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>25.396275</td>\n",
       "      <td>22.898628</td>\n",
       "      <td>23.799541</td>\n",
       "      <td>0.984188</td>\n",
       "      <td>0.983161</td>\n",
       "      <td>0.238856</td>\n",
       "      <td>-0.006324</td>\n",
       "      <td>24.886794</td>\n",
       "      <td>-6.363178</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.256486</td>\n",
       "      <td>-1.181221</td>\n",
       "      <td>-0.075265</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.020972</td>\n",
       "      <td>48.873300</td>\n",
       "      <td>53.821045</td>\n",
       "      <td>-4.947745</td>\n",
       "      <td>-0.005730</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>-2.627734</td>\n",
       "      <td>-11.823537</td>\n",
       "      <td>-0.032794</td>\n",
       "      <td>-3.332348e-03</td>\n",
       "      <td>1.156144e-12</td>\n",
       "      <td>-0.421218</td>\n",
       "      <td>985.260125</td>\n",
       "      <td>49.718009</td>\n",
       "      <td>48.920859</td>\n",
       "      <td>-0.126826</td>\n",
       "      <td>49.245812</td>\n",
       "      <td>50.283767</td>\n",
       "      <td>50.248067</td>\n",
       "      <td>-49.716233</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.678597</td>\n",
       "      <td>44.882606</td>\n",
       "      <td>16.190408</td>\n",
       "      <td>2.967072</td>\n",
       "      <td>310.145311</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.512527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.573052e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>243.568117</td>\n",
       "      <td>0.026755</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.547605e-05</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>10.916563</td>\n",
       "      <td>7.871240</td>\n",
       "      <td>8.386831</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.156645</td>\n",
       "      <td>0.182983</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>108.646523</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>13.867574</td>\n",
       "      <td>13.621176</td>\n",
       "      <td>4.208580</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>33.245533</td>\n",
       "      <td>33.161315</td>\n",
       "      <td>56.048953</td>\n",
       "      <td>0.411266</td>\n",
       "      <td>0.412725</td>\n",
       "      <td>3.864709</td>\n",
       "      <td>232.269055</td>\n",
       "      <td>0.184855</td>\n",
       "      <td>1.421062e-01</td>\n",
       "      <td>2.333458e-11</td>\n",
       "      <td>8.259312</td>\n",
       "      <td>12.732075</td>\n",
       "      <td>10.589298</td>\n",
       "      <td>19.069128</td>\n",
       "      <td>12.984373</td>\n",
       "      <td>9.663123</td>\n",
       "      <td>26.495306</td>\n",
       "      <td>24.048273</td>\n",
       "      <td>26.495306</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617724</td>\n",
       "      <td>2.426682</td>\n",
       "      <td>8.782934</td>\n",
       "      <td>1.974494</td>\n",
       "      <td>16.813308</td>\n",
       "      <td>0.182216</td>\n",
       "      <td>0.182216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.915942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452325e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.019134</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.193810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-2.089936e-04</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>8.727206</td>\n",
       "      <td>3.854257</td>\n",
       "      <td>3.855724</td>\n",
       "      <td>0.487343</td>\n",
       "      <td>0.484985</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>-0.346318</td>\n",
       "      <td>20.647260</td>\n",
       "      <td>-527.587876</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>-87.475404</td>\n",
       "      <td>-83.160174</td>\n",
       "      <td>-27.189257</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-5.207317</td>\n",
       "      <td>-5.347796</td>\n",
       "      <td>-11.069812</td>\n",
       "      <td>-1989.105675</td>\n",
       "      <td>-0.553080</td>\n",
       "      <td>-4.463384e+00</td>\n",
       "      <td>-8.092963e-11</td>\n",
       "      <td>-202.584464</td>\n",
       "      <td>951.986120</td>\n",
       "      <td>14.324958</td>\n",
       "      <td>3.156019</td>\n",
       "      <td>-34.305654</td>\n",
       "      <td>14.073463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378128</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570540e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>49.003941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.020442</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-1.347095e-05</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.020251</td>\n",
       "      <td>16.819045</td>\n",
       "      <td>17.283758</td>\n",
       "      <td>18.052005</td>\n",
       "      <td>0.875764</td>\n",
       "      <td>0.883719</td>\n",
       "      <td>0.095851</td>\n",
       "      <td>-0.028188</td>\n",
       "      <td>23.912071</td>\n",
       "      <td>-86.349097</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-6.704556</td>\n",
       "      <td>-6.495337</td>\n",
       "      <td>-2.109634</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-0.190905</td>\n",
       "      <td>-0.191087</td>\n",
       "      <td>-5.816738</td>\n",
       "      <td>-76.342672</td>\n",
       "      <td>-0.159598</td>\n",
       "      <td>-2.507827e-03</td>\n",
       "      <td>-1.213642e-11</td>\n",
       "      <td>-0.250783</td>\n",
       "      <td>974.764088</td>\n",
       "      <td>42.510963</td>\n",
       "      <td>34.343029</td>\n",
       "      <td>-8.826047</td>\n",
       "      <td>42.456905</td>\n",
       "      <td>29.302085</td>\n",
       "      <td>31.152532</td>\n",
       "      <td>-70.697915</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.571796e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.020972</td>\n",
       "      <td>88.370943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.021303</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>1.805383e-07</td>\n",
       "      <td>0.021025</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>23.545483</td>\n",
       "      <td>22.315960</td>\n",
       "      <td>22.905309</td>\n",
       "      <td>0.974774</td>\n",
       "      <td>0.991147</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>24.809315</td>\n",
       "      <td>-5.978497</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.092593</td>\n",
       "      <td>-0.989413</td>\n",
       "      <td>-0.127224</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>-2.353132</td>\n",
       "      <td>-2.892960</td>\n",
       "      <td>-0.045433</td>\n",
       "      <td>2.636999e-08</td>\n",
       "      <td>9.289720e-13</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>986.338151</td>\n",
       "      <td>49.444820</td>\n",
       "      <td>49.096055</td>\n",
       "      <td>-1.601136</td>\n",
       "      <td>49.290981</td>\n",
       "      <td>48.921560</td>\n",
       "      <td>48.838279</td>\n",
       "      <td>-51.078440</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.573052e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>170.577082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.021628</td>\n",
       "      <td>0.021716</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.365577e-05</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>30.928694</td>\n",
       "      <td>27.644285</td>\n",
       "      <td>28.956400</td>\n",
       "      <td>1.088987</td>\n",
       "      <td>1.089104</td>\n",
       "      <td>0.341273</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>25.778467</td>\n",
       "      <td>72.608647</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5.829415</td>\n",
       "      <td>5.772386</td>\n",
       "      <td>2.267086</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>0.021619</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.180121</td>\n",
       "      <td>0.179959</td>\n",
       "      <td>0.693196</td>\n",
       "      <td>61.557799</td>\n",
       "      <td>0.079938</td>\n",
       "      <td>2.885404e-03</td>\n",
       "      <td>1.436120e-11</td>\n",
       "      <td>0.262259</td>\n",
       "      <td>995.419226</td>\n",
       "      <td>56.572158</td>\n",
       "      <td>63.075899</td>\n",
       "      <td>10.404720</td>\n",
       "      <td>55.748865</td>\n",
       "      <td>71.469127</td>\n",
       "      <td>69.748646</td>\n",
       "      <td>-28.530873</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.574309e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.023016</td>\n",
       "      <td>0.022623</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>3847.705315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.022745</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>7.015455e-05</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>63.859515</td>\n",
       "      <td>53.734469</td>\n",
       "      <td>56.273988</td>\n",
       "      <td>1.504774</td>\n",
       "      <td>1.486762</td>\n",
       "      <td>0.955507</td>\n",
       "      <td>0.129782</td>\n",
       "      <td>30.677616</td>\n",
       "      <td>312.342764</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>31.458065</td>\n",
       "      <td>29.442797</td>\n",
       "      <td>13.615516</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.327156</td>\n",
       "      <td>2.300491</td>\n",
       "      <td>6.204170</td>\n",
       "      <td>2107.945796</td>\n",
       "      <td>0.537787</td>\n",
       "      <td>1.210524e+00</td>\n",
       "      <td>7.987940e-11</td>\n",
       "      <td>69.914962</td>\n",
       "      <td>1013.086060</td>\n",
       "      <td>79.825888</td>\n",
       "      <td>94.403365</td>\n",
       "      <td>35.263099</td>\n",
       "      <td>75.701382</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.961219</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.575565e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open         high          low        close       volume         fake  volatility_atr  volatility_bbh  volatility_bbl  volatility_bbm  volatility_kcc  volatility_kch  volatility_kcl  volatility_dch  volatility_dcl   trend_macd  trend_macd_signal  trend_macd_diff  trend_ema_fast  trend_ema_slow    trend_adx  trend_adx_pos  trend_adx_neg  trend_vortex_ind_pos  trend_vortex_ind_neg  trend_vortex_diff   trend_trix  trend_mass_index    trend_cci    trend_dpo    trend_kst  trend_kst_sig  trend_kst_diff  trend_ichimoku_a  trend_ichimoku_b  trend_visual_ichimoku_a  trend_visual_ichimoku_b  trend_aroon_up  trend_aroon_down  trend_aroon_ind    others_dr   others_dlr    others_cr   volume_adi   volume_cmf     volume_fi     volume_em   volume_vpt   volume_nvi  momentum_rsi  momentum_mfi  momentum_tsi  momentum_uo  momentum_stoch  momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama    Year        Month         Week          Day    Dayofweek    Dayofyear  Is_month_end  \\\n",
       "count  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000  1397.000000        1397.000000     1.397000e+03     1397.000000     1397.000000  1397.000000    1397.000000    1397.000000           1397.000000           1397.000000        1397.000000  1397.000000       1397.000000  1397.000000  1397.000000  1397.000000    1397.000000     1397.000000       1397.000000       1397.000000              1397.000000              1397.000000     1397.000000       1397.000000      1397.000000  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000  1.397000e+03  1.397000e+03  1397.000000  1397.000000   1397.000000   1397.000000   1397.000000  1397.000000     1397.000000            1397.000000  1397.000000  1397.000000    1397.000000  1397.0  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000   1397.000000   \n",
       "mean      0.020915     0.020967     0.020861     0.020913   153.582367     0.000716        0.000108        0.021151        0.020703        0.020927        0.020920        0.021026        0.020814        0.021123        0.020733    -0.000010          -0.000009    -3.143768e-07        0.020921        0.020931    25.396275      22.898628      23.799541              0.984188              0.983161           0.238856    -0.006324         24.886794    -6.363178     0.000003    -1.256486      -1.181221       -0.075265          0.020920          0.020938                 0.020956                 0.020972       48.873300         53.821045        -4.947745    -0.005730    -0.006579    -2.627734   -11.823537    -0.032794 -3.332348e-03  1.156144e-12    -0.421218   985.260125     49.718009     48.920859     -0.126826    49.245812       50.283767              50.248067   -49.716233    -0.000021       0.020929  2019.0    10.678597    44.882606    16.190408     2.967072   310.145311      0.034359   \n",
       "std       0.000830     0.000828     0.000835     0.000830   243.568117     0.026755        0.000042        0.000824        0.000852        0.000820        0.000825        0.000820        0.000833        0.000813        0.000840     0.000086           0.000082     2.547605e-05        0.000820        0.000809    10.916563       7.871240       8.386831              0.155383              0.156645           0.182983     0.058278          1.521083   108.646523     0.000106    13.867574      13.621176        4.208580          0.000817          0.000794                 0.000817                 0.000791       33.245533         33.161315        56.048953     0.411266     0.412725     3.864709   232.269055     0.184855  1.421062e-01  2.333458e-11     8.259312    12.732075     10.589298     19.069128     12.984373     9.663123       26.495306              24.048273    26.495306     0.000219       0.000814     0.0     0.617724     2.426682     8.782934     1.974494    16.813308      0.182216   \n",
       "min       0.019134     0.019194     0.018897     0.019100     0.193810     0.000000        0.000055        0.019485        0.018684        0.019273        0.019240        0.019377        0.019050        0.019511        0.019100    -0.000557          -0.000487    -2.089936e-04        0.019228        0.019334     8.727206       3.854257       3.855724              0.487343              0.484985           0.000226    -0.346318         20.647260  -527.587876    -0.000763   -87.475404     -83.160174      -27.189257          0.019250          0.019377                 0.019250                 0.019377        4.000000          4.000000       -96.000000    -5.207317    -5.347796   -11.069812 -1989.105675    -0.553080 -4.463384e+00 -8.092963e-11  -202.584464   951.986120     14.324958      3.156019    -34.305654    14.073463        0.000000               0.378128  -100.000000    -0.001671       0.019412  2019.0    10.000000    41.000000     1.000000     0.000000   281.000000      0.000000   \n",
       "25%       0.020229     0.020268     0.020182     0.020228    49.003941     0.000000        0.000079        0.020442        0.020009        0.020255        0.020241        0.020334        0.020149        0.020437        0.020070    -0.000042          -0.000039    -1.347095e-05        0.020240        0.020251    16.819045      17.283758      18.052005              0.875764              0.883719           0.095851    -0.028188         23.912071   -86.349097    -0.000055    -6.704556      -6.495337       -2.109634          0.020240          0.020254                 0.020264                 0.020311       16.000000         20.000000       -52.000000    -0.190905    -0.191087    -5.816738   -76.342672    -0.159598 -2.507827e-03 -1.213642e-11    -0.250783   974.764088     42.510963     34.343029     -8.826047    42.456905       29.302085              31.152532   -70.697915    -0.000110       0.020275  2019.0    10.000000    43.000000     9.000000     1.000000   296.000000      0.000000   \n",
       "50%       0.020977     0.021021     0.020926     0.020972    88.370943     0.000000        0.000096        0.021303        0.020789        0.021065        0.021028        0.021146        0.020906        0.021233        0.020862    -0.000008          -0.000007     1.805383e-07        0.021025        0.021047    23.545483      22.315960      22.905309              0.974774              0.991147           0.200018    -0.004513         24.809315    -5.978497     0.000003    -1.092593      -0.989413       -0.127224          0.021067          0.021051                 0.021100                 0.021186       44.000000         56.000000       -20.000000     0.003096     0.003096    -2.353132    -2.892960    -0.045433  2.636999e-08  9.289720e-13     0.008176   986.338151     49.444820     49.096055     -1.601136    49.290981       48.921560              48.838279   -51.078440    -0.000018       0.021032  2019.0    11.000000    45.000000    16.000000     3.000000   310.000000      0.000000   \n",
       "75%       0.021627     0.021674     0.021588     0.021626   170.577082     0.000000        0.000126        0.021808        0.021491        0.021626        0.021628        0.021716        0.021545        0.021764        0.021498     0.000036           0.000034     1.365577e-05        0.021617        0.021610    30.928694      27.644285      28.956400              1.088987              1.089104           0.341273     0.024507         25.778467    72.608647     0.000061     5.829415       5.772386        2.267086          0.021610          0.021573                 0.021619                 0.021607       80.000000         84.000000        44.000000     0.180121     0.179959     0.693196    61.557799     0.079938  2.885404e-03  1.436120e-11     0.262259   995.419226     56.572158     63.075899     10.404720    55.748865       71.469127              69.748646   -28.530873     0.000082       0.021620  2019.0    11.000000    47.000000    24.000000     5.000000   325.000000      0.000000   \n",
       "max       0.022810     0.023016     0.022623     0.022810  3847.705315     1.000000        0.000343        0.022745        0.022215        0.022456        0.022511        0.022707        0.022381        0.022810        0.022197     0.000199           0.000175     7.015455e-05        0.022485        0.022396    63.859515      53.734469      56.273988              1.504774              1.486762           0.955507     0.129782         30.677616   312.342764     0.000712    31.458065      29.442797       13.615516          0.022539          0.022530                 0.022539                 0.022530      100.000000        100.000000        96.000000     2.327156     2.300491     6.204170  2107.945796     0.537787  1.210524e+00  7.987940e-11    69.914962  1013.086060     79.825888     94.403365     35.263099    75.701382      100.000000              99.961219    -0.000000     0.000482       0.022452  2019.0    12.000000    49.000000    31.000000     6.000000   339.000000      1.000000   \n",
       "\n",
       "       Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  Is_year_start         Hour  Minute  Second       Elapsed  \n",
       "count     1397.000000          1397.0            1397.0       1397.0         1397.0  1397.000000  1397.0  1397.0  1.397000e+03  \n",
       "mean         0.034359             0.0               0.0          0.0            0.0    11.512527     0.0     0.0  1.573052e+09  \n",
       "std          0.182216             0.0               0.0          0.0            0.0     6.915942     0.0     0.0  1.452325e+06  \n",
       "min          0.000000             0.0               0.0          0.0            0.0     0.000000     0.0     0.0  1.570540e+09  \n",
       "25%          0.000000             0.0               0.0          0.0            0.0     6.000000     0.0     0.0  1.571796e+09  \n",
       "50%          0.000000             0.0               0.0          0.0            0.0    12.000000     0.0     0.0  1.573052e+09  \n",
       "75%          0.000000             0.0               0.0          0.0            0.0    17.000000     0.0     0.0  1.574309e+09  \n",
       "max          1.000000             0.0               0.0          0.0            0.0    23.000000     0.0     0.0  1.575565e+09  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns=['Second', 'Month', 'Year', \\\n",
    "              'Is_quarter_end', 'Is_quarter_start', \\\n",
    "              'Is_year_end', 'Is_year_start',\n",
    "              'Is_month_end', 'Is_month_start',\n",
    "              'Week', 'Dayofyear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1397, 63)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=drop_columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>volatility_kcc</th>\n",
       "      <th>volatility_kch</th>\n",
       "      <th>volatility_kcl</th>\n",
       "      <th>volatility_dch</th>\n",
       "      <th>volatility_dcl</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>trend_macd_signal</th>\n",
       "      <th>trend_macd_diff</th>\n",
       "      <th>trend_ema_fast</th>\n",
       "      <th>trend_ema_slow</th>\n",
       "      <th>trend_adx</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "      <th>trend_adx_neg</th>\n",
       "      <th>trend_vortex_ind_pos</th>\n",
       "      <th>trend_vortex_ind_neg</th>\n",
       "      <th>trend_vortex_diff</th>\n",
       "      <th>trend_trix</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>trend_dpo</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>trend_kst_diff</th>\n",
       "      <th>trend_ichimoku_a</th>\n",
       "      <th>trend_ichimoku_b</th>\n",
       "      <th>trend_visual_ichimoku_a</th>\n",
       "      <th>trend_visual_ichimoku_b</th>\n",
       "      <th>trend_aroon_up</th>\n",
       "      <th>trend_aroon_down</th>\n",
       "      <th>trend_aroon_ind</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_vpt</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_mfi</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>momentum_stoch</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1.397000e+03</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1.397000e+03</td>\n",
       "      <td>1.397000e+03</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>1.397000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.020861</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>153.582367</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.020814</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-3.143768e-07</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>25.396275</td>\n",
       "      <td>22.898628</td>\n",
       "      <td>23.799541</td>\n",
       "      <td>0.984188</td>\n",
       "      <td>0.983161</td>\n",
       "      <td>0.238856</td>\n",
       "      <td>-0.006324</td>\n",
       "      <td>24.886794</td>\n",
       "      <td>-6.363178</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.256486</td>\n",
       "      <td>-1.181221</td>\n",
       "      <td>-0.075265</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.020972</td>\n",
       "      <td>48.873300</td>\n",
       "      <td>53.821045</td>\n",
       "      <td>-4.947745</td>\n",
       "      <td>-0.005730</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>-2.627734</td>\n",
       "      <td>-11.823537</td>\n",
       "      <td>-0.032794</td>\n",
       "      <td>-3.332348e-03</td>\n",
       "      <td>1.156144e-12</td>\n",
       "      <td>-0.421218</td>\n",
       "      <td>985.260125</td>\n",
       "      <td>49.718009</td>\n",
       "      <td>48.920859</td>\n",
       "      <td>-0.126826</td>\n",
       "      <td>49.245812</td>\n",
       "      <td>50.283767</td>\n",
       "      <td>50.248067</td>\n",
       "      <td>-49.716233</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>16.190408</td>\n",
       "      <td>2.967072</td>\n",
       "      <td>11.512527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.573052e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>243.568117</td>\n",
       "      <td>0.026755</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.547605e-05</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>10.916563</td>\n",
       "      <td>7.871240</td>\n",
       "      <td>8.386831</td>\n",
       "      <td>0.155383</td>\n",
       "      <td>0.156645</td>\n",
       "      <td>0.182983</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>1.521083</td>\n",
       "      <td>108.646523</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>13.867574</td>\n",
       "      <td>13.621176</td>\n",
       "      <td>4.208580</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>33.245533</td>\n",
       "      <td>33.161315</td>\n",
       "      <td>56.048953</td>\n",
       "      <td>0.411266</td>\n",
       "      <td>0.412725</td>\n",
       "      <td>3.864709</td>\n",
       "      <td>232.269055</td>\n",
       "      <td>0.184855</td>\n",
       "      <td>1.421062e-01</td>\n",
       "      <td>2.333458e-11</td>\n",
       "      <td>8.259312</td>\n",
       "      <td>12.732075</td>\n",
       "      <td>10.589298</td>\n",
       "      <td>19.069128</td>\n",
       "      <td>12.984373</td>\n",
       "      <td>9.663123</td>\n",
       "      <td>26.495306</td>\n",
       "      <td>24.048273</td>\n",
       "      <td>26.495306</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>8.782934</td>\n",
       "      <td>1.974494</td>\n",
       "      <td>6.915942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452325e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.019134</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.193810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-2.089936e-04</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>8.727206</td>\n",
       "      <td>3.854257</td>\n",
       "      <td>3.855724</td>\n",
       "      <td>0.487343</td>\n",
       "      <td>0.484985</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>-0.346318</td>\n",
       "      <td>20.647260</td>\n",
       "      <td>-527.587876</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>-87.475404</td>\n",
       "      <td>-83.160174</td>\n",
       "      <td>-27.189257</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-5.207317</td>\n",
       "      <td>-5.347796</td>\n",
       "      <td>-11.069812</td>\n",
       "      <td>-1989.105675</td>\n",
       "      <td>-0.553080</td>\n",
       "      <td>-4.463384e+00</td>\n",
       "      <td>-8.092963e-11</td>\n",
       "      <td>-202.584464</td>\n",
       "      <td>951.986120</td>\n",
       "      <td>14.324958</td>\n",
       "      <td>3.156019</td>\n",
       "      <td>-34.305654</td>\n",
       "      <td>14.073463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378128</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570540e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>49.003941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.020442</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-1.347095e-05</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.020251</td>\n",
       "      <td>16.819045</td>\n",
       "      <td>17.283758</td>\n",
       "      <td>18.052005</td>\n",
       "      <td>0.875764</td>\n",
       "      <td>0.883719</td>\n",
       "      <td>0.095851</td>\n",
       "      <td>-0.028188</td>\n",
       "      <td>23.912071</td>\n",
       "      <td>-86.349097</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-6.704556</td>\n",
       "      <td>-6.495337</td>\n",
       "      <td>-2.109634</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-0.190905</td>\n",
       "      <td>-0.191087</td>\n",
       "      <td>-5.816738</td>\n",
       "      <td>-76.342672</td>\n",
       "      <td>-0.159598</td>\n",
       "      <td>-2.507827e-03</td>\n",
       "      <td>-1.213642e-11</td>\n",
       "      <td>-0.250783</td>\n",
       "      <td>974.764088</td>\n",
       "      <td>42.510963</td>\n",
       "      <td>34.343029</td>\n",
       "      <td>-8.826047</td>\n",
       "      <td>42.456905</td>\n",
       "      <td>29.302085</td>\n",
       "      <td>31.152532</td>\n",
       "      <td>-70.697915</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.571796e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.020972</td>\n",
       "      <td>88.370943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.021303</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>1.805383e-07</td>\n",
       "      <td>0.021025</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>23.545483</td>\n",
       "      <td>22.315960</td>\n",
       "      <td>22.905309</td>\n",
       "      <td>0.974774</td>\n",
       "      <td>0.991147</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>24.809315</td>\n",
       "      <td>-5.978497</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.092593</td>\n",
       "      <td>-0.989413</td>\n",
       "      <td>-0.127224</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>-2.353132</td>\n",
       "      <td>-2.892960</td>\n",
       "      <td>-0.045433</td>\n",
       "      <td>2.636999e-08</td>\n",
       "      <td>9.289720e-13</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>986.338151</td>\n",
       "      <td>49.444820</td>\n",
       "      <td>49.096055</td>\n",
       "      <td>-1.601136</td>\n",
       "      <td>49.290981</td>\n",
       "      <td>48.921560</td>\n",
       "      <td>48.838279</td>\n",
       "      <td>-51.078440</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.573052e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>170.577082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.021628</td>\n",
       "      <td>0.021716</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.365577e-05</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>30.928694</td>\n",
       "      <td>27.644285</td>\n",
       "      <td>28.956400</td>\n",
       "      <td>1.088987</td>\n",
       "      <td>1.089104</td>\n",
       "      <td>0.341273</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>25.778467</td>\n",
       "      <td>72.608647</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5.829415</td>\n",
       "      <td>5.772386</td>\n",
       "      <td>2.267086</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>0.021619</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.180121</td>\n",
       "      <td>0.179959</td>\n",
       "      <td>0.693196</td>\n",
       "      <td>61.557799</td>\n",
       "      <td>0.079938</td>\n",
       "      <td>2.885404e-03</td>\n",
       "      <td>1.436120e-11</td>\n",
       "      <td>0.262259</td>\n",
       "      <td>995.419226</td>\n",
       "      <td>56.572158</td>\n",
       "      <td>63.075899</td>\n",
       "      <td>10.404720</td>\n",
       "      <td>55.748865</td>\n",
       "      <td>71.469127</td>\n",
       "      <td>69.748646</td>\n",
       "      <td>-28.530873</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.574309e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.023016</td>\n",
       "      <td>0.022623</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>3847.705315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.022745</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>7.015455e-05</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>63.859515</td>\n",
       "      <td>53.734469</td>\n",
       "      <td>56.273988</td>\n",
       "      <td>1.504774</td>\n",
       "      <td>1.486762</td>\n",
       "      <td>0.955507</td>\n",
       "      <td>0.129782</td>\n",
       "      <td>30.677616</td>\n",
       "      <td>312.342764</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>31.458065</td>\n",
       "      <td>29.442797</td>\n",
       "      <td>13.615516</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.327156</td>\n",
       "      <td>2.300491</td>\n",
       "      <td>6.204170</td>\n",
       "      <td>2107.945796</td>\n",
       "      <td>0.537787</td>\n",
       "      <td>1.210524e+00</td>\n",
       "      <td>7.987940e-11</td>\n",
       "      <td>69.914962</td>\n",
       "      <td>1013.086060</td>\n",
       "      <td>79.825888</td>\n",
       "      <td>94.403365</td>\n",
       "      <td>35.263099</td>\n",
       "      <td>75.701382</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.961219</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.575565e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open         high          low        close       volume         fake  volatility_atr  volatility_bbh  volatility_bbl  volatility_bbm  volatility_kcc  volatility_kch  volatility_kcl  volatility_dch  volatility_dcl   trend_macd  trend_macd_signal  trend_macd_diff  trend_ema_fast  trend_ema_slow    trend_adx  trend_adx_pos  trend_adx_neg  trend_vortex_ind_pos  trend_vortex_ind_neg  trend_vortex_diff   trend_trix  trend_mass_index    trend_cci    trend_dpo    trend_kst  trend_kst_sig  trend_kst_diff  trend_ichimoku_a  trend_ichimoku_b  trend_visual_ichimoku_a  trend_visual_ichimoku_b  trend_aroon_up  trend_aroon_down  trend_aroon_ind    others_dr   others_dlr    others_cr   volume_adi   volume_cmf     volume_fi     volume_em   volume_vpt   volume_nvi  momentum_rsi  momentum_mfi  momentum_tsi  momentum_uo  momentum_stoch  momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama          Day    Dayofweek         Hour  Minute       Elapsed\n",
       "count  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000     1397.000000  1397.000000        1397.000000     1.397000e+03     1397.000000     1397.000000  1397.000000    1397.000000    1397.000000           1397.000000           1397.000000        1397.000000  1397.000000       1397.000000  1397.000000  1397.000000  1397.000000    1397.000000     1397.000000       1397.000000       1397.000000              1397.000000              1397.000000     1397.000000       1397.000000      1397.000000  1397.000000  1397.000000  1397.000000  1397.000000  1397.000000  1.397000e+03  1.397000e+03  1397.000000  1397.000000   1397.000000   1397.000000   1397.000000  1397.000000     1397.000000            1397.000000  1397.000000  1397.000000    1397.000000  1397.000000  1397.000000  1397.000000  1397.0  1.397000e+03\n",
       "mean      0.020915     0.020967     0.020861     0.020913   153.582367     0.000716        0.000108        0.021151        0.020703        0.020927        0.020920        0.021026        0.020814        0.021123        0.020733    -0.000010          -0.000009    -3.143768e-07        0.020921        0.020931    25.396275      22.898628      23.799541              0.984188              0.983161           0.238856    -0.006324         24.886794    -6.363178     0.000003    -1.256486      -1.181221       -0.075265          0.020920          0.020938                 0.020956                 0.020972       48.873300         53.821045        -4.947745    -0.005730    -0.006579    -2.627734   -11.823537    -0.032794 -3.332348e-03  1.156144e-12    -0.421218   985.260125     49.718009     48.920859     -0.126826    49.245812       50.283767              50.248067   -49.716233    -0.000021       0.020929    16.190408     2.967072    11.512527     0.0  1.573052e+09\n",
       "std       0.000830     0.000828     0.000835     0.000830   243.568117     0.026755        0.000042        0.000824        0.000852        0.000820        0.000825        0.000820        0.000833        0.000813        0.000840     0.000086           0.000082     2.547605e-05        0.000820        0.000809    10.916563       7.871240       8.386831              0.155383              0.156645           0.182983     0.058278          1.521083   108.646523     0.000106    13.867574      13.621176        4.208580          0.000817          0.000794                 0.000817                 0.000791       33.245533         33.161315        56.048953     0.411266     0.412725     3.864709   232.269055     0.184855  1.421062e-01  2.333458e-11     8.259312    12.732075     10.589298     19.069128     12.984373     9.663123       26.495306              24.048273    26.495306     0.000219       0.000814     8.782934     1.974494     6.915942     0.0  1.452325e+06\n",
       "min       0.019134     0.019194     0.018897     0.019100     0.193810     0.000000        0.000055        0.019485        0.018684        0.019273        0.019240        0.019377        0.019050        0.019511        0.019100    -0.000557          -0.000487    -2.089936e-04        0.019228        0.019334     8.727206       3.854257       3.855724              0.487343              0.484985           0.000226    -0.346318         20.647260  -527.587876    -0.000763   -87.475404     -83.160174      -27.189257          0.019250          0.019377                 0.019250                 0.019377        4.000000          4.000000       -96.000000    -5.207317    -5.347796   -11.069812 -1989.105675    -0.553080 -4.463384e+00 -8.092963e-11  -202.584464   951.986120     14.324958      3.156019    -34.305654    14.073463        0.000000               0.378128  -100.000000    -0.001671       0.019412     1.000000     0.000000     0.000000     0.0  1.570540e+09\n",
       "25%       0.020229     0.020268     0.020182     0.020228    49.003941     0.000000        0.000079        0.020442        0.020009        0.020255        0.020241        0.020334        0.020149        0.020437        0.020070    -0.000042          -0.000039    -1.347095e-05        0.020240        0.020251    16.819045      17.283758      18.052005              0.875764              0.883719           0.095851    -0.028188         23.912071   -86.349097    -0.000055    -6.704556      -6.495337       -2.109634          0.020240          0.020254                 0.020264                 0.020311       16.000000         20.000000       -52.000000    -0.190905    -0.191087    -5.816738   -76.342672    -0.159598 -2.507827e-03 -1.213642e-11    -0.250783   974.764088     42.510963     34.343029     -8.826047    42.456905       29.302085              31.152532   -70.697915    -0.000110       0.020275     9.000000     1.000000     6.000000     0.0  1.571796e+09\n",
       "50%       0.020977     0.021021     0.020926     0.020972    88.370943     0.000000        0.000096        0.021303        0.020789        0.021065        0.021028        0.021146        0.020906        0.021233        0.020862    -0.000008          -0.000007     1.805383e-07        0.021025        0.021047    23.545483      22.315960      22.905309              0.974774              0.991147           0.200018    -0.004513         24.809315    -5.978497     0.000003    -1.092593      -0.989413       -0.127224          0.021067          0.021051                 0.021100                 0.021186       44.000000         56.000000       -20.000000     0.003096     0.003096    -2.353132    -2.892960    -0.045433  2.636999e-08  9.289720e-13     0.008176   986.338151     49.444820     49.096055     -1.601136    49.290981       48.921560              48.838279   -51.078440    -0.000018       0.021032    16.000000     3.000000    12.000000     0.0  1.573052e+09\n",
       "75%       0.021627     0.021674     0.021588     0.021626   170.577082     0.000000        0.000126        0.021808        0.021491        0.021626        0.021628        0.021716        0.021545        0.021764        0.021498     0.000036           0.000034     1.365577e-05        0.021617        0.021610    30.928694      27.644285      28.956400              1.088987              1.089104           0.341273     0.024507         25.778467    72.608647     0.000061     5.829415       5.772386        2.267086          0.021610          0.021573                 0.021619                 0.021607       80.000000         84.000000        44.000000     0.180121     0.179959     0.693196    61.557799     0.079938  2.885404e-03  1.436120e-11     0.262259   995.419226     56.572158     63.075899     10.404720    55.748865       71.469127              69.748646   -28.530873     0.000082       0.021620    24.000000     5.000000    17.000000     0.0  1.574309e+09\n",
       "max       0.022810     0.023016     0.022623     0.022810  3847.705315     1.000000        0.000343        0.022745        0.022215        0.022456        0.022511        0.022707        0.022381        0.022810        0.022197     0.000199           0.000175     7.015455e-05        0.022485        0.022396    63.859515      53.734469      56.273988              1.504774              1.486762           0.955507     0.129782         30.677616   312.342764     0.000712    31.458065      29.442797       13.615516          0.022539          0.022530                 0.022539                 0.022530      100.000000        100.000000        96.000000     2.327156     2.300491     6.204170  2107.945796     0.537787  1.210524e+00  7.987940e-11    69.914962  1013.086060     79.825888     94.403365     35.263099    75.701382      100.000000              99.961219    -0.000000     0.000482       0.022452    31.000000     6.000000    23.000000     0.0  1.575565e+09"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_target_column_name = TARGET_COLUMN_NAME+'_future'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[True_target_column_name] = df[TARGET_COLUMN_NAME].shift(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>volatility_kcc</th>\n",
       "      <th>volatility_kch</th>\n",
       "      <th>volatility_kcl</th>\n",
       "      <th>volatility_dch</th>\n",
       "      <th>volatility_dcl</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>trend_macd_signal</th>\n",
       "      <th>trend_macd_diff</th>\n",
       "      <th>trend_ema_fast</th>\n",
       "      <th>trend_ema_slow</th>\n",
       "      <th>trend_adx</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "      <th>trend_adx_neg</th>\n",
       "      <th>trend_vortex_ind_pos</th>\n",
       "      <th>trend_vortex_ind_neg</th>\n",
       "      <th>trend_vortex_diff</th>\n",
       "      <th>trend_trix</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>trend_dpo</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>trend_kst_diff</th>\n",
       "      <th>trend_ichimoku_a</th>\n",
       "      <th>trend_ichimoku_b</th>\n",
       "      <th>trend_visual_ichimoku_a</th>\n",
       "      <th>trend_visual_ichimoku_b</th>\n",
       "      <th>trend_aroon_up</th>\n",
       "      <th>trend_aroon_down</th>\n",
       "      <th>trend_aroon_ind</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_vpt</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_mfi</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>momentum_stoch</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Elapsed</th>\n",
       "      <th>close_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>305.268381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.022178</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>4.050609e-05</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>38.046339</td>\n",
       "      <td>20.372602</td>\n",
       "      <td>19.221993</td>\n",
       "      <td>0.930175</td>\n",
       "      <td>0.977537</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>0.038957</td>\n",
       "      <td>25.356309</td>\n",
       "      <td>-69.846984</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>13.844427</td>\n",
       "      <td>18.541129</td>\n",
       "      <td>-4.696702</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.767433</td>\n",
       "      <td>-0.770393</td>\n",
       "      <td>1.951313</td>\n",
       "      <td>-173.111180</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>-0.046022</td>\n",
       "      <td>1.258194e-11</td>\n",
       "      <td>-2.556899</td>\n",
       "      <td>1000.167981</td>\n",
       "      <td>45.157443</td>\n",
       "      <td>28.591248</td>\n",
       "      <td>35.263099</td>\n",
       "      <td>50.670902</td>\n",
       "      <td>3.022479</td>\n",
       "      <td>35.313687</td>\n",
       "      <td>-96.977521</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.021977</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570540e+09</td>\n",
       "      <td>0.021937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>136.451949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>0.021948</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>2.344225e-05</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>35.930512</td>\n",
       "      <td>19.174406</td>\n",
       "      <td>22.702431</td>\n",
       "      <td>0.919094</td>\n",
       "      <td>1.040293</td>\n",
       "      <td>0.121199</td>\n",
       "      <td>0.034057</td>\n",
       "      <td>25.171494</td>\n",
       "      <td>-134.077921</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>11.404185</td>\n",
       "      <td>17.474347</td>\n",
       "      <td>-6.070162</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.148472</td>\n",
       "      <td>-0.148582</td>\n",
       "      <td>1.799944</td>\n",
       "      <td>-238.458117</td>\n",
       "      <td>-0.033459</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>8.448113e-12</td>\n",
       "      <td>-2.545324</td>\n",
       "      <td>998.683014</td>\n",
       "      <td>43.532803</td>\n",
       "      <td>29.578064</td>\n",
       "      <td>33.326024</td>\n",
       "      <td>50.240787</td>\n",
       "      <td>12.782255</td>\n",
       "      <td>19.826985</td>\n",
       "      <td>-87.217745</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.021955</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570543e+09</td>\n",
       "      <td>0.021924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>288.438229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>1.002575e-05</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.021983</td>\n",
       "      <td>33.965816</td>\n",
       "      <td>18.442493</td>\n",
       "      <td>21.835849</td>\n",
       "      <td>0.871923</td>\n",
       "      <td>1.230179</td>\n",
       "      <td>0.358256</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>24.977694</td>\n",
       "      <td>-130.430573</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>9.612247</td>\n",
       "      <td>16.189727</td>\n",
       "      <td>-6.577480</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>175.768671</td>\n",
       "      <td>-0.055078</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>-1.210681e-11</td>\n",
       "      <td>-0.166181</td>\n",
       "      <td>998.683014</td>\n",
       "      <td>43.717932</td>\n",
       "      <td>20.524735</td>\n",
       "      <td>31.591883</td>\n",
       "      <td>47.917554</td>\n",
       "      <td>13.526088</td>\n",
       "      <td>9.776940</td>\n",
       "      <td>-86.473912</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570547e+09</td>\n",
       "      <td>0.021878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>92.436833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.022110</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>4.265964e-06</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>31.846827</td>\n",
       "      <td>21.874441</td>\n",
       "      <td>20.070808</td>\n",
       "      <td>0.805081</td>\n",
       "      <td>1.178914</td>\n",
       "      <td>0.373833</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>24.956667</td>\n",
       "      <td>-93.352030</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>7.643302</td>\n",
       "      <td>14.772269</td>\n",
       "      <td>-7.128967</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021771</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.285823</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>2.103800</td>\n",
       "      <td>194.673649</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>-0.002872</td>\n",
       "      <td>-1.118031e-11</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1001.537481</td>\n",
       "      <td>47.884700</td>\n",
       "      <td>25.320718</td>\n",
       "      <td>30.209204</td>\n",
       "      <td>49.308124</td>\n",
       "      <td>34.472678</td>\n",
       "      <td>20.260340</td>\n",
       "      <td>-65.527322</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570550e+09</td>\n",
       "      <td>0.021843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>69.129320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.021989</td>\n",
       "      <td>0.022094</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>3.446183e-07</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>29.879194</td>\n",
       "      <td>20.877244</td>\n",
       "      <td>19.155834</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>0.302302</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>24.519695</td>\n",
       "      <td>-92.771810</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>6.537904</td>\n",
       "      <td>13.332853</td>\n",
       "      <td>-6.794950</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021767</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>2.141933</td>\n",
       "      <td>110.401060</td>\n",
       "      <td>0.032866</td>\n",
       "      <td>-0.015503</td>\n",
       "      <td>-9.509085e-12</td>\n",
       "      <td>0.290024</td>\n",
       "      <td>1001.911531</td>\n",
       "      <td>48.423552</td>\n",
       "      <td>30.578143</td>\n",
       "      <td>28.984263</td>\n",
       "      <td>55.993278</td>\n",
       "      <td>36.710383</td>\n",
       "      <td>28.236383</td>\n",
       "      <td>-63.289617</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570554e+09</td>\n",
       "      <td>0.021928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.021946</td>\n",
       "      <td>0.021924</td>\n",
       "      <td>0.021924</td>\n",
       "      <td>68.978514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.022249</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.021975</td>\n",
       "      <td>0.022074</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>-3.764113e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.021968</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>28.136054</td>\n",
       "      <td>21.082387</td>\n",
       "      <td>18.893607</td>\n",
       "      <td>0.862266</td>\n",
       "      <td>1.130144</td>\n",
       "      <td>0.267878</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>24.155461</td>\n",
       "      <td>-75.921565</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.332824</td>\n",
       "      <td>11.795020</td>\n",
       "      <td>-6.462196</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.060354</td>\n",
       "      <td>-0.060372</td>\n",
       "      <td>2.080287</td>\n",
       "      <td>-0.970600</td>\n",
       "      <td>-0.012540</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>-8.690107e-12</td>\n",
       "      <td>-0.015813</td>\n",
       "      <td>1001.306840</td>\n",
       "      <td>47.567300</td>\n",
       "      <td>27.173056</td>\n",
       "      <td>27.800384</td>\n",
       "      <td>55.748865</td>\n",
       "      <td>34.609670</td>\n",
       "      <td>35.264243</td>\n",
       "      <td>-65.390330</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570558e+09</td>\n",
       "      <td>0.022075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021922</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>74.481940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.022032</td>\n",
       "      <td>0.021955</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>-1.050869e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.021955</td>\n",
       "      <td>0.021965</td>\n",
       "      <td>26.353317</td>\n",
       "      <td>19.970037</td>\n",
       "      <td>21.280880</td>\n",
       "      <td>0.845371</td>\n",
       "      <td>1.124680</td>\n",
       "      <td>0.279310</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>23.901891</td>\n",
       "      <td>-89.515199</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.436864</td>\n",
       "      <td>10.116328</td>\n",
       "      <td>-6.679464</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.208218</td>\n",
       "      <td>-0.208435</td>\n",
       "      <td>1.867737</td>\n",
       "      <td>-131.200353</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>-9.306631e-12</td>\n",
       "      <td>-0.196716</td>\n",
       "      <td>1001.306840</td>\n",
       "      <td>44.636588</td>\n",
       "      <td>27.579825</td>\n",
       "      <td>26.474303</td>\n",
       "      <td>48.627683</td>\n",
       "      <td>21.565322</td>\n",
       "      <td>30.961791</td>\n",
       "      <td>-78.434678</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570561e+09</td>\n",
       "      <td>0.022108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>111.521616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.022025</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.022038</td>\n",
       "      <td>0.021833</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>-1.842853e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>24.782921</td>\n",
       "      <td>20.938425</td>\n",
       "      <td>19.185886</td>\n",
       "      <td>0.815478</td>\n",
       "      <td>1.087508</td>\n",
       "      <td>0.272030</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>23.869353</td>\n",
       "      <td>-86.875489</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1.799267</td>\n",
       "      <td>8.396102</td>\n",
       "      <td>-6.596835</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.160934</td>\n",
       "      <td>-0.161064</td>\n",
       "      <td>1.703797</td>\n",
       "      <td>-173.743454</td>\n",
       "      <td>-0.055851</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-1.019817e-11</td>\n",
       "      <td>-0.334562</td>\n",
       "      <td>1001.306840</td>\n",
       "      <td>42.463438</td>\n",
       "      <td>24.515809</td>\n",
       "      <td>25.076064</td>\n",
       "      <td>46.525830</td>\n",
       "      <td>11.504172</td>\n",
       "      <td>22.559721</td>\n",
       "      <td>-88.495828</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.021914</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570565e+09</td>\n",
       "      <td>0.022174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.021851</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>30.455618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.022009</td>\n",
       "      <td>0.021915</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>-1.778703e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.021936</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>23.313415</td>\n",
       "      <td>19.794898</td>\n",
       "      <td>18.195560</td>\n",
       "      <td>0.868638</td>\n",
       "      <td>1.105195</td>\n",
       "      <td>0.236557</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>23.766852</td>\n",
       "      <td>-74.913988</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.238002</td>\n",
       "      <td>6.649891</td>\n",
       "      <td>-6.411890</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.387305</td>\n",
       "      <td>0.386557</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>-81.065998</td>\n",
       "      <td>-0.103142</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-1.248488e-11</td>\n",
       "      <td>-0.061521</td>\n",
       "      <td>1005.184950</td>\n",
       "      <td>48.900720</td>\n",
       "      <td>26.705130</td>\n",
       "      <td>24.080574</td>\n",
       "      <td>50.361030</td>\n",
       "      <td>35.678363</td>\n",
       "      <td>22.915952</td>\n",
       "      <td>-64.321637</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.021915</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570568e+09</td>\n",
       "      <td>0.022143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>118.963935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.022214</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>0.021914</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.021810</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>-5.529656e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>23.388149</td>\n",
       "      <td>27.165916</td>\n",
       "      <td>16.523349</td>\n",
       "      <td>0.920401</td>\n",
       "      <td>1.010333</td>\n",
       "      <td>0.089932</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>23.763439</td>\n",
       "      <td>19.359012</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.423936</td>\n",
       "      <td>5.064518</td>\n",
       "      <td>-5.488453</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>16.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.670927</td>\n",
       "      <td>0.668687</td>\n",
       "      <td>2.782702</td>\n",
       "      <td>149.419553</td>\n",
       "      <td>-0.036447</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>-3.359094e-12</td>\n",
       "      <td>0.916118</td>\n",
       "      <td>1005.184950</td>\n",
       "      <td>57.752754</td>\n",
       "      <td>28.541539</td>\n",
       "      <td>23.666123</td>\n",
       "      <td>56.396925</td>\n",
       "      <td>77.717453</td>\n",
       "      <td>41.633330</td>\n",
       "      <td>-22.282547</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.021916</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570572e+09</td>\n",
       "      <td>0.022170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close      volume  fake  volatility_atr  volatility_bbh  volatility_bbl  volatility_bbm  volatility_kcc  volatility_kch  volatility_kcl  volatility_dch  volatility_dcl    trend_macd  trend_macd_signal  trend_macd_diff  trend_ema_fast  trend_ema_slow  trend_adx  trend_adx_pos  trend_adx_neg  trend_vortex_ind_pos  trend_vortex_ind_neg  trend_vortex_diff  trend_trix  trend_mass_index   trend_cci  trend_dpo  trend_kst  trend_kst_sig  trend_kst_diff  trend_ichimoku_a  trend_ichimoku_b  trend_visual_ichimoku_a  trend_visual_ichimoku_b  trend_aroon_up  trend_aroon_down  trend_aroon_ind  others_dr  others_dlr  others_cr  volume_adi  volume_cmf  volume_fi     volume_em  volume_vpt   volume_nvi  momentum_rsi  momentum_mfi  momentum_tsi  momentum_uo  momentum_stoch  momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama  Day  Dayofweek  Hour  Minute       Elapsed  close_future\n",
       "0  0.022053  0.022053  0.021884  0.021896  305.268381   0.0        0.000128        0.022258        0.021808        0.022033        0.022077        0.022178        0.021976        0.022259        0.021825  4.050609e-05           0.000062        -0.000021        0.022044        0.022004  38.046339      20.372602      19.221993              0.930175              0.977537           0.047362    0.038957         25.356309  -69.846984   0.000094  13.844427      18.541129       -4.696702          0.021992          0.021849                 0.021740                 0.021685            52.0               8.0             44.0  -0.767433   -0.770393   1.951313 -173.111180   -0.095308  -0.046022  1.258194e-11   -2.556899  1000.167981     45.157443     28.591248     35.263099    50.670902        3.022479              35.313687   -96.977521     0.000107       0.021977  8.0        1.0  13.0     0.0  1.570540e+09      0.021937\n",
       "1  0.021882  0.021907  0.021803  0.021864  136.451949   0.0        0.000126        0.022256        0.021811        0.022034        0.022049        0.022150        0.021948        0.022259        0.021825  2.344225e-05           0.000054        -0.000030        0.022016        0.021993  35.930512      19.174406      22.702431              0.919094              1.040293           0.121199    0.034057         25.171494 -134.077921   0.000038  11.404185      17.474347       -6.070162          0.021971          0.021849                 0.021797                 0.021710            48.0               4.0             44.0  -0.148472   -0.148582   1.799944 -238.458117   -0.033459   0.006629  8.448113e-12   -2.545324   998.683014     43.532803     29.578064     33.326024    50.240787       12.782255              19.826985   -87.217745     0.000059       0.021955  8.0        1.0  14.0     0.0  1.570543e+09      0.021924\n",
       "2  0.021853  0.021882  0.021817  0.021867  288.438229   0.0        0.000122        0.022261        0.021801        0.022031        0.022024        0.022123        0.021925        0.022259        0.021825  1.002575e-05           0.000045        -0.000035        0.021993        0.021983  33.965816      18.442493      21.835849              0.871923              1.230179           0.358256    0.028417         24.977694 -130.430573   0.000135   9.612247      16.189727       -6.577480          0.021971          0.021849                 0.021781                 0.021710            44.0               4.0             40.0   0.012624    0.012623   1.812795  175.768671   -0.055078   0.000501 -1.210681e-11   -0.166181   998.683014     43.717932     20.524735     31.591883    47.917554       13.526088               9.776940   -86.473912     0.000008       0.021939  8.0        1.0  15.0     0.0  1.570547e+09      0.021878\n",
       "3  0.021874  0.021967  0.021828  0.021929   92.436833   0.0        0.000123        0.022252        0.021820        0.022036        0.022004        0.022110        0.021898        0.022259        0.021864  4.265964e-06           0.000037        -0.000033        0.021984        0.021979  31.846827      21.874441      20.070808              0.805081              1.178914           0.373833    0.023136         24.956667  -93.352030   0.000089   7.643302      14.772269       -7.128967          0.021971          0.021849                 0.021771                 0.021710            40.0              20.0             20.0   0.285823    0.285415   2.103800  194.673649    0.000955  -0.002872 -1.118031e-11    0.300617  1001.537481     47.884700     25.320718     30.209204    49.308124       34.472678              20.260340   -65.527322    -0.000037       0.021939  8.0        1.0  16.0     0.0  1.570550e+09      0.021843\n",
       "4  0.021909  0.021938  0.021862  0.021937   69.129320   0.0        0.000120        0.022247        0.021831        0.022039        0.021989        0.022094        0.021885        0.022259        0.021864  3.446183e-07           0.000029        -0.000029        0.021976        0.021976  29.879194      20.877244      19.155834              0.821500              1.123802           0.302302    0.018361         24.519695  -92.771810   0.000060   6.537904      13.332853       -6.794950          0.021978          0.021849                 0.021767                 0.021710            36.0              16.0             20.0   0.037348    0.037341   2.141933  110.401060    0.032866  -0.015503 -9.509085e-12    0.290024  1001.911531     48.423552     30.578143     28.984263    55.993278       36.710383              28.236383   -63.289617    -0.000065       0.021939  8.0        1.0  17.0     0.0  1.570554e+09      0.021928\n",
       "5  0.021929  0.021946  0.021924  0.021924   68.978514   0.0        0.000113        0.022249        0.021824        0.022036        0.021975        0.022074        0.021876        0.022259        0.021864 -3.764113e-06           0.000023        -0.000027        0.021968        0.021972  28.136054      21.082387      18.893607              0.862266              1.130144           0.267878    0.013964         24.155461  -75.921565   0.000029   5.332824      11.795020       -6.462196          0.022010          0.021849                 0.021809                 0.021752            32.0              12.0             20.0  -0.060354   -0.060372   2.080287   -0.970600   -0.012540   0.000118 -8.690107e-12   -0.015813  1001.306840     47.567300     27.173056     27.800384    55.748865       34.609670              35.264243   -65.390330    -0.000075       0.021937  8.0        1.0  18.0     0.0  1.570558e+09      0.022075\n",
       "6  0.021922  0.021953  0.021872  0.021878   74.481940   0.0        0.000110        0.022253        0.021810        0.022032        0.021955        0.022052        0.021858        0.022259        0.021864 -1.050869e-05           0.000016        -0.000027        0.021955        0.021965  26.353317      19.970037      21.280880              0.845371              1.124680           0.279310    0.009550         23.901891  -89.515199   0.000052   3.436864      10.116328       -6.679464          0.022008          0.021849                 0.021809                 0.021752            28.0               8.0             20.0  -0.208218   -0.208435   1.867737 -131.200353    0.003302  -0.000315 -9.306631e-12   -0.196716  1001.306840     44.636588     27.579825     26.474303    48.627683       21.565322              30.961791   -78.434678    -0.000064       0.021928  8.0        1.0  19.0     0.0  1.570561e+09      0.022108\n",
       "7  0.021895  0.022000  0.021843  0.021843  111.521616   0.0        0.000114        0.022261        0.021790        0.022025        0.021935        0.022038        0.021833        0.022259        0.021843 -1.842853e-05           0.000009        -0.000028        0.021937        0.021956  24.782921      20.938425      19.185886              0.815478              1.087508           0.272030    0.004977         23.869353  -86.875489   0.000107   1.799267       8.396102       -6.596835          0.021997          0.021849                 0.021809                 0.021752            24.0               4.0             20.0  -0.160934   -0.161064   1.703797 -173.743454   -0.055851  -0.003440 -1.019817e-11   -0.334562  1001.306840     42.463438     24.515809     25.076064    46.525830       11.504172              22.559721   -88.495828    -0.000050       0.021914  8.0        1.0  20.0     0.0  1.570565e+09      0.022174\n",
       "8  0.021851  0.021928  0.021842  0.021928   30.455618   0.0        0.000112        0.022221        0.021796        0.022009        0.021915        0.022019        0.021810        0.022166        0.021843 -1.778703e-05           0.000004        -0.000022        0.021936        0.021954  23.313415      19.794898      18.195560              0.868638              1.105195           0.236557    0.001286         23.766852  -74.913988   0.000064   0.238002       6.649891       -6.411890          0.021985          0.021849                 0.021809                 0.021752            20.0              96.0            -76.0   0.387305    0.386557   2.097700  -81.065998   -0.103142  -0.002174 -1.248488e-11   -0.061521  1005.184950     48.900720     26.705130     24.080574    50.361030       35.678363              22.915952   -64.321637    -0.000053       0.021915  8.0        1.0  21.0     0.0  1.570568e+09      0.022143\n",
       "9  0.021939  0.022075  0.021939  0.022075  118.963935   0.0        0.000114        0.022214        0.021798        0.022006        0.021914        0.022017        0.021810        0.022166        0.021843 -5.529656e-06           0.000002        -0.000007        0.021957        0.021963  23.388149      27.165916      16.523349              0.920401              1.010333           0.089932   -0.000304         23.763439   19.359012   0.000088  -0.423936       5.064518       -5.488453          0.021990          0.021849                 0.021809                 0.021752            16.0              92.0            -76.0   0.670927    0.668687   2.782702  149.419553   -0.036447   0.001725 -3.359094e-12    0.916118  1005.184950     57.752754     28.541539     23.666123    56.396925       77.717453              41.633330   -22.282547    -0.000034       0.021916  8.0        1.0  22.0     0.0  1.570572e+09      0.022170"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train valid test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1047, 209, 139]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1047, 1257, 1397)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN_VALID_TEST_SPLIT_RATIOS\n",
    "trvate_split = tuple(int(x * len(df)) for x in (0.75, 0.9, 1.0))\n",
    "print([int(len(df)* x) for x in (0.75, 0.15, 0.1)])\n",
    "trvate_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for batch size using http://www.alcula.com/calculators/math/gcd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 210, 140)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train_limit = trvate_split[0]-trvate_split[0]%BATCH_SIZE\n",
    "train_df = df[:tmp_train_limit]\n",
    "\n",
    "tmp_valid_limit = trvate_split[1] -trvate_split[0]%BATCH_SIZE -(trvate_split[1]-trvate_split[0])%BATCH_SIZE\n",
    "valid_df = df[tmp_train_limit:tmp_valid_limit]\n",
    "\n",
    "test_df = df[tmp_valid_limit:(len(df)- len(df)%BATCH_SIZE)]\n",
    "\n",
    "len(train_df), len(valid_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(self: pd.DataFrame):\n",
    "    return self.drop(columns=[True_target_column_name])\n",
    "def target(self: pd.DataFrame):\n",
    "    return self[[True_target_column_name]]\n",
    "\n",
    "pd.DataFrame.input_data = input_data\n",
    "pd.DataFrame.target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>volatility_kcc</th>\n",
       "      <th>volatility_kch</th>\n",
       "      <th>volatility_kcl</th>\n",
       "      <th>volatility_dch</th>\n",
       "      <th>volatility_dcl</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>trend_macd_signal</th>\n",
       "      <th>trend_macd_diff</th>\n",
       "      <th>trend_ema_fast</th>\n",
       "      <th>trend_ema_slow</th>\n",
       "      <th>trend_adx</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "      <th>trend_adx_neg</th>\n",
       "      <th>trend_vortex_ind_pos</th>\n",
       "      <th>trend_vortex_ind_neg</th>\n",
       "      <th>trend_vortex_diff</th>\n",
       "      <th>trend_trix</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>trend_dpo</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>trend_kst_diff</th>\n",
       "      <th>trend_ichimoku_a</th>\n",
       "      <th>trend_ichimoku_b</th>\n",
       "      <th>trend_visual_ichimoku_a</th>\n",
       "      <th>trend_visual_ichimoku_b</th>\n",
       "      <th>trend_aroon_up</th>\n",
       "      <th>trend_aroon_down</th>\n",
       "      <th>trend_aroon_ind</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_vpt</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_mfi</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>momentum_stoch</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>305.268381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.022178</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>4.050609e-05</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>38.046339</td>\n",
       "      <td>20.372602</td>\n",
       "      <td>19.221993</td>\n",
       "      <td>0.930175</td>\n",
       "      <td>0.977537</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>0.038957</td>\n",
       "      <td>25.356309</td>\n",
       "      <td>-69.846984</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>13.844427</td>\n",
       "      <td>18.541129</td>\n",
       "      <td>-4.696702</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.767433</td>\n",
       "      <td>-0.770393</td>\n",
       "      <td>1.951313</td>\n",
       "      <td>-173.111180</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>-0.046022</td>\n",
       "      <td>1.258194e-11</td>\n",
       "      <td>-2.556899</td>\n",
       "      <td>1000.167981</td>\n",
       "      <td>45.157443</td>\n",
       "      <td>28.591248</td>\n",
       "      <td>35.263099</td>\n",
       "      <td>50.670902</td>\n",
       "      <td>3.022479</td>\n",
       "      <td>35.313687</td>\n",
       "      <td>-96.977521</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.021977</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570540e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>136.451949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>0.021948</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>2.344225e-05</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>35.930512</td>\n",
       "      <td>19.174406</td>\n",
       "      <td>22.702431</td>\n",
       "      <td>0.919094</td>\n",
       "      <td>1.040293</td>\n",
       "      <td>0.121199</td>\n",
       "      <td>0.034057</td>\n",
       "      <td>25.171494</td>\n",
       "      <td>-134.077921</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>11.404185</td>\n",
       "      <td>17.474347</td>\n",
       "      <td>-6.070162</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.148472</td>\n",
       "      <td>-0.148582</td>\n",
       "      <td>1.799944</td>\n",
       "      <td>-238.458117</td>\n",
       "      <td>-0.033459</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>8.448113e-12</td>\n",
       "      <td>-2.545324</td>\n",
       "      <td>998.683014</td>\n",
       "      <td>43.532803</td>\n",
       "      <td>29.578064</td>\n",
       "      <td>33.326024</td>\n",
       "      <td>50.240787</td>\n",
       "      <td>12.782255</td>\n",
       "      <td>19.826985</td>\n",
       "      <td>-87.217745</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.021955</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570543e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>288.438229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>1.002575e-05</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.021983</td>\n",
       "      <td>33.965816</td>\n",
       "      <td>18.442493</td>\n",
       "      <td>21.835849</td>\n",
       "      <td>0.871923</td>\n",
       "      <td>1.230179</td>\n",
       "      <td>0.358256</td>\n",
       "      <td>0.028417</td>\n",
       "      <td>24.977694</td>\n",
       "      <td>-130.430573</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>9.612247</td>\n",
       "      <td>16.189727</td>\n",
       "      <td>-6.577480</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>175.768671</td>\n",
       "      <td>-0.055078</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>-1.210681e-11</td>\n",
       "      <td>-0.166181</td>\n",
       "      <td>998.683014</td>\n",
       "      <td>43.717932</td>\n",
       "      <td>20.524735</td>\n",
       "      <td>31.591883</td>\n",
       "      <td>47.917554</td>\n",
       "      <td>13.526088</td>\n",
       "      <td>9.776940</td>\n",
       "      <td>-86.473912</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570547e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>92.436833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.022110</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>4.265964e-06</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>31.846827</td>\n",
       "      <td>21.874441</td>\n",
       "      <td>20.070808</td>\n",
       "      <td>0.805081</td>\n",
       "      <td>1.178914</td>\n",
       "      <td>0.373833</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>24.956667</td>\n",
       "      <td>-93.352030</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>7.643302</td>\n",
       "      <td>14.772269</td>\n",
       "      <td>-7.128967</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021771</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.285823</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>2.103800</td>\n",
       "      <td>194.673649</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>-0.002872</td>\n",
       "      <td>-1.118031e-11</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1001.537481</td>\n",
       "      <td>47.884700</td>\n",
       "      <td>25.320718</td>\n",
       "      <td>30.209204</td>\n",
       "      <td>49.308124</td>\n",
       "      <td>34.472678</td>\n",
       "      <td>20.260340</td>\n",
       "      <td>-65.527322</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570550e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>69.129320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.021989</td>\n",
       "      <td>0.022094</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>3.446183e-07</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>29.879194</td>\n",
       "      <td>20.877244</td>\n",
       "      <td>19.155834</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>0.302302</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>24.519695</td>\n",
       "      <td>-92.771810</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>6.537904</td>\n",
       "      <td>13.332853</td>\n",
       "      <td>-6.794950</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.021767</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>2.141933</td>\n",
       "      <td>110.401060</td>\n",
       "      <td>0.032866</td>\n",
       "      <td>-0.015503</td>\n",
       "      <td>-9.509085e-12</td>\n",
       "      <td>0.290024</td>\n",
       "      <td>1001.911531</td>\n",
       "      <td>48.423552</td>\n",
       "      <td>30.578143</td>\n",
       "      <td>28.984263</td>\n",
       "      <td>55.993278</td>\n",
       "      <td>36.710383</td>\n",
       "      <td>28.236383</td>\n",
       "      <td>-63.289617</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.570554e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close      volume  fake  volatility_atr  volatility_bbh  volatility_bbl  volatility_bbm  volatility_kcc  volatility_kch  volatility_kcl  volatility_dch  volatility_dcl    trend_macd  trend_macd_signal  trend_macd_diff  trend_ema_fast  trend_ema_slow  trend_adx  trend_adx_pos  trend_adx_neg  trend_vortex_ind_pos  trend_vortex_ind_neg  trend_vortex_diff  trend_trix  trend_mass_index   trend_cci  trend_dpo  trend_kst  trend_kst_sig  trend_kst_diff  trend_ichimoku_a  trend_ichimoku_b  trend_visual_ichimoku_a  trend_visual_ichimoku_b  trend_aroon_up  trend_aroon_down  trend_aroon_ind  others_dr  others_dlr  others_cr  volume_adi  volume_cmf  volume_fi     volume_em  volume_vpt   volume_nvi  momentum_rsi  momentum_mfi  momentum_tsi  momentum_uo  momentum_stoch  momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama  Day  Dayofweek  Hour  Minute       Elapsed\n",
       "0  0.022053  0.022053  0.021884  0.021896  305.268381   0.0        0.000128        0.022258        0.021808        0.022033        0.022077        0.022178        0.021976        0.022259        0.021825  4.050609e-05           0.000062        -0.000021        0.022044        0.022004  38.046339      20.372602      19.221993              0.930175              0.977537           0.047362    0.038957         25.356309  -69.846984   0.000094  13.844427      18.541129       -4.696702          0.021992          0.021849                 0.021740                 0.021685            52.0               8.0             44.0  -0.767433   -0.770393   1.951313 -173.111180   -0.095308  -0.046022  1.258194e-11   -2.556899  1000.167981     45.157443     28.591248     35.263099    50.670902        3.022479              35.313687   -96.977521     0.000107       0.021977  8.0        1.0  13.0     0.0  1.570540e+09\n",
       "1  0.021882  0.021907  0.021803  0.021864  136.451949   0.0        0.000126        0.022256        0.021811        0.022034        0.022049        0.022150        0.021948        0.022259        0.021825  2.344225e-05           0.000054        -0.000030        0.022016        0.021993  35.930512      19.174406      22.702431              0.919094              1.040293           0.121199    0.034057         25.171494 -134.077921   0.000038  11.404185      17.474347       -6.070162          0.021971          0.021849                 0.021797                 0.021710            48.0               4.0             44.0  -0.148472   -0.148582   1.799944 -238.458117   -0.033459   0.006629  8.448113e-12   -2.545324   998.683014     43.532803     29.578064     33.326024    50.240787       12.782255              19.826985   -87.217745     0.000059       0.021955  8.0        1.0  14.0     0.0  1.570543e+09\n",
       "2  0.021853  0.021882  0.021817  0.021867  288.438229   0.0        0.000122        0.022261        0.021801        0.022031        0.022024        0.022123        0.021925        0.022259        0.021825  1.002575e-05           0.000045        -0.000035        0.021993        0.021983  33.965816      18.442493      21.835849              0.871923              1.230179           0.358256    0.028417         24.977694 -130.430573   0.000135   9.612247      16.189727       -6.577480          0.021971          0.021849                 0.021781                 0.021710            44.0               4.0             40.0   0.012624    0.012623   1.812795  175.768671   -0.055078   0.000501 -1.210681e-11   -0.166181   998.683014     43.717932     20.524735     31.591883    47.917554       13.526088               9.776940   -86.473912     0.000008       0.021939  8.0        1.0  15.0     0.0  1.570547e+09\n",
       "3  0.021874  0.021967  0.021828  0.021929   92.436833   0.0        0.000123        0.022252        0.021820        0.022036        0.022004        0.022110        0.021898        0.022259        0.021864  4.265964e-06           0.000037        -0.000033        0.021984        0.021979  31.846827      21.874441      20.070808              0.805081              1.178914           0.373833    0.023136         24.956667  -93.352030   0.000089   7.643302      14.772269       -7.128967          0.021971          0.021849                 0.021771                 0.021710            40.0              20.0             20.0   0.285823    0.285415   2.103800  194.673649    0.000955  -0.002872 -1.118031e-11    0.300617  1001.537481     47.884700     25.320718     30.209204    49.308124       34.472678              20.260340   -65.527322    -0.000037       0.021939  8.0        1.0  16.0     0.0  1.570550e+09\n",
       "4  0.021909  0.021938  0.021862  0.021937   69.129320   0.0        0.000120        0.022247        0.021831        0.022039        0.021989        0.022094        0.021885        0.022259        0.021864  3.446183e-07           0.000029        -0.000029        0.021976        0.021976  29.879194      20.877244      19.155834              0.821500              1.123802           0.302302    0.018361         24.519695  -92.771810   0.000060   6.537904      13.332853       -6.794950          0.021978          0.021849                 0.021767                 0.021710            36.0              16.0             20.0   0.037348    0.037341   2.141933  110.401060    0.032866  -0.015503 -9.509085e-12    0.290024  1001.911531     48.423552     30.578143     28.984263    55.993278       36.710383              28.236383   -63.289617    -0.000065       0.021939  8.0        1.0  17.0     0.0  1.570554e+09"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.input_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape (1397, 64)\n",
      "train_df.shape (1040, 64)\n",
      "valid_df.shape (210, 64)\n",
      "test_df.shape (140, 64)\n"
     ]
    }
   ],
   "source": [
    "print('df.shape', df.shape)\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('valid_df.shape', valid_df.shape)\n",
    "print('test_df.shape', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "     (\"poli-feature\", PolynomialFeatures(degree=2)),\n",
    "     (\"normalizer\", StandardScaler())\n",
    "]).fit(train_df.input_data(), train_df.target())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df_to_transform, transformer, columns):\n",
    "    return pd.DataFrame(transformer.transform(df_to_transform), columns=columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_pipeline[\"poli-feature\"].get_feature_names(valid_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fake</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>volatility_bbm</th>\n",
       "      <th>volatility_kcc</th>\n",
       "      <th>volatility_kch</th>\n",
       "      <th>volatility_kcl</th>\n",
       "      <th>volatility_dch</th>\n",
       "      <th>volatility_dcl</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>trend_macd_signal</th>\n",
       "      <th>trend_macd_diff</th>\n",
       "      <th>trend_ema_fast</th>\n",
       "      <th>trend_ema_slow</th>\n",
       "      <th>trend_adx</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "      <th>trend_adx_neg</th>\n",
       "      <th>trend_vortex_ind_pos</th>\n",
       "      <th>trend_vortex_ind_neg</th>\n",
       "      <th>trend_vortex_diff</th>\n",
       "      <th>trend_trix</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>trend_dpo</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>trend_kst_diff</th>\n",
       "      <th>trend_ichimoku_a</th>\n",
       "      <th>trend_ichimoku_b</th>\n",
       "      <th>trend_visual_ichimoku_a</th>\n",
       "      <th>trend_visual_ichimoku_b</th>\n",
       "      <th>trend_aroon_up</th>\n",
       "      <th>trend_aroon_down</th>\n",
       "      <th>trend_aroon_ind</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_vpt</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_mfi</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>momentum_stoch</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Elapsed</th>\n",
       "      <th>open^2</th>\n",
       "      <th>open high</th>\n",
       "      <th>open low</th>\n",
       "      <th>open close</th>\n",
       "      <th>open volume</th>\n",
       "      <th>open fake</th>\n",
       "      <th>open volatility_atr</th>\n",
       "      <th>open volatility_bbh</th>\n",
       "      <th>open volatility_bbl</th>\n",
       "      <th>open volatility_bbm</th>\n",
       "      <th>open volatility_kcc</th>\n",
       "      <th>open volatility_kch</th>\n",
       "      <th>open volatility_kcl</th>\n",
       "      <th>open volatility_dch</th>\n",
       "      <th>open volatility_dcl</th>\n",
       "      <th>open trend_macd</th>\n",
       "      <th>open trend_macd_signal</th>\n",
       "      <th>open trend_macd_diff</th>\n",
       "      <th>open trend_ema_fast</th>\n",
       "      <th>open trend_ema_slow</th>\n",
       "      <th>open trend_adx</th>\n",
       "      <th>open trend_adx_pos</th>\n",
       "      <th>open trend_adx_neg</th>\n",
       "      <th>open trend_vortex_ind_pos</th>\n",
       "      <th>open trend_vortex_ind_neg</th>\n",
       "      <th>open trend_vortex_diff</th>\n",
       "      <th>open trend_trix</th>\n",
       "      <th>open trend_mass_index</th>\n",
       "      <th>open trend_cci</th>\n",
       "      <th>open trend_dpo</th>\n",
       "      <th>open trend_kst</th>\n",
       "      <th>open trend_kst_sig</th>\n",
       "      <th>open trend_kst_diff</th>\n",
       "      <th>open trend_ichimoku_a</th>\n",
       "      <th>open trend_ichimoku_b</th>\n",
       "      <th>open trend_visual_ichimoku_a</th>\n",
       "      <th>open trend_visual_ichimoku_b</th>\n",
       "      <th>open trend_aroon_up</th>\n",
       "      <th>open trend_aroon_down</th>\n",
       "      <th>open trend_aroon_ind</th>\n",
       "      <th>open others_dr</th>\n",
       "      <th>open others_dlr</th>\n",
       "      <th>open others_cr</th>\n",
       "      <th>open volume_adi</th>\n",
       "      <th>open volume_cmf</th>\n",
       "      <th>open volume_fi</th>\n",
       "      <th>open volume_em</th>\n",
       "      <th>open volume_vpt</th>\n",
       "      <th>open volume_nvi</th>\n",
       "      <th>open momentum_rsi</th>\n",
       "      <th>open momentum_mfi</th>\n",
       "      <th>open momentum_tsi</th>\n",
       "      <th>open momentum_uo</th>\n",
       "      <th>open momentum_stoch</th>\n",
       "      <th>open momentum_stoch_signal</th>\n",
       "      <th>open momentum_wr</th>\n",
       "      <th>open momentum_ao</th>\n",
       "      <th>open momentum_kama</th>\n",
       "      <th>open Day</th>\n",
       "      <th>open Dayofweek</th>\n",
       "      <th>open Hour</th>\n",
       "      <th>open Minute</th>\n",
       "      <th>open Elapsed</th>\n",
       "      <th>high^2</th>\n",
       "      <th>high low</th>\n",
       "      <th>high close</th>\n",
       "      <th>high volume</th>\n",
       "      <th>high fake</th>\n",
       "      <th>high volatility_atr</th>\n",
       "      <th>high volatility_bbh</th>\n",
       "      <th>high volatility_bbl</th>\n",
       "      <th>high volatility_bbm</th>\n",
       "      <th>high volatility_kcc</th>\n",
       "      <th>high volatility_kch</th>\n",
       "      <th>high volatility_kcl</th>\n",
       "      <th>high volatility_dch</th>\n",
       "      <th>high volatility_dcl</th>\n",
       "      <th>high trend_macd</th>\n",
       "      <th>high trend_macd_signal</th>\n",
       "      <th>high trend_macd_diff</th>\n",
       "      <th>high trend_ema_fast</th>\n",
       "      <th>high trend_ema_slow</th>\n",
       "      <th>high trend_adx</th>\n",
       "      <th>high trend_adx_pos</th>\n",
       "      <th>high trend_adx_neg</th>\n",
       "      <th>high trend_vortex_ind_pos</th>\n",
       "      <th>high trend_vortex_ind_neg</th>\n",
       "      <th>high trend_vortex_diff</th>\n",
       "      <th>high trend_trix</th>\n",
       "      <th>high trend_mass_index</th>\n",
       "      <th>high trend_cci</th>\n",
       "      <th>high trend_dpo</th>\n",
       "      <th>high trend_kst</th>\n",
       "      <th>high trend_kst_sig</th>\n",
       "      <th>high trend_kst_diff</th>\n",
       "      <th>high trend_ichimoku_a</th>\n",
       "      <th>high trend_ichimoku_b</th>\n",
       "      <th>high trend_visual_ichimoku_a</th>\n",
       "      <th>high trend_visual_ichimoku_b</th>\n",
       "      <th>high trend_aroon_up</th>\n",
       "      <th>high trend_aroon_down</th>\n",
       "      <th>high trend_aroon_ind</th>\n",
       "      <th>high others_dr</th>\n",
       "      <th>high others_dlr</th>\n",
       "      <th>high others_cr</th>\n",
       "      <th>high volume_adi</th>\n",
       "      <th>high volume_cmf</th>\n",
       "      <th>high volume_fi</th>\n",
       "      <th>high volume_em</th>\n",
       "      <th>high volume_vpt</th>\n",
       "      <th>high volume_nvi</th>\n",
       "      <th>high momentum_rsi</th>\n",
       "      <th>high momentum_mfi</th>\n",
       "      <th>high momentum_tsi</th>\n",
       "      <th>high momentum_uo</th>\n",
       "      <th>high momentum_stoch</th>\n",
       "      <th>high momentum_stoch_signal</th>\n",
       "      <th>high momentum_wr</th>\n",
       "      <th>high momentum_ao</th>\n",
       "      <th>high momentum_kama</th>\n",
       "      <th>high Day</th>\n",
       "      <th>high Dayofweek</th>\n",
       "      <th>high Hour</th>\n",
       "      <th>high Minute</th>\n",
       "      <th>high Elapsed</th>\n",
       "      <th>low^2</th>\n",
       "      <th>low close</th>\n",
       "      <th>low volume</th>\n",
       "      <th>low fake</th>\n",
       "      <th>low volatility_atr</th>\n",
       "      <th>low volatility_bbh</th>\n",
       "      <th>low volatility_bbl</th>\n",
       "      <th>low volatility_bbm</th>\n",
       "      <th>low volatility_kcc</th>\n",
       "      <th>low volatility_kch</th>\n",
       "      <th>low volatility_kcl</th>\n",
       "      <th>low volatility_dch</th>\n",
       "      <th>low volatility_dcl</th>\n",
       "      <th>low trend_macd</th>\n",
       "      <th>low trend_macd_signal</th>\n",
       "      <th>low trend_macd_diff</th>\n",
       "      <th>low trend_ema_fast</th>\n",
       "      <th>low trend_ema_slow</th>\n",
       "      <th>low trend_adx</th>\n",
       "      <th>low trend_adx_pos</th>\n",
       "      <th>low trend_adx_neg</th>\n",
       "      <th>low trend_vortex_ind_pos</th>\n",
       "      <th>low trend_vortex_ind_neg</th>\n",
       "      <th>low trend_vortex_diff</th>\n",
       "      <th>low trend_trix</th>\n",
       "      <th>low trend_mass_index</th>\n",
       "      <th>low trend_cci</th>\n",
       "      <th>low trend_dpo</th>\n",
       "      <th>low trend_kst</th>\n",
       "      <th>low trend_kst_sig</th>\n",
       "      <th>low trend_kst_diff</th>\n",
       "      <th>low trend_ichimoku_a</th>\n",
       "      <th>low trend_ichimoku_b</th>\n",
       "      <th>low trend_visual_ichimoku_a</th>\n",
       "      <th>low trend_visual_ichimoku_b</th>\n",
       "      <th>low trend_aroon_up</th>\n",
       "      <th>low trend_aroon_down</th>\n",
       "      <th>low trend_aroon_ind</th>\n",
       "      <th>low others_dr</th>\n",
       "      <th>low others_dlr</th>\n",
       "      <th>low others_cr</th>\n",
       "      <th>low volume_adi</th>\n",
       "      <th>low volume_cmf</th>\n",
       "      <th>low volume_fi</th>\n",
       "      <th>low volume_em</th>\n",
       "      <th>low volume_vpt</th>\n",
       "      <th>low volume_nvi</th>\n",
       "      <th>low momentum_rsi</th>\n",
       "      <th>low momentum_mfi</th>\n",
       "      <th>low momentum_tsi</th>\n",
       "      <th>low momentum_uo</th>\n",
       "      <th>low momentum_stoch</th>\n",
       "      <th>low momentum_stoch_signal</th>\n",
       "      <th>low momentum_wr</th>\n",
       "      <th>low momentum_ao</th>\n",
       "      <th>low momentum_kama</th>\n",
       "      <th>low Day</th>\n",
       "      <th>low Dayofweek</th>\n",
       "      <th>low Hour</th>\n",
       "      <th>low Minute</th>\n",
       "      <th>low Elapsed</th>\n",
       "      <th>close^2</th>\n",
       "      <th>...</th>\n",
       "      <th>others_dlr volume_cmf</th>\n",
       "      <th>others_dlr volume_fi</th>\n",
       "      <th>others_dlr volume_em</th>\n",
       "      <th>others_dlr volume_vpt</th>\n",
       "      <th>others_dlr volume_nvi</th>\n",
       "      <th>others_dlr momentum_rsi</th>\n",
       "      <th>others_dlr momentum_mfi</th>\n",
       "      <th>others_dlr momentum_tsi</th>\n",
       "      <th>others_dlr momentum_uo</th>\n",
       "      <th>others_dlr momentum_stoch</th>\n",
       "      <th>others_dlr momentum_stoch_signal</th>\n",
       "      <th>others_dlr momentum_wr</th>\n",
       "      <th>others_dlr momentum_ao</th>\n",
       "      <th>others_dlr momentum_kama</th>\n",
       "      <th>others_dlr Day</th>\n",
       "      <th>others_dlr Dayofweek</th>\n",
       "      <th>others_dlr Hour</th>\n",
       "      <th>others_dlr Minute</th>\n",
       "      <th>others_dlr Elapsed</th>\n",
       "      <th>others_cr^2</th>\n",
       "      <th>others_cr volume_adi</th>\n",
       "      <th>others_cr volume_cmf</th>\n",
       "      <th>others_cr volume_fi</th>\n",
       "      <th>others_cr volume_em</th>\n",
       "      <th>others_cr volume_vpt</th>\n",
       "      <th>others_cr volume_nvi</th>\n",
       "      <th>others_cr momentum_rsi</th>\n",
       "      <th>others_cr momentum_mfi</th>\n",
       "      <th>others_cr momentum_tsi</th>\n",
       "      <th>others_cr momentum_uo</th>\n",
       "      <th>others_cr momentum_stoch</th>\n",
       "      <th>others_cr momentum_stoch_signal</th>\n",
       "      <th>others_cr momentum_wr</th>\n",
       "      <th>others_cr momentum_ao</th>\n",
       "      <th>others_cr momentum_kama</th>\n",
       "      <th>others_cr Day</th>\n",
       "      <th>others_cr Dayofweek</th>\n",
       "      <th>others_cr Hour</th>\n",
       "      <th>others_cr Minute</th>\n",
       "      <th>others_cr Elapsed</th>\n",
       "      <th>volume_adi^2</th>\n",
       "      <th>volume_adi volume_cmf</th>\n",
       "      <th>volume_adi volume_fi</th>\n",
       "      <th>volume_adi volume_em</th>\n",
       "      <th>volume_adi volume_vpt</th>\n",
       "      <th>volume_adi volume_nvi</th>\n",
       "      <th>volume_adi momentum_rsi</th>\n",
       "      <th>volume_adi momentum_mfi</th>\n",
       "      <th>volume_adi momentum_tsi</th>\n",
       "      <th>volume_adi momentum_uo</th>\n",
       "      <th>volume_adi momentum_stoch</th>\n",
       "      <th>volume_adi momentum_stoch_signal</th>\n",
       "      <th>volume_adi momentum_wr</th>\n",
       "      <th>volume_adi momentum_ao</th>\n",
       "      <th>volume_adi momentum_kama</th>\n",
       "      <th>volume_adi Day</th>\n",
       "      <th>volume_adi Dayofweek</th>\n",
       "      <th>volume_adi Hour</th>\n",
       "      <th>volume_adi Minute</th>\n",
       "      <th>volume_adi Elapsed</th>\n",
       "      <th>volume_cmf^2</th>\n",
       "      <th>volume_cmf volume_fi</th>\n",
       "      <th>volume_cmf volume_em</th>\n",
       "      <th>volume_cmf volume_vpt</th>\n",
       "      <th>volume_cmf volume_nvi</th>\n",
       "      <th>volume_cmf momentum_rsi</th>\n",
       "      <th>volume_cmf momentum_mfi</th>\n",
       "      <th>volume_cmf momentum_tsi</th>\n",
       "      <th>volume_cmf momentum_uo</th>\n",
       "      <th>volume_cmf momentum_stoch</th>\n",
       "      <th>volume_cmf momentum_stoch_signal</th>\n",
       "      <th>volume_cmf momentum_wr</th>\n",
       "      <th>volume_cmf momentum_ao</th>\n",
       "      <th>volume_cmf momentum_kama</th>\n",
       "      <th>volume_cmf Day</th>\n",
       "      <th>volume_cmf Dayofweek</th>\n",
       "      <th>volume_cmf Hour</th>\n",
       "      <th>volume_cmf Minute</th>\n",
       "      <th>volume_cmf Elapsed</th>\n",
       "      <th>volume_fi^2</th>\n",
       "      <th>volume_fi volume_em</th>\n",
       "      <th>volume_fi volume_vpt</th>\n",
       "      <th>volume_fi volume_nvi</th>\n",
       "      <th>volume_fi momentum_rsi</th>\n",
       "      <th>volume_fi momentum_mfi</th>\n",
       "      <th>volume_fi momentum_tsi</th>\n",
       "      <th>volume_fi momentum_uo</th>\n",
       "      <th>volume_fi momentum_stoch</th>\n",
       "      <th>volume_fi momentum_stoch_signal</th>\n",
       "      <th>volume_fi momentum_wr</th>\n",
       "      <th>volume_fi momentum_ao</th>\n",
       "      <th>volume_fi momentum_kama</th>\n",
       "      <th>volume_fi Day</th>\n",
       "      <th>volume_fi Dayofweek</th>\n",
       "      <th>volume_fi Hour</th>\n",
       "      <th>volume_fi Minute</th>\n",
       "      <th>volume_fi Elapsed</th>\n",
       "      <th>volume_em^2</th>\n",
       "      <th>volume_em volume_vpt</th>\n",
       "      <th>volume_em volume_nvi</th>\n",
       "      <th>volume_em momentum_rsi</th>\n",
       "      <th>volume_em momentum_mfi</th>\n",
       "      <th>volume_em momentum_tsi</th>\n",
       "      <th>volume_em momentum_uo</th>\n",
       "      <th>volume_em momentum_stoch</th>\n",
       "      <th>volume_em momentum_stoch_signal</th>\n",
       "      <th>volume_em momentum_wr</th>\n",
       "      <th>volume_em momentum_ao</th>\n",
       "      <th>volume_em momentum_kama</th>\n",
       "      <th>volume_em Day</th>\n",
       "      <th>volume_em Dayofweek</th>\n",
       "      <th>volume_em Hour</th>\n",
       "      <th>volume_em Minute</th>\n",
       "      <th>volume_em Elapsed</th>\n",
       "      <th>volume_vpt^2</th>\n",
       "      <th>volume_vpt volume_nvi</th>\n",
       "      <th>volume_vpt momentum_rsi</th>\n",
       "      <th>volume_vpt momentum_mfi</th>\n",
       "      <th>volume_vpt momentum_tsi</th>\n",
       "      <th>volume_vpt momentum_uo</th>\n",
       "      <th>volume_vpt momentum_stoch</th>\n",
       "      <th>volume_vpt momentum_stoch_signal</th>\n",
       "      <th>volume_vpt momentum_wr</th>\n",
       "      <th>volume_vpt momentum_ao</th>\n",
       "      <th>volume_vpt momentum_kama</th>\n",
       "      <th>volume_vpt Day</th>\n",
       "      <th>volume_vpt Dayofweek</th>\n",
       "      <th>volume_vpt Hour</th>\n",
       "      <th>volume_vpt Minute</th>\n",
       "      <th>volume_vpt Elapsed</th>\n",
       "      <th>volume_nvi^2</th>\n",
       "      <th>volume_nvi momentum_rsi</th>\n",
       "      <th>volume_nvi momentum_mfi</th>\n",
       "      <th>volume_nvi momentum_tsi</th>\n",
       "      <th>volume_nvi momentum_uo</th>\n",
       "      <th>volume_nvi momentum_stoch</th>\n",
       "      <th>volume_nvi momentum_stoch_signal</th>\n",
       "      <th>volume_nvi momentum_wr</th>\n",
       "      <th>volume_nvi momentum_ao</th>\n",
       "      <th>volume_nvi momentum_kama</th>\n",
       "      <th>volume_nvi Day</th>\n",
       "      <th>volume_nvi Dayofweek</th>\n",
       "      <th>volume_nvi Hour</th>\n",
       "      <th>volume_nvi Minute</th>\n",
       "      <th>volume_nvi Elapsed</th>\n",
       "      <th>momentum_rsi^2</th>\n",
       "      <th>momentum_rsi momentum_mfi</th>\n",
       "      <th>momentum_rsi momentum_tsi</th>\n",
       "      <th>momentum_rsi momentum_uo</th>\n",
       "      <th>momentum_rsi momentum_stoch</th>\n",
       "      <th>momentum_rsi momentum_stoch_signal</th>\n",
       "      <th>momentum_rsi momentum_wr</th>\n",
       "      <th>momentum_rsi momentum_ao</th>\n",
       "      <th>momentum_rsi momentum_kama</th>\n",
       "      <th>momentum_rsi Day</th>\n",
       "      <th>momentum_rsi Dayofweek</th>\n",
       "      <th>momentum_rsi Hour</th>\n",
       "      <th>momentum_rsi Minute</th>\n",
       "      <th>momentum_rsi Elapsed</th>\n",
       "      <th>momentum_mfi^2</th>\n",
       "      <th>momentum_mfi momentum_tsi</th>\n",
       "      <th>momentum_mfi momentum_uo</th>\n",
       "      <th>momentum_mfi momentum_stoch</th>\n",
       "      <th>momentum_mfi momentum_stoch_signal</th>\n",
       "      <th>momentum_mfi momentum_wr</th>\n",
       "      <th>momentum_mfi momentum_ao</th>\n",
       "      <th>momentum_mfi momentum_kama</th>\n",
       "      <th>momentum_mfi Day</th>\n",
       "      <th>momentum_mfi Dayofweek</th>\n",
       "      <th>momentum_mfi Hour</th>\n",
       "      <th>momentum_mfi Minute</th>\n",
       "      <th>momentum_mfi Elapsed</th>\n",
       "      <th>momentum_tsi^2</th>\n",
       "      <th>momentum_tsi momentum_uo</th>\n",
       "      <th>momentum_tsi momentum_stoch</th>\n",
       "      <th>momentum_tsi momentum_stoch_signal</th>\n",
       "      <th>momentum_tsi momentum_wr</th>\n",
       "      <th>momentum_tsi momentum_ao</th>\n",
       "      <th>momentum_tsi momentum_kama</th>\n",
       "      <th>momentum_tsi Day</th>\n",
       "      <th>momentum_tsi Dayofweek</th>\n",
       "      <th>momentum_tsi Hour</th>\n",
       "      <th>momentum_tsi Minute</th>\n",
       "      <th>momentum_tsi Elapsed</th>\n",
       "      <th>momentum_uo^2</th>\n",
       "      <th>momentum_uo momentum_stoch</th>\n",
       "      <th>momentum_uo momentum_stoch_signal</th>\n",
       "      <th>momentum_uo momentum_wr</th>\n",
       "      <th>momentum_uo momentum_ao</th>\n",
       "      <th>momentum_uo momentum_kama</th>\n",
       "      <th>momentum_uo Day</th>\n",
       "      <th>momentum_uo Dayofweek</th>\n",
       "      <th>momentum_uo Hour</th>\n",
       "      <th>momentum_uo Minute</th>\n",
       "      <th>momentum_uo Elapsed</th>\n",
       "      <th>momentum_stoch^2</th>\n",
       "      <th>momentum_stoch momentum_stoch_signal</th>\n",
       "      <th>momentum_stoch momentum_wr</th>\n",
       "      <th>momentum_stoch momentum_ao</th>\n",
       "      <th>momentum_stoch momentum_kama</th>\n",
       "      <th>momentum_stoch Day</th>\n",
       "      <th>momentum_stoch Dayofweek</th>\n",
       "      <th>momentum_stoch Hour</th>\n",
       "      <th>momentum_stoch Minute</th>\n",
       "      <th>momentum_stoch Elapsed</th>\n",
       "      <th>momentum_stoch_signal^2</th>\n",
       "      <th>momentum_stoch_signal momentum_wr</th>\n",
       "      <th>momentum_stoch_signal momentum_ao</th>\n",
       "      <th>momentum_stoch_signal momentum_kama</th>\n",
       "      <th>momentum_stoch_signal Day</th>\n",
       "      <th>momentum_stoch_signal Dayofweek</th>\n",
       "      <th>momentum_stoch_signal Hour</th>\n",
       "      <th>momentum_stoch_signal Minute</th>\n",
       "      <th>momentum_stoch_signal Elapsed</th>\n",
       "      <th>momentum_wr^2</th>\n",
       "      <th>momentum_wr momentum_ao</th>\n",
       "      <th>momentum_wr momentum_kama</th>\n",
       "      <th>momentum_wr Day</th>\n",
       "      <th>momentum_wr Dayofweek</th>\n",
       "      <th>momentum_wr Hour</th>\n",
       "      <th>momentum_wr Minute</th>\n",
       "      <th>momentum_wr Elapsed</th>\n",
       "      <th>momentum_ao^2</th>\n",
       "      <th>momentum_ao momentum_kama</th>\n",
       "      <th>momentum_ao Day</th>\n",
       "      <th>momentum_ao Dayofweek</th>\n",
       "      <th>momentum_ao Hour</th>\n",
       "      <th>momentum_ao Minute</th>\n",
       "      <th>momentum_ao Elapsed</th>\n",
       "      <th>momentum_kama^2</th>\n",
       "      <th>momentum_kama Day</th>\n",
       "      <th>momentum_kama Dayofweek</th>\n",
       "      <th>momentum_kama Hour</th>\n",
       "      <th>momentum_kama Minute</th>\n",
       "      <th>momentum_kama Elapsed</th>\n",
       "      <th>Day^2</th>\n",
       "      <th>Day Dayofweek</th>\n",
       "      <th>Day Hour</th>\n",
       "      <th>Day Minute</th>\n",
       "      <th>Day Elapsed</th>\n",
       "      <th>Dayofweek^2</th>\n",
       "      <th>Dayofweek Hour</th>\n",
       "      <th>Dayofweek Minute</th>\n",
       "      <th>Dayofweek Elapsed</th>\n",
       "      <th>Hour^2</th>\n",
       "      <th>Hour Minute</th>\n",
       "      <th>Hour Elapsed</th>\n",
       "      <th>Minute^2</th>\n",
       "      <th>Minute Elapsed</th>\n",
       "      <th>Elapsed^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.115167</td>\n",
       "      <td>1.061529</td>\n",
       "      <td>0.977340</td>\n",
       "      <td>0.939421</td>\n",
       "      <td>0.607035</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.563340</td>\n",
       "      <td>1.101099</td>\n",
       "      <td>1.051955</td>\n",
       "      <td>1.100725</td>\n",
       "      <td>1.146237</td>\n",
       "      <td>1.152766</td>\n",
       "      <td>1.135801</td>\n",
       "      <td>1.150218</td>\n",
       "      <td>1.052307</td>\n",
       "      <td>0.455894</td>\n",
       "      <td>0.715358</td>\n",
       "      <td>-0.765850</td>\n",
       "      <td>1.115534</td>\n",
       "      <td>1.081382</td>\n",
       "      <td>0.979734</td>\n",
       "      <td>-0.405030</td>\n",
       "      <td>-0.499584</td>\n",
       "      <td>-0.422855</td>\n",
       "      <td>0.039964</td>\n",
       "      <td>-1.056991</td>\n",
       "      <td>0.636169</td>\n",
       "      <td>0.346047</td>\n",
       "      <td>-0.663183</td>\n",
       "      <td>0.854971</td>\n",
       "      <td>0.930836</td>\n",
       "      <td>1.260959</td>\n",
       "      <td>-1.034186</td>\n",
       "      <td>1.063465</td>\n",
       "      <td>0.919514</td>\n",
       "      <td>0.760628</td>\n",
       "      <td>0.716554</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>-1.311744</td>\n",
       "      <td>0.779564</td>\n",
       "      <td>-1.862537</td>\n",
       "      <td>-1.858758</td>\n",
       "      <td>0.939421</td>\n",
       "      <td>-0.670494</td>\n",
       "      <td>-0.325491</td>\n",
       "      <td>-0.261555</td>\n",
       "      <td>0.457529</td>\n",
       "      <td>-0.216362</td>\n",
       "      <td>1.123375</td>\n",
       "      <td>-0.527758</td>\n",
       "      <td>-1.124479</td>\n",
       "      <td>2.447305</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>-1.832772</td>\n",
       "      <td>-0.685978</td>\n",
       "      <td>-1.832772</td>\n",
       "      <td>0.472445</td>\n",
       "      <td>1.043151</td>\n",
       "      <td>-0.954716</td>\n",
       "      <td>-0.987042</td>\n",
       "      <td>0.211442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.730386</td>\n",
       "      <td>1.131502</td>\n",
       "      <td>1.103554</td>\n",
       "      <td>1.059935</td>\n",
       "      <td>1.039824</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.756797</td>\n",
       "      <td>1.143733</td>\n",
       "      <td>1.105303</td>\n",
       "      <td>1.130221</td>\n",
       "      <td>1.150714</td>\n",
       "      <td>1.154757</td>\n",
       "      <td>1.145707</td>\n",
       "      <td>1.163156</td>\n",
       "      <td>1.103555</td>\n",
       "      <td>0.484347</td>\n",
       "      <td>0.767633</td>\n",
       "      <td>-0.823548</td>\n",
       "      <td>1.133770</td>\n",
       "      <td>1.119586</td>\n",
       "      <td>1.193973</td>\n",
       "      <td>-0.292550</td>\n",
       "      <td>-0.393602</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0.319155</td>\n",
       "      <td>-1.049312</td>\n",
       "      <td>0.682902</td>\n",
       "      <td>0.938533</td>\n",
       "      <td>-0.694635</td>\n",
       "      <td>0.912677</td>\n",
       "      <td>1.004965</td>\n",
       "      <td>1.365716</td>\n",
       "      <td>-1.117893</td>\n",
       "      <td>1.107353</td>\n",
       "      <td>1.043594</td>\n",
       "      <td>0.977150</td>\n",
       "      <td>0.962291</td>\n",
       "      <td>0.082960</td>\n",
       "      <td>-1.299937</td>\n",
       "      <td>0.813160</td>\n",
       "      <td>-1.975116</td>\n",
       "      <td>-1.971485</td>\n",
       "      <td>0.957045</td>\n",
       "      <td>-0.695333</td>\n",
       "      <td>-0.360863</td>\n",
       "      <td>-0.282328</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>-0.237091</td>\n",
       "      <td>1.433412</td>\n",
       "      <td>-0.327244</td>\n",
       "      <td>-1.044427</td>\n",
       "      <td>2.582484</td>\n",
       "      <td>0.322462</td>\n",
       "      <td>-1.813602</td>\n",
       "      <td>-0.613776</td>\n",
       "      <td>-2.004493</td>\n",
       "      <td>0.503652</td>\n",
       "      <td>1.095685</td>\n",
       "      <td>-0.940708</td>\n",
       "      <td>-0.967602</td>\n",
       "      <td>0.298372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.091681</td>\n",
       "      <td>1.074236</td>\n",
       "      <td>1.031837</td>\n",
       "      <td>1.010796</td>\n",
       "      <td>0.640413</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.745261</td>\n",
       "      <td>1.113768</td>\n",
       "      <td>1.078108</td>\n",
       "      <td>1.101589</td>\n",
       "      <td>1.122378</td>\n",
       "      <td>1.125925</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.133191</td>\n",
       "      <td>1.076015</td>\n",
       "      <td>0.482654</td>\n",
       "      <td>0.765196</td>\n",
       "      <td>-0.820159</td>\n",
       "      <td>1.105274</td>\n",
       "      <td>1.090759</td>\n",
       "      <td>1.184065</td>\n",
       "      <td>-0.298260</td>\n",
       "      <td>-0.399039</td>\n",
       "      <td>-0.160958</td>\n",
       "      <td>0.305708</td>\n",
       "      <td>-1.049479</td>\n",
       "      <td>0.680791</td>\n",
       "      <td>0.900082</td>\n",
       "      <td>-0.693270</td>\n",
       "      <td>0.910044</td>\n",
       "      <td>1.001610</td>\n",
       "      <td>1.361533</td>\n",
       "      <td>-1.113651</td>\n",
       "      <td>1.078641</td>\n",
       "      <td>1.014241</td>\n",
       "      <td>0.947597</td>\n",
       "      <td>0.932278</td>\n",
       "      <td>0.078837</td>\n",
       "      <td>-1.300576</td>\n",
       "      <td>0.810820</td>\n",
       "      <td>-1.966759</td>\n",
       "      <td>-1.963309</td>\n",
       "      <td>0.955521</td>\n",
       "      <td>-0.691728</td>\n",
       "      <td>-0.359490</td>\n",
       "      <td>-0.281914</td>\n",
       "      <td>0.490412</td>\n",
       "      <td>-0.235496</td>\n",
       "      <td>1.378963</td>\n",
       "      <td>-0.336642</td>\n",
       "      <td>-1.047362</td>\n",
       "      <td>2.575086</td>\n",
       "      <td>0.308995</td>\n",
       "      <td>-1.812166</td>\n",
       "      <td>-0.617308</td>\n",
       "      <td>-1.998547</td>\n",
       "      <td>0.501883</td>\n",
       "      <td>1.067122</td>\n",
       "      <td>-0.942901</td>\n",
       "      <td>-0.968935</td>\n",
       "      <td>0.293407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.037838</td>\n",
       "      <td>0.986856</td>\n",
       "      <td>0.967321</td>\n",
       "      <td>0.656191</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.747072</td>\n",
       "      <td>1.072151</td>\n",
       "      <td>1.034425</td>\n",
       "      <td>1.058495</td>\n",
       "      <td>1.078817</td>\n",
       "      <td>1.083044</td>\n",
       "      <td>1.073716</td>\n",
       "      <td>1.090881</td>\n",
       "      <td>1.031840</td>\n",
       "      <td>0.482528</td>\n",
       "      <td>0.764725</td>\n",
       "      <td>-0.823325</td>\n",
       "      <td>1.061779</td>\n",
       "      <td>1.047452</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>-0.306093</td>\n",
       "      <td>-0.406380</td>\n",
       "      <td>-0.177295</td>\n",
       "      <td>0.287866</td>\n",
       "      <td>-1.050990</td>\n",
       "      <td>0.680229</td>\n",
       "      <td>0.867950</td>\n",
       "      <td>-0.693076</td>\n",
       "      <td>0.911067</td>\n",
       "      <td>1.001298</td>\n",
       "      <td>1.360246</td>\n",
       "      <td>-1.115546</td>\n",
       "      <td>1.035129</td>\n",
       "      <td>0.970846</td>\n",
       "      <td>0.905633</td>\n",
       "      <td>0.889092</td>\n",
       "      <td>0.074450</td>\n",
       "      <td>-1.302379</td>\n",
       "      <td>0.808646</td>\n",
       "      <td>-1.998386</td>\n",
       "      <td>-1.995751</td>\n",
       "      <td>0.954763</td>\n",
       "      <td>-0.698111</td>\n",
       "      <td>-0.358850</td>\n",
       "      <td>-0.298934</td>\n",
       "      <td>0.489050</td>\n",
       "      <td>-0.246257</td>\n",
       "      <td>1.292333</td>\n",
       "      <td>-0.348741</td>\n",
       "      <td>-1.051563</td>\n",
       "      <td>2.569360</td>\n",
       "      <td>0.294408</td>\n",
       "      <td>-1.812204</td>\n",
       "      <td>-0.621349</td>\n",
       "      <td>-1.989827</td>\n",
       "      <td>0.501835</td>\n",
       "      <td>1.023517</td>\n",
       "      <td>-0.947265</td>\n",
       "      <td>-0.970162</td>\n",
       "      <td>0.288208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953273</td>\n",
       "      <td>0.946414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512923</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>-0.676706</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>-1.882191</td>\n",
       "      <td>-1.863997</td>\n",
       "      <td>-1.161375</td>\n",
       "      <td>-3.961776</td>\n",
       "      <td>-1.973999</td>\n",
       "      <td>-0.288932</td>\n",
       "      <td>-1.331480</td>\n",
       "      <td>2.647665</td>\n",
       "      <td>-0.440317</td>\n",
       "      <td>-1.961942</td>\n",
       "      <td>-0.677383</td>\n",
       "      <td>-0.439552</td>\n",
       "      <td>-1.807585</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.856910</td>\n",
       "      <td>-0.594282</td>\n",
       "      <td>-0.387835</td>\n",
       "      <td>-0.560847</td>\n",
       "      <td>-0.099710</td>\n",
       "      <td>0.087823</td>\n",
       "      <td>-0.115694</td>\n",
       "      <td>0.948152</td>\n",
       "      <td>0.874646</td>\n",
       "      <td>0.655416</td>\n",
       "      <td>0.786345</td>\n",
       "      <td>0.927769</td>\n",
       "      <td>0.408005</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>-1.227249</td>\n",
       "      <td>-0.006703</td>\n",
       "      <td>0.955054</td>\n",
       "      <td>0.552067</td>\n",
       "      <td>0.503810</td>\n",
       "      <td>0.840263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939194</td>\n",
       "      <td>-0.092074</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>-0.021367</td>\n",
       "      <td>-0.385225</td>\n",
       "      <td>-0.058934</td>\n",
       "      <td>-0.680253</td>\n",
       "      <td>-0.636124</td>\n",
       "      <td>-0.368572</td>\n",
       "      <td>-1.649068</td>\n",
       "      <td>-0.740354</td>\n",
       "      <td>-0.130406</td>\n",
       "      <td>-0.460571</td>\n",
       "      <td>1.028929</td>\n",
       "      <td>-0.251365</td>\n",
       "      <td>-0.691761</td>\n",
       "      <td>-0.246371</td>\n",
       "      <td>-0.124399</td>\n",
       "      <td>-0.633079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.669911</td>\n",
       "      <td>-0.545167</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>-0.410290</td>\n",
       "      <td>-0.027163</td>\n",
       "      <td>-0.332497</td>\n",
       "      <td>-0.352721</td>\n",
       "      <td>-0.223743</td>\n",
       "      <td>-1.400502</td>\n",
       "      <td>-0.432490</td>\n",
       "      <td>-0.058803</td>\n",
       "      <td>-0.323207</td>\n",
       "      <td>0.520039</td>\n",
       "      <td>-0.399932</td>\n",
       "      <td>-0.357148</td>\n",
       "      <td>-0.107852</td>\n",
       "      <td>0.041570</td>\n",
       "      <td>-0.344819</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.324882</td>\n",
       "      <td>-0.038799</td>\n",
       "      <td>-0.083405</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>-0.263096</td>\n",
       "      <td>-0.509436</td>\n",
       "      <td>-0.355150</td>\n",
       "      <td>-0.627434</td>\n",
       "      <td>-0.391700</td>\n",
       "      <td>-0.067389</td>\n",
       "      <td>-0.397692</td>\n",
       "      <td>0.298886</td>\n",
       "      <td>-0.072894</td>\n",
       "      <td>-0.279165</td>\n",
       "      <td>-0.058588</td>\n",
       "      <td>-0.026724</td>\n",
       "      <td>-0.590877</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.261290</td>\n",
       "      <td>-0.377658</td>\n",
       "      <td>-0.102923</td>\n",
       "      <td>0.461259</td>\n",
       "      <td>0.257778</td>\n",
       "      <td>0.058543</td>\n",
       "      <td>0.921407</td>\n",
       "      <td>0.387620</td>\n",
       "      <td>-0.296543</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>-1.187211</td>\n",
       "      <td>-0.174856</td>\n",
       "      <td>0.492095</td>\n",
       "      <td>0.179288</td>\n",
       "      <td>0.170215</td>\n",
       "      <td>0.465555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456791</td>\n",
       "      <td>-0.056636</td>\n",
       "      <td>-0.217742</td>\n",
       "      <td>-0.394158</td>\n",
       "      <td>-0.278104</td>\n",
       "      <td>-0.578750</td>\n",
       "      <td>-0.327522</td>\n",
       "      <td>-0.068462</td>\n",
       "      <td>-0.309578</td>\n",
       "      <td>0.249222</td>\n",
       "      <td>-0.085566</td>\n",
       "      <td>-0.231613</td>\n",
       "      <td>-0.032275</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>-0.413934</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.216122</td>\n",
       "      <td>1.126086</td>\n",
       "      <td>-0.464847</td>\n",
       "      <td>-1.099399</td>\n",
       "      <td>2.471141</td>\n",
       "      <td>0.157093</td>\n",
       "      <td>-1.825034</td>\n",
       "      <td>-0.664919</td>\n",
       "      <td>-1.892603</td>\n",
       "      <td>0.474049</td>\n",
       "      <td>1.375789</td>\n",
       "      <td>-0.944809</td>\n",
       "      <td>-0.980872</td>\n",
       "      <td>0.237554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988686</td>\n",
       "      <td>-0.597039</td>\n",
       "      <td>-0.991476</td>\n",
       "      <td>2.028633</td>\n",
       "      <td>-0.327012</td>\n",
       "      <td>-1.462496</td>\n",
       "      <td>-0.717330</td>\n",
       "      <td>-2.061181</td>\n",
       "      <td>0.309916</td>\n",
       "      <td>-0.344718</td>\n",
       "      <td>-0.994480</td>\n",
       "      <td>-0.986599</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.532464</td>\n",
       "      <td>-1.070717</td>\n",
       "      <td>1.132128</td>\n",
       "      <td>-0.917890</td>\n",
       "      <td>-1.325028</td>\n",
       "      <td>-0.922873</td>\n",
       "      <td>-0.467638</td>\n",
       "      <td>0.084494</td>\n",
       "      <td>-1.053629</td>\n",
       "      <td>-1.165176</td>\n",
       "      <td>-0.961423</td>\n",
       "      <td>-0.477813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.126012</td>\n",
       "      <td>4.437901</td>\n",
       "      <td>2.391857</td>\n",
       "      <td>-0.082914</td>\n",
       "      <td>1.408016</td>\n",
       "      <td>-4.414034</td>\n",
       "      <td>0.304808</td>\n",
       "      <td>2.571576</td>\n",
       "      <td>1.152031</td>\n",
       "      <td>0.622293</td>\n",
       "      <td>2.380996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.444248</td>\n",
       "      <td>-0.007142</td>\n",
       "      <td>-1.501629</td>\n",
       "      <td>-0.587912</td>\n",
       "      <td>-2.401456</td>\n",
       "      <td>0.431566</td>\n",
       "      <td>0.308655</td>\n",
       "      <td>-0.841353</td>\n",
       "      <td>-0.946241</td>\n",
       "      <td>0.236734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084920</td>\n",
       "      <td>-1.189547</td>\n",
       "      <td>-1.187547</td>\n",
       "      <td>2.106307</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-1.822126</td>\n",
       "      <td>-1.263796</td>\n",
       "      <td>-1.083213</td>\n",
       "      <td>-1.095937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.832721</td>\n",
       "      <td>-0.781842</td>\n",
       "      <td>-1.756897</td>\n",
       "      <td>0.105571</td>\n",
       "      <td>-0.620620</td>\n",
       "      <td>-0.888740</td>\n",
       "      <td>-0.888568</td>\n",
       "      <td>-0.260517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.687658</td>\n",
       "      <td>2.402241</td>\n",
       "      <td>-0.901065</td>\n",
       "      <td>-1.977288</td>\n",
       "      <td>-0.042788</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>-1.315294</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.828762</td>\n",
       "      <td>-0.195111</td>\n",
       "      <td>0.502152</td>\n",
       "      <td>0.240438</td>\n",
       "      <td>0.227120</td>\n",
       "      <td>0.492384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471881</td>\n",
       "      <td>1.054922</td>\n",
       "      <td>-0.944471</td>\n",
       "      <td>-0.969260</td>\n",
       "      <td>0.290468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019191</td>\n",
       "      <td>-0.908946</td>\n",
       "      <td>-0.920057</td>\n",
       "      <td>-0.495377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.955968</td>\n",
       "      <td>-0.941311</td>\n",
       "      <td>-0.626671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.987605</td>\n",
       "      <td>-0.072404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.729701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921270</td>\n",
       "      <td>0.896015</td>\n",
       "      <td>0.885663</td>\n",
       "      <td>0.902630</td>\n",
       "      <td>-0.054063</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.523018</td>\n",
       "      <td>1.099248</td>\n",
       "      <td>1.055340</td>\n",
       "      <td>1.101577</td>\n",
       "      <td>1.114948</td>\n",
       "      <td>1.121236</td>\n",
       "      <td>1.104858</td>\n",
       "      <td>1.150218</td>\n",
       "      <td>1.052307</td>\n",
       "      <td>0.273638</td>\n",
       "      <td>0.628506</td>\n",
       "      <td>-1.111212</td>\n",
       "      <td>1.083796</td>\n",
       "      <td>1.068989</td>\n",
       "      <td>0.793620</td>\n",
       "      <td>-0.550285</td>\n",
       "      <td>-0.097646</td>\n",
       "      <td>-0.492012</td>\n",
       "      <td>0.425631</td>\n",
       "      <td>-0.669262</td>\n",
       "      <td>0.558719</td>\n",
       "      <td>0.220353</td>\n",
       "      <td>-1.257810</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.768075</td>\n",
       "      <td>1.188595</td>\n",
       "      <td>-1.340759</td>\n",
       "      <td>1.040085</td>\n",
       "      <td>0.919514</td>\n",
       "      <td>0.825597</td>\n",
       "      <td>0.745954</td>\n",
       "      <td>-0.107683</td>\n",
       "      <td>-1.433603</td>\n",
       "      <td>0.779564</td>\n",
       "      <td>-0.357560</td>\n",
       "      <td>-0.354062</td>\n",
       "      <td>0.902630</td>\n",
       "      <td>-0.942986</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.063043</td>\n",
       "      <td>0.274742</td>\n",
       "      <td>-0.215141</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>-0.677092</td>\n",
       "      <td>-1.073565</td>\n",
       "      <td>2.304146</td>\n",
       "      <td>0.047483</td>\n",
       "      <td>-1.467585</td>\n",
       "      <td>-1.321750</td>\n",
       "      <td>-1.467585</td>\n",
       "      <td>0.268124</td>\n",
       "      <td>1.017398</td>\n",
       "      <td>-0.954716</td>\n",
       "      <td>-0.987042</td>\n",
       "      <td>0.356112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727055</td>\n",
       "      <td>0.927302</td>\n",
       "      <td>0.914393</td>\n",
       "      <td>0.909908</td>\n",
       "      <td>0.918639</td>\n",
       "      <td>-0.037753</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.686476</td>\n",
       "      <td>1.037563</td>\n",
       "      <td>1.006507</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>1.031238</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>1.026980</td>\n",
       "      <td>1.057873</td>\n",
       "      <td>1.002305</td>\n",
       "      <td>0.283612</td>\n",
       "      <td>0.667645</td>\n",
       "      <td>-1.186088</td>\n",
       "      <td>1.014039</td>\n",
       "      <td>1.009173</td>\n",
       "      <td>0.964633</td>\n",
       "      <td>-0.461501</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>-0.260345</td>\n",
       "      <td>0.666337</td>\n",
       "      <td>-0.646669</td>\n",
       "      <td>0.593591</td>\n",
       "      <td>0.717860</td>\n",
       "      <td>-1.305561</td>\n",
       "      <td>0.364533</td>\n",
       "      <td>0.820863</td>\n",
       "      <td>1.276622</td>\n",
       "      <td>-1.438230</td>\n",
       "      <td>0.991971</td>\n",
       "      <td>0.938687</td>\n",
       "      <td>0.907616</td>\n",
       "      <td>0.871501</td>\n",
       "      <td>-0.053186</td>\n",
       "      <td>-1.428956</td>\n",
       "      <td>0.806740</td>\n",
       "      <td>-0.374601</td>\n",
       "      <td>-0.371085</td>\n",
       "      <td>0.913277</td>\n",
       "      <td>-0.968433</td>\n",
       "      <td>-0.013612</td>\n",
       "      <td>0.065162</td>\n",
       "      <td>0.291658</td>\n",
       "      <td>-0.233529</td>\n",
       "      <td>1.203354</td>\n",
       "      <td>-0.510086</td>\n",
       "      <td>-1.004087</td>\n",
       "      <td>2.410889</td>\n",
       "      <td>0.237527</td>\n",
       "      <td>-1.438578</td>\n",
       "      <td>-1.277277</td>\n",
       "      <td>-1.595751</td>\n",
       "      <td>0.279302</td>\n",
       "      <td>0.978986</td>\n",
       "      <td>-0.949326</td>\n",
       "      <td>-0.971725</td>\n",
       "      <td>0.432922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897003</td>\n",
       "      <td>0.900334</td>\n",
       "      <td>0.896830</td>\n",
       "      <td>0.904776</td>\n",
       "      <td>-0.039074</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.679164</td>\n",
       "      <td>1.023277</td>\n",
       "      <td>0.994208</td>\n",
       "      <td>1.013966</td>\n",
       "      <td>1.018174</td>\n",
       "      <td>1.021189</td>\n",
       "      <td>1.014291</td>\n",
       "      <td>1.043601</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.283034</td>\n",
       "      <td>0.666323</td>\n",
       "      <td>-1.182544</td>\n",
       "      <td>1.000834</td>\n",
       "      <td>0.995773</td>\n",
       "      <td>0.959417</td>\n",
       "      <td>-0.463597</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>-0.267092</td>\n",
       "      <td>0.660498</td>\n",
       "      <td>-0.647283</td>\n",
       "      <td>0.592470</td>\n",
       "      <td>0.697512</td>\n",
       "      <td>-1.303888</td>\n",
       "      <td>0.363824</td>\n",
       "      <td>0.819119</td>\n",
       "      <td>1.274212</td>\n",
       "      <td>-1.434494</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.924914</td>\n",
       "      <td>0.893636</td>\n",
       "      <td>0.857316</td>\n",
       "      <td>-0.055173</td>\n",
       "      <td>-1.429148</td>\n",
       "      <td>0.805368</td>\n",
       "      <td>-0.374826</td>\n",
       "      <td>-0.371341</td>\n",
       "      <td>0.912424</td>\n",
       "      <td>-0.964433</td>\n",
       "      <td>-0.013403</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.290845</td>\n",
       "      <td>-0.232290</td>\n",
       "      <td>1.177434</td>\n",
       "      <td>-0.513844</td>\n",
       "      <td>-1.005339</td>\n",
       "      <td>2.406958</td>\n",
       "      <td>0.230417</td>\n",
       "      <td>-1.437944</td>\n",
       "      <td>-1.278126</td>\n",
       "      <td>-1.594228</td>\n",
       "      <td>0.278752</td>\n",
       "      <td>0.965735</td>\n",
       "      <td>-0.950218</td>\n",
       "      <td>-0.972439</td>\n",
       "      <td>0.430024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871641</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>0.899739</td>\n",
       "      <td>-0.036577</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.689978</td>\n",
       "      <td>1.021074</td>\n",
       "      <td>0.988419</td>\n",
       "      <td>1.009736</td>\n",
       "      <td>1.013453</td>\n",
       "      <td>1.017316</td>\n",
       "      <td>1.008769</td>\n",
       "      <td>1.040760</td>\n",
       "      <td>0.983734</td>\n",
       "      <td>0.283375</td>\n",
       "      <td>0.667727</td>\n",
       "      <td>-1.190276</td>\n",
       "      <td>0.996206</td>\n",
       "      <td>0.991568</td>\n",
       "      <td>0.962561</td>\n",
       "      <td>-0.464262</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>-0.266278</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>-0.647521</td>\n",
       "      <td>0.593585</td>\n",
       "      <td>0.706230</td>\n",
       "      <td>-1.306727</td>\n",
       "      <td>0.365701</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>1.276696</td>\n",
       "      <td>-1.441001</td>\n",
       "      <td>0.973919</td>\n",
       "      <td>0.920950</td>\n",
       "      <td>0.890774</td>\n",
       "      <td>0.854061</td>\n",
       "      <td>-0.054936</td>\n",
       "      <td>-1.430372</td>\n",
       "      <td>0.805584</td>\n",
       "      <td>-0.382960</td>\n",
       "      <td>-0.379605</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>-0.976103</td>\n",
       "      <td>-0.013887</td>\n",
       "      <td>0.066271</td>\n",
       "      <td>0.290814</td>\n",
       "      <td>-0.243792</td>\n",
       "      <td>1.164657</td>\n",
       "      <td>-0.513662</td>\n",
       "      <td>-1.005158</td>\n",
       "      <td>2.409033</td>\n",
       "      <td>0.230945</td>\n",
       "      <td>-1.437744</td>\n",
       "      <td>-1.277355</td>\n",
       "      <td>-1.596148</td>\n",
       "      <td>0.279137</td>\n",
       "      <td>0.961060</td>\n",
       "      <td>-0.951382</td>\n",
       "      <td>-0.972129</td>\n",
       "      <td>0.430544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861279</td>\n",
       "      <td>0.907816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056366</td>\n",
       "      <td>-0.047393</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.040558</td>\n",
       "      <td>-0.358771</td>\n",
       "      <td>-0.405775</td>\n",
       "      <td>-0.268791</td>\n",
       "      <td>-0.734045</td>\n",
       "      <td>-0.417335</td>\n",
       "      <td>-0.269533</td>\n",
       "      <td>-0.185586</td>\n",
       "      <td>0.325871</td>\n",
       "      <td>-0.064813</td>\n",
       "      <td>-0.372464</td>\n",
       "      <td>-0.116373</td>\n",
       "      <td>-0.055677</td>\n",
       "      <td>-0.383806</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.353721</td>\n",
       "      <td>-0.614390</td>\n",
       "      <td>-0.468438</td>\n",
       "      <td>-0.406323</td>\n",
       "      <td>-0.029171</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>-0.110471</td>\n",
       "      <td>0.910147</td>\n",
       "      <td>0.827100</td>\n",
       "      <td>0.643901</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.887032</td>\n",
       "      <td>0.481154</td>\n",
       "      <td>0.551686</td>\n",
       "      <td>-1.091287</td>\n",
       "      <td>-0.067418</td>\n",
       "      <td>0.914703</td>\n",
       "      <td>0.537858</td>\n",
       "      <td>0.494401</td>\n",
       "      <td>0.837284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902443</td>\n",
       "      <td>-0.002658</td>\n",
       "      <td>-0.108827</td>\n",
       "      <td>-0.053896</td>\n",
       "      <td>-0.359510</td>\n",
       "      <td>-0.048400</td>\n",
       "      <td>-0.954817</td>\n",
       "      <td>-0.842067</td>\n",
       "      <td>-0.522272</td>\n",
       "      <td>-2.144668</td>\n",
       "      <td>-1.002784</td>\n",
       "      <td>-0.300807</td>\n",
       "      <td>-0.361429</td>\n",
       "      <td>1.320572</td>\n",
       "      <td>-0.197816</td>\n",
       "      <td>-0.970708</td>\n",
       "      <td>-0.358821</td>\n",
       "      <td>-0.206516</td>\n",
       "      <td>-0.962719</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.942190</td>\n",
       "      <td>-0.703857</td>\n",
       "      <td>-0.059979</td>\n",
       "      <td>-0.213627</td>\n",
       "      <td>-0.068247</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.067234</td>\n",
       "      <td>-0.060902</td>\n",
       "      <td>-0.616840</td>\n",
       "      <td>-0.107663</td>\n",
       "      <td>-0.071099</td>\n",
       "      <td>-0.083501</td>\n",
       "      <td>-0.083930</td>\n",
       "      <td>-0.282148</td>\n",
       "      <td>-0.012509</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>0.134988</td>\n",
       "      <td>-0.043030</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-0.042123</td>\n",
       "      <td>-0.021188</td>\n",
       "      <td>-0.036936</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>0.045293</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.057919</td>\n",
       "      <td>-0.020659</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>-0.029717</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>0.044626</td>\n",
       "      <td>0.042840</td>\n",
       "      <td>0.079311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063011</td>\n",
       "      <td>-0.469328</td>\n",
       "      <td>-0.084624</td>\n",
       "      <td>0.275943</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.483182</td>\n",
       "      <td>0.206172</td>\n",
       "      <td>-0.243835</td>\n",
       "      <td>-0.202709</td>\n",
       "      <td>-0.785461</td>\n",
       "      <td>-0.252056</td>\n",
       "      <td>0.295162</td>\n",
       "      <td>0.107845</td>\n",
       "      <td>0.118243</td>\n",
       "      <td>0.317682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274234</td>\n",
       "      <td>-0.056676</td>\n",
       "      <td>-0.216113</td>\n",
       "      <td>-0.378245</td>\n",
       "      <td>-0.285621</td>\n",
       "      <td>-0.546657</td>\n",
       "      <td>-0.322943</td>\n",
       "      <td>-0.142126</td>\n",
       "      <td>-0.175995</td>\n",
       "      <td>0.213649</td>\n",
       "      <td>-0.068673</td>\n",
       "      <td>-0.230032</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>-0.446126</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.214902</td>\n",
       "      <td>1.000464</td>\n",
       "      <td>-0.618678</td>\n",
       "      <td>-1.050365</td>\n",
       "      <td>2.322575</td>\n",
       "      <td>0.105851</td>\n",
       "      <td>-1.457312</td>\n",
       "      <td>-1.307091</td>\n",
       "      <td>-1.515942</td>\n",
       "      <td>0.267704</td>\n",
       "      <td>1.312219</td>\n",
       "      <td>-0.946358</td>\n",
       "      <td>-0.981632</td>\n",
       "      <td>0.381215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869350</td>\n",
       "      <td>-0.725461</td>\n",
       "      <td>-0.993927</td>\n",
       "      <td>1.823381</td>\n",
       "      <td>-0.435282</td>\n",
       "      <td>-1.238319</td>\n",
       "      <td>-1.134415</td>\n",
       "      <td>-1.506839</td>\n",
       "      <td>0.089952</td>\n",
       "      <td>-0.502053</td>\n",
       "      <td>-1.025975</td>\n",
       "      <td>-1.002381</td>\n",
       "      <td>0.067179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.681500</td>\n",
       "      <td>-1.041407</td>\n",
       "      <td>1.101358</td>\n",
       "      <td>-0.886743</td>\n",
       "      <td>-1.186666</td>\n",
       "      <td>-1.130548</td>\n",
       "      <td>-0.320563</td>\n",
       "      <td>-0.039916</td>\n",
       "      <td>-1.002560</td>\n",
       "      <td>-1.147665</td>\n",
       "      <td>-0.953262</td>\n",
       "      <td>-0.378693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.075169</td>\n",
       "      <td>3.879425</td>\n",
       "      <td>2.229248</td>\n",
       "      <td>0.332388</td>\n",
       "      <td>0.632990</td>\n",
       "      <td>-3.742999</td>\n",
       "      <td>-0.016459</td>\n",
       "      <td>2.418300</td>\n",
       "      <td>1.090135</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>2.425831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.301250</td>\n",
       "      <td>-0.051462</td>\n",
       "      <td>-1.220302</td>\n",
       "      <td>-1.079773</td>\n",
       "      <td>-1.928263</td>\n",
       "      <td>0.218321</td>\n",
       "      <td>0.258452</td>\n",
       "      <td>-0.849149</td>\n",
       "      <td>-0.950522</td>\n",
       "      <td>0.359283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041375</td>\n",
       "      <td>-1.135731</td>\n",
       "      <td>-1.132783</td>\n",
       "      <td>0.943616</td>\n",
       "      <td>-0.120268</td>\n",
       "      <td>-1.442849</td>\n",
       "      <td>-1.136491</td>\n",
       "      <td>-1.011405</td>\n",
       "      <td>-0.813186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.468019</td>\n",
       "      <td>-1.107094</td>\n",
       "      <td>0.215402</td>\n",
       "      <td>-0.119062</td>\n",
       "      <td>-1.281189</td>\n",
       "      <td>-1.101941</td>\n",
       "      <td>-1.007768</td>\n",
       "      <td>-0.649535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.322559</td>\n",
       "      <td>1.726076</td>\n",
       "      <td>-0.537472</td>\n",
       "      <td>-1.594986</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.432713</td>\n",
       "      <td>-1.239416</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.463970</td>\n",
       "      <td>-0.230117</td>\n",
       "      <td>0.281737</td>\n",
       "      <td>0.169659</td>\n",
       "      <td>0.179298</td>\n",
       "      <td>0.299728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267769</td>\n",
       "      <td>1.027823</td>\n",
       "      <td>-0.945591</td>\n",
       "      <td>-0.969797</td>\n",
       "      <td>0.438634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993375</td>\n",
       "      <td>-0.908946</td>\n",
       "      <td>-0.920057</td>\n",
       "      <td>-0.441867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.955965</td>\n",
       "      <td>-0.941311</td>\n",
       "      <td>-0.596876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.987604</td>\n",
       "      <td>0.091662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.726374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.889089</td>\n",
       "      <td>0.867764</td>\n",
       "      <td>0.901325</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>0.541127</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.419636</td>\n",
       "      <td>1.104271</td>\n",
       "      <td>1.043529</td>\n",
       "      <td>1.097888</td>\n",
       "      <td>1.086304</td>\n",
       "      <td>1.089870</td>\n",
       "      <td>1.078994</td>\n",
       "      <td>1.150218</td>\n",
       "      <td>1.052307</td>\n",
       "      <td>0.130338</td>\n",
       "      <td>0.528851</td>\n",
       "      <td>-1.280122</td>\n",
       "      <td>1.057431</td>\n",
       "      <td>1.057815</td>\n",
       "      <td>0.620800</td>\n",
       "      <td>-0.639013</td>\n",
       "      <td>-0.197723</td>\n",
       "      <td>-0.786403</td>\n",
       "      <td>1.592578</td>\n",
       "      <td>0.575557</td>\n",
       "      <td>0.469572</td>\n",
       "      <td>0.088547</td>\n",
       "      <td>-1.224044</td>\n",
       "      <td>1.231124</td>\n",
       "      <td>0.648556</td>\n",
       "      <td>1.101455</td>\n",
       "      <td>-1.453999</td>\n",
       "      <td>1.040085</td>\n",
       "      <td>0.919514</td>\n",
       "      <td>0.807504</td>\n",
       "      <td>0.745954</td>\n",
       "      <td>-0.227204</td>\n",
       "      <td>-1.433603</td>\n",
       "      <td>0.707803</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.036031</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>0.784309</td>\n",
       "      <td>-0.111292</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>-0.634144</td>\n",
       "      <td>0.036010</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>-0.660075</td>\n",
       "      <td>-1.540662</td>\n",
       "      <td>2.175984</td>\n",
       "      <td>-0.188135</td>\n",
       "      <td>-1.439752</td>\n",
       "      <td>-1.734333</td>\n",
       "      <td>-1.439752</td>\n",
       "      <td>0.054234</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>-0.954716</td>\n",
       "      <td>-0.987042</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.723724</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.882721</td>\n",
       "      <td>0.901350</td>\n",
       "      <td>0.903397</td>\n",
       "      <td>0.569882</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.568911</td>\n",
       "      <td>1.022749</td>\n",
       "      <td>0.983424</td>\n",
       "      <td>1.008144</td>\n",
       "      <td>0.999149</td>\n",
       "      <td>1.001099</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>1.040399</td>\n",
       "      <td>0.985501</td>\n",
       "      <td>0.128512</td>\n",
       "      <td>0.558950</td>\n",
       "      <td>-1.364780</td>\n",
       "      <td>0.983178</td>\n",
       "      <td>0.986116</td>\n",
       "      <td>0.773753</td>\n",
       "      <td>-0.555566</td>\n",
       "      <td>-0.101780</td>\n",
       "      <td>-0.557509</td>\n",
       "      <td>1.852605</td>\n",
       "      <td>0.650001</td>\n",
       "      <td>0.496182</td>\n",
       "      <td>0.587591</td>\n",
       "      <td>-1.268947</td>\n",
       "      <td>1.301385</td>\n",
       "      <td>0.690517</td>\n",
       "      <td>1.180635</td>\n",
       "      <td>-1.557760</td>\n",
       "      <td>0.974864</td>\n",
       "      <td>0.921276</td>\n",
       "      <td>0.880477</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>-0.178526</td>\n",
       "      <td>-1.429121</td>\n",
       "      <td>0.731201</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.039794</td>\n",
       "      <td>0.916034</td>\n",
       "      <td>0.798396</td>\n",
       "      <td>-0.133145</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>-0.682052</td>\n",
       "      <td>0.034802</td>\n",
       "      <td>1.171308</td>\n",
       "      <td>-0.498222</td>\n",
       "      <td>-1.484103</td>\n",
       "      <td>2.273245</td>\n",
       "      <td>-0.007567</td>\n",
       "      <td>-1.410603</td>\n",
       "      <td>-1.700839</td>\n",
       "      <td>-1.562483</td>\n",
       "      <td>0.048393</td>\n",
       "      <td>0.952658</td>\n",
       "      <td>-0.950757</td>\n",
       "      <td>-0.972410</td>\n",
       "      <td>0.579793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864741</td>\n",
       "      <td>0.870767</td>\n",
       "      <td>0.890371</td>\n",
       "      <td>0.891641</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.562695</td>\n",
       "      <td>1.010643</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.988183</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>0.985747</td>\n",
       "      <td>1.028309</td>\n",
       "      <td>0.975038</td>\n",
       "      <td>0.128391</td>\n",
       "      <td>0.557978</td>\n",
       "      <td>-1.360908</td>\n",
       "      <td>0.972077</td>\n",
       "      <td>0.974851</td>\n",
       "      <td>0.769454</td>\n",
       "      <td>-0.556923</td>\n",
       "      <td>-0.104273</td>\n",
       "      <td>-0.563023</td>\n",
       "      <td>1.849382</td>\n",
       "      <td>0.647297</td>\n",
       "      <td>0.495368</td>\n",
       "      <td>0.570228</td>\n",
       "      <td>-1.267542</td>\n",
       "      <td>1.299423</td>\n",
       "      <td>0.689200</td>\n",
       "      <td>1.178614</td>\n",
       "      <td>-1.553979</td>\n",
       "      <td>0.963591</td>\n",
       "      <td>0.909667</td>\n",
       "      <td>0.868651</td>\n",
       "      <td>0.841823</td>\n",
       "      <td>-0.180051</td>\n",
       "      <td>-1.429292</td>\n",
       "      <td>0.730062</td>\n",
       "      <td>0.036074</td>\n",
       "      <td>0.037965</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.794394</td>\n",
       "      <td>-0.132797</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>-0.681119</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>1.149351</td>\n",
       "      <td>-0.501376</td>\n",
       "      <td>-1.484218</td>\n",
       "      <td>2.269932</td>\n",
       "      <td>-0.013046</td>\n",
       "      <td>-1.409955</td>\n",
       "      <td>-1.701017</td>\n",
       "      <td>-1.561507</td>\n",
       "      <td>0.048518</td>\n",
       "      <td>0.941521</td>\n",
       "      <td>-0.951466</td>\n",
       "      <td>-0.973037</td>\n",
       "      <td>0.577033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843320</td>\n",
       "      <td>0.906975</td>\n",
       "      <td>0.909622</td>\n",
       "      <td>0.583689</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.577784</td>\n",
       "      <td>1.032274</td>\n",
       "      <td>0.990228</td>\n",
       "      <td>1.016213</td>\n",
       "      <td>1.006842</td>\n",
       "      <td>1.009409</td>\n",
       "      <td>1.003452</td>\n",
       "      <td>1.049323</td>\n",
       "      <td>0.991953</td>\n",
       "      <td>0.128242</td>\n",
       "      <td>0.560006</td>\n",
       "      <td>-1.372146</td>\n",
       "      <td>0.990839</td>\n",
       "      <td>0.994212</td>\n",
       "      <td>0.777893</td>\n",
       "      <td>-0.553646</td>\n",
       "      <td>-0.098932</td>\n",
       "      <td>-0.551210</td>\n",
       "      <td>1.862135</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>0.497047</td>\n",
       "      <td>0.603351</td>\n",
       "      <td>-1.272537</td>\n",
       "      <td>1.306744</td>\n",
       "      <td>0.691996</td>\n",
       "      <td>1.182982</td>\n",
       "      <td>-1.563778</td>\n",
       "      <td>0.982291</td>\n",
       "      <td>0.929474</td>\n",
       "      <td>0.889570</td>\n",
       "      <td>0.862725</td>\n",
       "      <td>-0.177461</td>\n",
       "      <td>-1.430290</td>\n",
       "      <td>0.731563</td>\n",
       "      <td>0.035564</td>\n",
       "      <td>0.037472</td>\n",
       "      <td>0.916778</td>\n",
       "      <td>0.804158</td>\n",
       "      <td>-0.133968</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>-0.684170</td>\n",
       "      <td>0.033684</td>\n",
       "      <td>1.180244</td>\n",
       "      <td>-0.494071</td>\n",
       "      <td>-1.481894</td>\n",
       "      <td>2.276208</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>-1.408840</td>\n",
       "      <td>-1.699209</td>\n",
       "      <td>-1.569366</td>\n",
       "      <td>0.047944</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>-0.950678</td>\n",
       "      <td>-0.971793</td>\n",
       "      <td>0.581581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877062</td>\n",
       "      <td>0.911090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103492</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.077491</td>\n",
       "      <td>-0.051492</td>\n",
       "      <td>0.035450</td>\n",
       "      <td>-0.044317</td>\n",
       "      <td>-0.033195</td>\n",
       "      <td>0.043352</td>\n",
       "      <td>-0.019451</td>\n",
       "      <td>-0.175992</td>\n",
       "      <td>-0.040606</td>\n",
       "      <td>-0.202411</td>\n",
       "      <td>-0.019948</td>\n",
       "      <td>0.039068</td>\n",
       "      <td>0.029069</td>\n",
       "      <td>0.043843</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035982</td>\n",
       "      <td>-0.612746</td>\n",
       "      <td>0.190935</td>\n",
       "      <td>-0.455008</td>\n",
       "      <td>-0.036815</td>\n",
       "      <td>-0.225143</td>\n",
       "      <td>-0.055662</td>\n",
       "      <td>0.913313</td>\n",
       "      <td>0.831460</td>\n",
       "      <td>0.571555</td>\n",
       "      <td>0.624498</td>\n",
       "      <td>0.869829</td>\n",
       "      <td>0.487621</td>\n",
       "      <td>0.472875</td>\n",
       "      <td>-1.090328</td>\n",
       "      <td>-0.120950</td>\n",
       "      <td>0.917751</td>\n",
       "      <td>0.539065</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.872649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905565</td>\n",
       "      <td>-0.088991</td>\n",
       "      <td>-0.340517</td>\n",
       "      <td>-0.048211</td>\n",
       "      <td>-0.377351</td>\n",
       "      <td>-0.089180</td>\n",
       "      <td>0.792496</td>\n",
       "      <td>0.609216</td>\n",
       "      <td>0.256633</td>\n",
       "      <td>1.486667</td>\n",
       "      <td>0.665932</td>\n",
       "      <td>0.065364</td>\n",
       "      <td>0.099927</td>\n",
       "      <td>-1.297535</td>\n",
       "      <td>-0.016777</td>\n",
       "      <td>0.801751</td>\n",
       "      <td>0.353985</td>\n",
       "      <td>0.314015</td>\n",
       "      <td>0.847608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783746</td>\n",
       "      <td>-0.665719</td>\n",
       "      <td>-0.057145</td>\n",
       "      <td>-0.009886</td>\n",
       "      <td>-0.087946</td>\n",
       "      <td>-0.115514</td>\n",
       "      <td>-0.162617</td>\n",
       "      <td>-0.074114</td>\n",
       "      <td>-0.834911</td>\n",
       "      <td>-0.206521</td>\n",
       "      <td>-0.099043</td>\n",
       "      <td>-0.072421</td>\n",
       "      <td>0.092216</td>\n",
       "      <td>-0.260369</td>\n",
       "      <td>-0.132570</td>\n",
       "      <td>-0.012408</td>\n",
       "      <td>0.102335</td>\n",
       "      <td>-0.183133</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.110975</td>\n",
       "      <td>-0.042193</td>\n",
       "      <td>-0.027268</td>\n",
       "      <td>-0.036351</td>\n",
       "      <td>0.025198</td>\n",
       "      <td>-0.017215</td>\n",
       "      <td>-0.041499</td>\n",
       "      <td>-0.035581</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>-0.036935</td>\n",
       "      <td>-0.021599</td>\n",
       "      <td>-0.044733</td>\n",
       "      <td>-0.032842</td>\n",
       "      <td>0.024874</td>\n",
       "      <td>0.032612</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>-0.390027</td>\n",
       "      <td>-0.044287</td>\n",
       "      <td>-0.641367</td>\n",
       "      <td>-0.674084</td>\n",
       "      <td>-0.455822</td>\n",
       "      <td>-1.311542</td>\n",
       "      <td>-0.649189</td>\n",
       "      <td>-0.448575</td>\n",
       "      <td>-0.416352</td>\n",
       "      <td>0.697186</td>\n",
       "      <td>-0.305697</td>\n",
       "      <td>-0.680641</td>\n",
       "      <td>-0.247399</td>\n",
       "      <td>-0.140185</td>\n",
       "      <td>-0.661383</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.633513</td>\n",
       "      <td>-0.061054</td>\n",
       "      <td>0.035880</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>-0.037900</td>\n",
       "      <td>-0.068296</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>-0.052188</td>\n",
       "      <td>-0.012179</td>\n",
       "      <td>-0.070815</td>\n",
       "      <td>-0.048596</td>\n",
       "      <td>0.035460</td>\n",
       "      <td>0.049115</td>\n",
       "      <td>0.062010</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.036024</td>\n",
       "      <td>1.000464</td>\n",
       "      <td>-0.601844</td>\n",
       "      <td>-1.520469</td>\n",
       "      <td>2.193079</td>\n",
       "      <td>-0.129672</td>\n",
       "      <td>-1.429273</td>\n",
       "      <td>-1.722418</td>\n",
       "      <td>-1.487653</td>\n",
       "      <td>0.052403</td>\n",
       "      <td>1.294485</td>\n",
       "      <td>-0.946358</td>\n",
       "      <td>-0.981632</td>\n",
       "      <td>0.527707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869534</td>\n",
       "      <td>-0.711065</td>\n",
       "      <td>-1.267920</td>\n",
       "      <td>1.722444</td>\n",
       "      <td>-0.534144</td>\n",
       "      <td>-1.219697</td>\n",
       "      <td>-1.382822</td>\n",
       "      <td>-1.491256</td>\n",
       "      <td>-0.122617</td>\n",
       "      <td>-0.487493</td>\n",
       "      <td>-1.022386</td>\n",
       "      <td>-1.000582</td>\n",
       "      <td>0.189556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.664507</td>\n",
       "      <td>-1.273016</td>\n",
       "      <td>0.640015</td>\n",
       "      <td>-1.306597</td>\n",
       "      <td>-1.234321</td>\n",
       "      <td>-1.319849</td>\n",
       "      <td>0.292866</td>\n",
       "      <td>-0.187280</td>\n",
       "      <td>-1.486050</td>\n",
       "      <td>-1.308318</td>\n",
       "      <td>-1.028128</td>\n",
       "      <td>-0.626972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.541577</td>\n",
       "      <td>3.406218</td>\n",
       "      <td>1.997204</td>\n",
       "      <td>0.334121</td>\n",
       "      <td>0.166419</td>\n",
       "      <td>-3.514467</td>\n",
       "      <td>-0.316903</td>\n",
       "      <td>2.281858</td>\n",
       "      <td>1.034723</td>\n",
       "      <td>0.554610</td>\n",
       "      <td>2.466095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.173233</td>\n",
       "      <td>-0.284322</td>\n",
       "      <td>-1.216881</td>\n",
       "      <td>-1.406937</td>\n",
       "      <td>-1.716351</td>\n",
       "      <td>-0.002354</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>-0.891255</td>\n",
       "      <td>-0.973643</td>\n",
       "      <td>0.401530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.193885</td>\n",
       "      <td>-1.128903</td>\n",
       "      <td>-1.178024</td>\n",
       "      <td>0.866057</td>\n",
       "      <td>-0.174137</td>\n",
       "      <td>-1.414301</td>\n",
       "      <td>-1.126789</td>\n",
       "      <td>-1.005932</td>\n",
       "      <td>-0.764719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.440222</td>\n",
       "      <td>-1.220413</td>\n",
       "      <td>1.243583</td>\n",
       "      <td>-0.212150</td>\n",
       "      <td>-1.709163</td>\n",
       "      <td>-1.240298</td>\n",
       "      <td>-1.085122</td>\n",
       "      <td>-0.930150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.734577</td>\n",
       "      <td>1.677481</td>\n",
       "      <td>-0.231939</td>\n",
       "      <td>-1.563798</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.438224</td>\n",
       "      <td>-1.384937</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.436175</td>\n",
       "      <td>-0.244845</td>\n",
       "      <td>0.051491</td>\n",
       "      <td>0.095566</td>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.062908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054097</td>\n",
       "      <td>1.009201</td>\n",
       "      <td>-0.946362</td>\n",
       "      <td>-0.970165</td>\n",
       "      <td>0.587208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975638</td>\n",
       "      <td>-0.908946</td>\n",
       "      <td>-0.920057</td>\n",
       "      <td>-0.388357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.955963</td>\n",
       "      <td>-0.941311</td>\n",
       "      <td>-0.567081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.987603</td>\n",
       "      <td>0.267881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.723047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.913072</td>\n",
       "      <td>0.964062</td>\n",
       "      <td>0.913308</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>-0.226430</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.449692</td>\n",
       "      <td>1.093563</td>\n",
       "      <td>1.065020</td>\n",
       "      <td>1.103818</td>\n",
       "      <td>1.063343</td>\n",
       "      <td>1.075325</td>\n",
       "      <td>1.047832</td>\n",
       "      <td>1.150218</td>\n",
       "      <td>1.094923</td>\n",
       "      <td>0.068818</td>\n",
       "      <td>0.436374</td>\n",
       "      <td>-1.190046</td>\n",
       "      <td>1.046126</td>\n",
       "      <td>1.053032</td>\n",
       "      <td>0.434408</td>\n",
       "      <td>-0.222965</td>\n",
       "      <td>-0.401559</td>\n",
       "      <td>-1.203557</td>\n",
       "      <td>1.277530</td>\n",
       "      <td>0.657353</td>\n",
       "      <td>0.386101</td>\n",
       "      <td>0.074247</td>\n",
       "      <td>-0.880784</td>\n",
       "      <td>0.809842</td>\n",
       "      <td>0.517230</td>\n",
       "      <td>1.005304</td>\n",
       "      <td>-1.577098</td>\n",
       "      <td>1.040085</td>\n",
       "      <td>0.919514</td>\n",
       "      <td>0.796032</td>\n",
       "      <td>0.745954</td>\n",
       "      <td>-0.346725</td>\n",
       "      <td>-0.946166</td>\n",
       "      <td>0.349003</td>\n",
       "      <td>0.698409</td>\n",
       "      <td>0.696151</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.863142</td>\n",
       "      <td>0.187037</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>-0.593177</td>\n",
       "      <td>0.085287</td>\n",
       "      <td>1.237640</td>\n",
       "      <td>-0.277073</td>\n",
       "      <td>-1.293219</td>\n",
       "      <td>2.073797</td>\n",
       "      <td>-0.047106</td>\n",
       "      <td>-0.655982</td>\n",
       "      <td>-1.303960</td>\n",
       "      <td>-0.655982</td>\n",
       "      <td>-0.137625</td>\n",
       "      <td>0.998769</td>\n",
       "      <td>-0.954716</td>\n",
       "      <td>-0.987042</td>\n",
       "      <td>0.645453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.720394</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.945691</td>\n",
       "      <td>0.920205</td>\n",
       "      <td>0.953119</td>\n",
       "      <td>-0.214281</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.604954</td>\n",
       "      <td>1.030122</td>\n",
       "      <td>1.007487</td>\n",
       "      <td>1.024045</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>1.006301</td>\n",
       "      <td>0.992521</td>\n",
       "      <td>1.053421</td>\n",
       "      <td>1.020834</td>\n",
       "      <td>0.062125</td>\n",
       "      <td>0.459313</td>\n",
       "      <td>-1.269898</td>\n",
       "      <td>0.989997</td>\n",
       "      <td>0.996472</td>\n",
       "      <td>0.575595</td>\n",
       "      <td>-0.126393</td>\n",
       "      <td>-0.310702</td>\n",
       "      <td>-0.963393</td>\n",
       "      <td>1.537232</td>\n",
       "      <td>0.737244</td>\n",
       "      <td>0.406070</td>\n",
       "      <td>0.589409</td>\n",
       "      <td>-0.914580</td>\n",
       "      <td>0.857545</td>\n",
       "      <td>0.549006</td>\n",
       "      <td>1.077614</td>\n",
       "      <td>-1.691405</td>\n",
       "      <td>0.987613</td>\n",
       "      <td>0.934252</td>\n",
       "      <td>0.887251</td>\n",
       "      <td>0.866994</td>\n",
       "      <td>-0.300744</td>\n",
       "      <td>-0.921042</td>\n",
       "      <td>0.359193</td>\n",
       "      <td>0.737367</td>\n",
       "      <td>0.734959</td>\n",
       "      <td>0.992902</td>\n",
       "      <td>0.879776</td>\n",
       "      <td>0.177299</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>-0.638699</td>\n",
       "      <td>0.087410</td>\n",
       "      <td>1.265688</td>\n",
       "      <td>-0.109278</td>\n",
       "      <td>-1.229596</td>\n",
       "      <td>2.168440</td>\n",
       "      <td>0.140025</td>\n",
       "      <td>-0.603526</td>\n",
       "      <td>-1.259318</td>\n",
       "      <td>-0.752050</td>\n",
       "      <td>-0.158585</td>\n",
       "      <td>0.964937</td>\n",
       "      <td>-0.949691</td>\n",
       "      <td>-0.971900</td>\n",
       "      <td>0.731708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888884</td>\n",
       "      <td>0.971690</td>\n",
       "      <td>0.946936</td>\n",
       "      <td>0.979281</td>\n",
       "      <td>-0.213121</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.607836</td>\n",
       "      <td>1.057071</td>\n",
       "      <td>1.034720</td>\n",
       "      <td>1.051356</td>\n",
       "      <td>1.027034</td>\n",
       "      <td>1.033380</td>\n",
       "      <td>1.019823</td>\n",
       "      <td>1.080434</td>\n",
       "      <td>1.048137</td>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.459864</td>\n",
       "      <td>-1.270014</td>\n",
       "      <td>1.017125</td>\n",
       "      <td>1.023808</td>\n",
       "      <td>0.580444</td>\n",
       "      <td>-0.121481</td>\n",
       "      <td>-0.306122</td>\n",
       "      <td>-0.954109</td>\n",
       "      <td>1.555196</td>\n",
       "      <td>0.740332</td>\n",
       "      <td>0.406602</td>\n",
       "      <td>0.613566</td>\n",
       "      <td>-0.916346</td>\n",
       "      <td>0.858716</td>\n",
       "      <td>0.549606</td>\n",
       "      <td>1.078935</td>\n",
       "      <td>-1.692258</td>\n",
       "      <td>1.014653</td>\n",
       "      <td>0.961638</td>\n",
       "      <td>0.914333</td>\n",
       "      <td>0.894634</td>\n",
       "      <td>-0.298471</td>\n",
       "      <td>-0.919880</td>\n",
       "      <td>0.359629</td>\n",
       "      <td>0.735008</td>\n",
       "      <td>0.732679</td>\n",
       "      <td>0.993608</td>\n",
       "      <td>0.877815</td>\n",
       "      <td>0.177224</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>-0.639378</td>\n",
       "      <td>0.086861</td>\n",
       "      <td>1.315919</td>\n",
       "      <td>-0.101224</td>\n",
       "      <td>-1.226298</td>\n",
       "      <td>2.172071</td>\n",
       "      <td>0.148733</td>\n",
       "      <td>-0.600920</td>\n",
       "      <td>-1.257581</td>\n",
       "      <td>-0.758370</td>\n",
       "      <td>-0.158388</td>\n",
       "      <td>0.992140</td>\n",
       "      <td>-0.947209</td>\n",
       "      <td>-0.970998</td>\n",
       "      <td>0.735689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940107</td>\n",
       "      <td>0.919551</td>\n",
       "      <td>0.952919</td>\n",
       "      <td>-0.215563</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.612595</td>\n",
       "      <td>1.033190</td>\n",
       "      <td>1.008062</td>\n",
       "      <td>1.025747</td>\n",
       "      <td>1.001223</td>\n",
       "      <td>1.008268</td>\n",
       "      <td>0.993381</td>\n",
       "      <td>1.055874</td>\n",
       "      <td>1.020967</td>\n",
       "      <td>0.061592</td>\n",
       "      <td>0.459875</td>\n",
       "      <td>-1.276195</td>\n",
       "      <td>0.991343</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>0.577850</td>\n",
       "      <td>-0.126075</td>\n",
       "      <td>-0.310199</td>\n",
       "      <td>-0.957638</td>\n",
       "      <td>1.542448</td>\n",
       "      <td>0.738576</td>\n",
       "      <td>0.406499</td>\n",
       "      <td>0.598232</td>\n",
       "      <td>-0.917060</td>\n",
       "      <td>0.860844</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>1.079202</td>\n",
       "      <td>-1.697071</td>\n",
       "      <td>0.988697</td>\n",
       "      <td>0.935996</td>\n",
       "      <td>0.889917</td>\n",
       "      <td>0.869355</td>\n",
       "      <td>-0.300329</td>\n",
       "      <td>-0.921484</td>\n",
       "      <td>0.359026</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.744029</td>\n",
       "      <td>0.993512</td>\n",
       "      <td>0.885847</td>\n",
       "      <td>0.176962</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>-0.640471</td>\n",
       "      <td>0.088180</td>\n",
       "      <td>1.262030</td>\n",
       "      <td>-0.108498</td>\n",
       "      <td>-1.228164</td>\n",
       "      <td>2.170132</td>\n",
       "      <td>0.141089</td>\n",
       "      <td>-0.603077</td>\n",
       "      <td>-1.258194</td>\n",
       "      <td>-0.755421</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>0.966198</td>\n",
       "      <td>-0.950140</td>\n",
       "      <td>-0.971536</td>\n",
       "      <td>0.732451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889150</td>\n",
       "      <td>0.985355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095445</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>-0.268319</td>\n",
       "      <td>-0.048965</td>\n",
       "      <td>0.704550</td>\n",
       "      <td>0.630977</td>\n",
       "      <td>0.319543</td>\n",
       "      <td>1.238182</td>\n",
       "      <td>0.644621</td>\n",
       "      <td>0.260919</td>\n",
       "      <td>0.226706</td>\n",
       "      <td>-0.864562</td>\n",
       "      <td>-0.074957</td>\n",
       "      <td>0.734994</td>\n",
       "      <td>0.275188</td>\n",
       "      <td>0.212251</td>\n",
       "      <td>0.808836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695446</td>\n",
       "      <td>-0.572385</td>\n",
       "      <td>0.271100</td>\n",
       "      <td>-0.329852</td>\n",
       "      <td>-0.041634</td>\n",
       "      <td>-0.235736</td>\n",
       "      <td>-0.043706</td>\n",
       "      <td>0.986484</td>\n",
       "      <td>0.936143</td>\n",
       "      <td>0.644041</td>\n",
       "      <td>0.712639</td>\n",
       "      <td>0.951213</td>\n",
       "      <td>0.692853</td>\n",
       "      <td>0.582117</td>\n",
       "      <td>-1.010626</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>0.994249</td>\n",
       "      <td>0.566380</td>\n",
       "      <td>0.513288</td>\n",
       "      <td>0.987455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976221</td>\n",
       "      <td>-0.065708</td>\n",
       "      <td>-0.211067</td>\n",
       "      <td>-0.050416</td>\n",
       "      <td>-0.384979</td>\n",
       "      <td>-0.083556</td>\n",
       "      <td>0.874589</td>\n",
       "      <td>0.740780</td>\n",
       "      <td>0.353198</td>\n",
       "      <td>1.574917</td>\n",
       "      <td>0.762164</td>\n",
       "      <td>0.357834</td>\n",
       "      <td>0.259214</td>\n",
       "      <td>-1.119856</td>\n",
       "      <td>-0.119178</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.386517</td>\n",
       "      <td>0.337772</td>\n",
       "      <td>0.992511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862519</td>\n",
       "      <td>-0.726145</td>\n",
       "      <td>-0.056783</td>\n",
       "      <td>-0.155262</td>\n",
       "      <td>-0.090244</td>\n",
       "      <td>0.185647</td>\n",
       "      <td>0.083393</td>\n",
       "      <td>0.034233</td>\n",
       "      <td>-0.217685</td>\n",
       "      <td>0.070629</td>\n",
       "      <td>-0.030536</td>\n",
       "      <td>-0.022939</td>\n",
       "      <td>-0.368584</td>\n",
       "      <td>-0.254619</td>\n",
       "      <td>0.178949</td>\n",
       "      <td>0.120523</td>\n",
       "      <td>0.186967</td>\n",
       "      <td>0.146406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186951</td>\n",
       "      <td>-0.042180</td>\n",
       "      <td>-0.023528</td>\n",
       "      <td>-0.036379</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>-0.054583</td>\n",
       "      <td>-0.061133</td>\n",
       "      <td>-0.072635</td>\n",
       "      <td>-0.022167</td>\n",
       "      <td>-0.059022</td>\n",
       "      <td>-0.036155</td>\n",
       "      <td>-0.027079</td>\n",
       "      <td>-0.031999</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>-0.055259</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>-0.412778</td>\n",
       "      <td>-0.053504</td>\n",
       "      <td>-0.601446</td>\n",
       "      <td>-0.679248</td>\n",
       "      <td>-0.485087</td>\n",
       "      <td>-1.190648</td>\n",
       "      <td>-0.624625</td>\n",
       "      <td>-0.615579</td>\n",
       "      <td>-0.497177</td>\n",
       "      <td>0.435934</td>\n",
       "      <td>-0.258949</td>\n",
       "      <td>-0.636650</td>\n",
       "      <td>-0.231386</td>\n",
       "      <td>-0.128537</td>\n",
       "      <td>-0.652512</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.592598</td>\n",
       "      <td>-0.061012</td>\n",
       "      <td>0.085413</td>\n",
       "      <td>0.049476</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>0.065724</td>\n",
       "      <td>-0.014739</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>-0.117492</td>\n",
       "      <td>-0.049947</td>\n",
       "      <td>0.087511</td>\n",
       "      <td>0.065007</td>\n",
       "      <td>0.072934</td>\n",
       "      <td>0.097542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085256</td>\n",
       "      <td>1.242106</td>\n",
       "      <td>-0.210524</td>\n",
       "      <td>-1.267674</td>\n",
       "      <td>2.096276</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>-0.635985</td>\n",
       "      <td>-1.286789</td>\n",
       "      <td>-0.698152</td>\n",
       "      <td>-0.141176</td>\n",
       "      <td>1.366072</td>\n",
       "      <td>-0.943381</td>\n",
       "      <td>-0.980172</td>\n",
       "      <td>0.680899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.099466</td>\n",
       "      <td>-0.370880</td>\n",
       "      <td>-1.046674</td>\n",
       "      <td>1.817270</td>\n",
       "      <td>-0.248862</td>\n",
       "      <td>-0.654194</td>\n",
       "      <td>-1.073390</td>\n",
       "      <td>-0.879540</td>\n",
       "      <td>-0.329297</td>\n",
       "      <td>-0.095488</td>\n",
       "      <td>-0.941608</td>\n",
       "      <td>-0.960106</td>\n",
       "      <td>0.481259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.282233</td>\n",
       "      <td>-1.160747</td>\n",
       "      <td>0.799362</td>\n",
       "      <td>-1.085176</td>\n",
       "      <td>-0.951934</td>\n",
       "      <td>-1.166584</td>\n",
       "      <td>0.381011</td>\n",
       "      <td>-0.291673</td>\n",
       "      <td>-1.230555</td>\n",
       "      <td>-1.223212</td>\n",
       "      <td>-0.988468</td>\n",
       "      <td>-0.399639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.294494</td>\n",
       "      <td>3.047031</td>\n",
       "      <td>1.962153</td>\n",
       "      <td>1.132581</td>\n",
       "      <td>0.568410</td>\n",
       "      <td>-2.530558</td>\n",
       "      <td>-0.561158</td>\n",
       "      <td>2.174426</td>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.529119</td>\n",
       "      <td>2.518224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.071162</td>\n",
       "      <td>-0.146268</td>\n",
       "      <td>-0.611906</td>\n",
       "      <td>-1.077990</td>\n",
       "      <td>-0.904715</td>\n",
       "      <td>-0.194272</td>\n",
       "      <td>0.157449</td>\n",
       "      <td>-0.866052</td>\n",
       "      <td>-0.959804</td>\n",
       "      <td>0.594116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.053052</td>\n",
       "      <td>-0.778127</td>\n",
       "      <td>-0.966665</td>\n",
       "      <td>-0.675161</td>\n",
       "      <td>-0.291672</td>\n",
       "      <td>-0.600652</td>\n",
       "      <td>-0.853564</td>\n",
       "      <td>-0.851815</td>\n",
       "      <td>-0.058808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.657487</td>\n",
       "      <td>-1.100477</td>\n",
       "      <td>0.682670</td>\n",
       "      <td>-0.284031</td>\n",
       "      <td>-1.263381</td>\n",
       "      <td>-1.095975</td>\n",
       "      <td>-1.004433</td>\n",
       "      <td>-0.549681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.304789</td>\n",
       "      <td>0.479928</td>\n",
       "      <td>-0.014809</td>\n",
       "      <td>-0.751967</td>\n",
       "      <td>0.367181</td>\n",
       "      <td>0.593423</td>\n",
       "      <td>-0.909171</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.653238</td>\n",
       "      <td>-0.238982</td>\n",
       "      <td>-0.154864</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>0.084333</td>\n",
       "      <td>-0.179932</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.137567</td>\n",
       "      <td>1.008237</td>\n",
       "      <td>-0.946402</td>\n",
       "      <td>-0.970184</td>\n",
       "      <td>0.737165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974775</td>\n",
       "      <td>-0.908946</td>\n",
       "      <td>-0.920057</td>\n",
       "      <td>-0.334848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.955961</td>\n",
       "      <td>-0.941311</td>\n",
       "      <td>-0.537286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.987602</td>\n",
       "      <td>0.456253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.719720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.931259</td>\n",
       "      <td>0.951529</td>\n",
       "      <td>0.985753</td>\n",
       "      <td>-0.317704</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.370781</td>\n",
       "      <td>1.088370</td>\n",
       "      <td>1.076667</td>\n",
       "      <td>1.107336</td>\n",
       "      <td>1.046922</td>\n",
       "      <td>1.056951</td>\n",
       "      <td>1.033390</td>\n",
       "      <td>1.150218</td>\n",
       "      <td>1.094923</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>0.353744</td>\n",
       "      <td>-1.064361</td>\n",
       "      <td>1.038003</td>\n",
       "      <td>1.049343</td>\n",
       "      <td>0.261330</td>\n",
       "      <td>-0.343853</td>\n",
       "      <td>-0.507224</td>\n",
       "      <td>-1.101087</td>\n",
       "      <td>0.938840</td>\n",
       "      <td>0.281735</td>\n",
       "      <td>0.310620</td>\n",
       "      <td>-0.222943</td>\n",
       "      <td>-0.875413</td>\n",
       "      <td>0.545307</td>\n",
       "      <td>0.443501</td>\n",
       "      <td>0.907664</td>\n",
       "      <td>-1.502541</td>\n",
       "      <td>1.048088</td>\n",
       "      <td>0.919514</td>\n",
       "      <td>0.792239</td>\n",
       "      <td>0.745954</td>\n",
       "      <td>-0.466245</td>\n",
       "      <td>-1.068025</td>\n",
       "      <td>0.349003</td>\n",
       "      <td>0.094252</td>\n",
       "      <td>0.095845</td>\n",
       "      <td>0.985753</td>\n",
       "      <td>0.511731</td>\n",
       "      <td>0.356942</td>\n",
       "      <td>-0.073404</td>\n",
       "      <td>-0.519279</td>\n",
       "      <td>0.084169</td>\n",
       "      <td>1.268850</td>\n",
       "      <td>-0.227543</td>\n",
       "      <td>-1.021967</td>\n",
       "      <td>1.983268</td>\n",
       "      <td>0.630890</td>\n",
       "      <td>-0.572253</td>\n",
       "      <td>-0.976521</td>\n",
       "      <td>-0.572253</td>\n",
       "      <td>-0.253494</td>\n",
       "      <td>0.998691</td>\n",
       "      <td>-0.954716</td>\n",
       "      <td>-0.987042</td>\n",
       "      <td>0.790124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.717063</td>\n",
       "      <td>0.960143</td>\n",
       "      <td>0.949297</td>\n",
       "      <td>0.961043</td>\n",
       "      <td>0.978766</td>\n",
       "      <td>-0.307222</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.523366</td>\n",
       "      <td>1.048797</td>\n",
       "      <td>1.034297</td>\n",
       "      <td>1.046957</td>\n",
       "      <td>1.012116</td>\n",
       "      <td>1.017744</td>\n",
       "      <td>1.005649</td>\n",
       "      <td>1.074860</td>\n",
       "      <td>1.041488</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.370382</td>\n",
       "      <td>-1.137476</td>\n",
       "      <td>1.006689</td>\n",
       "      <td>1.015695</td>\n",
       "      <td>0.393215</td>\n",
       "      <td>-0.246309</td>\n",
       "      <td>-0.416660</td>\n",
       "      <td>-0.854362</td>\n",
       "      <td>1.201411</td>\n",
       "      <td>0.347980</td>\n",
       "      <td>0.324658</td>\n",
       "      <td>0.360384</td>\n",
       "      <td>-0.910434</td>\n",
       "      <td>0.578983</td>\n",
       "      <td>0.469935</td>\n",
       "      <td>0.973389</td>\n",
       "      <td>-1.613980</td>\n",
       "      <td>1.012787</td>\n",
       "      <td>0.955614</td>\n",
       "      <td>0.906526</td>\n",
       "      <td>0.888701</td>\n",
       "      <td>-0.422506</td>\n",
       "      <td>-1.047221</td>\n",
       "      <td>0.359787</td>\n",
       "      <td>0.101394</td>\n",
       "      <td>0.102963</td>\n",
       "      <td>1.003811</td>\n",
       "      <td>0.520994</td>\n",
       "      <td>0.354563</td>\n",
       "      <td>-0.080043</td>\n",
       "      <td>-0.560215</td>\n",
       "      <td>0.086268</td>\n",
       "      <td>1.314371</td>\n",
       "      <td>-0.052352</td>\n",
       "      <td>-0.949177</td>\n",
       "      <td>2.077073</td>\n",
       "      <td>0.835831</td>\n",
       "      <td>-0.515108</td>\n",
       "      <td>-0.921806</td>\n",
       "      <td>-0.669044</td>\n",
       "      <td>-0.284078</td>\n",
       "      <td>0.985896</td>\n",
       "      <td>-0.947936</td>\n",
       "      <td>-0.971060</td>\n",
       "      <td>0.885506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928595</td>\n",
       "      <td>0.937267</td>\n",
       "      <td>0.950040</td>\n",
       "      <td>0.966953</td>\n",
       "      <td>-0.306435</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.517342</td>\n",
       "      <td>1.036594</td>\n",
       "      <td>1.024039</td>\n",
       "      <td>1.035750</td>\n",
       "      <td>1.001059</td>\n",
       "      <td>1.006327</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>1.062678</td>\n",
       "      <td>1.031012</td>\n",
       "      <td>0.017035</td>\n",
       "      <td>0.369828</td>\n",
       "      <td>-1.134260</td>\n",
       "      <td>0.995509</td>\n",
       "      <td>1.004357</td>\n",
       "      <td>0.389615</td>\n",
       "      <td>-0.248846</td>\n",
       "      <td>-0.419035</td>\n",
       "      <td>-0.859605</td>\n",
       "      <td>1.197278</td>\n",
       "      <td>0.345774</td>\n",
       "      <td>0.324215</td>\n",
       "      <td>0.344014</td>\n",
       "      <td>-0.909603</td>\n",
       "      <td>0.578029</td>\n",
       "      <td>0.469109</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>-1.610052</td>\n",
       "      <td>1.001450</td>\n",
       "      <td>0.943935</td>\n",
       "      <td>0.894615</td>\n",
       "      <td>0.876644</td>\n",
       "      <td>-0.423610</td>\n",
       "      <td>-1.047780</td>\n",
       "      <td>0.359138</td>\n",
       "      <td>0.099314</td>\n",
       "      <td>0.100901</td>\n",
       "      <td>1.002894</td>\n",
       "      <td>0.518219</td>\n",
       "      <td>0.354220</td>\n",
       "      <td>-0.080384</td>\n",
       "      <td>-0.559489</td>\n",
       "      <td>0.085627</td>\n",
       "      <td>1.292489</td>\n",
       "      <td>-0.057371</td>\n",
       "      <td>-0.950289</td>\n",
       "      <td>2.074023</td>\n",
       "      <td>0.827572</td>\n",
       "      <td>-0.516568</td>\n",
       "      <td>-0.922979</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-0.283041</td>\n",
       "      <td>0.974694</td>\n",
       "      <td>-0.948660</td>\n",
       "      <td>-0.971693</td>\n",
       "      <td>0.882303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907214</td>\n",
       "      <td>0.959705</td>\n",
       "      <td>0.977967</td>\n",
       "      <td>-0.310236</td>\n",
       "      <td>-0.031024</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>1.051337</td>\n",
       "      <td>1.034300</td>\n",
       "      <td>1.048107</td>\n",
       "      <td>1.012989</td>\n",
       "      <td>1.019190</td>\n",
       "      <td>1.005977</td>\n",
       "      <td>1.076770</td>\n",
       "      <td>1.041059</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>0.370726</td>\n",
       "      <td>-1.143164</td>\n",
       "      <td>1.007495</td>\n",
       "      <td>1.016862</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>-0.245949</td>\n",
       "      <td>-0.416792</td>\n",
       "      <td>-0.849340</td>\n",
       "      <td>1.205736</td>\n",
       "      <td>0.348908</td>\n",
       "      <td>0.324894</td>\n",
       "      <td>0.367278</td>\n",
       "      <td>-0.912875</td>\n",
       "      <td>0.581363</td>\n",
       "      <td>0.470534</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>-1.619348</td>\n",
       "      <td>1.013301</td>\n",
       "      <td>0.956798</td>\n",
       "      <td>0.908652</td>\n",
       "      <td>0.890500</td>\n",
       "      <td>-0.422129</td>\n",
       "      <td>-1.047879</td>\n",
       "      <td>0.359607</td>\n",
       "      <td>0.100033</td>\n",
       "      <td>0.101658</td>\n",
       "      <td>1.004413</td>\n",
       "      <td>0.524089</td>\n",
       "      <td>0.354412</td>\n",
       "      <td>-0.087033</td>\n",
       "      <td>-0.561842</td>\n",
       "      <td>0.086996</td>\n",
       "      <td>1.309346</td>\n",
       "      <td>-0.051951</td>\n",
       "      <td>-0.948089</td>\n",
       "      <td>2.078597</td>\n",
       "      <td>0.835671</td>\n",
       "      <td>-0.514829</td>\n",
       "      <td>-0.920964</td>\n",
       "      <td>-0.672127</td>\n",
       "      <td>-0.285530</td>\n",
       "      <td>0.986601</td>\n",
       "      <td>-0.948424</td>\n",
       "      <td>-0.970716</td>\n",
       "      <td>0.886186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927584</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087504</td>\n",
       "      <td>-0.046856</td>\n",
       "      <td>-0.090195</td>\n",
       "      <td>-0.051120</td>\n",
       "      <td>0.096192</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.142664</td>\n",
       "      <td>0.053816</td>\n",
       "      <td>-0.121761</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.032808</td>\n",
       "      <td>0.102125</td>\n",
       "      <td>0.051370</td>\n",
       "      <td>0.059102</td>\n",
       "      <td>0.103338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095737</td>\n",
       "      <td>-0.566651</td>\n",
       "      <td>0.118494</td>\n",
       "      <td>-0.245816</td>\n",
       "      <td>-0.060468</td>\n",
       "      <td>-0.214513</td>\n",
       "      <td>-0.043850</td>\n",
       "      <td>0.996103</td>\n",
       "      <td>0.950661</td>\n",
       "      <td>0.699216</td>\n",
       "      <td>0.691997</td>\n",
       "      <td>1.029365</td>\n",
       "      <td>0.718965</td>\n",
       "      <td>0.660458</td>\n",
       "      <td>-1.000952</td>\n",
       "      <td>-0.211166</td>\n",
       "      <td>1.004274</td>\n",
       "      <td>0.569960</td>\n",
       "      <td>0.515658</td>\n",
       "      <td>1.036297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985481</td>\n",
       "      <td>-0.151183</td>\n",
       "      <td>-0.165900</td>\n",
       "      <td>-0.054342</td>\n",
       "      <td>-0.207833</td>\n",
       "      <td>-0.085255</td>\n",
       "      <td>0.518264</td>\n",
       "      <td>0.421370</td>\n",
       "      <td>0.239701</td>\n",
       "      <td>0.853734</td>\n",
       "      <td>0.482669</td>\n",
       "      <td>0.178439</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>-0.700257</td>\n",
       "      <td>-0.117652</td>\n",
       "      <td>0.522140</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.231872</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511385</td>\n",
       "      <td>-0.704640</td>\n",
       "      <td>-0.064176</td>\n",
       "      <td>-0.220034</td>\n",
       "      <td>-0.087848</td>\n",
       "      <td>0.357713</td>\n",
       "      <td>0.238382</td>\n",
       "      <td>0.126271</td>\n",
       "      <td>0.104657</td>\n",
       "      <td>0.255642</td>\n",
       "      <td>0.072821</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>-0.561251</td>\n",
       "      <td>-0.284622</td>\n",
       "      <td>0.356359</td>\n",
       "      <td>0.196231</td>\n",
       "      <td>0.235167</td>\n",
       "      <td>0.359242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356627</td>\n",
       "      <td>-0.041808</td>\n",
       "      <td>-0.012231</td>\n",
       "      <td>-0.036505</td>\n",
       "      <td>-0.074139</td>\n",
       "      <td>-0.198295</td>\n",
       "      <td>-0.156053</td>\n",
       "      <td>-0.203585</td>\n",
       "      <td>-0.144723</td>\n",
       "      <td>-0.157165</td>\n",
       "      <td>-0.123725</td>\n",
       "      <td>0.033385</td>\n",
       "      <td>-0.024694</td>\n",
       "      <td>-0.079534</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>-0.266269</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>-0.449238</td>\n",
       "      <td>-0.052469</td>\n",
       "      <td>-0.526809</td>\n",
       "      <td>-0.615647</td>\n",
       "      <td>-0.491579</td>\n",
       "      <td>-1.022710</td>\n",
       "      <td>-0.608588</td>\n",
       "      <td>-0.588204</td>\n",
       "      <td>-0.528555</td>\n",
       "      <td>0.327222</td>\n",
       "      <td>-0.240963</td>\n",
       "      <td>-0.557337</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.107525</td>\n",
       "      <td>-0.596256</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.518794</td>\n",
       "      <td>-0.061016</td>\n",
       "      <td>0.084299</td>\n",
       "      <td>0.048277</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.069582</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>-0.115651</td>\n",
       "      <td>-0.050974</td>\n",
       "      <td>0.086329</td>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.072686</td>\n",
       "      <td>0.099162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084139</td>\n",
       "      <td>1.273822</td>\n",
       "      <td>-0.159738</td>\n",
       "      <td>-0.993302</td>\n",
       "      <td>2.005353</td>\n",
       "      <td>0.707373</td>\n",
       "      <td>-0.550876</td>\n",
       "      <td>-0.955792</td>\n",
       "      <td>-0.613707</td>\n",
       "      <td>-0.258246</td>\n",
       "      <td>1.375495</td>\n",
       "      <td>-0.942990</td>\n",
       "      <td>-0.979981</td>\n",
       "      <td>0.828743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.129757</td>\n",
       "      <td>-0.324627</td>\n",
       "      <td>-0.858385</td>\n",
       "      <td>1.754893</td>\n",
       "      <td>0.126468</td>\n",
       "      <td>-0.586437</td>\n",
       "      <td>-0.846962</td>\n",
       "      <td>-0.810014</td>\n",
       "      <td>-0.459422</td>\n",
       "      <td>-0.044788</td>\n",
       "      <td>-0.931162</td>\n",
       "      <td>-0.954872</td>\n",
       "      <td>0.632004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232788</td>\n",
       "      <td>-1.010689</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>-0.697803</td>\n",
       "      <td>-0.833494</td>\n",
       "      <td>-0.994636</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>-0.388915</td>\n",
       "      <td>-0.950439</td>\n",
       "      <td>-1.129918</td>\n",
       "      <td>-0.944992</td>\n",
       "      <td>-0.131550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.023636</td>\n",
       "      <td>2.742247</td>\n",
       "      <td>2.154943</td>\n",
       "      <td>1.162007</td>\n",
       "      <td>0.842031</td>\n",
       "      <td>-2.340765</td>\n",
       "      <td>-0.693459</td>\n",
       "      <td>2.079322</td>\n",
       "      <td>0.951400</td>\n",
       "      <td>0.506535</td>\n",
       "      <td>2.569891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.980735</td>\n",
       "      <td>0.572554</td>\n",
       "      <td>-0.407254</td>\n",
       "      <td>-0.717088</td>\n",
       "      <td>-1.182880</td>\n",
       "      <td>-0.348118</td>\n",
       "      <td>0.853819</td>\n",
       "      <td>-0.744891</td>\n",
       "      <td>-0.893272</td>\n",
       "      <td>1.041379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623960</td>\n",
       "      <td>-0.722554</td>\n",
       "      <td>-0.840436</td>\n",
       "      <td>-0.766401</td>\n",
       "      <td>-0.383299</td>\n",
       "      <td>-0.513733</td>\n",
       "      <td>-0.824376</td>\n",
       "      <td>-0.835351</td>\n",
       "      <td>0.088001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.573865</td>\n",
       "      <td>-0.953148</td>\n",
       "      <td>0.148155</td>\n",
       "      <td>-0.376226</td>\n",
       "      <td>-0.924211</td>\n",
       "      <td>-0.986171</td>\n",
       "      <td>-0.943042</td>\n",
       "      <td>-0.215634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.977793</td>\n",
       "      <td>0.371508</td>\n",
       "      <td>0.099343</td>\n",
       "      <td>-0.665246</td>\n",
       "      <td>0.396351</td>\n",
       "      <td>0.610003</td>\n",
       "      <td>-0.961758</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.569602</td>\n",
       "      <td>-0.226705</td>\n",
       "      <td>-0.279488</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>0.057213</td>\n",
       "      <td>-0.350140</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.253319</td>\n",
       "      <td>1.008156</td>\n",
       "      <td>-0.946406</td>\n",
       "      <td>-0.970186</td>\n",
       "      <td>0.887194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974755</td>\n",
       "      <td>-0.908946</td>\n",
       "      <td>-0.920057</td>\n",
       "      <td>-0.281338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.955958</td>\n",
       "      <td>-0.941311</td>\n",
       "      <td>-0.507491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.987600</td>\n",
       "      <td>0.656779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.716393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open      high       low     close    volume      fake  volatility_atr  volatility_bbh  volatility_bbl  volatility_bbm  volatility_kcc  volatility_kch  volatility_kcl  volatility_dch  volatility_dcl  trend_macd  trend_macd_signal  trend_macd_diff  trend_ema_fast  trend_ema_slow  trend_adx  trend_adx_pos  trend_adx_neg  trend_vortex_ind_pos  trend_vortex_ind_neg  trend_vortex_diff  trend_trix  trend_mass_index  trend_cci  trend_dpo  trend_kst  trend_kst_sig  trend_kst_diff  trend_ichimoku_a  trend_ichimoku_b  trend_visual_ichimoku_a  trend_visual_ichimoku_b  trend_aroon_up  trend_aroon_down  trend_aroon_ind  others_dr  others_dlr  others_cr  volume_adi  volume_cmf  volume_fi  volume_em  volume_vpt  volume_nvi  momentum_rsi  momentum_mfi  momentum_tsi  momentum_uo  momentum_stoch  momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama       Day  Dayofweek      Hour  Minute   Elapsed    open^2  open high  open low  open close  open volume  open fake  open volatility_atr  \\\n",
       "0  1.115167  1.061529  0.977340  0.939421  0.607035 -0.031024        0.563340        1.101099        1.051955        1.100725        1.146237        1.152766        1.135801        1.150218        1.052307    0.455894           0.715358        -0.765850        1.115534        1.081382   0.979734      -0.405030      -0.499584             -0.422855              0.039964          -1.056991    0.636169          0.346047  -0.663183   0.854971   0.930836       1.260959       -1.034186          1.063465          0.919514                 0.760628                 0.716554        0.011837         -1.311744         0.779564  -1.862537   -1.858758   0.939421   -0.670494   -0.325491  -0.261555   0.457529   -0.216362    1.123375     -0.527758     -1.124479      2.447305     0.091104       -1.832772              -0.685978    -1.832772     0.472445       1.043151 -0.954716  -0.987042  0.211442     0.0 -1.730386  1.131502   1.103554  1.059935    1.039824     0.648410  -0.031024             0.756797   \n",
       "1  0.921270  0.896015  0.885663  0.902630 -0.054063 -0.031024        0.523018        1.099248        1.055340        1.101577        1.114948        1.121236        1.104858        1.150218        1.052307    0.273638           0.628506        -1.111212        1.083796        1.068989   0.793620      -0.550285      -0.097646             -0.492012              0.425631          -0.669262    0.558719          0.220353  -1.257810   0.343104   0.768075       1.188595       -1.340759          1.040085          0.919514                 0.825597                 0.745954       -0.107683         -1.433603         0.779564  -0.357560   -0.354062   0.902630   -0.942986    0.003810   0.063043   0.274742   -0.215141    0.999475     -0.677092     -1.073565      2.304146     0.047483       -1.467585              -1.321750    -1.467585     0.268124       1.017398 -0.954716  -0.987042  0.356112     0.0 -1.727055  0.927302   0.914393  0.909908    0.918639    -0.037753  -0.031024             0.686476   \n",
       "2  0.889089  0.867764  0.901325  0.905753  0.541127 -0.031024        0.419636        1.104271        1.043529        1.097888        1.086304        1.089870        1.078994        1.150218        1.052307    0.130338           0.528851        -1.280122        1.057431        1.057815   0.620800      -0.639013      -0.197723             -0.786403              1.592578           0.575557    0.469572          0.088547  -1.224044   1.231124   0.648556       1.101455       -1.453999          1.040085          0.919514                 0.807504                 0.745954       -0.227204         -1.433603         0.707803   0.034136    0.036031   0.905753    0.784309   -0.111292   0.025260  -0.634144    0.036010    0.999475     -0.660075     -1.540662      2.175984    -0.188135       -1.439752              -1.734333    -1.439752     0.054234       0.999686 -0.954716  -0.987042  0.500783     0.0 -1.723724  0.893566   0.882721  0.901350    0.903397     0.569882  -0.031024             0.568911   \n",
       "3  0.913072  0.964062  0.913308  0.976484 -0.226430 -0.031024        0.449692        1.093563        1.065020        1.103818        1.063343        1.075325        1.047832        1.150218        1.094923    0.068818           0.436374        -1.190046        1.046126        1.053032   0.434408      -0.222965      -0.401559             -1.203557              1.277530           0.657353    0.386101          0.074247  -0.880784   0.809842   0.517230       1.005304       -1.577098          1.040085          0.919514                 0.796032                 0.745954       -0.346725         -0.946166         0.349003   0.698409    0.696151   0.976484    0.863142    0.187037   0.004465  -0.593177    0.085287    1.237640     -0.277073     -1.293219      2.073797    -0.047106       -0.655982              -1.303960    -0.655982    -0.137625       0.998769 -0.954716  -0.987042  0.645453     0.0 -1.720394  0.918704   0.945691  0.920205    0.953119    -0.214281  -0.031024             0.604954   \n",
       "4  0.952555  0.931259  0.951529  0.985753 -0.317704 -0.031024        0.370781        1.088370        1.076667        1.107336        1.046922        1.056951        1.033390        1.150218        1.094923    0.026935           0.353744        -1.064361        1.038003        1.049343   0.261330      -0.343853      -0.507224             -1.101087              0.938840           0.281735    0.310620         -0.222943  -0.875413   0.545307   0.443501       0.907664       -1.502541          1.048088          0.919514                 0.792239                 0.745954       -0.466245         -1.068025         0.349003   0.094252    0.095845   0.985753    0.511731    0.356942  -0.073404  -0.519279    0.084169    1.268850     -0.227543     -1.021967      1.983268     0.630890       -0.572253              -0.976521    -0.572253    -0.253494       0.998691 -0.954716  -0.987042  0.790124     0.0 -1.717063  0.960143   0.949297  0.961043    0.978766    -0.307222  -0.031024             0.523366   \n",
       "\n",
       "   open volatility_bbh  open volatility_bbl  open volatility_bbm  open volatility_kcc  open volatility_kch  open volatility_kcl  open volatility_dch  open volatility_dcl  open trend_macd  open trend_macd_signal  open trend_macd_diff  open trend_ema_fast  open trend_ema_slow  open trend_adx  open trend_adx_pos  open trend_adx_neg  open trend_vortex_ind_pos  open trend_vortex_ind_neg  open trend_vortex_diff  open trend_trix  open trend_mass_index  open trend_cci  open trend_dpo  open trend_kst  open trend_kst_sig  open trend_kst_diff  open trend_ichimoku_a  open trend_ichimoku_b  open trend_visual_ichimoku_a  open trend_visual_ichimoku_b  open trend_aroon_up  open trend_aroon_down  open trend_aroon_ind  open others_dr  open others_dlr  open others_cr  open volume_adi  open volume_cmf  open volume_fi  open volume_em  open volume_vpt  open volume_nvi  open momentum_rsi  open momentum_mfi  open momentum_tsi  open momentum_uo  open momentum_stoch  open momentum_stoch_signal  \\\n",
       "0             1.143733             1.105303             1.130221             1.150714             1.154757             1.145707             1.163156             1.103555         0.484347                0.767633             -0.823548             1.133770             1.119586        1.193973           -0.292550           -0.393602                  -0.147390                   0.319155               -1.049312         0.682902               0.938533       -0.694635        0.912677        1.004965            1.365716            -1.117893               1.107353               1.043594                      0.977150                      0.962291             0.082960              -1.299937              0.813160       -1.975116        -1.971485        0.957045        -0.695333        -0.360863       -0.282328        0.492300        -0.237091         1.433412          -0.327244          -1.044427           2.582484          0.322462            -1.813602                   -0.613776   \n",
       "1             1.037563             1.006507             1.027242             1.031238             1.034633             1.026980             1.057873             1.002305         0.283612                0.667645             -1.186088             1.014039             1.009173        0.964633           -0.461501            0.005472                  -0.260345                   0.666337               -0.646669         0.593591               0.717860       -1.305561        0.364533        0.820863            1.276622            -1.438230               0.991971               0.938687                      0.907616                      0.871501            -0.053186              -1.428956              0.806740       -0.374601        -0.371085        0.913277        -0.968433        -0.013612        0.065162        0.291658        -0.233529         1.203354          -0.510086          -1.004087           2.410889          0.237527            -1.438578                   -1.277277   \n",
       "2             1.022749             0.983424             1.008144             0.999149             1.001099             0.996357             1.040399             0.985501         0.128512                0.558950             -1.364780             0.983178             0.986116        0.773753           -0.555566           -0.101780                  -0.557509                   1.852605                0.650001         0.496182               0.587591       -1.268947        1.301385        0.690517            1.180635            -1.557760               0.974864               0.921276                      0.880477                      0.853810            -0.178526              -1.429121              0.731201        0.037915         0.039794        0.916034         0.798396        -0.133145        0.024985       -0.682052         0.034802         1.171308          -0.498222          -1.484103           2.273245         -0.007567            -1.410603                   -1.700839   \n",
       "3             1.030122             1.007487             1.024045             0.999824             1.006301             0.992521             1.053421             1.020834         0.062125                0.459313             -1.269898             0.989997             0.996472        0.575595           -0.126393           -0.310702                  -0.963393                   1.537232                0.737244         0.406070               0.589409       -0.914580        0.857545        0.549006            1.077614            -1.691405               0.987613               0.934252                      0.887251                      0.866994            -0.300744              -0.921042              0.359193        0.737367         0.734959        0.992902         0.879776         0.177299        0.002885       -0.638699         0.087410         1.265688          -0.109278          -1.229596           2.168440          0.140025            -0.603526                   -1.259318   \n",
       "4             1.048797             1.034297             1.046957             1.012116             1.017744             1.005649             1.074860             1.041488         0.016858                0.370382             -1.137476             1.006689             1.015695        0.393215           -0.246309           -0.416660                  -0.854362                   1.201411                0.347980         0.324658               0.360384       -0.910434        0.578983        0.469935            0.973389            -1.613980               1.012787               0.955614                      0.906526                      0.888701            -0.422506              -1.047221              0.359787        0.101394         0.102963        1.003811         0.520994         0.354563       -0.080043       -0.560215         0.086268         1.314371          -0.052352          -0.949177           2.077073          0.835831            -0.515108                   -0.921806   \n",
       "\n",
       "   open momentum_wr  open momentum_ao  open momentum_kama  open Day  open Dayofweek  open Hour  open Minute  open Elapsed    high^2  high low  high close  high volume  high fake  high volatility_atr  high volatility_bbh  high volatility_bbl  high volatility_bbm  high volatility_kcc  high volatility_kch  high volatility_kcl  high volatility_dch  high volatility_dcl  high trend_macd  high trend_macd_signal  high trend_macd_diff  high trend_ema_fast  high trend_ema_slow  high trend_adx  high trend_adx_pos  high trend_adx_neg  high trend_vortex_ind_pos  high trend_vortex_ind_neg  high trend_vortex_diff  high trend_trix  high trend_mass_index  high trend_cci  high trend_dpo  high trend_kst  high trend_kst_sig  high trend_kst_diff  high trend_ichimoku_a  high trend_ichimoku_b  high trend_visual_ichimoku_a  high trend_visual_ichimoku_b  high trend_aroon_up  high trend_aroon_down  high trend_aroon_ind  high others_dr  high others_dlr  high others_cr  high volume_adi  high volume_cmf  \\\n",
       "0         -2.004493          0.503652            1.095685 -0.940708       -0.967602   0.298372          0.0      1.091681  1.074236  1.031837    1.010796     0.640413  -0.031024             0.745261             1.113768             1.078108             1.101589             1.122378             1.125925             1.117876             1.133191             1.076015         0.482654                0.765196             -0.820159             1.105274             1.090759        1.184065           -0.298260           -0.399039                  -0.160958                   0.305708               -1.049479         0.680791               0.900082       -0.693270        0.910044        1.001610            1.361533            -1.113651               1.078641               1.014241                      0.947597                      0.932278             0.078837              -1.300576              0.810820       -1.966759        -1.963309        0.955521        -0.691728        -0.359490   \n",
       "1         -1.595751          0.279302            0.978986 -0.949326       -0.971725   0.432922          0.0      0.897003  0.900334  0.896830    0.904776    -0.039074  -0.031024             0.679164             1.023277             0.994208             1.013966             1.018174             1.021189             1.014291             1.043601             0.989761         0.283034                0.666323             -1.182544             1.000834             0.995773        0.959417           -0.463597            0.002489                  -0.267092                   0.660498               -0.647283         0.592470               0.697512       -1.303888        0.363824        0.819119            1.274212            -1.434494               0.978571               0.924914                      0.893636                      0.857316            -0.055173              -1.429148              0.805368       -0.374826        -0.371341        0.912424        -0.964433        -0.013403   \n",
       "2         -1.562483          0.048393            0.952658 -0.950757       -0.972410   0.579793          0.0      0.864741  0.870767  0.890371    0.891641     0.564092  -0.031024             0.562695             1.010643             0.973180             0.996997             0.988183             0.989773             0.985747             1.028309             0.975038         0.128391                0.557978             -1.360908             0.972077             0.974851        0.769454           -0.556923           -0.104273                  -0.563023                   1.849382                0.647297         0.495368               0.570228       -1.267542        1.299423        0.689200            1.178614            -1.553979               0.963591               0.909667                      0.868651                      0.841823            -0.180051              -1.429292              0.730062        0.036074         0.037965        0.915254         0.794394        -0.132797   \n",
       "3         -0.752050         -0.158585            0.964937 -0.949691       -0.971900   0.731708          0.0      0.888884  0.971690  0.946936    0.979281    -0.213121  -0.031024             0.607836             1.057071             1.034720             1.051356             1.027034             1.033380             1.019823             1.080434             1.048137         0.062324                0.459864             -1.270014             1.017125             1.023808        0.580444           -0.121481           -0.306122                  -0.954109                   1.555196                0.740332         0.406602               0.613566       -0.916346        0.858716        0.549606            1.078935            -1.692258               1.014653               0.961638                      0.914333                      0.894634            -0.298471              -0.919880              0.359629        0.735008         0.732679        0.993608         0.877815         0.177224   \n",
       "4         -0.669044         -0.284078            0.985896 -0.947936       -0.971060   0.885506          0.0      0.928595  0.937267  0.950040    0.966953    -0.306435  -0.031024             0.517342             1.036594             1.024039             1.035750             1.001059             1.006327             0.994945             1.062678             1.031012         0.017035                0.369828             -1.134260             0.995509             1.004357        0.389615           -0.248846           -0.419035                  -0.859605                   1.197278                0.345774         0.324215               0.344014       -0.909603        0.578029        0.469109            0.971751            -1.610052               1.001450               0.943935                      0.894615                      0.876644            -0.423610              -1.047780              0.359138        0.099314         0.100901        1.002894         0.518219         0.354220   \n",
       "\n",
       "   high volume_fi  high volume_em  high volume_vpt  high volume_nvi  high momentum_rsi  high momentum_mfi  high momentum_tsi  high momentum_uo  high momentum_stoch  high momentum_stoch_signal  high momentum_wr  high momentum_ao  high momentum_kama  high Day  high Dayofweek  high Hour  high Minute  high Elapsed     low^2  low close  low volume  low fake  low volatility_atr  low volatility_bbh  low volatility_bbl  low volatility_bbm  low volatility_kcc  low volatility_kch  low volatility_kcl  low volatility_dch  low volatility_dcl  low trend_macd  low trend_macd_signal  low trend_macd_diff  low trend_ema_fast  low trend_ema_slow  low trend_adx  low trend_adx_pos  low trend_adx_neg  low trend_vortex_ind_pos  low trend_vortex_ind_neg  low trend_vortex_diff  low trend_trix  low trend_mass_index  low trend_cci  low trend_dpo  low trend_kst  low trend_kst_sig  low trend_kst_diff  low trend_ichimoku_a  low trend_ichimoku_b  low trend_visual_ichimoku_a  low trend_visual_ichimoku_b  \\\n",
       "0       -0.281914        0.490412        -0.235496         1.378963          -0.336642          -1.047362           2.575086          0.308995            -1.812166                   -0.617308         -1.998547          0.501883            1.067122 -0.942901       -0.968935   0.293407          0.0      1.037838  0.986856   0.967321    0.656191 -0.031024            0.747072            1.072151            1.034425            1.058495            1.078817            1.083044            1.073716            1.090881            1.031840        0.482528               0.764725            -0.823325            1.061779            1.047452       1.177166          -0.306093          -0.406380                 -0.177295                  0.287866              -1.050990        0.680229              0.867950      -0.693076       0.911067       1.001298           1.360246           -1.115546              1.035129              0.970846                     0.905633                     0.889092   \n",
       "1        0.064559        0.290845        -0.232290         1.177434          -0.513844          -1.005339           2.406958          0.230417            -1.437944                   -1.278126         -1.594228          0.278752            0.965735 -0.950218       -0.972439   0.430024          0.0      0.871641  0.890547   0.899739   -0.036577 -0.031024            0.689978            1.021074            0.988419            1.009736            1.013453            1.017316            1.008769            1.040760            0.983734        0.283375               0.667727            -1.190276            0.996206            0.991568       0.962561          -0.464262           0.003629                 -0.266278                  0.660377              -0.647521        0.593585              0.706230      -1.306727       0.365701       0.821117           1.276696           -1.441001              0.973919              0.920950                     0.890774                     0.854061   \n",
       "2        0.024460       -0.681119         0.034457         1.149351          -0.501376          -1.484218           2.269932         -0.013046            -1.409955                   -1.701017         -1.561507          0.048518            0.941521 -0.951466       -0.973037   0.577033          0.0      0.843320  0.906975   0.909622    0.583689 -0.031024            0.577784            1.032274            0.990228            1.016213            1.006842            1.009409            1.003452            1.049323            0.991953        0.128242               0.560006            -1.372146            0.990839            0.994212       0.777893          -0.553646          -0.098932                 -0.551210                  1.862135               0.652200        0.497047              0.603351      -1.272537       1.306744       0.691996           1.182982           -1.563778              0.982291              0.929474                     0.889570                     0.862725   \n",
       "3        0.002344       -0.639378         0.086861         1.315919          -0.101224          -1.226298           2.172071          0.148733            -0.600920                   -1.257581         -0.758370         -0.158388            0.992140 -0.947209       -0.970998   0.735689          0.0      0.940107  0.919551   0.952919   -0.215563 -0.031024            0.612595            1.033190            1.008062            1.025747            1.001223            1.008268            0.993381            1.055874            1.020967        0.061592               0.459875            -1.276195            0.991343            0.998186       0.577850          -0.126075          -0.310199                 -0.957638                  1.542448               0.738576        0.406499              0.598232      -0.917060       0.860844       0.549812           1.079202           -1.697071              0.988697              0.935996                     0.889917                     0.869355   \n",
       "4       -0.080384       -0.559489         0.085627         1.292489          -0.057371          -0.950289           2.074023          0.827572            -0.516568                   -0.922979         -0.667937         -0.283041            0.974694 -0.948660       -0.971693   0.882303          0.0      0.907214  0.959705   0.977967   -0.310236 -0.031024            0.530198            1.051337            1.034300            1.048107            1.012989            1.019190            1.005977            1.076770            1.041059        0.016183               0.370726            -1.143164            1.007495            1.016862       0.395056          -0.245949          -0.416792                 -0.849340                  1.205736               0.348908        0.324894              0.367278      -0.912875       0.581363       0.470534           0.974752           -1.619348              1.013301              0.956798                     0.908652                     0.890500   \n",
       "\n",
       "   low trend_aroon_up  low trend_aroon_down  low trend_aroon_ind  low others_dr  low others_dlr  low others_cr  low volume_adi  low volume_cmf  low volume_fi  low volume_em  low volume_vpt  low volume_nvi  low momentum_rsi  low momentum_mfi  low momentum_tsi  low momentum_uo  low momentum_stoch  low momentum_stoch_signal  low momentum_wr  low momentum_ao  low momentum_kama   low Day  low Dayofweek  low Hour  low Minute  low Elapsed   close^2  ...  others_dlr volume_cmf  others_dlr volume_fi  others_dlr volume_em  others_dlr volume_vpt  others_dlr volume_nvi  others_dlr momentum_rsi  others_dlr momentum_mfi  others_dlr momentum_tsi  others_dlr momentum_uo  others_dlr momentum_stoch  others_dlr momentum_stoch_signal  others_dlr momentum_wr  others_dlr momentum_ao  others_dlr momentum_kama  others_dlr Day  others_dlr Dayofweek  others_dlr Hour  others_dlr Minute  others_dlr Elapsed  others_cr^2  others_cr volume_adi  others_cr volume_cmf  others_cr volume_fi  others_cr volume_em  \\\n",
       "0            0.074450             -1.302379             0.808646      -1.998386       -1.995751       0.954763       -0.698111       -0.358850      -0.298934       0.489050       -0.246257        1.292333         -0.348741         -1.051563          2.569360         0.294408           -1.812204                  -0.621349        -1.989827         0.501835           1.023517 -0.947265      -0.970162  0.288208         0.0     0.953273  0.946414  ...               0.512923              0.000809             -0.676706               0.005204              -1.882191                -1.863997                -1.161375                -3.961776               -1.973999                  -0.288932                         -1.331480                2.647665               -0.440317                 -1.961942       -0.677383             -0.439552        -1.807585               -0.0           -1.856910    -0.594282             -0.387835             -0.560847            -0.099710             0.087823   \n",
       "1           -0.054936             -1.430372             0.805584      -0.382960       -0.379605       0.913100       -0.976103       -0.013887       0.066271       0.290814       -0.243792        1.164657         -0.513662         -1.005158          2.409033         0.230945           -1.437744                  -1.277355        -1.596148         0.279137           0.961060 -0.951382      -0.972129  0.430544         0.0     0.861279  0.907816  ...              -0.056366             -0.047393             -0.146733              -0.040558              -0.358771                -0.405775                -0.268791                -0.734045               -0.417335                  -0.269533                         -0.185586                0.325871               -0.064813                 -0.372464       -0.116373             -0.055677        -0.383806               -0.0           -0.353721    -0.614390             -0.468438             -0.406323            -0.029171             0.024924   \n",
       "2           -0.177461             -1.430290             0.731563       0.035564        0.037472       0.916778        0.804158       -0.133968       0.023902      -0.684170        0.033684        1.180244         -0.494071         -1.481894          2.276208        -0.003929           -1.408840                  -1.699209        -1.569366         0.047944           0.960265 -0.950678      -0.971793  0.581581         0.0     0.877062  0.911090  ...              -0.103492             -0.046082             -0.077491              -0.051492               0.035450                -0.044317                -0.033195                 0.043352               -0.019451                  -0.175992                         -0.040606               -0.202411               -0.019948                  0.039068        0.029069              0.043843         0.023411                0.0            0.035982    -0.612746              0.190935             -0.455008            -0.036815            -0.225143   \n",
       "3           -0.300329             -0.921484             0.359026       0.746114        0.744029       0.993512        0.885847        0.176962       0.000557      -0.640471        0.088180        1.262030         -0.108498         -1.228164          2.170132         0.141089           -0.603077                  -1.258194        -0.755421        -0.159672           0.966198 -0.950140      -0.971536  0.732451         0.0     0.889150  0.985355  ...              -0.095445             -0.047175             -0.268319              -0.048965               0.704550                 0.630977                 0.319543                 1.238182                0.644621                   0.260919                          0.226706               -0.864562               -0.074957                  0.734994        0.275188              0.212251         0.808836                0.0            0.695446    -0.572385              0.271100             -0.329852            -0.041634            -0.235736   \n",
       "4           -0.422129             -1.047879             0.359607       0.100033        0.101658       1.004413        0.524089        0.354412      -0.087033      -0.561842        0.086996        1.309346         -0.051951         -0.948089          2.078597         0.835671           -0.514829                  -0.920964        -0.672127        -0.285530           0.986601 -0.948424      -0.970716  0.886186         0.0     0.927584  0.995102  ...              -0.087504             -0.046856             -0.090195              -0.051120               0.096192                 0.020370                 0.011492                 0.142664                0.053816                  -0.121761                          0.003367               -0.250227               -0.032808                  0.102125        0.051370              0.059102         0.103338                0.0            0.095737    -0.566651              0.118494             -0.245816            -0.060468            -0.214513   \n",
       "\n",
       "   others_cr volume_vpt  others_cr volume_nvi  others_cr momentum_rsi  others_cr momentum_mfi  others_cr momentum_tsi  others_cr momentum_uo  others_cr momentum_stoch  others_cr momentum_stoch_signal  others_cr momentum_wr  others_cr momentum_ao  others_cr momentum_kama  others_cr Day  others_cr Dayofweek  others_cr Hour  others_cr Minute  others_cr Elapsed  volume_adi^2  volume_adi volume_cmf  volume_adi volume_fi  volume_adi volume_em  volume_adi volume_vpt  volume_adi volume_nvi  volume_adi momentum_rsi  volume_adi momentum_mfi  volume_adi momentum_tsi  volume_adi momentum_uo  volume_adi momentum_stoch  volume_adi momentum_stoch_signal  volume_adi momentum_wr  volume_adi momentum_ao  volume_adi momentum_kama  volume_adi Day  volume_adi Dayofweek  volume_adi Hour  volume_adi Minute  volume_adi Elapsed  volume_cmf^2  volume_cmf volume_fi  volume_cmf volume_em  volume_cmf volume_vpt  volume_cmf volume_nvi  volume_cmf momentum_rsi  volume_cmf momentum_mfi  volume_cmf momentum_tsi  \\\n",
       "0             -0.115694              0.948152                0.874646                0.655416                0.786345               0.927769                  0.408005                         0.697431              -1.227249              -0.006703                 0.955054       0.552067             0.503810        0.840263               0.0           0.939194     -0.092074               0.002959             -0.021367             -0.385225              -0.058934              -0.680253                -0.636124                -0.368572                -1.649068               -0.740354                  -0.130406                         -0.460571                1.028929               -0.251365                 -0.691761       -0.246371             -0.124399        -0.633079               -0.0           -0.669911     -0.545167              0.007253             -0.410290              -0.027163              -0.332497                -0.352721                -0.223743                -1.400502   \n",
       "1             -0.110471              0.910147                0.827100                0.643901                0.662582               0.887032                  0.481154                         0.551686              -1.091287              -0.067418                 0.914703       0.537858             0.494401        0.837284               0.0           0.902443     -0.002658              -0.108827             -0.053896             -0.359510              -0.048400              -0.954817                -0.842067                -0.522272                -2.144668               -1.002784                  -0.300807                         -0.361429                1.320572               -0.197816                 -0.970708       -0.358821             -0.206516        -0.962719               -0.0           -0.942190     -0.703857             -0.059979             -0.213627              -0.068247               0.000675                -0.067234                -0.060902                -0.616840   \n",
       "2             -0.055662              0.913313                0.831460                0.571555                0.624498               0.869829                  0.487621                         0.472875              -1.090328              -0.120950                 0.917751       0.539065             0.495200        0.872649               0.0           0.905565     -0.088991              -0.340517             -0.048211             -0.377351              -0.089180               0.792496                 0.609216                 0.256633                 1.486667                0.665932                   0.065364                          0.099927               -1.297535               -0.016777                  0.801751        0.353985              0.314015         0.847608                0.0            0.783746     -0.665719             -0.057145             -0.009886              -0.087946              -0.115514                -0.162617                -0.074114                -0.834911   \n",
       "3             -0.043706              0.986484                0.936143                0.644041                0.712639               0.951213                  0.692853                         0.582117              -1.010626              -0.175778                 0.994249       0.566380             0.513288        0.987455               0.0           0.976221     -0.065708              -0.211067             -0.050416             -0.384979              -0.083556               0.874589                 0.740780                 0.353198                 1.574917                0.762164                   0.357834                          0.259214               -1.119856               -0.119178                  0.882582        0.386517              0.337772         0.992511                0.0            0.862519     -0.726145             -0.056783             -0.155262              -0.090244               0.185647                 0.083393                 0.034233                -0.217685   \n",
       "4             -0.043850              0.996103                0.950661                0.699216                0.691997               1.029365                  0.718965                         0.660458              -1.000952              -0.211166                 1.004274       0.569960             0.515658        1.036297               0.0           0.985481     -0.151183              -0.165900             -0.054342             -0.207833              -0.085255               0.518264                 0.421370                 0.239701                 0.853734                0.482669                   0.178439                          0.200039               -0.700257               -0.117652                  0.522140        0.241500              0.231872         0.617426                0.0            0.511385     -0.704640             -0.064176             -0.220034              -0.087848               0.357713                 0.238382                 0.126271                 0.104657   \n",
       "\n",
       "   volume_cmf momentum_uo  volume_cmf momentum_stoch  volume_cmf momentum_stoch_signal  volume_cmf momentum_wr  volume_cmf momentum_ao  volume_cmf momentum_kama  volume_cmf Day  volume_cmf Dayofweek  volume_cmf Hour  volume_cmf Minute  volume_cmf Elapsed  volume_fi^2  volume_fi volume_em  volume_fi volume_vpt  volume_fi volume_nvi  volume_fi momentum_rsi  volume_fi momentum_mfi  volume_fi momentum_tsi  volume_fi momentum_uo  volume_fi momentum_stoch  volume_fi momentum_stoch_signal  volume_fi momentum_wr  volume_fi momentum_ao  volume_fi momentum_kama  volume_fi Day  volume_fi Dayofweek  volume_fi Hour  volume_fi Minute  volume_fi Elapsed  volume_em^2  volume_em volume_vpt  volume_em volume_nvi  volume_em momentum_rsi  volume_em momentum_mfi  volume_em momentum_tsi  volume_em momentum_uo  volume_em momentum_stoch  volume_em momentum_stoch_signal  volume_em momentum_wr  volume_em momentum_ao  volume_em momentum_kama  volume_em Day  volume_em Dayofweek  volume_em Hour  \\\n",
       "0               -0.432490                  -0.058803                         -0.323207                0.520039               -0.399932                 -0.357148       -0.107852              0.041570        -0.344819               -0.0           -0.324882    -0.038799            -0.083405             -0.032255             -0.263096               -0.509436               -0.355150               -0.627434              -0.391700                 -0.067389                        -0.397692               0.298886              -0.072894                -0.279165      -0.058588            -0.026724       -0.590877              -0.0          -0.261290    -0.377658             -0.102923              0.461259                0.257778                0.058543                0.921407               0.387620                 -0.296543                         0.004168              -1.187211              -0.174856                 0.492095       0.179288             0.170215        0.465555   \n",
       "1               -0.107663                  -0.071099                         -0.083501               -0.083930               -0.282148                 -0.012509        0.038880              0.134988        -0.043030               -0.0            0.003972    -0.042123            -0.021188             -0.036936              0.063119                0.045293                0.002447                0.038498               0.057919                 -0.020659                         0.007596              -0.085519              -0.029717                 0.064888       0.044626             0.042840        0.079311               0.0           0.063011    -0.469328             -0.084624              0.275943                0.087618               -0.034360                0.483182               0.206172                 -0.243835                        -0.202709              -0.785461              -0.252056                 0.295162       0.107845             0.118243        0.317682   \n",
       "2               -0.206521                  -0.099043                         -0.072421                0.092216               -0.260369                 -0.132570       -0.012408              0.102335        -0.183133               -0.0           -0.110975    -0.042193            -0.027268             -0.036351              0.025198               -0.017215               -0.041499               -0.035581               0.005776                 -0.036935                        -0.021599              -0.044733              -0.032842                 0.024874       0.032612             0.034743       -0.003406               0.0           0.025263    -0.390027             -0.044287             -0.641367               -0.674084               -0.455822               -1.311542              -0.649189                 -0.448575                        -0.416352               0.697186              -0.305697                -0.680641      -0.247399            -0.140185       -0.661383   \n",
       "3                0.070629                  -0.030536                         -0.022939               -0.368584               -0.254619                  0.178949        0.120523              0.186967         0.146406                0.0            0.186951    -0.042180            -0.023528             -0.036379              0.004275               -0.054583               -0.061133               -0.072635              -0.022167                 -0.059022                        -0.036155              -0.027079              -0.031999                 0.002868       0.026000             0.030286       -0.055259              -0.0           0.004486    -0.412778             -0.053504             -0.601446               -0.679248               -0.485087               -1.190648              -0.624625                 -0.615579                        -0.497177               0.435934              -0.258949                -0.636650      -0.231386            -0.128537       -0.652512   \n",
       "4                0.255642                   0.072821                          0.057665               -0.561251               -0.284622                  0.356359        0.196231              0.235167         0.359242                0.0            0.356627    -0.041808            -0.012231             -0.036505             -0.074139               -0.198295               -0.156053               -0.203585              -0.144723                 -0.157165                        -0.123725               0.033385              -0.024694                -0.079534       0.001239             0.013598       -0.266269              -0.0          -0.073312    -0.449238             -0.052469             -0.526809               -0.615647               -0.491579               -1.022710              -0.608588                 -0.588204                        -0.528555               0.327222              -0.240963                -0.557337      -0.202503            -0.107525       -0.596256   \n",
       "\n",
       "   volume_em Minute  volume_em Elapsed  volume_vpt^2  volume_vpt volume_nvi  volume_vpt momentum_rsi  volume_vpt momentum_mfi  volume_vpt momentum_tsi  volume_vpt momentum_uo  volume_vpt momentum_stoch  volume_vpt momentum_stoch_signal  volume_vpt momentum_wr  volume_vpt momentum_ao  volume_vpt momentum_kama  volume_vpt Day  volume_vpt Dayofweek  volume_vpt Hour  volume_vpt Minute  volume_vpt Elapsed  volume_nvi^2  volume_nvi momentum_rsi  volume_nvi momentum_mfi  volume_nvi momentum_tsi  volume_nvi momentum_uo  volume_nvi momentum_stoch  volume_nvi momentum_stoch_signal  volume_nvi momentum_wr  volume_nvi momentum_ao  volume_nvi momentum_kama  volume_nvi Day  volume_nvi Dayofweek  volume_nvi Hour  volume_nvi Minute  volume_nvi Elapsed  momentum_rsi^2  momentum_rsi momentum_mfi  momentum_rsi momentum_tsi  momentum_rsi momentum_uo  momentum_rsi momentum_stoch  momentum_rsi momentum_stoch_signal  momentum_rsi momentum_wr  momentum_rsi momentum_ao  momentum_rsi momentum_kama  \\\n",
       "0               0.0           0.456791     -0.056636              -0.217742                -0.394158                -0.278104                -0.578750               -0.327522                  -0.068462                         -0.309578                0.249222               -0.085566                 -0.231613       -0.032275              0.006060        -0.413934               -0.0           -0.216122      1.126086                -0.464847                -1.099399                 2.471141                0.157093                  -1.825034                         -0.664919               -1.892603                0.474049                  1.375789       -0.944809             -0.980872         0.237554                0.0            0.988686       -0.597039                  -0.991476                   2.028633                 -0.327012                    -1.462496                           -0.717330                 -2.061181                  0.309916                   -0.344718   \n",
       "1               0.0           0.274234     -0.056676              -0.216113                -0.378245                -0.285621                -0.546657               -0.322943                  -0.142126                         -0.175995                0.213649               -0.068673                 -0.230032       -0.031881              0.006331        -0.446126               -0.0           -0.214902      1.000464                -0.618678                -1.050365                 2.322575                0.105851                  -1.457312                         -1.307091               -1.515942                0.267704                  1.312219       -0.946358             -0.981632         0.381215                0.0            0.869350       -0.725461                  -0.993927                   1.823381                 -0.435282                    -1.238319                           -1.134415                 -1.506839                  0.089952                   -0.502053   \n",
       "2              -0.0          -0.633513     -0.061054               0.035880                -0.024521                -0.037900                -0.068296                0.003664                  -0.052188                         -0.012179               -0.070815               -0.048596                  0.035460        0.049115              0.062010        -0.000622               -0.0            0.036024      1.000464                -0.601844                -1.520469                 2.193079               -0.129672                  -1.429273                         -1.722418               -1.487653                0.052403                  1.294485       -0.946358             -0.981632         0.527707                0.0            0.869534       -0.711065                  -1.267920                   1.722444                 -0.534144                    -1.219697                           -1.382822                 -1.491256                 -0.122617                   -0.487493   \n",
       "3              -0.0          -0.592598     -0.061012               0.085413                 0.049476                 0.000090                 0.017856                0.065724                  -0.014739                          0.013698               -0.117492               -0.049947                  0.087511        0.065007              0.072934         0.097542                0.0            0.085256      1.242106                -0.210524                -1.267674                 2.096276                0.025588                  -0.635985                         -1.286789               -0.698152               -0.141176                  1.366072       -0.943381             -0.980172         0.680899                0.0            1.099466       -0.370880                  -1.046674                   1.817270                 -0.248862                    -0.654194                           -1.073390                 -0.879540                 -0.329297                   -0.095488   \n",
       "4              -0.0          -0.518794     -0.061016               0.084299                 0.048277                 0.004421                 0.013797                0.069582                  -0.013897                          0.020737               -0.115651               -0.050974                  0.086329        0.064646              0.072686         0.099162                0.0            0.084139      1.273822                -0.159738                -0.993302                 2.005353                0.707373                  -0.550876                         -0.955792               -0.613707               -0.258246                  1.375495       -0.942990             -0.979981         0.828743                0.0            1.129757       -0.324627                  -0.858385                   1.754893                  0.126468                    -0.586437                           -0.846962                 -0.810014                 -0.459422                   -0.044788   \n",
       "\n",
       "   momentum_rsi Day  momentum_rsi Dayofweek  momentum_rsi Hour  momentum_rsi Minute  momentum_rsi Elapsed  momentum_mfi^2  momentum_mfi momentum_tsi  momentum_mfi momentum_uo  momentum_mfi momentum_stoch  momentum_mfi momentum_stoch_signal  momentum_mfi momentum_wr  momentum_mfi momentum_ao  momentum_mfi momentum_kama  momentum_mfi Day  momentum_mfi Dayofweek  momentum_mfi Hour  momentum_mfi Minute  momentum_mfi Elapsed  momentum_tsi^2  momentum_tsi momentum_uo  momentum_tsi momentum_stoch  momentum_tsi momentum_stoch_signal  momentum_tsi momentum_wr  momentum_tsi momentum_ao  momentum_tsi momentum_kama  momentum_tsi Day  momentum_tsi Dayofweek  momentum_tsi Hour  momentum_tsi Minute  momentum_tsi Elapsed  momentum_uo^2  momentum_uo momentum_stoch  momentum_uo momentum_stoch_signal  momentum_uo momentum_wr  momentum_uo momentum_ao  momentum_uo momentum_kama  momentum_uo Day  momentum_uo Dayofweek  momentum_uo Hour  momentum_uo Minute  momentum_uo Elapsed  momentum_stoch^2  \\\n",
       "0         -0.994480               -0.986599           0.007952                  0.0             -0.532464       -1.070717                   1.132128                 -0.917890                    -1.325028                           -0.922873                 -0.467638                  0.084494                   -1.053629         -1.165176               -0.961423          -0.477813                  0.0             -1.126012        4.437901                  2.391857                    -0.082914                            1.408016                 -4.414034                  0.304808                    2.571576          1.152031                0.622293           2.380996                  0.0              2.444248      -0.007142                   -1.501629                          -0.587912                -2.401456                 0.431566                   0.308655        -0.841353              -0.946241          0.236734                 0.0             0.084920         -1.189547   \n",
       "1         -1.025975               -1.002381           0.067179                  0.0             -0.681500       -1.041407                   1.101358                 -0.886743                    -1.186666                           -1.130548                 -0.320563                 -0.039916                   -1.002560         -1.147665               -0.953262          -0.378693                  0.0             -1.075169        3.879425                  2.229248                     0.332388                            0.632990                 -3.742999                 -0.016459                    2.418300          1.090135                0.586581           2.425831                  0.0              2.301250      -0.051462                   -1.220302                          -1.079773                -1.928263                 0.218321                   0.258452        -0.849149              -0.950522          0.359283                 0.0             0.041375         -1.135731   \n",
       "2         -1.022386               -1.000582           0.189556                  0.0             -0.664507       -1.273016                   0.640015                 -1.306597                    -1.234321                           -1.319849                  0.292866                 -0.187280                   -1.486050         -1.308318               -1.028128          -0.626972                  0.0             -1.541577        3.406218                  1.997204                     0.334121                            0.166419                 -3.514467                 -0.316903                    2.281858          1.034723                0.554610           2.466095                  0.0              2.173233      -0.284322                   -1.216881                          -1.406937                -1.716351                -0.002354                   0.012775        -0.891255              -0.973643          0.401530                 0.0            -0.193885         -1.128903   \n",
       "3         -0.941608               -0.960106           0.481259                  0.0             -0.282233       -1.160747                   0.799362                 -1.085176                    -0.951934                           -1.166584                  0.381011                 -0.291673                   -1.230555         -1.223212               -0.988468          -0.399639                  0.0             -1.294494        3.047031                  1.962153                     1.132581                            0.568410                 -2.530558                 -0.561158                    2.174426          0.990541                0.529119           2.518224                  0.0              2.071162      -0.146268                   -0.611906                          -1.077990                -0.904715                -0.194272                   0.157449        -0.866052              -0.959804          0.594116                 0.0            -0.053052         -0.778127   \n",
       "4         -0.931162               -0.954872           0.632004                  0.0             -0.232788       -1.010689                   0.965358                 -0.697803                    -0.833494                           -0.994636                  0.170600                 -0.388915                   -0.950439         -1.129918               -0.944992          -0.131550                  0.0             -1.023636        2.742247                  2.154943                     1.162007                            0.842031                 -2.340765                 -0.693459                    2.079322          0.951400                0.506535           2.569891                  0.0              1.980735       0.572554                   -0.407254                          -0.717088                -1.182880                -0.348118                   0.853819        -0.744891              -0.893272          1.041379                 0.0             0.623960         -0.722554   \n",
       "\n",
       "   momentum_stoch momentum_stoch_signal  momentum_stoch momentum_wr  momentum_stoch momentum_ao  momentum_stoch momentum_kama  momentum_stoch Day  momentum_stoch Dayofweek  momentum_stoch Hour  momentum_stoch Minute  momentum_stoch Elapsed  momentum_stoch_signal^2  momentum_stoch_signal momentum_wr  momentum_stoch_signal momentum_ao  momentum_stoch_signal momentum_kama  momentum_stoch_signal Day  momentum_stoch_signal Dayofweek  momentum_stoch_signal Hour  momentum_stoch_signal Minute  momentum_stoch_signal Elapsed  momentum_wr^2  momentum_wr momentum_ao  momentum_wr momentum_kama  momentum_wr Day  momentum_wr Dayofweek  momentum_wr Hour  momentum_wr Minute  momentum_wr Elapsed  momentum_ao^2  momentum_ao momentum_kama  momentum_ao Day  momentum_ao Dayofweek  momentum_ao Hour  momentum_ao Minute  momentum_ao Elapsed  momentum_kama^2  momentum_kama Day  momentum_kama Dayofweek  momentum_kama Hour  momentum_kama Minute  momentum_kama Elapsed     Day^2  Day Dayofweek  Day Hour  \\\n",
       "0                             -1.187547                    2.106307                   -0.156014                     -1.822126           -1.263796                 -1.083213            -1.095937                    0.0               -1.832721                -0.781842                          -1.756897                           0.105571                            -0.620620                  -0.888740                        -0.888568                   -0.260517                           0.0                      -0.687658       2.402241                -0.901065                  -1.977288        -0.042788               0.360400         -1.315294                -0.0            -1.828762      -0.195111                   0.502152         0.240438               0.227120          0.492384                 0.0             0.471881         1.054922          -0.944471                -0.969260            0.290468                   0.0               1.019191 -0.908946      -0.920057 -0.495377   \n",
       "1                             -1.132783                    0.943616                   -0.120268                     -1.442849           -1.136491                 -1.011405            -0.813186                    0.0               -1.468019                -1.107094                           0.215402                          -0.119062                            -1.281189                  -1.101941                        -1.007768                   -0.649535                           0.0                      -1.322559       1.726076                -0.537472                  -1.594986         0.084435               0.432713         -1.239416                -0.0            -1.463970      -0.230117                   0.281737         0.169659               0.179298          0.299728                 0.0             0.267769         1.027823          -0.945591                -0.969797            0.438634                   0.0               0.993375 -0.908946      -0.920057 -0.441867   \n",
       "2                             -1.178024                    0.866057                   -0.174137                     -1.414301           -1.126789                 -1.005932            -0.764719                    0.0               -1.440222                -1.220413                           1.243583                          -0.212150                            -1.709163                  -1.240298                        -1.085122                   -0.930150                           0.0                      -1.734577       1.677481                -0.231939                  -1.563798         0.094132               0.438224         -1.384937                -0.0            -1.436175      -0.244845                   0.051491         0.095566               0.129237          0.062908                 0.0             0.054097         1.009201          -0.946362                -0.970165            0.587208                   0.0               0.975638 -0.908946      -0.920057 -0.388357   \n",
       "3                             -0.966665                   -0.675161                   -0.291672                     -0.600652           -0.853564                 -0.851815            -0.058808                    0.0               -0.657487                -1.100477                           0.682670                          -0.284031                            -1.263381                  -1.095975                        -1.004433                   -0.549681                           0.0                      -1.304789       0.479928                -0.014809                  -0.751967         0.367181               0.593423         -0.909171                -0.0            -0.653238      -0.238982                  -0.154864         0.029104               0.084333         -0.179932                -0.0            -0.137567         1.008237          -0.946402                -0.970184            0.737165                   0.0               0.974775 -0.908946      -0.920057 -0.334848   \n",
       "4                             -0.840436                   -0.766401                   -0.383299                     -0.513733           -0.824376                 -0.835351             0.088001                    0.0               -0.573865                -0.953148                           0.148155                          -0.376226                            -0.924211                  -0.986171                        -0.943042                   -0.215634                           0.0                      -0.977793       0.371508                 0.099343                  -0.665246         0.396351               0.610003         -0.961758                -0.0            -0.569602      -0.226705                  -0.279488        -0.011034               0.057213         -0.350140                -0.0            -0.253319         1.008156          -0.946406                -0.970186            0.887194                   0.0               0.974755 -0.908946      -0.920057 -0.281338   \n",
       "\n",
       "   Day Minute  Day Elapsed  Dayofweek^2  Dayofweek Hour  Dayofweek Minute  Dayofweek Elapsed    Hour^2  Hour Minute  Hour Elapsed  Minute^2  Minute Elapsed  Elapsed^2  \n",
       "0         0.0    -0.955968    -0.941311       -0.626671               0.0          -0.987605 -0.072404          0.0      0.209207       0.0             0.0  -1.729701  \n",
       "1         0.0    -0.955965    -0.941311       -0.596876               0.0          -0.987604  0.091662          0.0      0.353711       0.0             0.0  -1.726374  \n",
       "2         0.0    -0.955963    -0.941311       -0.567081               0.0          -0.987603  0.267881          0.0      0.498216       0.0             0.0  -1.723047  \n",
       "3         0.0    -0.955961    -0.941311       -0.537286               0.0          -0.987602  0.456253          0.0      0.642721       0.0             0.0  -1.719720  \n",
       "4         0.0    -0.955958    -0.941311       -0.507491               0.0          -0.987600  0.656779          0.0      0.787228       0.0             0.0  -1.716393  \n",
       "\n",
       "[5 rows x 2079 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#std scaler\n",
    "# std_scaler = StandardScaler()\n",
    "# std_scaler.fit(train_df)\n",
    "\n",
    "# train_data = transform_df(train_df, std_scaler, columns=train_df.columns)\n",
    "# valid_data = transform_df(valid_df, std_scaler, columns=valid_df.columns)\n",
    "# test_data = transform_df(test_df, std_scaler, columns=test_df.columns)\n",
    "\n",
    "#poly transform\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "temp = train_df.input_data()\n",
    "poly_features.fit(temp)\n",
    "temp = poly_features.get_feature_names(temp.columns)\n",
    "\n",
    "train_data = transform_df(train_df.input_data(), preprocessing_pipeline, columns=temp)\n",
    "valid_data = transform_df(valid_df.input_data(), preprocessing_pipeline, columns=temp)\n",
    "test_data = transform_df(test_df.input_data(), preprocessing_pipeline, columns=temp)\n",
    "\n",
    "del temp\n",
    "\n",
    "train_data.drop(columns=['1'], inplace=True)\n",
    "valid_data.drop(columns=['1'], inplace=True)\n",
    "test_data.drop(columns=['1'], inplace=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(train_data.values),\n",
    "                                        torch.from_numpy(train_df.target().values)),\n",
    "                          shuffle=False, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(valid_data.values),\n",
    "                                      torch.from_numpy(valid_df.target().values)),\n",
    "                        shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(torch.from_numpy(test_data.values),\n",
    "                                       torch.from_numpy(test_df.target().values)),\n",
    "                         shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, features, output_size=1,\n",
    "#                  embedding_dim=10,\n",
    "#                  hidden_dim=50,\n",
    "                 n_layers=1,\n",
    "                 drop_prob=0.5, device=torch.device(\"cpu\")):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        \n",
    "        embedding_dim=features*2\n",
    "        hidden_dim=features\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.liniar = nn.Linear(features, embedding_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=n_layers, dropout=drop_prob, batch_first=True)\n",
    "#         self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_dim, hidden_dim//2),\n",
    "                                nn.BatchNorm1d(num_features=hidden_dim//2),\n",
    "                                nn.Dropout(drop_prob),\n",
    "                                nn.Tanh(),\n",
    "                                nn.Linear(hidden_dim//2, output_size))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.float()\n",
    "        \n",
    "        liniar = F.relu(self.bn1(self.liniar(x)))\n",
    "        lstm_out, hidden = self.lstm(liniar.view(batch_size, -1, liniar.shape[1]),\n",
    "                                     (hidden[0][:,-batch_size:,:],# hidden\n",
    "                                      hidden[1][:,-batch_size:,:]))# cell state\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "#         out = self.dropout(lstm_out)\n",
    "        out = self.fc(lstm_out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "#         out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device), # hidden\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device)) # cell state\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count = train_data.shape[1]\n",
    "# output_size = 1\n",
    "# embedding_dim = 400\n",
    "# hidden_dim = 512\n",
    "# n_layers = 2\n",
    "\n",
    "model = SentimentNet(features_count, device=DEVICE, n_layers=3)\n",
    "model.to(DEVICE)\n",
    "\n",
    "lr=0.0003\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Step: 1... Loss: 0.217899... Val Loss: 0.006104\n",
      "Validation loss decreased (inf --> 0.006104).  Saving model ...\n",
      "Epoch: 1/100... Step: 2... Loss: 0.394786... Val Loss: 0.006676\n",
      "Epoch: 1/100... Step: 3... Loss: 0.265888... Val Loss: 0.007701\n",
      "Epoch: 1/100... Step: 4... Loss: 0.248042... Val Loss: 0.008835\n",
      "Epoch: 1/100... Step: 5... Loss: 0.068984... Val Loss: 0.009877\n",
      "Epoch: 1/100... Step: 6... Loss: 0.228424... Val Loss: 0.010427\n",
      "Epoch: 1/100... Step: 7... Loss: 0.186950... Val Loss: 0.011015\n",
      "Epoch: 1/100... Step: 8... Loss: 0.324271... Val Loss: 0.011799\n",
      "Epoch: 1/100... Step: 9... Loss: 0.265622... Val Loss: 0.012589\n",
      "Epoch: 1/100... Step: 10... Loss: 0.244969... Val Loss: 0.013946\n",
      "Epoch: 1/100... Step: 11... Loss: 0.238541... Val Loss: 0.015252\n",
      "Epoch: 1/100... Step: 12... Loss: 0.274581... Val Loss: 0.016342\n",
      "Epoch: 1/100... Step: 13... Loss: 0.200680... Val Loss: 0.017621\n",
      "Epoch: 1/100... Step: 14... Loss: 0.330375... Val Loss: 0.019520\n",
      "Epoch: 1/100... Step: 15... Loss: 0.262565... Val Loss: 0.022669\n",
      "Epoch: 1/100... Step: 16... Loss: 0.291695... Val Loss: 0.026220\n",
      "Epoch: 1/100... Step: 17... Loss: 0.262371... Val Loss: 0.030627\n",
      "Epoch: 1/100... Step: 18... Loss: 0.309170... Val Loss: 0.032443\n",
      "Epoch: 1/100... Step: 19... Loss: 0.277337... Val Loss: 0.034140\n",
      "Epoch: 1/100... Step: 20... Loss: 0.225275... Val Loss: 0.034201\n",
      "Epoch: 1/100... Step: 21... Loss: 0.108554... Val Loss: 0.036005\n",
      "Epoch: 1/100... Step: 22... Loss: 0.258123... Val Loss: 0.039028\n",
      "Epoch: 1/100... Step: 23... Loss: 0.313386... Val Loss: 0.043111\n",
      "Epoch: 1/100... Step: 24... Loss: 0.265264... Val Loss: 0.046872\n",
      "Epoch: 1/100... Step: 25... Loss: 0.267721... Val Loss: 0.050525\n",
      "Epoch: 1/100... Step: 26... Loss: 0.345913... Val Loss: 0.055195\n",
      "Epoch: 1/100... Step: 27... Loss: 0.141638... Val Loss: 0.055790\n",
      "Epoch: 1/100... Step: 28... Loss: 0.297158... Val Loss: 0.056494\n",
      "Epoch: 1/100... Step: 29... Loss: 0.259723... Val Loss: 0.059685\n",
      "Epoch: 1/100... Step: 30... Loss: 0.198037... Val Loss: 0.058655\n",
      "Epoch: 1/100... Step: 31... Loss: 0.203432... Val Loss: 0.063862\n",
      "Epoch: 1/100... Step: 32... Loss: 0.198796... Val Loss: 0.063654\n",
      "Epoch: 1/100... Step: 33... Loss: 0.243953... Val Loss: 0.066410\n",
      "Epoch: 1/100... Step: 34... Loss: 0.237274... Val Loss: 0.069630\n",
      "Epoch: 1/100... Step: 35... Loss: 0.378684... Val Loss: 0.070661\n",
      "Epoch: 1/100... Step: 36... Loss: 0.278029... Val Loss: 0.069390\n",
      "Epoch: 1/100... Step: 37... Loss: 0.133575... Val Loss: 0.067187\n",
      "Epoch: 1/100... Step: 38... Loss: 0.203463... Val Loss: 0.073266\n",
      "Epoch: 1/100... Step: 39... Loss: 0.221652... Val Loss: 0.080187\n",
      "Epoch: 1/100... Step: 40... Loss: 0.152867... Val Loss: 0.086201\n",
      "Epoch: 1/100... Step: 41... Loss: 0.267461... Val Loss: 0.085144\n",
      "Epoch: 1/100... Step: 42... Loss: 0.309054... Val Loss: 0.065217\n",
      "Epoch: 1/100... Step: 43... Loss: 0.371828... Val Loss: 0.047938\n",
      "Epoch: 1/100... Step: 44... Loss: 0.347236... Val Loss: 0.054247\n",
      "Epoch: 1/100... Step: 45... Loss: 0.290404... Val Loss: 0.050989\n",
      "Epoch: 1/100... Step: 46... Loss: 0.232700... Val Loss: 0.050769\n",
      "Epoch: 1/100... Step: 47... Loss: 0.260644... Val Loss: 0.047469\n",
      "Epoch: 1/100... Step: 48... Loss: 0.283200... Val Loss: 0.045455\n",
      "Epoch: 1/100... Step: 49... Loss: 0.257812... Val Loss: 0.040300\n",
      "Epoch: 1/100... Step: 50... Loss: 0.262815... Val Loss: 0.039574\n",
      "Epoch: 1/100... Step: 51... Loss: 0.157885... Val Loss: 0.040546\n",
      "Epoch: 1/100... Step: 52... Loss: 0.211673... Val Loss: 0.038481\n",
      "Epoch: 1/100... Step: 53... Loss: 0.279594... Val Loss: 0.038033\n",
      "Epoch: 1/100... Step: 54... Loss: 0.307325... Val Loss: 0.040232\n",
      "Epoch: 1/100... Step: 55... Loss: 0.403917... Val Loss: 0.046559\n",
      "Epoch: 1/100... Step: 56... Loss: 0.329863... Val Loss: 0.052684\n",
      "Epoch: 1/100... Step: 57... Loss: 0.263013... Val Loss: 0.054846\n",
      "Epoch: 1/100... Step: 58... Loss: 0.267205... Val Loss: 0.062804\n",
      "Epoch: 1/100... Step: 59... Loss: 0.323952... Val Loss: 0.067624\n",
      "Epoch: 1/100... Step: 60... Loss: 0.211903... Val Loss: 0.073562\n",
      "Epoch: 1/100... Step: 61... Loss: 0.284380... Val Loss: 0.073932\n",
      "Epoch: 1/100... Step: 62... Loss: 0.180797... Val Loss: 0.077932\n",
      "Epoch: 1/100... Step: 63... Loss: 0.258661... Val Loss: 0.084444\n",
      "Epoch: 1/100... Step: 64... Loss: 0.202761... Val Loss: 0.088855\n",
      "Epoch: 1/100... Step: 65... Loss: 0.304853... Val Loss: 0.097246\n",
      "Epoch: 1/100... Step: 66... Loss: 0.193392... Val Loss: 0.097121\n",
      "Epoch: 1/100... Step: 67... Loss: 0.186954... Val Loss: 0.108030\n",
      "Epoch: 1/100... Step: 68... Loss: 0.235085... Val Loss: 0.135988\n",
      "Epoch: 1/100... Step: 69... Loss: 0.324903... Val Loss: 0.153180\n",
      "Epoch: 1/100... Step: 70... Loss: 0.240651... Val Loss: 0.145427\n",
      "Epoch: 1/100... Step: 71... Loss: 0.204282... Val Loss: 0.140698\n",
      "Epoch: 1/100... Step: 72... Loss: 0.116438... Val Loss: 0.130726\n",
      "Epoch: 1/100... Step: 73... Loss: 0.231674... Val Loss: 0.132673\n",
      "Epoch: 1/100... Step: 74... Loss: 0.264943... Val Loss: 0.143697\n",
      "Epoch: 1/100... Step: 75... Loss: 0.178821... Val Loss: 0.153247\n",
      "Epoch: 1/100... Step: 76... Loss: 0.350037... Val Loss: 0.135878\n",
      "Epoch: 1/100... Step: 77... Loss: 0.315885... Val Loss: 0.125721\n",
      "Epoch: 1/100... Step: 78... Loss: 0.272306... Val Loss: 0.131625\n",
      "Epoch: 1/100... Step: 79... Loss: 0.189171... Val Loss: 0.122669\n",
      "Epoch: 1/100... Step: 80... Loss: 0.299564... Val Loss: 0.127941\n",
      "Epoch: 1/100... Step: 81... Loss: 0.173776... Val Loss: 0.154218\n",
      "Epoch: 1/100... Step: 82... Loss: 0.296581... Val Loss: 0.180451\n",
      "Epoch: 1/100... Step: 83... Loss: 0.382675... Val Loss: 0.168591\n",
      "Epoch: 1/100... Step: 84... Loss: 0.316315... Val Loss: 0.178709\n",
      "Epoch: 1/100... Step: 85... Loss: 0.272556... Val Loss: 0.195623\n",
      "Epoch: 1/100... Step: 86... Loss: 0.317567... Val Loss: 0.200218\n",
      "Epoch: 1/100... Step: 87... Loss: 0.246816... Val Loss: 0.203886\n",
      "Epoch: 1/100... Step: 88... Loss: 0.343184... Val Loss: 0.179184\n",
      "Epoch: 1/100... Step: 89... Loss: 0.187508... Val Loss: 0.163782\n",
      "Epoch: 1/100... Step: 90... Loss: 0.257900... Val Loss: 0.175411\n",
      "Epoch: 1/100... Step: 91... Loss: 0.158419... Val Loss: 0.172902\n",
      "Epoch: 1/100... Step: 92... Loss: 0.119950... Val Loss: 0.165781\n",
      "Epoch: 1/100... Step: 93... Loss: 0.260174... Val Loss: 0.171890\n",
      "Epoch: 1/100... Step: 94... Loss: 0.239443... Val Loss: 0.164705\n",
      "Epoch: 1/100... Step: 95... Loss: 0.268955... Val Loss: 0.192145\n",
      "Epoch: 1/100... Step: 96... Loss: 0.245181... Val Loss: 0.192960\n",
      "Epoch: 1/100... Step: 97... Loss: 0.204507... Val Loss: 0.181768\n",
      "Epoch: 1/100... Step: 98... Loss: 0.199070... Val Loss: 0.181268\n",
      "Epoch: 1/100... Step: 99... Loss: 0.265777... Val Loss: 0.161985\n",
      "Epoch: 1/100... Step: 100... Loss: 0.257803... Val Loss: 0.187491\n",
      "Epoch: 1/100... Step: 101... Loss: 0.259224... Val Loss: 0.206495\n",
      "Epoch: 1/100... Step: 102... Loss: 0.289225... Val Loss: 0.191199\n",
      "Epoch: 1/100... Step: 103... Loss: 0.192680... Val Loss: 0.188130\n",
      "Epoch: 1/100... Step: 104... Loss: 0.294558... Val Loss: 0.193953\n",
      "Epoch: 2/100... Step: 105... Loss: 0.246278... Val Loss: 0.210743\n",
      "Epoch: 2/100... Step: 106... Loss: 0.211632... Val Loss: 0.183326\n",
      "Epoch: 2/100... Step: 107... Loss: 0.226851... Val Loss: 0.157922\n",
      "Epoch: 2/100... Step: 108... Loss: 0.281917... Val Loss: 0.153917\n",
      "Epoch: 2/100... Step: 109... Loss: 0.317326... Val Loss: 0.143998\n",
      "Epoch: 2/100... Step: 110... Loss: 0.293806... Val Loss: 0.142960\n",
      "Epoch: 2/100... Step: 111... Loss: 0.184174... Val Loss: 0.156277\n",
      "Epoch: 2/100... Step: 112... Loss: 0.233931... Val Loss: 0.159174\n",
      "Epoch: 2/100... Step: 113... Loss: 0.256439... Val Loss: 0.156829\n",
      "Epoch: 2/100... Step: 114... Loss: 0.243967... Val Loss: 0.158296\n",
      "Epoch: 2/100... Step: 115... Loss: 0.331414... Val Loss: 0.168334\n",
      "Epoch: 2/100... Step: 116... Loss: 0.309635... Val Loss: 0.180923\n",
      "Epoch: 2/100... Step: 117... Loss: 0.270781... Val Loss: 0.175884\n",
      "Epoch: 2/100... Step: 118... Loss: 0.284553... Val Loss: 0.150099\n",
      "Epoch: 2/100... Step: 119... Loss: 0.238828... Val Loss: 0.147721\n",
      "Epoch: 2/100... Step: 120... Loss: 0.280783... Val Loss: 0.165479\n",
      "Epoch: 2/100... Step: 121... Loss: 0.237527... Val Loss: 0.180757\n",
      "Epoch: 2/100... Step: 122... Loss: 0.240870... Val Loss: 0.159029\n",
      "Epoch: 2/100... Step: 123... Loss: 0.239588... Val Loss: 0.149385\n",
      "Epoch: 2/100... Step: 124... Loss: 0.176502... Val Loss: 0.140163\n",
      "Epoch: 2/100... Step: 125... Loss: 0.237625... Val Loss: 0.138545\n",
      "Epoch: 2/100... Step: 126... Loss: 0.209699... Val Loss: 0.141291\n",
      "Epoch: 2/100... Step: 127... Loss: 0.222258... Val Loss: 0.138295\n",
      "Epoch: 2/100... Step: 128... Loss: 0.255812... Val Loss: 0.134069\n",
      "Epoch: 2/100... Step: 129... Loss: 0.353651... Val Loss: 0.132214\n",
      "Epoch: 2/100... Step: 130... Loss: 0.296843... Val Loss: 0.129963\n",
      "Epoch: 2/100... Step: 131... Loss: 0.224861... Val Loss: 0.150712\n",
      "Epoch: 2/100... Step: 132... Loss: 0.193101... Val Loss: 0.150149\n",
      "Epoch: 2/100... Step: 133... Loss: 0.349218... Val Loss: 0.159368\n",
      "Epoch: 2/100... Step: 134... Loss: 0.332715... Val Loss: 0.170030\n",
      "Epoch: 2/100... Step: 135... Loss: 0.183501... Val Loss: 0.166456\n",
      "Epoch: 2/100... Step: 136... Loss: 0.375998... Val Loss: 0.160702\n",
      "Epoch: 2/100... Step: 137... Loss: 0.351537... Val Loss: 0.141764\n",
      "Epoch: 2/100... Step: 138... Loss: 0.267506... Val Loss: 0.137614\n",
      "Epoch: 2/100... Step: 139... Loss: 0.239134... Val Loss: 0.146941\n",
      "Epoch: 2/100... Step: 140... Loss: 0.326770... Val Loss: 0.168909\n",
      "Epoch: 2/100... Step: 141... Loss: 0.360684... Val Loss: 0.181025\n",
      "Epoch: 2/100... Step: 142... Loss: 0.297468... Val Loss: 0.151044\n",
      "Epoch: 2/100... Step: 143... Loss: 0.145330... Val Loss: 0.127221\n",
      "Epoch: 2/100... Step: 144... Loss: 0.279951... Val Loss: 0.130646\n",
      "Epoch: 2/100... Step: 145... Loss: 0.153231... Val Loss: 0.135172\n",
      "Epoch: 2/100... Step: 146... Loss: 0.189073... Val Loss: 0.157321\n",
      "Epoch: 2/100... Step: 147... Loss: 0.199369... Val Loss: 0.178131\n",
      "Epoch: 2/100... Step: 148... Loss: 0.233843... Val Loss: 0.156895\n",
      "Epoch: 2/100... Step: 149... Loss: 0.196922... Val Loss: 0.121993\n",
      "Epoch: 2/100... Step: 150... Loss: 0.251836... Val Loss: 0.119904\n",
      "Epoch: 2/100... Step: 151... Loss: 0.172764... Val Loss: 0.160397\n",
      "Epoch: 2/100... Step: 152... Loss: 0.170927... Val Loss: 0.209842\n",
      "Epoch: 2/100... Step: 153... Loss: 0.222701... Val Loss: 0.253706\n",
      "Epoch: 2/100... Step: 154... Loss: 0.218746... Val Loss: 0.277272\n",
      "Epoch: 2/100... Step: 155... Loss: 0.243864... Val Loss: 0.307055\n",
      "Epoch: 2/100... Step: 156... Loss: 0.316261... Val Loss: 0.278764\n",
      "Epoch: 2/100... Step: 157... Loss: 0.165414... Val Loss: 0.283902\n",
      "Epoch: 2/100... Step: 158... Loss: 0.234786... Val Loss: 0.281605\n",
      "Epoch: 2/100... Step: 159... Loss: 0.183779... Val Loss: 0.279319\n",
      "Epoch: 2/100... Step: 160... Loss: 0.213394... Val Loss: 0.317783\n",
      "Epoch: 2/100... Step: 161... Loss: 0.289542... Val Loss: 0.344484\n",
      "Epoch: 2/100... Step: 162... Loss: 0.185322... Val Loss: 0.392672\n",
      "Epoch: 2/100... Step: 163... Loss: 0.373645... Val Loss: 0.418719\n",
      "Epoch: 2/100... Step: 164... Loss: 0.254294... Val Loss: 0.440495\n",
      "Epoch: 2/100... Step: 165... Loss: 0.274160... Val Loss: 0.412443\n",
      "Epoch: 2/100... Step: 166... Loss: 0.208865... Val Loss: 0.413196\n",
      "Epoch: 2/100... Step: 167... Loss: 0.252458... Val Loss: 0.425823\n",
      "Epoch: 2/100... Step: 168... Loss: 0.210494... Val Loss: 0.444298\n",
      "Epoch: 2/100... Step: 169... Loss: 0.359970... Val Loss: 0.466229\n",
      "Epoch: 2/100... Step: 170... Loss: 0.241561... Val Loss: 0.478167\n",
      "Epoch: 2/100... Step: 171... Loss: 0.261939... Val Loss: 0.512820\n",
      "Epoch: 2/100... Step: 172... Loss: 0.213307... Val Loss: 0.515795\n",
      "Epoch: 2/100... Step: 173... Loss: 0.254411... Val Loss: 0.508104\n",
      "Epoch: 2/100... Step: 174... Loss: 0.269295... Val Loss: 0.470064\n",
      "Epoch: 2/100... Step: 175... Loss: 0.245167... Val Loss: 0.473753\n",
      "Epoch: 2/100... Step: 176... Loss: 0.381503... Val Loss: 0.495242\n",
      "Epoch: 2/100... Step: 177... Loss: 0.356578... Val Loss: 0.508670\n",
      "Epoch: 2/100... Step: 178... Loss: 0.307229... Val Loss: 0.543378\n",
      "Epoch: 2/100... Step: 179... Loss: 0.257488... Val Loss: 0.555797\n",
      "Epoch: 2/100... Step: 180... Loss: 0.259612... Val Loss: 0.481083\n",
      "Epoch: 2/100... Step: 181... Loss: 0.210958... Val Loss: 0.418588\n",
      "Epoch: 2/100... Step: 182... Loss: 0.239534... Val Loss: 0.366205\n",
      "Epoch: 2/100... Step: 183... Loss: 0.302884... Val Loss: 0.327890\n",
      "Epoch: 2/100... Step: 184... Loss: 0.259467... Val Loss: 0.304257\n",
      "Epoch: 2/100... Step: 185... Loss: 0.196656... Val Loss: 0.304950\n",
      "Epoch: 2/100... Step: 186... Loss: 0.277225... Val Loss: 0.265984\n",
      "Epoch: 2/100... Step: 187... Loss: 0.321564... Val Loss: 0.252131\n",
      "Epoch: 2/100... Step: 188... Loss: 0.267894... Val Loss: 0.264409\n",
      "Epoch: 2/100... Step: 189... Loss: 0.348391... Val Loss: 0.270207\n",
      "Epoch: 2/100... Step: 190... Loss: 0.253049... Val Loss: 0.292754\n",
      "Epoch: 2/100... Step: 191... Loss: 0.278075... Val Loss: 0.281091\n",
      "Epoch: 2/100... Step: 192... Loss: 0.133769... Val Loss: 0.288219\n",
      "Epoch: 2/100... Step: 193... Loss: 0.195966... Val Loss: 0.303113\n",
      "Epoch: 2/100... Step: 194... Loss: 0.178958... Val Loss: 0.314862\n",
      "Epoch: 2/100... Step: 195... Loss: 0.223503... Val Loss: 0.334520\n",
      "Epoch: 2/100... Step: 196... Loss: 0.229062... Val Loss: 0.325375\n",
      "Epoch: 2/100... Step: 197... Loss: 0.195321... Val Loss: 0.290200\n",
      "Epoch: 2/100... Step: 198... Loss: 0.170084... Val Loss: 0.277325\n",
      "Epoch: 2/100... Step: 199... Loss: 0.260185... Val Loss: 0.283794\n",
      "Epoch: 2/100... Step: 200... Loss: 0.258981... Val Loss: 0.293567\n",
      "Epoch: 2/100... Step: 201... Loss: 0.198843... Val Loss: 0.290374\n",
      "Epoch: 2/100... Step: 202... Loss: 0.194077... Val Loss: 0.309059\n",
      "Epoch: 2/100... Step: 203... Loss: 0.256969... Val Loss: 0.332778\n",
      "Epoch: 2/100... Step: 204... Loss: 0.216895... Val Loss: 0.328953\n",
      "Epoch: 2/100... Step: 205... Loss: 0.186153... Val Loss: 0.332950\n",
      "Epoch: 2/100... Step: 206... Loss: 0.189008... Val Loss: 0.340723\n",
      "Epoch: 2/100... Step: 207... Loss: 0.315597... Val Loss: 0.321033\n",
      "Epoch: 2/100... Step: 208... Loss: 0.382476... Val Loss: 0.322716\n",
      "Epoch: 3/100... Step: 209... Loss: 0.176586... Val Loss: 0.393779\n",
      "Epoch: 3/100... Step: 210... Loss: 0.160365... Val Loss: 0.377578\n",
      "Epoch: 3/100... Step: 211... Loss: 0.212601... Val Loss: 0.402918\n",
      "Epoch: 3/100... Step: 212... Loss: 0.364860... Val Loss: 0.393553\n",
      "Epoch: 3/100... Step: 213... Loss: 0.217926... Val Loss: 0.376752\n",
      "Epoch: 3/100... Step: 214... Loss: 0.261600... Val Loss: 0.372494\n",
      "Epoch: 3/100... Step: 215... Loss: 0.303949... Val Loss: 0.362574\n",
      "Epoch: 3/100... Step: 216... Loss: 0.291930... Val Loss: 0.358682\n",
      "Epoch: 3/100... Step: 217... Loss: 0.190493... Val Loss: 0.327246\n",
      "Epoch: 3/100... Step: 218... Loss: 0.208523... Val Loss: 0.322368\n",
      "Epoch: 3/100... Step: 219... Loss: 0.152779... Val Loss: 0.333503\n",
      "Epoch: 3/100... Step: 220... Loss: 0.269100... Val Loss: 0.336198\n",
      "Epoch: 3/100... Step: 221... Loss: 0.230611... Val Loss: 0.363672\n",
      "Epoch: 3/100... Step: 222... Loss: 0.273716... Val Loss: 0.363064\n",
      "Epoch: 3/100... Step: 223... Loss: 0.267216... Val Loss: 0.406686\n",
      "Epoch: 3/100... Step: 224... Loss: 0.251518... Val Loss: 0.430348\n",
      "Epoch: 3/100... Step: 225... Loss: 0.204507... Val Loss: 0.422951\n",
      "Epoch: 3/100... Step: 226... Loss: 0.300582... Val Loss: 0.397908\n",
      "Epoch: 3/100... Step: 227... Loss: 0.212003... Val Loss: 0.360301\n",
      "Epoch: 3/100... Step: 228... Loss: 0.233070... Val Loss: 0.357083\n",
      "Epoch: 3/100... Step: 229... Loss: 0.201460... Val Loss: 0.344225\n",
      "Epoch: 3/100... Step: 230... Loss: 0.322259... Val Loss: 0.352527\n",
      "Epoch: 3/100... Step: 231... Loss: 0.287962... Val Loss: 0.367917\n",
      "Epoch: 3/100... Step: 232... Loss: 0.249513... Val Loss: 0.339143\n",
      "Epoch: 3/100... Step: 233... Loss: 0.228761... Val Loss: 0.346622\n",
      "Epoch: 3/100... Step: 234... Loss: 0.354624... Val Loss: 0.363402\n",
      "Epoch: 3/100... Step: 235... Loss: 0.326992... Val Loss: 0.360603\n",
      "Epoch: 3/100... Step: 236... Loss: 0.182918... Val Loss: 0.355730\n",
      "Epoch: 3/100... Step: 237... Loss: 0.278704... Val Loss: 0.360740\n",
      "Epoch: 3/100... Step: 238... Loss: 0.326262... Val Loss: 0.340774\n",
      "Epoch: 3/100... Step: 239... Loss: 0.329917... Val Loss: 0.304737\n",
      "Epoch: 3/100... Step: 240... Loss: 0.363243... Val Loss: 0.265784\n",
      "Epoch: 3/100... Step: 241... Loss: 0.320763... Val Loss: 0.280340\n",
      "Epoch: 3/100... Step: 242... Loss: 0.180994... Val Loss: 0.266467\n",
      "Epoch: 3/100... Step: 243... Loss: 0.294092... Val Loss: 0.299030\n",
      "Epoch: 3/100... Step: 244... Loss: 0.256182... Val Loss: 0.278460\n",
      "Epoch: 3/100... Step: 245... Loss: 0.223576... Val Loss: 0.306591\n",
      "Epoch: 3/100... Step: 246... Loss: 0.273962... Val Loss: 0.387564\n",
      "Epoch: 3/100... Step: 247... Loss: 0.262525... Val Loss: 0.415205\n",
      "Epoch: 3/100... Step: 248... Loss: 0.210975... Val Loss: 0.363781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Step: 249... Loss: 0.231142... Val Loss: 0.347028\n",
      "Epoch: 3/100... Step: 250... Loss: 0.282515... Val Loss: 0.252378\n",
      "Epoch: 3/100... Step: 251... Loss: 0.266814... Val Loss: 0.198198\n",
      "Epoch: 3/100... Step: 252... Loss: 0.283867... Val Loss: 0.209403\n",
      "Epoch: 3/100... Step: 253... Loss: 0.227168... Val Loss: 0.169239\n",
      "Epoch: 3/100... Step: 254... Loss: 0.164457... Val Loss: 0.173480\n",
      "Epoch: 3/100... Step: 255... Loss: 0.346852... Val Loss: 0.160829\n",
      "Epoch: 3/100... Step: 256... Loss: 0.245270... Val Loss: 0.144687\n",
      "Epoch: 3/100... Step: 257... Loss: 0.228889... Val Loss: 0.153176\n",
      "Epoch: 3/100... Step: 258... Loss: 0.245200... Val Loss: 0.168267\n",
      "Epoch: 3/100... Step: 259... Loss: 0.281580... Val Loss: 0.178563\n",
      "Epoch: 3/100... Step: 260... Loss: 0.312728... Val Loss: 0.193529\n",
      "Epoch: 3/100... Step: 261... Loss: 0.165501... Val Loss: 0.228993\n",
      "Epoch: 3/100... Step: 262... Loss: 0.275352... Val Loss: 0.246785\n",
      "Epoch: 3/100... Step: 263... Loss: 0.233176... Val Loss: 0.246663\n",
      "Epoch: 3/100... Step: 264... Loss: 0.250603... Val Loss: 0.250191\n",
      "Epoch: 3/100... Step: 265... Loss: 0.159154... Val Loss: 0.214111\n",
      "Epoch: 3/100... Step: 266... Loss: 0.254127... Val Loss: 0.188500\n",
      "Epoch: 3/100... Step: 267... Loss: 0.293194... Val Loss: 0.150971\n",
      "Epoch: 3/100... Step: 268... Loss: 0.212395... Val Loss: 0.119888\n",
      "Epoch: 3/100... Step: 269... Loss: 0.179411... Val Loss: 0.108565\n",
      "Epoch: 3/100... Step: 270... Loss: 0.214192... Val Loss: 0.111159\n",
      "Epoch: 3/100... Step: 271... Loss: 0.225932... Val Loss: 0.129790\n",
      "Epoch: 3/100... Step: 272... Loss: 0.271087... Val Loss: 0.162673\n",
      "Epoch: 3/100... Step: 273... Loss: 0.191851... Val Loss: 0.178802\n",
      "Epoch: 3/100... Step: 274... Loss: 0.184256... Val Loss: 0.189678\n",
      "Epoch: 3/100... Step: 275... Loss: 0.208635... Val Loss: 0.200054\n",
      "Epoch: 3/100... Step: 276... Loss: 0.248469... Val Loss: 0.180800\n",
      "Epoch: 3/100... Step: 277... Loss: 0.265349... Val Loss: 0.180504\n",
      "Epoch: 3/100... Step: 278... Loss: 0.230265... Val Loss: 0.148433\n",
      "Epoch: 3/100... Step: 279... Loss: 0.291630... Val Loss: 0.169490\n",
      "Epoch: 3/100... Step: 280... Loss: 0.308600... Val Loss: 0.222735\n",
      "Epoch: 3/100... Step: 281... Loss: 0.226815... Val Loss: 0.261076\n",
      "Epoch: 3/100... Step: 282... Loss: 0.143684... Val Loss: 0.296237\n",
      "Epoch: 3/100... Step: 283... Loss: 0.287572... Val Loss: 0.271375\n",
      "Epoch: 3/100... Step: 284... Loss: 0.232860... Val Loss: 0.282631\n",
      "Epoch: 3/100... Step: 285... Loss: 0.163279... Val Loss: 0.307175\n",
      "Epoch: 3/100... Step: 286... Loss: 0.229489... Val Loss: 0.325349\n",
      "Epoch: 3/100... Step: 287... Loss: 0.294504... Val Loss: 0.349018\n",
      "Epoch: 3/100... Step: 288... Loss: 0.333359... Val Loss: 0.329155\n",
      "Epoch: 3/100... Step: 289... Loss: 0.216032... Val Loss: 0.358339\n",
      "Epoch: 3/100... Step: 290... Loss: 0.219191... Val Loss: 0.388904\n",
      "Epoch: 3/100... Step: 291... Loss: 0.172816... Val Loss: 0.418287\n",
      "Epoch: 3/100... Step: 292... Loss: 0.150503... Val Loss: 0.446114\n",
      "Epoch: 3/100... Step: 293... Loss: 0.255172... Val Loss: 0.456218\n",
      "Epoch: 3/100... Step: 294... Loss: 0.378627... Val Loss: 0.498728\n",
      "Epoch: 3/100... Step: 295... Loss: 0.112139... Val Loss: 0.510433\n",
      "Epoch: 3/100... Step: 296... Loss: 0.193162... Val Loss: 0.528158\n",
      "Epoch: 3/100... Step: 297... Loss: 0.209737... Val Loss: 0.557723\n",
      "Epoch: 3/100... Step: 298... Loss: 0.250796... Val Loss: 0.619916\n",
      "Epoch: 3/100... Step: 299... Loss: 0.218834... Val Loss: 0.675059\n",
      "Epoch: 3/100... Step: 300... Loss: 0.204600... Val Loss: 0.722599\n",
      "Epoch: 3/100... Step: 301... Loss: 0.149745... Val Loss: 0.767922\n",
      "Epoch: 3/100... Step: 302... Loss: 0.247040... Val Loss: 0.789894\n",
      "Epoch: 3/100... Step: 303... Loss: 0.305641... Val Loss: 0.794172\n",
      "Epoch: 3/100... Step: 304... Loss: 0.274204... Val Loss: 0.764386\n",
      "Epoch: 3/100... Step: 305... Loss: 0.293934... Val Loss: 0.782948\n",
      "Epoch: 3/100... Step: 306... Loss: 0.308970... Val Loss: 0.851811\n",
      "Epoch: 3/100... Step: 307... Loss: 0.261159... Val Loss: 0.841731\n",
      "Epoch: 3/100... Step: 308... Loss: 0.259374... Val Loss: 0.925461\n",
      "Epoch: 3/100... Step: 309... Loss: 0.228858... Val Loss: 0.928774\n",
      "Epoch: 3/100... Step: 310... Loss: 0.338376... Val Loss: 0.889867\n",
      "Epoch: 3/100... Step: 311... Loss: 0.313622... Val Loss: 0.929989\n",
      "Epoch: 3/100... Step: 312... Loss: 0.308046... Val Loss: 0.870838\n",
      "Epoch: 4/100... Step: 313... Loss: 0.201609... Val Loss: 0.806476\n",
      "Epoch: 4/100... Step: 314... Loss: 0.279057... Val Loss: 0.846712\n",
      "Epoch: 4/100... Step: 315... Loss: 0.235891... Val Loss: 0.797580\n",
      "Epoch: 4/100... Step: 316... Loss: 0.298970... Val Loss: 0.785594\n",
      "Epoch: 4/100... Step: 317... Loss: 0.300899... Val Loss: 0.788197\n",
      "Epoch: 4/100... Step: 318... Loss: 0.339938... Val Loss: 0.818835\n",
      "Epoch: 4/100... Step: 319... Loss: 0.254885... Val Loss: 0.815012\n",
      "Epoch: 4/100... Step: 320... Loss: 0.281237... Val Loss: 0.797064\n",
      "Epoch: 4/100... Step: 321... Loss: 0.308763... Val Loss: 0.802595\n",
      "Epoch: 4/100... Step: 322... Loss: 0.204145... Val Loss: 0.802425\n",
      "Epoch: 4/100... Step: 323... Loss: 0.257676... Val Loss: 0.754765\n",
      "Epoch: 4/100... Step: 324... Loss: 0.211498... Val Loss: 0.747290\n",
      "Epoch: 4/100... Step: 325... Loss: 0.272412... Val Loss: 0.732891\n",
      "Epoch: 4/100... Step: 326... Loss: 0.221898... Val Loss: 0.776024\n",
      "Epoch: 4/100... Step: 327... Loss: 0.284429... Val Loss: 0.793903\n",
      "Epoch: 4/100... Step: 328... Loss: 0.173756... Val Loss: 0.755548\n",
      "Epoch: 4/100... Step: 329... Loss: 0.303943... Val Loss: 0.710029\n",
      "Epoch: 4/100... Step: 330... Loss: 0.300120... Val Loss: 0.713789\n",
      "Epoch: 4/100... Step: 331... Loss: 0.207774... Val Loss: 0.722054\n",
      "Epoch: 4/100... Step: 332... Loss: 0.209483... Val Loss: 0.711260\n",
      "Epoch: 4/100... Step: 333... Loss: 0.212320... Val Loss: 0.697714\n",
      "Epoch: 4/100... Step: 334... Loss: 0.289076... Val Loss: 0.702536\n",
      "Epoch: 4/100... Step: 335... Loss: 0.213171... Val Loss: 0.667824\n",
      "Epoch: 4/100... Step: 336... Loss: 0.214820... Val Loss: 0.648255\n",
      "Epoch: 4/100... Step: 337... Loss: 0.200844... Val Loss: 0.637060\n",
      "Epoch: 4/100... Step: 338... Loss: 0.208920... Val Loss: 0.608144\n",
      "Epoch: 4/100... Step: 339... Loss: 0.262751... Val Loss: 0.574915\n",
      "Epoch: 4/100... Step: 340... Loss: 0.254399... Val Loss: 0.552420\n",
      "Epoch: 4/100... Step: 341... Loss: 0.216280... Val Loss: 0.518847\n",
      "Epoch: 4/100... Step: 342... Loss: 0.216382... Val Loss: 0.480253\n",
      "Epoch: 4/100... Step: 343... Loss: 0.222923... Val Loss: 0.406145\n",
      "Epoch: 4/100... Step: 344... Loss: 0.240318... Val Loss: 0.384369\n",
      "Epoch: 4/100... Step: 345... Loss: 0.316472... Val Loss: 0.398159\n",
      "Epoch: 4/100... Step: 346... Loss: 0.254299... Val Loss: 0.385601\n",
      "Epoch: 4/100... Step: 347... Loss: 0.235483... Val Loss: 0.369204\n",
      "Epoch: 4/100... Step: 348... Loss: 0.215932... Val Loss: 0.329703\n",
      "Epoch: 4/100... Step: 349... Loss: 0.245749... Val Loss: 0.306221\n",
      "Epoch: 4/100... Step: 350... Loss: 0.367168... Val Loss: 0.334702\n",
      "Epoch: 4/100... Step: 351... Loss: 0.182060... Val Loss: 0.372270\n",
      "Epoch: 4/100... Step: 352... Loss: 0.270358... Val Loss: 0.382643\n",
      "Epoch: 4/100... Step: 353... Loss: 0.240727... Val Loss: 0.417428\n",
      "Epoch: 4/100... Step: 354... Loss: 0.353794... Val Loss: 0.321699\n",
      "Epoch: 4/100... Step: 355... Loss: 0.247533... Val Loss: 0.151963\n",
      "Epoch: 4/100... Step: 356... Loss: 0.344461... Val Loss: 0.157081\n",
      "Epoch: 4/100... Step: 357... Loss: 0.305357... Val Loss: 0.251086\n",
      "Epoch: 4/100... Step: 358... Loss: 0.292956... Val Loss: 0.286225\n",
      "Epoch: 4/100... Step: 359... Loss: 0.269087... Val Loss: 0.316422\n",
      "Epoch: 4/100... Step: 360... Loss: 0.213318... Val Loss: 0.347260\n",
      "Epoch: 4/100... Step: 361... Loss: 0.178388... Val Loss: 0.371412\n",
      "Epoch: 4/100... Step: 362... Loss: 0.255502... Val Loss: 0.426461\n",
      "Epoch: 4/100... Step: 363... Loss: 0.282754... Val Loss: 0.474138\n",
      "Epoch: 4/100... Step: 364... Loss: 0.225293... Val Loss: 0.498446\n",
      "Epoch: 4/100... Step: 365... Loss: 0.235415... Val Loss: 0.561775\n",
      "Epoch: 4/100... Step: 366... Loss: 0.265856... Val Loss: 0.600829\n",
      "Epoch: 4/100... Step: 367... Loss: 0.277567... Val Loss: 0.638804\n",
      "Epoch: 4/100... Step: 368... Loss: 0.169772... Val Loss: 0.706078\n",
      "Epoch: 4/100... Step: 369... Loss: 0.171299... Val Loss: 0.713335\n",
      "Epoch: 4/100... Step: 370... Loss: 0.233609... Val Loss: 0.730041\n",
      "Epoch: 4/100... Step: 371... Loss: 0.179804... Val Loss: 0.768022\n",
      "Epoch: 4/100... Step: 372... Loss: 0.297055... Val Loss: 0.785226\n",
      "Epoch: 4/100... Step: 373... Loss: 0.230201... Val Loss: 0.756196\n",
      "Epoch: 4/100... Step: 374... Loss: 0.191740... Val Loss: 0.722623\n",
      "Epoch: 4/100... Step: 375... Loss: 0.203727... Val Loss: 0.700551\n",
      "Epoch: 4/100... Step: 376... Loss: 0.233087... Val Loss: 0.697914\n",
      "Epoch: 4/100... Step: 377... Loss: 0.167665... Val Loss: 0.665555\n",
      "Epoch: 4/100... Step: 378... Loss: 0.331387... Val Loss: 0.596150\n",
      "Epoch: 4/100... Step: 379... Loss: 0.186165... Val Loss: 0.582536\n",
      "Epoch: 4/100... Step: 380... Loss: 0.303118... Val Loss: 0.478865\n",
      "Epoch: 4/100... Step: 381... Loss: 0.176562... Val Loss: 0.389787\n",
      "Epoch: 4/100... Step: 382... Loss: 0.281672... Val Loss: 0.305173\n",
      "Epoch: 4/100... Step: 383... Loss: 0.284549... Val Loss: 0.249725\n",
      "Epoch: 4/100... Step: 384... Loss: 0.334388... Val Loss: 0.247610\n",
      "Epoch: 4/100... Step: 385... Loss: 0.332533... Val Loss: 0.262071\n",
      "Epoch: 4/100... Step: 386... Loss: 0.341064... Val Loss: 0.290133\n",
      "Epoch: 4/100... Step: 387... Loss: 0.219923... Val Loss: 0.250182\n",
      "Epoch: 4/100... Step: 388... Loss: 0.310147... Val Loss: 0.189721\n",
      "Epoch: 4/100... Step: 389... Loss: 0.244340... Val Loss: 0.175344\n",
      "Epoch: 4/100... Step: 390... Loss: 0.272249... Val Loss: 0.169210\n",
      "Epoch: 4/100... Step: 391... Loss: 0.222865... Val Loss: 0.157703\n",
      "Epoch: 4/100... Step: 392... Loss: 0.283960... Val Loss: 0.155018\n",
      "Epoch: 4/100... Step: 393... Loss: 0.209960... Val Loss: 0.176005\n",
      "Epoch: 4/100... Step: 394... Loss: 0.253919... Val Loss: 0.164416\n",
      "Epoch: 4/100... Step: 395... Loss: 0.260683... Val Loss: 0.176263\n",
      "Epoch: 4/100... Step: 396... Loss: 0.389530... Val Loss: 0.186798\n",
      "Epoch: 4/100... Step: 397... Loss: 0.246006... Val Loss: 0.186653\n",
      "Epoch: 4/100... Step: 398... Loss: 0.175328... Val Loss: 0.186748\n",
      "Epoch: 4/100... Step: 399... Loss: 0.255549... Val Loss: 0.181854\n",
      "Epoch: 4/100... Step: 400... Loss: 0.177550... Val Loss: 0.179962\n",
      "Epoch: 4/100... Step: 401... Loss: 0.262856... Val Loss: 0.191296\n",
      "Epoch: 4/100... Step: 402... Loss: 0.226013... Val Loss: 0.199743\n",
      "Epoch: 4/100... Step: 403... Loss: 0.235026... Val Loss: 0.193127\n",
      "Epoch: 4/100... Step: 404... Loss: 0.199722... Val Loss: 0.201992\n",
      "Epoch: 4/100... Step: 405... Loss: 0.238697... Val Loss: 0.184807\n",
      "Epoch: 4/100... Step: 406... Loss: 0.307994... Val Loss: 0.176485\n",
      "Epoch: 4/100... Step: 407... Loss: 0.294150... Val Loss: 0.193157\n",
      "Epoch: 4/100... Step: 408... Loss: 0.223881... Val Loss: 0.251165\n",
      "Epoch: 4/100... Step: 409... Loss: 0.149852... Val Loss: 0.270569\n",
      "Epoch: 4/100... Step: 410... Loss: 0.223157... Val Loss: 0.303105\n",
      "Epoch: 4/100... Step: 411... Loss: 0.193722... Val Loss: 0.360263\n",
      "Epoch: 4/100... Step: 412... Loss: 0.359086... Val Loss: 0.374426\n",
      "Epoch: 4/100... Step: 413... Loss: 0.261309... Val Loss: 0.401418\n",
      "Epoch: 4/100... Step: 414... Loss: 0.204721... Val Loss: 0.417872\n",
      "Epoch: 4/100... Step: 415... Loss: 0.219746... Val Loss: 0.398873\n",
      "Epoch: 4/100... Step: 416... Loss: 0.181794... Val Loss: 0.437264\n",
      "Epoch: 5/100... Step: 417... Loss: 0.211146... Val Loss: 0.546040\n",
      "Epoch: 5/100... Step: 418... Loss: 0.302787... Val Loss: 0.449570\n",
      "Epoch: 5/100... Step: 419... Loss: 0.300161... Val Loss: 0.396387\n",
      "Epoch: 5/100... Step: 420... Loss: 0.207292... Val Loss: 0.402344\n",
      "Epoch: 5/100... Step: 421... Loss: 0.192009... Val Loss: 0.424732\n",
      "Epoch: 5/100... Step: 422... Loss: 0.103739... Val Loss: 0.429910\n",
      "Epoch: 5/100... Step: 423... Loss: 0.183318... Val Loss: 0.433883\n",
      "Epoch: 5/100... Step: 424... Loss: 0.196736... Val Loss: 0.438240\n",
      "Epoch: 5/100... Step: 425... Loss: 0.152112... Val Loss: 0.436454\n",
      "Epoch: 5/100... Step: 426... Loss: 0.210263... Val Loss: 0.477171\n",
      "Epoch: 5/100... Step: 427... Loss: 0.255338... Val Loss: 0.510665\n",
      "Epoch: 5/100... Step: 428... Loss: 0.242405... Val Loss: 0.528193\n",
      "Epoch: 5/100... Step: 429... Loss: 0.174286... Val Loss: 0.564023\n",
      "Epoch: 5/100... Step: 430... Loss: 0.237830... Val Loss: 0.565198\n",
      "Epoch: 5/100... Step: 431... Loss: 0.209220... Val Loss: 0.604728\n",
      "Epoch: 5/100... Step: 432... Loss: 0.301674... Val Loss: 0.660255\n",
      "Epoch: 5/100... Step: 433... Loss: 0.236399... Val Loss: 0.750860\n",
      "Epoch: 5/100... Step: 434... Loss: 0.268370... Val Loss: 0.775610\n",
      "Epoch: 5/100... Step: 435... Loss: 0.217157... Val Loss: 0.764633\n",
      "Epoch: 5/100... Step: 436... Loss: 0.159562... Val Loss: 0.709330\n",
      "Epoch: 5/100... Step: 437... Loss: 0.228003... Val Loss: 0.642894\n",
      "Epoch: 5/100... Step: 438... Loss: 0.180803... Val Loss: 0.578694\n",
      "Epoch: 5/100... Step: 439... Loss: 0.298518... Val Loss: 0.524818\n",
      "Epoch: 5/100... Step: 440... Loss: 0.237560... Val Loss: 0.495844\n",
      "Epoch: 5/100... Step: 441... Loss: 0.213848... Val Loss: 0.454108\n",
      "Epoch: 5/100... Step: 442... Loss: 0.187971... Val Loss: 0.388126\n",
      "Epoch: 5/100... Step: 443... Loss: 0.137354... Val Loss: 0.341307\n",
      "Epoch: 5/100... Step: 444... Loss: 0.320044... Val Loss: 0.345305\n",
      "Epoch: 5/100... Step: 445... Loss: 0.275241... Val Loss: 0.339073\n",
      "Epoch: 5/100... Step: 446... Loss: 0.228941... Val Loss: 0.304123\n",
      "Epoch: 5/100... Step: 447... Loss: 0.300092... Val Loss: 0.274927\n",
      "Epoch: 5/100... Step: 448... Loss: 0.222172... Val Loss: 0.244602\n",
      "Epoch: 5/100... Step: 449... Loss: 0.248250... Val Loss: 0.263088\n",
      "Epoch: 5/100... Step: 450... Loss: 0.251542... Val Loss: 0.269746\n",
      "Epoch: 5/100... Step: 451... Loss: 0.257662... Val Loss: 0.303735\n",
      "Epoch: 5/100... Step: 452... Loss: 0.185653... Val Loss: 0.410174\n",
      "Epoch: 5/100... Step: 453... Loss: 0.139456... Val Loss: 0.468102\n",
      "Epoch: 5/100... Step: 454... Loss: 0.279649... Val Loss: 0.480461\n",
      "Epoch: 5/100... Step: 455... Loss: 0.232437... Val Loss: 0.442996\n",
      "Epoch: 5/100... Step: 456... Loss: 0.127272... Val Loss: 0.408324\n",
      "Epoch: 5/100... Step: 457... Loss: 0.258476... Val Loss: 0.353692\n",
      "Epoch: 5/100... Step: 458... Loss: 0.373973... Val Loss: 0.221963\n",
      "Epoch: 5/100... Step: 459... Loss: 0.181479... Val Loss: 0.164480\n",
      "Epoch: 5/100... Step: 460... Loss: 0.250586... Val Loss: 0.227180\n",
      "Epoch: 5/100... Step: 461... Loss: 0.179048... Val Loss: 0.310792\n",
      "Epoch: 5/100... Step: 462... Loss: 0.237767... Val Loss: 0.383147\n",
      "Epoch: 5/100... Step: 463... Loss: 0.301185... Val Loss: 0.453534\n",
      "Epoch: 5/100... Step: 464... Loss: 0.241246... Val Loss: 0.518755\n",
      "Epoch: 5/100... Step: 465... Loss: 0.245310... Val Loss: 0.574207\n",
      "Epoch: 5/100... Step: 466... Loss: 0.137333... Val Loss: 0.568713\n",
      "Epoch: 5/100... Step: 467... Loss: 0.211826... Val Loss: 0.563526\n",
      "Epoch: 5/100... Step: 468... Loss: 0.221570... Val Loss: 0.513580\n",
      "Epoch: 5/100... Step: 469... Loss: 0.133622... Val Loss: 0.464314\n",
      "Epoch: 5/100... Step: 470... Loss: 0.214360... Val Loss: 0.432805\n",
      "Epoch: 5/100... Step: 471... Loss: 0.318566... Val Loss: 0.365369\n",
      "Epoch: 5/100... Step: 472... Loss: 0.161335... Val Loss: 0.366256\n",
      "Epoch: 5/100... Step: 473... Loss: 0.320908... Val Loss: 0.305021\n",
      "Epoch: 5/100... Step: 474... Loss: 0.214939... Val Loss: 0.289285\n",
      "Epoch: 5/100... Step: 475... Loss: 0.289321... Val Loss: 0.259021\n",
      "Epoch: 5/100... Step: 476... Loss: 0.224503... Val Loss: 0.220280\n",
      "Epoch: 5/100... Step: 477... Loss: 0.275434... Val Loss: 0.174032\n",
      "Epoch: 5/100... Step: 478... Loss: 0.269647... Val Loss: 0.145417\n",
      "Epoch: 5/100... Step: 479... Loss: 0.333418... Val Loss: 0.120818\n",
      "Epoch: 5/100... Step: 480... Loss: 0.252235... Val Loss: 0.124583\n",
      "Epoch: 5/100... Step: 481... Loss: 0.269495... Val Loss: 0.169795\n",
      "Epoch: 5/100... Step: 482... Loss: 0.214413... Val Loss: 0.233435\n",
      "Epoch: 5/100... Step: 483... Loss: 0.249507... Val Loss: 0.270861\n",
      "Epoch: 5/100... Step: 484... Loss: 0.212796... Val Loss: 0.348325\n",
      "Epoch: 5/100... Step: 485... Loss: 0.212762... Val Loss: 0.406875\n",
      "Epoch: 5/100... Step: 486... Loss: 0.281364... Val Loss: 0.431342\n",
      "Epoch: 5/100... Step: 487... Loss: 0.206740... Val Loss: 0.436360\n",
      "Epoch: 5/100... Step: 488... Loss: 0.261764... Val Loss: 0.460549\n",
      "Epoch: 5/100... Step: 489... Loss: 0.265655... Val Loss: 0.425742\n",
      "Epoch: 5/100... Step: 490... Loss: 0.261483... Val Loss: 0.460471\n",
      "Epoch: 5/100... Step: 491... Loss: 0.208299... Val Loss: 0.572672\n",
      "Epoch: 5/100... Step: 492... Loss: 0.219702... Val Loss: 0.703222\n",
      "Epoch: 5/100... Step: 493... Loss: 0.256032... Val Loss: 0.800894\n",
      "Epoch: 5/100... Step: 494... Loss: 0.223295... Val Loss: 0.875532\n",
      "Epoch: 5/100... Step: 495... Loss: 0.260782... Val Loss: 0.946918\n",
      "Epoch: 5/100... Step: 496... Loss: 0.208935... Val Loss: 0.973646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100... Step: 497... Loss: 0.286440... Val Loss: 0.964916\n",
      "Epoch: 5/100... Step: 498... Loss: 0.259960... Val Loss: 1.059749\n",
      "Epoch: 5/100... Step: 499... Loss: 0.232559... Val Loss: 1.108971\n",
      "Epoch: 5/100... Step: 500... Loss: 0.271829... Val Loss: 1.139115\n",
      "Epoch: 5/100... Step: 501... Loss: 0.181707... Val Loss: 1.209475\n",
      "Epoch: 5/100... Step: 502... Loss: 0.216263... Val Loss: 1.263525\n",
      "Epoch: 5/100... Step: 503... Loss: 0.180664... Val Loss: 1.312986\n",
      "Epoch: 5/100... Step: 504... Loss: 0.308123... Val Loss: 1.328766\n",
      "Epoch: 5/100... Step: 505... Loss: 0.312311... Val Loss: 1.325203\n",
      "Epoch: 5/100... Step: 506... Loss: 0.219634... Val Loss: 1.290699\n",
      "Epoch: 5/100... Step: 507... Loss: 0.174991... Val Loss: 1.273770\n",
      "Epoch: 5/100... Step: 508... Loss: 0.253899... Val Loss: 1.218791\n",
      "Epoch: 5/100... Step: 509... Loss: 0.247706... Val Loss: 1.177947\n",
      "Epoch: 5/100... Step: 510... Loss: 0.222409... Val Loss: 1.233565\n",
      "Epoch: 5/100... Step: 511... Loss: 0.264050... Val Loss: 1.247969\n",
      "Epoch: 5/100... Step: 512... Loss: 0.320912... Val Loss: 1.201522\n",
      "Epoch: 5/100... Step: 513... Loss: 0.259348... Val Loss: 1.220421\n",
      "Epoch: 5/100... Step: 514... Loss: 0.261573... Val Loss: 1.166119\n",
      "Epoch: 5/100... Step: 515... Loss: 0.295792... Val Loss: 1.077265\n",
      "Epoch: 5/100... Step: 516... Loss: 0.250220... Val Loss: 1.050813\n",
      "Epoch: 5/100... Step: 517... Loss: 0.172132... Val Loss: 0.947991\n",
      "Epoch: 5/100... Step: 518... Loss: 0.238639... Val Loss: 0.797980\n",
      "Epoch: 5/100... Step: 519... Loss: 0.223347... Val Loss: 0.782925\n",
      "Epoch: 5/100... Step: 520... Loss: 0.251389... Val Loss: 0.685836\n",
      "Epoch: 6/100... Step: 521... Loss: 0.183514... Val Loss: 0.526702\n",
      "Epoch: 6/100... Step: 522... Loss: 0.213675... Val Loss: 0.487973\n",
      "Epoch: 6/100... Step: 523... Loss: 0.255982... Val Loss: 0.508786\n",
      "Epoch: 6/100... Step: 524... Loss: 0.317096... Val Loss: 0.418803\n",
      "Epoch: 6/100... Step: 525... Loss: 0.323664... Val Loss: 0.318215\n",
      "Epoch: 6/100... Step: 526... Loss: 0.352190... Val Loss: 0.264402\n",
      "Epoch: 6/100... Step: 527... Loss: 0.234294... Val Loss: 0.211495\n",
      "Epoch: 6/100... Step: 528... Loss: 0.187515... Val Loss: 0.180212\n",
      "Epoch: 6/100... Step: 529... Loss: 0.211257... Val Loss: 0.181875\n",
      "Epoch: 6/100... Step: 530... Loss: 0.275372... Val Loss: 0.195731\n",
      "Epoch: 6/100... Step: 531... Loss: 0.233199... Val Loss: 0.230492\n",
      "Epoch: 6/100... Step: 532... Loss: 0.158094... Val Loss: 0.257050\n",
      "Epoch: 6/100... Step: 533... Loss: 0.261915... Val Loss: 0.297259\n",
      "Epoch: 6/100... Step: 534... Loss: 0.231084... Val Loss: 0.311656\n",
      "Epoch: 6/100... Step: 535... Loss: 0.246106... Val Loss: 0.297824\n",
      "Epoch: 6/100... Step: 536... Loss: 0.215723... Val Loss: 0.302733\n",
      "Epoch: 6/100... Step: 537... Loss: 0.242621... Val Loss: 0.389985\n",
      "Epoch: 6/100... Step: 538... Loss: 0.261107... Val Loss: 0.403364\n",
      "Epoch: 6/100... Step: 539... Loss: 0.212605... Val Loss: 0.414555\n",
      "Epoch: 6/100... Step: 540... Loss: 0.151367... Val Loss: 0.457377\n",
      "Epoch: 6/100... Step: 541... Loss: 0.200063... Val Loss: 0.452787\n",
      "Epoch: 6/100... Step: 542... Loss: 0.151495... Val Loss: 0.430275\n",
      "Epoch: 6/100... Step: 543... Loss: 0.269789... Val Loss: 0.387649\n",
      "Epoch: 6/100... Step: 544... Loss: 0.348368... Val Loss: 0.377351\n",
      "Epoch: 6/100... Step: 545... Loss: 0.236973... Val Loss: 0.300244\n",
      "Epoch: 6/100... Step: 546... Loss: 0.211079... Val Loss: 0.283702\n",
      "Epoch: 6/100... Step: 547... Loss: 0.291976... Val Loss: 0.254426\n",
      "Epoch: 6/100... Step: 548... Loss: 0.176654... Val Loss: 0.220295\n",
      "Epoch: 6/100... Step: 549... Loss: 0.229586... Val Loss: 0.209805\n",
      "Epoch: 6/100... Step: 550... Loss: 0.143567... Val Loss: 0.200899\n",
      "Epoch: 6/100... Step: 551... Loss: 0.194769... Val Loss: 0.217466\n",
      "Epoch: 6/100... Step: 552... Loss: 0.213270... Val Loss: 0.210457\n",
      "Epoch: 6/100... Step: 553... Loss: 0.282260... Val Loss: 0.237324\n",
      "Epoch: 6/100... Step: 554... Loss: 0.312073... Val Loss: 0.254242\n",
      "Epoch: 6/100... Step: 555... Loss: 0.207834... Val Loss: 0.253245\n",
      "Epoch: 6/100... Step: 556... Loss: 0.352708... Val Loss: 0.157232\n",
      "Epoch: 6/100... Step: 557... Loss: 0.174756... Val Loss: 0.122781\n",
      "Epoch: 6/100... Step: 558... Loss: 0.221331... Val Loss: 0.144322\n",
      "Epoch: 6/100... Step: 559... Loss: 0.161907... Val Loss: 0.155165\n",
      "Epoch: 6/100... Step: 560... Loss: 0.304519... Val Loss: 0.158690\n",
      "Epoch: 6/100... Step: 561... Loss: 0.186976... Val Loss: 0.192465\n",
      "Epoch: 6/100... Step: 562... Loss: 0.262438... Val Loss: 0.202666\n",
      "Epoch: 6/100... Step: 563... Loss: 0.190850... Val Loss: 0.163845\n",
      "Epoch: 6/100... Step: 564... Loss: 0.206608... Val Loss: 0.171146\n",
      "Epoch: 6/100... Step: 565... Loss: 0.231126... Val Loss: 0.172712\n",
      "Epoch: 6/100... Step: 566... Loss: 0.252265... Val Loss: 0.170423\n",
      "Epoch: 6/100... Step: 567... Loss: 0.236524... Val Loss: 0.180565\n",
      "Epoch: 6/100... Step: 568... Loss: 0.229064... Val Loss: 0.186696\n",
      "Epoch: 6/100... Step: 569... Loss: 0.180296... Val Loss: 0.165519\n",
      "Epoch: 6/100... Step: 570... Loss: 0.217997... Val Loss: 0.164573\n",
      "Epoch: 6/100... Step: 571... Loss: 0.330461... Val Loss: 0.178906\n",
      "Epoch: 6/100... Step: 572... Loss: 0.226918... Val Loss: 0.216898\n",
      "Epoch: 6/100... Step: 573... Loss: 0.354845... Val Loss: 0.241480\n",
      "Epoch: 6/100... Step: 574... Loss: 0.153889... Val Loss: 0.246018\n",
      "Epoch: 6/100... Step: 575... Loss: 0.298232... Val Loss: 0.255173\n",
      "Epoch: 6/100... Step: 576... Loss: 0.198579... Val Loss: 0.261413\n",
      "Epoch: 6/100... Step: 577... Loss: 0.303721... Val Loss: 0.266956\n",
      "Epoch: 6/100... Step: 578... Loss: 0.183106... Val Loss: 0.278935\n",
      "Epoch: 6/100... Step: 579... Loss: 0.274323... Val Loss: 0.265182\n",
      "Epoch: 6/100... Step: 580... Loss: 0.194300... Val Loss: 0.220126\n",
      "Epoch: 6/100... Step: 581... Loss: 0.297866... Val Loss: 0.170954\n",
      "Epoch: 6/100... Step: 582... Loss: 0.267031... Val Loss: 0.147414\n",
      "Epoch: 6/100... Step: 583... Loss: 0.097626... Val Loss: 0.129366\n",
      "Epoch: 6/100... Step: 584... Loss: 0.191326... Val Loss: 0.145233\n",
      "Epoch: 6/100... Step: 585... Loss: 0.201533... Val Loss: 0.170985\n",
      "Epoch: 6/100... Step: 586... Loss: 0.203587... Val Loss: 0.239632\n",
      "Epoch: 6/100... Step: 587... Loss: 0.323611... Val Loss: 0.268306\n",
      "Epoch: 6/100... Step: 588... Loss: 0.268362... Val Loss: 0.290864\n",
      "Epoch: 6/100... Step: 589... Loss: 0.273449... Val Loss: 0.297101\n",
      "Epoch: 6/100... Step: 590... Loss: 0.213269... Val Loss: 0.321741\n",
      "Epoch: 6/100... Step: 591... Loss: 0.186990... Val Loss: 0.338016\n",
      "Epoch: 6/100... Step: 592... Loss: 0.299696... Val Loss: 0.331991\n",
      "Epoch: 6/100... Step: 593... Loss: 0.202106... Val Loss: 0.300898\n",
      "Epoch: 6/100... Step: 594... Loss: 0.189649... Val Loss: 0.260388\n",
      "Epoch: 6/100... Step: 595... Loss: 0.238622... Val Loss: 0.253622\n",
      "Epoch: 6/100... Step: 596... Loss: 0.312228... Val Loss: 0.259924\n",
      "Epoch: 6/100... Step: 597... Loss: 0.258647... Val Loss: 0.285707\n",
      "Epoch: 6/100... Step: 598... Loss: 0.237105... Val Loss: 0.295917\n",
      "Epoch: 6/100... Step: 599... Loss: 0.274972... Val Loss: 0.295894\n",
      "Epoch: 6/100... Step: 600... Loss: 0.380885... Val Loss: 0.301996\n",
      "Epoch: 6/100... Step: 601... Loss: 0.134778... Val Loss: 0.270331\n",
      "Epoch: 6/100... Step: 602... Loss: 0.316999... Val Loss: 0.319667\n",
      "Epoch: 6/100... Step: 603... Loss: 0.147172... Val Loss: 0.326278\n",
      "Epoch: 6/100... Step: 604... Loss: 0.255855... Val Loss: 0.288097\n",
      "Epoch: 6/100... Step: 605... Loss: 0.262266... Val Loss: 0.276638\n",
      "Epoch: 6/100... Step: 606... Loss: 0.161849... Val Loss: 0.222565\n",
      "Epoch: 6/100... Step: 607... Loss: 0.204018... Val Loss: 0.184176\n",
      "Epoch: 6/100... Step: 608... Loss: 0.308576... Val Loss: 0.182111\n",
      "Epoch: 6/100... Step: 609... Loss: 0.267273... Val Loss: 0.164212\n",
      "Epoch: 6/100... Step: 610... Loss: 0.425132... Val Loss: 0.166202\n",
      "Epoch: 6/100... Step: 611... Loss: 0.328479... Val Loss: 0.166561\n",
      "Epoch: 6/100... Step: 612... Loss: 0.253927... Val Loss: 0.161695\n",
      "Epoch: 6/100... Step: 613... Loss: 0.155998... Val Loss: 0.161772\n",
      "Epoch: 6/100... Step: 614... Loss: 0.282573... Val Loss: 0.152262\n",
      "Epoch: 6/100... Step: 615... Loss: 0.260783... Val Loss: 0.146566\n",
      "Epoch: 6/100... Step: 616... Loss: 0.264164... Val Loss: 0.151645\n",
      "Epoch: 6/100... Step: 617... Loss: 0.199931... Val Loss: 0.133017\n",
      "Epoch: 6/100... Step: 618... Loss: 0.231803... Val Loss: 0.125397\n",
      "Epoch: 6/100... Step: 619... Loss: 0.262357... Val Loss: 0.127107\n",
      "Epoch: 6/100... Step: 620... Loss: 0.301429... Val Loss: 0.140442\n",
      "Epoch: 6/100... Step: 621... Loss: 0.184742... Val Loss: 0.154069\n",
      "Epoch: 6/100... Step: 622... Loss: 0.278140... Val Loss: 0.221001\n",
      "Epoch: 6/100... Step: 623... Loss: 0.209223... Val Loss: 0.208519\n",
      "Epoch: 6/100... Step: 624... Loss: 0.313856... Val Loss: 0.212325\n",
      "Epoch: 7/100... Step: 625... Loss: 0.280842... Val Loss: 0.232323\n",
      "Epoch: 7/100... Step: 626... Loss: 0.306629... Val Loss: 0.192337\n",
      "Epoch: 7/100... Step: 627... Loss: 0.246421... Val Loss: 0.114896\n",
      "Epoch: 7/100... Step: 628... Loss: 0.295924... Val Loss: 0.116005\n",
      "Epoch: 7/100... Step: 629... Loss: 0.219300... Val Loss: 0.140464\n",
      "Epoch: 7/100... Step: 630... Loss: 0.304704... Val Loss: 0.164205\n",
      "Epoch: 7/100... Step: 631... Loss: 0.253740... Val Loss: 0.168179\n",
      "Epoch: 7/100... Step: 632... Loss: 0.271414... Val Loss: 0.151451\n",
      "Epoch: 7/100... Step: 633... Loss: 0.332647... Val Loss: 0.138711\n",
      "Epoch: 7/100... Step: 634... Loss: 0.221071... Val Loss: 0.134097\n",
      "Epoch: 7/100... Step: 635... Loss: 0.264388... Val Loss: 0.139662\n",
      "Epoch: 7/100... Step: 636... Loss: 0.247662... Val Loss: 0.156751\n",
      "Epoch: 7/100... Step: 637... Loss: 0.313713... Val Loss: 0.188423\n",
      "Epoch: 7/100... Step: 638... Loss: 0.216141... Val Loss: 0.181772\n",
      "Epoch: 7/100... Step: 639... Loss: 0.218424... Val Loss: 0.202246\n",
      "Epoch: 7/100... Step: 640... Loss: 0.250231... Val Loss: 0.213602\n",
      "Epoch: 7/100... Step: 641... Loss: 0.217099... Val Loss: 0.208442\n",
      "Epoch: 7/100... Step: 642... Loss: 0.252465... Val Loss: 0.150451\n",
      "Epoch: 7/100... Step: 643... Loss: 0.171071... Val Loss: 0.108151\n",
      "Epoch: 7/100... Step: 644... Loss: 0.222904... Val Loss: 0.101644\n",
      "Epoch: 7/100... Step: 645... Loss: 0.194396... Val Loss: 0.140164\n",
      "Epoch: 7/100... Step: 646... Loss: 0.288334... Val Loss: 0.168002\n",
      "Epoch: 7/100... Step: 647... Loss: 0.218136... Val Loss: 0.167362\n",
      "Epoch: 7/100... Step: 648... Loss: 0.180052... Val Loss: 0.182521\n",
      "Epoch: 7/100... Step: 649... Loss: 0.247987... Val Loss: 0.176201\n",
      "Epoch: 7/100... Step: 650... Loss: 0.357484... Val Loss: 0.183047\n",
      "Epoch: 7/100... Step: 651... Loss: 0.361745... Val Loss: 0.217301\n",
      "Epoch: 7/100... Step: 652... Loss: 0.320376... Val Loss: 0.218523\n",
      "Epoch: 7/100... Step: 653... Loss: 0.314416... Val Loss: 0.208653\n",
      "Epoch: 7/100... Step: 654... Loss: 0.154076... Val Loss: 0.164386\n",
      "Epoch: 7/100... Step: 655... Loss: 0.249992... Val Loss: 0.162699\n",
      "Epoch: 7/100... Step: 656... Loss: 0.170684... Val Loss: 0.134562\n",
      "Epoch: 7/100... Step: 657... Loss: 0.187126... Val Loss: 0.107307\n",
      "Epoch: 7/100... Step: 658... Loss: 0.265576... Val Loss: 0.108024\n",
      "Epoch: 7/100... Step: 659... Loss: 0.294405... Val Loss: 0.127585\n",
      "Epoch: 7/100... Step: 660... Loss: 0.357770... Val Loss: 0.082765\n",
      "Epoch: 7/100... Step: 661... Loss: 0.288489... Val Loss: 0.082949\n",
      "Epoch: 7/100... Step: 662... Loss: 0.371797... Val Loss: 0.106415\n",
      "Epoch: 7/100... Step: 663... Loss: 0.214158... Val Loss: 0.175870\n",
      "Epoch: 7/100... Step: 664... Loss: 0.236140... Val Loss: 0.223024\n",
      "Epoch: 7/100... Step: 665... Loss: 0.132512... Val Loss: 0.260635\n",
      "Epoch: 7/100... Step: 666... Loss: 0.266895... Val Loss: 0.319530\n",
      "Epoch: 7/100... Step: 667... Loss: 0.218221... Val Loss: 0.327210\n",
      "Epoch: 7/100... Step: 668... Loss: 0.174417... Val Loss: 0.314164\n",
      "Epoch: 7/100... Step: 669... Loss: 0.214957... Val Loss: 0.224253\n",
      "Epoch: 7/100... Step: 670... Loss: 0.245297... Val Loss: 0.209799\n",
      "Epoch: 7/100... Step: 671... Loss: 0.200889... Val Loss: 0.148044\n",
      "Epoch: 7/100... Step: 672... Loss: 0.352770... Val Loss: 0.124200\n",
      "Epoch: 7/100... Step: 673... Loss: 0.222045... Val Loss: 0.120197\n",
      "Epoch: 7/100... Step: 674... Loss: 0.279835... Val Loss: 0.118967\n",
      "Epoch: 7/100... Step: 675... Loss: 0.220721... Val Loss: 0.149958\n",
      "Epoch: 7/100... Step: 676... Loss: 0.256445... Val Loss: 0.134991\n",
      "Epoch: 7/100... Step: 677... Loss: 0.358448... Val Loss: 0.129360\n",
      "Epoch: 7/100... Step: 678... Loss: 0.179745... Val Loss: 0.107830\n",
      "Epoch: 7/100... Step: 679... Loss: 0.245359... Val Loss: 0.076851\n",
      "Epoch: 7/100... Step: 680... Loss: 0.269404... Val Loss: 0.114856\n",
      "Epoch: 7/100... Step: 681... Loss: 0.197234... Val Loss: 0.114483\n",
      "Epoch: 7/100... Step: 682... Loss: 0.256103... Val Loss: 0.165877\n",
      "Epoch: 7/100... Step: 683... Loss: 0.204124... Val Loss: 0.244164\n",
      "Epoch: 7/100... Step: 684... Loss: 0.242077... Val Loss: 0.313182\n",
      "Epoch: 7/100... Step: 685... Loss: 0.170694... Val Loss: 0.361938\n",
      "Epoch: 7/100... Step: 686... Loss: 0.102682... Val Loss: 0.373329\n",
      "Epoch: 7/100... Step: 687... Loss: 0.230855... Val Loss: 0.407935\n",
      "Epoch: 7/100... Step: 688... Loss: 0.252749... Val Loss: 0.424057\n",
      "Epoch: 7/100... Step: 689... Loss: 0.357007... Val Loss: 0.438714\n",
      "Epoch: 7/100... Step: 690... Loss: 0.291452... Val Loss: 0.556070\n",
      "Epoch: 7/100... Step: 691... Loss: 0.308855... Val Loss: 0.707147\n",
      "Epoch: 7/100... Step: 692... Loss: 0.300966... Val Loss: 0.768977\n",
      "Epoch: 7/100... Step: 693... Loss: 0.251786... Val Loss: 0.836317\n",
      "Epoch: 7/100... Step: 694... Loss: 0.332947... Val Loss: 0.885525\n",
      "Epoch: 7/100... Step: 695... Loss: 0.275543... Val Loss: 0.998215\n",
      "Epoch: 7/100... Step: 696... Loss: 0.147106... Val Loss: 1.131826\n",
      "Epoch: 7/100... Step: 697... Loss: 0.163469... Val Loss: 1.240982\n",
      "Epoch: 7/100... Step: 698... Loss: 0.288023... Val Loss: 1.275790\n",
      "Epoch: 7/100... Step: 699... Loss: 0.272807... Val Loss: 1.242249\n",
      "Epoch: 7/100... Step: 700... Loss: 0.304480... Val Loss: 1.192538\n",
      "Epoch: 7/100... Step: 701... Loss: 0.180478... Val Loss: 1.214111\n",
      "Epoch: 7/100... Step: 702... Loss: 0.207827... Val Loss: 1.166915\n",
      "Epoch: 7/100... Step: 703... Loss: 0.399701... Val Loss: 1.078721\n",
      "Epoch: 7/100... Step: 704... Loss: 0.260794... Val Loss: 1.059973\n",
      "Epoch: 7/100... Step: 705... Loss: 0.270348... Val Loss: 1.034335\n",
      "Epoch: 7/100... Step: 706... Loss: 0.232422... Val Loss: 0.941581\n",
      "Epoch: 7/100... Step: 707... Loss: 0.228720... Val Loss: 0.955371\n",
      "Epoch: 7/100... Step: 708... Loss: 0.252780... Val Loss: 0.960179\n",
      "Epoch: 7/100... Step: 709... Loss: 0.286549... Val Loss: 0.971943\n",
      "Epoch: 7/100... Step: 710... Loss: 0.291925... Val Loss: 0.943347\n",
      "Epoch: 7/100... Step: 711... Loss: 0.248094... Val Loss: 0.890920\n",
      "Epoch: 7/100... Step: 712... Loss: 0.280270... Val Loss: 0.860215\n",
      "Epoch: 7/100... Step: 713... Loss: 0.307507... Val Loss: 0.796596\n",
      "Epoch: 7/100... Step: 714... Loss: 0.150235... Val Loss: 0.782371\n",
      "Epoch: 7/100... Step: 715... Loss: 0.288709... Val Loss: 0.731103\n",
      "Epoch: 7/100... Step: 716... Loss: 0.252895... Val Loss: 0.694707\n",
      "Epoch: 7/100... Step: 717... Loss: 0.262410... Val Loss: 0.614460\n",
      "Epoch: 7/100... Step: 718... Loss: 0.291502... Val Loss: 0.535007\n",
      "Epoch: 7/100... Step: 719... Loss: 0.317211... Val Loss: 0.487757\n",
      "Epoch: 7/100... Step: 720... Loss: 0.216538... Val Loss: 0.451665\n",
      "Epoch: 7/100... Step: 721... Loss: 0.253245... Val Loss: 0.445559\n",
      "Epoch: 7/100... Step: 722... Loss: 0.171250... Val Loss: 0.467605\n",
      "Epoch: 7/100... Step: 723... Loss: 0.253592... Val Loss: 0.414831\n",
      "Epoch: 7/100... Step: 724... Loss: 0.215309... Val Loss: 0.418247\n",
      "Epoch: 7/100... Step: 725... Loss: 0.124669... Val Loss: 0.469886\n",
      "Epoch: 7/100... Step: 726... Loss: 0.112680... Val Loss: 0.513781\n",
      "Epoch: 7/100... Step: 727... Loss: 0.357769... Val Loss: 0.507126\n",
      "Epoch: 7/100... Step: 728... Loss: 0.195528... Val Loss: 0.483740\n",
      "Epoch: 8/100... Step: 729... Loss: 0.388806... Val Loss: 0.515901\n",
      "Epoch: 8/100... Step: 730... Loss: 0.235663... Val Loss: 0.502864\n",
      "Epoch: 8/100... Step: 731... Loss: 0.298738... Val Loss: 0.485175\n",
      "Epoch: 8/100... Step: 732... Loss: 0.225370... Val Loss: 0.422433\n",
      "Epoch: 8/100... Step: 733... Loss: 0.175780... Val Loss: 0.296846\n",
      "Epoch: 8/100... Step: 734... Loss: 0.168989... Val Loss: 0.144158\n",
      "Epoch: 8/100... Step: 735... Loss: 0.273976... Val Loss: 0.164880\n",
      "Epoch: 8/100... Step: 736... Loss: 0.177060... Val Loss: 0.337767\n",
      "Epoch: 8/100... Step: 737... Loss: 0.239041... Val Loss: 0.546368\n",
      "Epoch: 8/100... Step: 738... Loss: 0.250786... Val Loss: 0.751545\n",
      "Epoch: 8/100... Step: 739... Loss: 0.190504... Val Loss: 0.939960\n",
      "Epoch: 8/100... Step: 740... Loss: 0.320972... Val Loss: 1.136544\n",
      "Epoch: 8/100... Step: 741... Loss: 0.174081... Val Loss: 1.318322\n",
      "Epoch: 8/100... Step: 742... Loss: 0.241599... Val Loss: 1.477441\n",
      "Epoch: 8/100... Step: 743... Loss: 0.244976... Val Loss: 1.586262\n",
      "Epoch: 8/100... Step: 744... Loss: 0.169701... Val Loss: 1.675559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Step: 745... Loss: 0.262366... Val Loss: 1.759417\n",
      "Epoch: 8/100... Step: 746... Loss: 0.231041... Val Loss: 1.831446\n",
      "Epoch: 8/100... Step: 747... Loss: 0.209133... Val Loss: 1.855186\n",
      "Epoch: 8/100... Step: 748... Loss: 0.230907... Val Loss: 1.873491\n",
      "Epoch: 8/100... Step: 749... Loss: 0.304281... Val Loss: 1.865388\n",
      "Epoch: 8/100... Step: 750... Loss: 0.242837... Val Loss: 1.878993\n",
      "Epoch: 8/100... Step: 751... Loss: 0.248943... Val Loss: 1.870967\n",
      "Epoch: 8/100... Step: 752... Loss: 0.187975... Val Loss: 1.830511\n",
      "Epoch: 8/100... Step: 753... Loss: 0.240819... Val Loss: 1.787336\n",
      "Epoch: 8/100... Step: 754... Loss: 0.158015... Val Loss: 1.739002\n",
      "Epoch: 8/100... Step: 755... Loss: 0.239851... Val Loss: 1.658324\n",
      "Epoch: 8/100... Step: 756... Loss: 0.196461... Val Loss: 1.587351\n",
      "Epoch: 8/100... Step: 757... Loss: 0.308615... Val Loss: 1.523420\n",
      "Epoch: 8/100... Step: 758... Loss: 0.271443... Val Loss: 1.437818\n",
      "Epoch: 8/100... Step: 759... Loss: 0.385807... Val Loss: 1.387583\n",
      "Epoch: 8/100... Step: 760... Loss: 0.172633... Val Loss: 1.321852\n",
      "Epoch: 8/100... Step: 761... Loss: 0.310709... Val Loss: 1.260915\n",
      "Epoch: 8/100... Step: 762... Loss: 0.248331... Val Loss: 1.222668\n",
      "Epoch: 8/100... Step: 763... Loss: 0.295277... Val Loss: 1.159982\n",
      "Epoch: 8/100... Step: 764... Loss: 0.339292... Val Loss: 0.992695\n",
      "Epoch: 8/100... Step: 765... Loss: 0.362465... Val Loss: 0.844526\n",
      "Epoch: 8/100... Step: 766... Loss: 0.222689... Val Loss: 0.714095\n",
      "Epoch: 8/100... Step: 767... Loss: 0.239885... Val Loss: 0.613382\n",
      "Epoch: 8/100... Step: 768... Loss: 0.162834... Val Loss: 0.568647\n",
      "Epoch: 8/100... Step: 769... Loss: 0.219333... Val Loss: 0.529212\n",
      "Epoch: 8/100... Step: 770... Loss: 0.283380... Val Loss: 0.400603\n",
      "Epoch: 8/100... Step: 771... Loss: 0.251203... Val Loss: 0.168130\n",
      "Epoch: 8/100... Step: 772... Loss: 0.351233... Val Loss: 0.068680\n",
      "Epoch: 8/100... Step: 773... Loss: 0.280099... Val Loss: 0.163967\n",
      "Epoch: 8/100... Step: 774... Loss: 0.233484... Val Loss: 0.268412\n",
      "Epoch: 8/100... Step: 775... Loss: 0.134111... Val Loss: 0.357536\n",
      "Epoch: 8/100... Step: 776... Loss: 0.267105... Val Loss: 0.433718\n",
      "Epoch: 8/100... Step: 777... Loss: 0.242160... Val Loss: 0.470190\n",
      "Epoch: 8/100... Step: 778... Loss: 0.254210... Val Loss: 0.490655\n",
      "Epoch: 8/100... Step: 779... Loss: 0.146747... Val Loss: 0.509136\n",
      "Epoch: 8/100... Step: 780... Loss: 0.147381... Val Loss: 0.526944\n",
      "Epoch: 8/100... Step: 781... Loss: 0.215096... Val Loss: 0.472454\n",
      "Epoch: 8/100... Step: 782... Loss: 0.173515... Val Loss: 0.417774\n",
      "Epoch: 8/100... Step: 783... Loss: 0.226963... Val Loss: 0.346363\n",
      "Epoch: 8/100... Step: 784... Loss: 0.354927... Val Loss: 0.288201\n",
      "Epoch: 8/100... Step: 785... Loss: 0.209129... Val Loss: 0.289015\n",
      "Epoch: 8/100... Step: 786... Loss: 0.174298... Val Loss: 0.263091\n",
      "Epoch: 8/100... Step: 787... Loss: 0.272910... Val Loss: 0.225796\n",
      "Epoch: 8/100... Step: 788... Loss: 0.345594... Val Loss: 0.206008\n",
      "Epoch: 8/100... Step: 789... Loss: 0.134756... Val Loss: 0.176523\n",
      "Epoch: 8/100... Step: 790... Loss: 0.241142... Val Loss: 0.160554\n",
      "Epoch: 8/100... Step: 791... Loss: 0.304163... Val Loss: 0.131660\n",
      "Epoch: 8/100... Step: 792... Loss: 0.182983... Val Loss: 0.094562\n",
      "Epoch: 8/100... Step: 793... Loss: 0.196294... Val Loss: 0.079957\n",
      "Epoch: 8/100... Step: 794... Loss: 0.267543... Val Loss: 0.059975\n",
      "Epoch: 8/100... Step: 795... Loss: 0.154156... Val Loss: 0.086084\n",
      "Epoch: 8/100... Step: 796... Loss: 0.348704... Val Loss: 0.099106\n",
      "Epoch: 8/100... Step: 797... Loss: 0.365498... Val Loss: 0.107961\n",
      "Epoch: 8/100... Step: 798... Loss: 0.310045... Val Loss: 0.130343\n",
      "Epoch: 8/100... Step: 799... Loss: 0.304686... Val Loss: 0.124101\n",
      "Epoch: 8/100... Step: 800... Loss: 0.242992... Val Loss: 0.121203\n",
      "Epoch: 8/100... Step: 801... Loss: 0.440401... Val Loss: 0.087948\n",
      "Epoch: 8/100... Step: 802... Loss: 0.393266... Val Loss: 0.079949\n",
      "Epoch: 8/100... Step: 803... Loss: 0.342715... Val Loss: 0.064605\n",
      "Epoch: 8/100... Step: 804... Loss: 0.411037... Val Loss: 0.074058\n",
      "Epoch: 8/100... Step: 805... Loss: 0.234483... Val Loss: 0.079601\n",
      "Epoch: 8/100... Step: 806... Loss: 0.236705... Val Loss: 0.088845\n",
      "Epoch: 8/100... Step: 807... Loss: 0.203130... Val Loss: 0.108943\n",
      "Epoch: 8/100... Step: 808... Loss: 0.231136... Val Loss: 0.161839\n",
      "Epoch: 8/100... Step: 809... Loss: 0.169994... Val Loss: 0.189368\n",
      "Epoch: 8/100... Step: 810... Loss: 0.148324... Val Loss: 0.196870\n",
      "Epoch: 8/100... Step: 811... Loss: 0.261002... Val Loss: 0.214615\n",
      "Epoch: 8/100... Step: 812... Loss: 0.257082... Val Loss: 0.228143\n",
      "Epoch: 8/100... Step: 813... Loss: 0.230084... Val Loss: 0.275912\n",
      "Epoch: 8/100... Step: 814... Loss: 0.227682... Val Loss: 0.293741\n",
      "Epoch: 8/100... Step: 815... Loss: 0.211101... Val Loss: 0.287137\n",
      "Epoch: 8/100... Step: 816... Loss: 0.291597... Val Loss: 0.303602\n",
      "Epoch: 8/100... Step: 817... Loss: 0.234833... Val Loss: 0.294698\n",
      "Epoch: 8/100... Step: 818... Loss: 0.249824... Val Loss: 0.300635\n",
      "Epoch: 8/100... Step: 819... Loss: 0.324845... Val Loss: 0.296971\n",
      "Epoch: 8/100... Step: 820... Loss: 0.198174... Val Loss: 0.288181\n",
      "Epoch: 8/100... Step: 821... Loss: 0.271452... Val Loss: 0.259325\n",
      "Epoch: 8/100... Step: 822... Loss: 0.202513... Val Loss: 0.236851\n",
      "Epoch: 8/100... Step: 823... Loss: 0.200692... Val Loss: 0.191402\n",
      "Epoch: 8/100... Step: 824... Loss: 0.214652... Val Loss: 0.143097\n",
      "Epoch: 8/100... Step: 825... Loss: 0.177335... Val Loss: 0.123179\n",
      "Epoch: 8/100... Step: 826... Loss: 0.183384... Val Loss: 0.081531\n",
      "Epoch: 8/100... Step: 827... Loss: 0.195751... Val Loss: 0.076394\n",
      "Epoch: 8/100... Step: 828... Loss: 0.277691... Val Loss: 0.076955\n",
      "Epoch: 8/100... Step: 829... Loss: 0.199746... Val Loss: 0.072445\n",
      "Epoch: 8/100... Step: 830... Loss: 0.227030... Val Loss: 0.088861\n",
      "Epoch: 8/100... Step: 831... Loss: 0.227701... Val Loss: 0.095900\n",
      "Epoch: 8/100... Step: 832... Loss: 0.302242... Val Loss: 0.103541\n",
      "Epoch: 9/100... Step: 833... Loss: 0.205837... Val Loss: 0.140307\n",
      "Epoch: 9/100... Step: 834... Loss: 0.249575... Val Loss: 0.138729\n",
      "Epoch: 9/100... Step: 835... Loss: 0.248748... Val Loss: 0.135132\n",
      "Epoch: 9/100... Step: 836... Loss: 0.202300... Val Loss: 0.233901\n",
      "Epoch: 9/100... Step: 837... Loss: 0.233357... Val Loss: 0.319032\n",
      "Epoch: 9/100... Step: 838... Loss: 0.186246... Val Loss: 0.370595\n",
      "Epoch: 9/100... Step: 839... Loss: 0.253235... Val Loss: 0.358473\n",
      "Epoch: 9/100... Step: 840... Loss: 0.113204... Val Loss: 0.338215\n",
      "Epoch: 9/100... Step: 841... Loss: 0.279889... Val Loss: 0.290194\n",
      "Epoch: 9/100... Step: 842... Loss: 0.244036... Val Loss: 0.245137\n",
      "Epoch: 9/100... Step: 843... Loss: 0.255076... Val Loss: 0.223117\n",
      "Epoch: 9/100... Step: 844... Loss: 0.204443... Val Loss: 0.251110\n",
      "Epoch: 9/100... Step: 845... Loss: 0.261391... Val Loss: 0.275345\n",
      "Epoch: 9/100... Step: 846... Loss: 0.222441... Val Loss: 0.330437\n",
      "Epoch: 9/100... Step: 847... Loss: 0.250996... Val Loss: 0.362865\n",
      "Epoch: 9/100... Step: 848... Loss: 0.242338... Val Loss: 0.391134\n",
      "Epoch: 9/100... Step: 849... Loss: 0.226767... Val Loss: 0.398251\n",
      "Epoch: 9/100... Step: 850... Loss: 0.241517... Val Loss: 0.416436\n",
      "Epoch: 9/100... Step: 851... Loss: 0.318744... Val Loss: 0.395825\n",
      "Epoch: 9/100... Step: 852... Loss: 0.204935... Val Loss: 0.368674\n",
      "Epoch: 9/100... Step: 853... Loss: 0.269474... Val Loss: 0.360140\n",
      "Epoch: 9/100... Step: 854... Loss: 0.236179... Val Loss: 0.365463\n",
      "Epoch: 9/100... Step: 855... Loss: 0.233408... Val Loss: 0.406105\n",
      "Epoch: 9/100... Step: 856... Loss: 0.202098... Val Loss: 0.418671\n",
      "Epoch: 9/100... Step: 857... Loss: 0.207230... Val Loss: 0.462254\n",
      "Epoch: 9/100... Step: 858... Loss: 0.221314... Val Loss: 0.499359\n",
      "Epoch: 9/100... Step: 859... Loss: 0.348973... Val Loss: 0.530366\n",
      "Epoch: 9/100... Step: 860... Loss: 0.247765... Val Loss: 0.571730\n",
      "Epoch: 9/100... Step: 861... Loss: 0.282491... Val Loss: 0.597347\n",
      "Epoch: 9/100... Step: 862... Loss: 0.238196... Val Loss: 0.615469\n",
      "Epoch: 9/100... Step: 863... Loss: 0.247553... Val Loss: 0.637671\n",
      "Epoch: 9/100... Step: 864... Loss: 0.159926... Val Loss: 0.655072\n",
      "Epoch: 9/100... Step: 865... Loss: 0.155331... Val Loss: 0.645799\n",
      "Epoch: 9/100... Step: 866... Loss: 0.343815... Val Loss: 0.643363\n",
      "Epoch: 9/100... Step: 867... Loss: 0.224053... Val Loss: 0.651250\n",
      "Epoch: 9/100... Step: 868... Loss: 0.274202... Val Loss: 0.587648\n",
      "Epoch: 9/100... Step: 869... Loss: 0.248276... Val Loss: 0.554647\n",
      "Epoch: 9/100... Step: 870... Loss: 0.230038... Val Loss: 0.508886\n",
      "Epoch: 9/100... Step: 871... Loss: 0.127225... Val Loss: 0.443811\n",
      "Epoch: 9/100... Step: 872... Loss: 0.208277... Val Loss: 0.383501\n",
      "Epoch: 9/100... Step: 873... Loss: 0.331741... Val Loss: 0.329413\n",
      "Epoch: 9/100... Step: 874... Loss: 0.226082... Val Loss: 0.249620\n",
      "Epoch: 9/100... Step: 875... Loss: 0.204495... Val Loss: 0.155420\n",
      "Epoch: 9/100... Step: 876... Loss: 0.220935... Val Loss: 0.118678\n",
      "Epoch: 9/100... Step: 877... Loss: 0.278136... Val Loss: 0.064935\n",
      "Epoch: 9/100... Step: 878... Loss: 0.276270... Val Loss: 0.079950\n",
      "Epoch: 9/100... Step: 879... Loss: 0.212726... Val Loss: 0.133739\n",
      "Epoch: 9/100... Step: 880... Loss: 0.252174... Val Loss: 0.177100\n",
      "Epoch: 9/100... Step: 881... Loss: 0.278905... Val Loss: 0.233830\n",
      "Epoch: 9/100... Step: 882... Loss: 0.299635... Val Loss: 0.244709\n",
      "Epoch: 9/100... Step: 883... Loss: 0.366821... Val Loss: 0.284140\n",
      "Epoch: 9/100... Step: 884... Loss: 0.241274... Val Loss: 0.308511\n",
      "Epoch: 9/100... Step: 885... Loss: 0.194920... Val Loss: 0.295161\n",
      "Epoch: 9/100... Step: 886... Loss: 0.317237... Val Loss: 0.299641\n",
      "Epoch: 9/100... Step: 887... Loss: 0.311153... Val Loss: 0.302591\n",
      "Epoch: 9/100... Step: 888... Loss: 0.158881... Val Loss: 0.310851\n",
      "Epoch: 9/100... Step: 889... Loss: 0.197945... Val Loss: 0.315219\n",
      "Epoch: 9/100... Step: 890... Loss: 0.328065... Val Loss: 0.296505\n",
      "Epoch: 9/100... Step: 891... Loss: 0.231288... Val Loss: 0.267812\n",
      "Epoch: 9/100... Step: 892... Loss: 0.240111... Val Loss: 0.232582\n",
      "Epoch: 9/100... Step: 893... Loss: 0.222048... Val Loss: 0.237035\n",
      "Epoch: 9/100... Step: 894... Loss: 0.185248... Val Loss: 0.196608\n",
      "Epoch: 9/100... Step: 895... Loss: 0.205303... Val Loss: 0.143327\n",
      "Epoch: 9/100... Step: 896... Loss: 0.321532... Val Loss: 0.117859\n",
      "Epoch: 9/100... Step: 897... Loss: 0.217358... Val Loss: 0.088751\n",
      "Epoch: 9/100... Step: 898... Loss: 0.143580... Val Loss: 0.051679\n",
      "Epoch: 9/100... Step: 899... Loss: 0.256997... Val Loss: 0.042972\n",
      "Epoch: 9/100... Step: 900... Loss: 0.265013... Val Loss: 0.071496\n",
      "Epoch: 9/100... Step: 901... Loss: 0.213591... Val Loss: 0.109292\n",
      "Epoch: 9/100... Step: 902... Loss: 0.222066... Val Loss: 0.148065\n",
      "Epoch: 9/100... Step: 903... Loss: 0.192796... Val Loss: 0.223856\n",
      "Epoch: 9/100... Step: 904... Loss: 0.234231... Val Loss: 0.281686\n",
      "Epoch: 9/100... Step: 905... Loss: 0.277873... Val Loss: 0.269880\n",
      "Epoch: 9/100... Step: 906... Loss: 0.248080... Val Loss: 0.251924\n",
      "Epoch: 9/100... Step: 907... Loss: 0.172428... Val Loss: 0.228928\n",
      "Epoch: 9/100... Step: 908... Loss: 0.238047... Val Loss: 0.212661\n",
      "Epoch: 9/100... Step: 909... Loss: 0.285029... Val Loss: 0.173703\n",
      "Epoch: 9/100... Step: 910... Loss: 0.212212... Val Loss: 0.124293\n",
      "Epoch: 9/100... Step: 911... Loss: 0.317568... Val Loss: 0.104831\n",
      "Epoch: 9/100... Step: 912... Loss: 0.207169... Val Loss: 0.104465\n",
      "Epoch: 9/100... Step: 913... Loss: 0.322515... Val Loss: 0.098423\n",
      "Epoch: 9/100... Step: 914... Loss: 0.285942... Val Loss: 0.132209\n",
      "Epoch: 9/100... Step: 915... Loss: 0.275422... Val Loss: 0.144428\n",
      "Epoch: 9/100... Step: 916... Loss: 0.134995... Val Loss: 0.102163\n",
      "Epoch: 9/100... Step: 917... Loss: 0.177255... Val Loss: 0.069813\n",
      "Epoch: 9/100... Step: 918... Loss: 0.196937... Val Loss: 0.098656\n",
      "Epoch: 9/100... Step: 919... Loss: 0.190818... Val Loss: 0.152797\n",
      "Epoch: 9/100... Step: 920... Loss: 0.244545... Val Loss: 0.185954\n",
      "Epoch: 9/100... Step: 921... Loss: 0.270461... Val Loss: 0.239846\n",
      "Epoch: 9/100... Step: 922... Loss: 0.266534... Val Loss: 0.287610\n",
      "Epoch: 9/100... Step: 923... Loss: 0.289117... Val Loss: 0.287032\n",
      "Epoch: 9/100... Step: 924... Loss: 0.133768... Val Loss: 0.284660\n",
      "Epoch: 9/100... Step: 925... Loss: 0.327787... Val Loss: 0.309842\n",
      "Epoch: 9/100... Step: 926... Loss: 0.256324... Val Loss: 0.349346\n",
      "Epoch: 9/100... Step: 927... Loss: 0.302015... Val Loss: 0.430059\n",
      "Epoch: 9/100... Step: 928... Loss: 0.209632... Val Loss: 0.493013\n",
      "Epoch: 9/100... Step: 929... Loss: 0.217124... Val Loss: 0.512233\n",
      "Epoch: 9/100... Step: 930... Loss: 0.160755... Val Loss: 0.571343\n",
      "Epoch: 9/100... Step: 931... Loss: 0.178219... Val Loss: 0.626194\n",
      "Epoch: 9/100... Step: 932... Loss: 0.237132... Val Loss: 0.650276\n",
      "Epoch: 9/100... Step: 933... Loss: 0.217267... Val Loss: 0.599453\n",
      "Epoch: 9/100... Step: 934... Loss: 0.319014... Val Loss: 0.595071\n",
      "Epoch: 9/100... Step: 935... Loss: 0.259333... Val Loss: 0.553199\n",
      "Epoch: 9/100... Step: 936... Loss: 0.193092... Val Loss: 0.498603\n",
      "Epoch: 10/100... Step: 937... Loss: 0.244767... Val Loss: 0.400395\n",
      "Epoch: 10/100... Step: 938... Loss: 0.275949... Val Loss: 0.312741\n",
      "Epoch: 10/100... Step: 939... Loss: 0.226046... Val Loss: 0.193188\n",
      "Epoch: 10/100... Step: 940... Loss: 0.219576... Val Loss: 0.112714\n",
      "Epoch: 10/100... Step: 941... Loss: 0.210509... Val Loss: 0.242939\n",
      "Epoch: 10/100... Step: 942... Loss: 0.186384... Val Loss: 0.384433\n",
      "Epoch: 10/100... Step: 943... Loss: 0.173506... Val Loss: 0.482271\n",
      "Epoch: 10/100... Step: 944... Loss: 0.206533... Val Loss: 0.594131\n",
      "Epoch: 10/100... Step: 945... Loss: 0.201319... Val Loss: 0.694010\n",
      "Epoch: 10/100... Step: 946... Loss: 0.211007... Val Loss: 0.771522\n",
      "Epoch: 10/100... Step: 947... Loss: 0.267964... Val Loss: 0.830839\n",
      "Epoch: 10/100... Step: 948... Loss: 0.249790... Val Loss: 0.870085\n",
      "Epoch: 10/100... Step: 949... Loss: 0.263263... Val Loss: 0.849592\n",
      "Epoch: 10/100... Step: 950... Loss: 0.200722... Val Loss: 0.875016\n",
      "Epoch: 10/100... Step: 951... Loss: 0.243922... Val Loss: 0.889818\n",
      "Epoch: 10/100... Step: 952... Loss: 0.144569... Val Loss: 0.909495\n",
      "Epoch: 10/100... Step: 953... Loss: 0.277649... Val Loss: 0.901226\n",
      "Epoch: 10/100... Step: 954... Loss: 0.213640... Val Loss: 0.905350\n",
      "Epoch: 10/100... Step: 955... Loss: 0.323030... Val Loss: 0.873889\n",
      "Epoch: 10/100... Step: 956... Loss: 0.262446... Val Loss: 0.877478\n",
      "Epoch: 10/100... Step: 957... Loss: 0.250383... Val Loss: 0.852623\n",
      "Epoch: 10/100... Step: 958... Loss: 0.337563... Val Loss: 0.832278\n",
      "Epoch: 10/100... Step: 959... Loss: 0.242990... Val Loss: 0.803974\n",
      "Epoch: 10/100... Step: 960... Loss: 0.192879... Val Loss: 0.745627\n",
      "Epoch: 10/100... Step: 961... Loss: 0.209203... Val Loss: 0.682683\n",
      "Epoch: 10/100... Step: 962... Loss: 0.329912... Val Loss: 0.629850\n",
      "Epoch: 10/100... Step: 963... Loss: 0.301446... Val Loss: 0.566763\n",
      "Epoch: 10/100... Step: 964... Loss: 0.246778... Val Loss: 0.471460\n",
      "Epoch: 10/100... Step: 965... Loss: 0.180179... Val Loss: 0.406824\n",
      "Epoch: 10/100... Step: 966... Loss: 0.216095... Val Loss: 0.299923\n",
      "Epoch: 10/100... Step: 967... Loss: 0.191585... Val Loss: 0.252366\n",
      "Epoch: 10/100... Step: 968... Loss: 0.119492... Val Loss: 0.224539\n",
      "Epoch: 10/100... Step: 969... Loss: 0.203795... Val Loss: 0.211557\n",
      "Epoch: 10/100... Step: 970... Loss: 0.227299... Val Loss: 0.249263\n",
      "Epoch: 10/100... Step: 971... Loss: 0.278896... Val Loss: 0.262649\n",
      "Epoch: 10/100... Step: 972... Loss: 0.213948... Val Loss: 0.229933\n",
      "Epoch: 10/100... Step: 973... Loss: 0.219904... Val Loss: 0.201729\n",
      "Epoch: 10/100... Step: 974... Loss: 0.213992... Val Loss: 0.183510\n",
      "Epoch: 10/100... Step: 975... Loss: 0.219675... Val Loss: 0.189779\n",
      "Epoch: 10/100... Step: 976... Loss: 0.301026... Val Loss: 0.168700\n",
      "Epoch: 10/100... Step: 977... Loss: 0.235141... Val Loss: 0.125922\n",
      "Epoch: 10/100... Step: 978... Loss: 0.276923... Val Loss: 0.138114\n",
      "Epoch: 10/100... Step: 979... Loss: 0.263258... Val Loss: 0.146549\n",
      "Epoch: 10/100... Step: 980... Loss: 0.234167... Val Loss: 0.121155\n",
      "Epoch: 10/100... Step: 981... Loss: 0.191677... Val Loss: 0.106783\n",
      "Epoch: 10/100... Step: 982... Loss: 0.288158... Val Loss: 0.107738\n",
      "Epoch: 10/100... Step: 983... Loss: 0.169928... Val Loss: 0.087744\n",
      "Epoch: 10/100... Step: 984... Loss: 0.176270... Val Loss: 0.058873\n",
      "Epoch: 10/100... Step: 985... Loss: 0.209496... Val Loss: 0.041059\n",
      "Epoch: 10/100... Step: 986... Loss: 0.251805... Val Loss: 0.045755\n",
      "Epoch: 10/100... Step: 987... Loss: 0.273487... Val Loss: 0.057718\n",
      "Epoch: 10/100... Step: 988... Loss: 0.266613... Val Loss: 0.084704\n",
      "Epoch: 10/100... Step: 989... Loss: 0.300724... Val Loss: 0.081363\n",
      "Epoch: 10/100... Step: 990... Loss: 0.249160... Val Loss: 0.081055\n",
      "Epoch: 10/100... Step: 991... Loss: 0.223897... Val Loss: 0.083811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Step: 992... Loss: 0.280797... Val Loss: 0.107425\n",
      "Epoch: 10/100... Step: 993... Loss: 0.223524... Val Loss: 0.115968\n",
      "Epoch: 10/100... Step: 994... Loss: 0.130192... Val Loss: 0.122189\n",
      "Epoch: 10/100... Step: 995... Loss: 0.205834... Val Loss: 0.123397\n",
      "Epoch: 10/100... Step: 996... Loss: 0.189632... Val Loss: 0.117028\n",
      "Epoch: 10/100... Step: 997... Loss: 0.316722... Val Loss: 0.096006\n",
      "Epoch: 10/100... Step: 998... Loss: 0.137806... Val Loss: 0.098481\n",
      "Epoch: 10/100... Step: 999... Loss: 0.263380... Val Loss: 0.106473\n",
      "Epoch: 10/100... Step: 1000... Loss: 0.153924... Val Loss: 0.083638\n",
      "Epoch: 10/100... Step: 1001... Loss: 0.205211... Val Loss: 0.077248\n",
      "Epoch: 10/100... Step: 1002... Loss: 0.241829... Val Loss: 0.083681\n",
      "Epoch: 10/100... Step: 1003... Loss: 0.251980... Val Loss: 0.091498\n",
      "Epoch: 10/100... Step: 1004... Loss: 0.231480... Val Loss: 0.093730\n",
      "Epoch: 10/100... Step: 1005... Loss: 0.266618... Val Loss: 0.104553\n",
      "Epoch: 10/100... Step: 1006... Loss: 0.260298... Val Loss: 0.109749\n",
      "Epoch: 10/100... Step: 1007... Loss: 0.091211... Val Loss: 0.099799\n",
      "Epoch: 10/100... Step: 1008... Loss: 0.276616... Val Loss: 0.090829\n",
      "Epoch: 10/100... Step: 1009... Loss: 0.277424... Val Loss: 0.112581\n",
      "Epoch: 10/100... Step: 1010... Loss: 0.268506... Val Loss: 0.102762\n",
      "Epoch: 10/100... Step: 1011... Loss: 0.255341... Val Loss: 0.109313\n",
      "Epoch: 10/100... Step: 1012... Loss: 0.199852... Val Loss: 0.115272\n",
      "Epoch: 10/100... Step: 1013... Loss: 0.272089... Val Loss: 0.109397\n",
      "Epoch: 10/100... Step: 1014... Loss: 0.222335... Val Loss: 0.126424\n",
      "Epoch: 10/100... Step: 1015... Loss: 0.241986... Val Loss: 0.164318\n",
      "Epoch: 10/100... Step: 1016... Loss: 0.256982... Val Loss: 0.189989\n",
      "Epoch: 10/100... Step: 1017... Loss: 0.118068... Val Loss: 0.180953\n",
      "Epoch: 10/100... Step: 1018... Loss: 0.264120... Val Loss: 0.167452\n",
      "Epoch: 10/100... Step: 1019... Loss: 0.201969... Val Loss: 0.130346\n",
      "Epoch: 10/100... Step: 1020... Loss: 0.356895... Val Loss: 0.104375\n",
      "Epoch: 10/100... Step: 1021... Loss: 0.173595... Val Loss: 0.168370\n",
      "Epoch: 10/100... Step: 1022... Loss: 0.253419... Val Loss: 0.278595\n",
      "Epoch: 10/100... Step: 1023... Loss: 0.178784... Val Loss: 0.401194\n",
      "Epoch: 10/100... Step: 1024... Loss: 0.344320... Val Loss: 0.531629\n",
      "Epoch: 10/100... Step: 1025... Loss: 0.086968... Val Loss: 0.608245\n",
      "Epoch: 10/100... Step: 1026... Loss: 0.106528... Val Loss: 0.686356\n",
      "Epoch: 10/100... Step: 1027... Loss: 0.181835... Val Loss: 0.740201\n",
      "Epoch: 10/100... Step: 1028... Loss: 0.222610... Val Loss: 0.773888\n",
      "Epoch: 10/100... Step: 1029... Loss: 0.199348... Val Loss: 0.801326\n",
      "Epoch: 10/100... Step: 1030... Loss: 0.288220... Val Loss: 0.822521\n",
      "Epoch: 10/100... Step: 1031... Loss: 0.211013... Val Loss: 0.853970\n",
      "Epoch: 10/100... Step: 1032... Loss: 0.161042... Val Loss: 0.901621\n",
      "Epoch: 10/100... Step: 1033... Loss: 0.236796... Val Loss: 0.899833\n",
      "Epoch: 10/100... Step: 1034... Loss: 0.215030... Val Loss: 0.898895\n",
      "Epoch: 10/100... Step: 1035... Loss: 0.232840... Val Loss: 0.910502\n",
      "Epoch: 10/100... Step: 1036... Loss: 0.236803... Val Loss: 0.920283\n",
      "Epoch: 10/100... Step: 1037... Loss: 0.174297... Val Loss: 0.912895\n",
      "Epoch: 10/100... Step: 1038... Loss: 0.159628... Val Loss: 0.890352\n",
      "Epoch: 10/100... Step: 1039... Loss: 0.225889... Val Loss: 0.855309\n",
      "Epoch: 10/100... Step: 1040... Loss: 0.197929... Val Loss: 0.828776\n",
      "Epoch: 11/100... Step: 1041... Loss: 0.227699... Val Loss: 0.791758\n",
      "Epoch: 11/100... Step: 1042... Loss: 0.195165... Val Loss: 0.812741\n",
      "Epoch: 11/100... Step: 1043... Loss: 0.300728... Val Loss: 0.694709\n",
      "Epoch: 11/100... Step: 1044... Loss: 0.218744... Val Loss: 0.536079\n",
      "Epoch: 11/100... Step: 1045... Loss: 0.231803... Val Loss: 0.286270\n",
      "Epoch: 11/100... Step: 1046... Loss: 0.241534... Val Loss: 0.182885\n",
      "Epoch: 11/100... Step: 1047... Loss: 0.237623... Val Loss: 0.418073\n",
      "Epoch: 11/100... Step: 1048... Loss: 0.266191... Val Loss: 0.705437\n",
      "Epoch: 11/100... Step: 1049... Loss: 0.135669... Val Loss: 0.920222\n",
      "Epoch: 11/100... Step: 1050... Loss: 0.154034... Val Loss: 1.135516\n",
      "Epoch: 11/100... Step: 1051... Loss: 0.312714... Val Loss: 1.274874\n",
      "Epoch: 11/100... Step: 1052... Loss: 0.187240... Val Loss: 1.394602\n",
      "Epoch: 11/100... Step: 1053... Loss: 0.336051... Val Loss: 1.472476\n",
      "Epoch: 11/100... Step: 1054... Loss: 0.173253... Val Loss: 1.557083\n",
      "Epoch: 11/100... Step: 1055... Loss: 0.300258... Val Loss: 1.626349\n",
      "Epoch: 11/100... Step: 1056... Loss: 0.217621... Val Loss: 1.684472\n",
      "Epoch: 11/100... Step: 1057... Loss: 0.250418... Val Loss: 1.732431\n",
      "Epoch: 11/100... Step: 1058... Loss: 0.230588... Val Loss: 1.707919\n",
      "Epoch: 11/100... Step: 1059... Loss: 0.181224... Val Loss: 1.666069\n",
      "Epoch: 11/100... Step: 1060... Loss: 0.212605... Val Loss: 1.555399\n",
      "Epoch: 11/100... Step: 1061... Loss: 0.136528... Val Loss: 1.473108\n",
      "Epoch: 11/100... Step: 1062... Loss: 0.180908... Val Loss: 1.421397\n",
      "Epoch: 11/100... Step: 1063... Loss: 0.319771... Val Loss: 1.346487\n",
      "Epoch: 11/100... Step: 1064... Loss: 0.156337... Val Loss: 1.219266\n",
      "Epoch: 11/100... Step: 1065... Loss: 0.232118... Val Loss: 1.099740\n",
      "Epoch: 11/100... Step: 1066... Loss: 0.165922... Val Loss: 0.964880\n",
      "Epoch: 11/100... Step: 1067... Loss: 0.193303... Val Loss: 0.849417\n",
      "Epoch: 11/100... Step: 1068... Loss: 0.365433... Val Loss: 0.726989\n",
      "Epoch: 11/100... Step: 1069... Loss: 0.215893... Val Loss: 0.586801\n",
      "Epoch: 11/100... Step: 1070... Loss: 0.172603... Val Loss: 0.486074\n",
      "Epoch: 11/100... Step: 1071... Loss: 0.233960... Val Loss: 0.365905\n",
      "Epoch: 11/100... Step: 1072... Loss: 0.178736... Val Loss: 0.309380\n",
      "Epoch: 11/100... Step: 1073... Loss: 0.193611... Val Loss: 0.282564\n",
      "Epoch: 11/100... Step: 1074... Loss: 0.252134... Val Loss: 0.253788\n",
      "Epoch: 11/100... Step: 1075... Loss: 0.218516... Val Loss: 0.222317\n",
      "Epoch: 11/100... Step: 1076... Loss: 0.200386... Val Loss: 0.171235\n",
      "Epoch: 11/100... Step: 1077... Loss: 0.261400... Val Loss: 0.116285\n",
      "Epoch: 11/100... Step: 1078... Loss: 0.188800... Val Loss: 0.072598\n",
      "Epoch: 11/100... Step: 1079... Loss: 0.273985... Val Loss: 0.077631\n",
      "Epoch: 11/100... Step: 1080... Loss: 0.299620... Val Loss: 0.100192\n",
      "Epoch: 11/100... Step: 1081... Loss: 0.196987... Val Loss: 0.099887\n",
      "Epoch: 11/100... Step: 1082... Loss: 0.202626... Val Loss: 0.080722\n",
      "Epoch: 11/100... Step: 1083... Loss: 0.219084... Val Loss: 0.092485\n",
      "Epoch: 11/100... Step: 1084... Loss: 0.155138... Val Loss: 0.176730\n",
      "Epoch: 11/100... Step: 1085... Loss: 0.121192... Val Loss: 0.287398\n",
      "Epoch: 11/100... Step: 1086... Loss: 0.245213... Val Loss: 0.387812\n",
      "Epoch: 11/100... Step: 1087... Loss: 0.280459... Val Loss: 0.439100\n",
      "Epoch: 11/100... Step: 1088... Loss: 0.192025... Val Loss: 0.416592\n",
      "Epoch: 11/100... Step: 1089... Loss: 0.162262... Val Loss: 0.396123\n",
      "Epoch: 11/100... Step: 1090... Loss: 0.240002... Val Loss: 0.365397\n",
      "Epoch: 11/100... Step: 1091... Loss: 0.125526... Val Loss: 0.320867\n",
      "Epoch: 11/100... Step: 1092... Loss: 0.268806... Val Loss: 0.255886\n",
      "Epoch: 11/100... Step: 1093... Loss: 0.142442... Val Loss: 0.188057\n",
      "Epoch: 11/100... Step: 1094... Loss: 0.298515... Val Loss: 0.134708\n",
      "Epoch: 11/100... Step: 1095... Loss: 0.282581... Val Loss: 0.095631\n",
      "Epoch: 11/100... Step: 1096... Loss: 0.277043... Val Loss: 0.071720\n",
      "Epoch: 11/100... Step: 1097... Loss: 0.202454... Val Loss: 0.066404\n",
      "Epoch: 11/100... Step: 1098... Loss: 0.264701... Val Loss: 0.119274\n",
      "Epoch: 11/100... Step: 1099... Loss: 0.196659... Val Loss: 0.137308\n",
      "Epoch: 11/100... Step: 1100... Loss: 0.213470... Val Loss: 0.197717\n",
      "Epoch: 11/100... Step: 1101... Loss: 0.245037... Val Loss: 0.229043\n",
      "Epoch: 11/100... Step: 1102... Loss: 0.248387... Val Loss: 0.295294\n",
      "Epoch: 11/100... Step: 1103... Loss: 0.263977... Val Loss: 0.344470\n",
      "Epoch: 11/100... Step: 1104... Loss: 0.185250... Val Loss: 0.410533\n",
      "Epoch: 11/100... Step: 1105... Loss: 0.168502... Val Loss: 0.437394\n",
      "Epoch: 11/100... Step: 1106... Loss: 0.244308... Val Loss: 0.475035\n",
      "Epoch: 11/100... Step: 1107... Loss: 0.142266... Val Loss: 0.535433\n",
      "Epoch: 11/100... Step: 1108... Loss: 0.176189... Val Loss: 0.570063\n",
      "Epoch: 11/100... Step: 1109... Loss: 0.323056... Val Loss: 0.587764\n",
      "Epoch: 11/100... Step: 1110... Loss: 0.280348... Val Loss: 0.628262\n",
      "Epoch: 11/100... Step: 1111... Loss: 0.226110... Val Loss: 0.632690\n",
      "Epoch: 11/100... Step: 1112... Loss: 0.136633... Val Loss: 0.629969\n",
      "Epoch: 11/100... Step: 1113... Loss: 0.101581... Val Loss: 0.656472\n",
      "Epoch: 11/100... Step: 1114... Loss: 0.324085... Val Loss: 0.686867\n",
      "Epoch: 11/100... Step: 1115... Loss: 0.268562... Val Loss: 0.769597\n",
      "Epoch: 11/100... Step: 1116... Loss: 0.132115... Val Loss: 0.835028\n",
      "Epoch: 11/100... Step: 1117... Loss: 0.279747... Val Loss: 0.908645\n",
      "Epoch: 11/100... Step: 1118... Loss: 0.272464... Val Loss: 0.957138\n",
      "Epoch: 11/100... Step: 1119... Loss: 0.367822... Val Loss: 0.934374\n",
      "Epoch: 11/100... Step: 1120... Loss: 0.279480... Val Loss: 0.942072\n",
      "Epoch: 11/100... Step: 1121... Loss: 0.180940... Val Loss: 0.905544\n",
      "Epoch: 11/100... Step: 1122... Loss: 0.198277... Val Loss: 0.875620\n",
      "Epoch: 11/100... Step: 1123... Loss: 0.205785... Val Loss: 0.852657\n",
      "Epoch: 11/100... Step: 1124... Loss: 0.241458... Val Loss: 0.869115\n",
      "Epoch: 11/100... Step: 1125... Loss: 0.178569... Val Loss: 0.861055\n",
      "Epoch: 11/100... Step: 1126... Loss: 0.238786... Val Loss: 0.797995\n",
      "Epoch: 11/100... Step: 1127... Loss: 0.165448... Val Loss: 0.724262\n",
      "Epoch: 11/100... Step: 1128... Loss: 0.242941... Val Loss: 0.663425\n",
      "Epoch: 11/100... Step: 1129... Loss: 0.242520... Val Loss: 0.621727\n",
      "Epoch: 11/100... Step: 1130... Loss: 0.227795... Val Loss: 0.594462\n",
      "Epoch: 11/100... Step: 1131... Loss: 0.218206... Val Loss: 0.521361\n",
      "Epoch: 11/100... Step: 1132... Loss: 0.138088... Val Loss: 0.549192\n",
      "Epoch: 11/100... Step: 1133... Loss: 0.208237... Val Loss: 0.499743\n",
      "Epoch: 11/100... Step: 1134... Loss: 0.137285... Val Loss: 0.476047\n",
      "Epoch: 11/100... Step: 1135... Loss: 0.230113... Val Loss: 0.495815\n",
      "Epoch: 11/100... Step: 1136... Loss: 0.144048... Val Loss: 0.550328\n",
      "Epoch: 11/100... Step: 1137... Loss: 0.167447... Val Loss: 0.606108\n",
      "Epoch: 11/100... Step: 1138... Loss: 0.326653... Val Loss: 0.649333\n",
      "Epoch: 11/100... Step: 1139... Loss: 0.236505... Val Loss: 0.661230\n",
      "Epoch: 11/100... Step: 1140... Loss: 0.202695... Val Loss: 0.668891\n",
      "Epoch: 11/100... Step: 1141... Loss: 0.220347... Val Loss: 0.668844\n",
      "Epoch: 11/100... Step: 1142... Loss: 0.257840... Val Loss: 0.598021\n",
      "Epoch: 11/100... Step: 1143... Loss: 0.242647... Val Loss: 0.479868\n",
      "Epoch: 11/100... Step: 1144... Loss: 0.219760... Val Loss: 0.372531\n",
      "Epoch: 12/100... Step: 1145... Loss: 0.244528... Val Loss: 0.330663\n",
      "Epoch: 12/100... Step: 1146... Loss: 0.140328... Val Loss: 0.274782\n",
      "Epoch: 12/100... Step: 1147... Loss: 0.238446... Val Loss: 0.247671\n",
      "Epoch: 12/100... Step: 1148... Loss: 0.179614... Val Loss: 0.265798\n",
      "Epoch: 12/100... Step: 1149... Loss: 0.118293... Val Loss: 0.218550\n",
      "Epoch: 12/100... Step: 1150... Loss: 0.251020... Val Loss: 0.150571\n",
      "Epoch: 12/100... Step: 1151... Loss: 0.159192... Val Loss: 0.118134\n",
      "Epoch: 12/100... Step: 1152... Loss: 0.298548... Val Loss: 0.050219\n",
      "Epoch: 12/100... Step: 1153... Loss: 0.145836... Val Loss: 0.082437\n",
      "Epoch: 12/100... Step: 1154... Loss: 0.224842... Val Loss: 0.142995\n",
      "Epoch: 12/100... Step: 1155... Loss: 0.278034... Val Loss: 0.212470\n",
      "Epoch: 12/100... Step: 1156... Loss: 0.170284... Val Loss: 0.240376\n",
      "Epoch: 12/100... Step: 1157... Loss: 0.159682... Val Loss: 0.215918\n",
      "Epoch: 12/100... Step: 1158... Loss: 0.191623... Val Loss: 0.149404\n",
      "Epoch: 12/100... Step: 1159... Loss: 0.264621... Val Loss: 0.117559\n",
      "Epoch: 12/100... Step: 1160... Loss: 0.267097... Val Loss: 0.136699\n",
      "Epoch: 12/100... Step: 1161... Loss: 0.279753... Val Loss: 0.194555\n",
      "Epoch: 12/100... Step: 1162... Loss: 0.229041... Val Loss: 0.230662\n",
      "Epoch: 12/100... Step: 1163... Loss: 0.263306... Val Loss: 0.270404\n",
      "Epoch: 12/100... Step: 1164... Loss: 0.284420... Val Loss: 0.307433\n",
      "Epoch: 12/100... Step: 1165... Loss: 0.256983... Val Loss: 0.371808\n",
      "Epoch: 12/100... Step: 1166... Loss: 0.198545... Val Loss: 0.477023\n",
      "Epoch: 12/100... Step: 1167... Loss: 0.214316... Val Loss: 0.569178\n",
      "Epoch: 12/100... Step: 1168... Loss: 0.221081... Val Loss: 0.697633\n",
      "Epoch: 12/100... Step: 1169... Loss: 0.191459... Val Loss: 0.853724\n",
      "Epoch: 12/100... Step: 1170... Loss: 0.153095... Val Loss: 1.075491\n",
      "Epoch: 12/100... Step: 1171... Loss: 0.253936... Val Loss: 1.246478\n",
      "Epoch: 12/100... Step: 1172... Loss: 0.260972... Val Loss: 1.378636\n",
      "Epoch: 12/100... Step: 1173... Loss: 0.139194... Val Loss: 1.483127\n",
      "Epoch: 12/100... Step: 1174... Loss: 0.182492... Val Loss: 1.543593\n",
      "Epoch: 12/100... Step: 1175... Loss: 0.161479... Val Loss: 1.546773\n",
      "Epoch: 12/100... Step: 1176... Loss: 0.226591... Val Loss: 1.566274\n",
      "Epoch: 12/100... Step: 1177... Loss: 0.241667... Val Loss: 1.565656\n",
      "Epoch: 12/100... Step: 1178... Loss: 0.175002... Val Loss: 1.530825\n",
      "Epoch: 12/100... Step: 1179... Loss: 0.187519... Val Loss: 1.503960\n",
      "Epoch: 12/100... Step: 1180... Loss: 0.195659... Val Loss: 1.460750\n",
      "Epoch: 12/100... Step: 1181... Loss: 0.144506... Val Loss: 1.378586\n",
      "Epoch: 12/100... Step: 1182... Loss: 0.295094... Val Loss: 1.291213\n",
      "Epoch: 12/100... Step: 1183... Loss: 0.178846... Val Loss: 1.193426\n",
      "Epoch: 12/100... Step: 1184... Loss: 0.185079... Val Loss: 1.075087\n",
      "Epoch: 12/100... Step: 1185... Loss: 0.153512... Val Loss: 1.000942\n",
      "Epoch: 12/100... Step: 1186... Loss: 0.173064... Val Loss: 0.883928\n",
      "Epoch: 12/100... Step: 1187... Loss: 0.255803... Val Loss: 0.747825\n",
      "Epoch: 12/100... Step: 1188... Loss: 0.281867... Val Loss: 0.516780\n",
      "Epoch: 12/100... Step: 1189... Loss: 0.225359... Val Loss: 0.305926\n",
      "Epoch: 12/100... Step: 1190... Loss: 0.198661... Val Loss: 0.173838\n",
      "Epoch: 12/100... Step: 1191... Loss: 0.228339... Val Loss: 0.197442\n",
      "Epoch: 12/100... Step: 1192... Loss: 0.240804... Val Loss: 0.311000\n",
      "Epoch: 12/100... Step: 1193... Loss: 0.232953... Val Loss: 0.488542\n",
      "Epoch: 12/100... Step: 1194... Loss: 0.241908... Val Loss: 0.646084\n",
      "Epoch: 12/100... Step: 1195... Loss: 0.233568... Val Loss: 0.827103\n",
      "Epoch: 12/100... Step: 1196... Loss: 0.214081... Val Loss: 0.964530\n",
      "Epoch: 12/100... Step: 1197... Loss: 0.142651... Val Loss: 1.053149\n",
      "Epoch: 12/100... Step: 1198... Loss: 0.190810... Val Loss: 1.151555\n",
      "Epoch: 12/100... Step: 1199... Loss: 0.126374... Val Loss: 1.190964\n",
      "Epoch: 12/100... Step: 1200... Loss: 0.222678... Val Loss: 1.183503\n",
      "Epoch: 12/100... Step: 1201... Loss: 0.289358... Val Loss: 1.174098\n",
      "Epoch: 12/100... Step: 1202... Loss: 0.147614... Val Loss: 1.180325\n",
      "Epoch: 12/100... Step: 1203... Loss: 0.162452... Val Loss: 1.202529\n",
      "Epoch: 12/100... Step: 1204... Loss: 0.134713... Val Loss: 1.189156\n",
      "Epoch: 12/100... Step: 1205... Loss: 0.242974... Val Loss: 1.162055\n",
      "Epoch: 12/100... Step: 1206... Loss: 0.236503... Val Loss: 1.070816\n",
      "Epoch: 12/100... Step: 1207... Loss: 0.124786... Val Loss: 0.927243\n",
      "Epoch: 12/100... Step: 1208... Loss: 0.273997... Val Loss: 0.854795\n",
      "Epoch: 12/100... Step: 1209... Loss: 0.165752... Val Loss: 0.797668\n",
      "Epoch: 12/100... Step: 1210... Loss: 0.231306... Val Loss: 0.728860\n",
      "Epoch: 12/100... Step: 1211... Loss: 0.218863... Val Loss: 0.629544\n",
      "Epoch: 12/100... Step: 1212... Loss: 0.211582... Val Loss: 0.533727\n",
      "Epoch: 12/100... Step: 1213... Loss: 0.237300... Val Loss: 0.437718\n",
      "Epoch: 12/100... Step: 1214... Loss: 0.229573... Val Loss: 0.331514\n",
      "Epoch: 12/100... Step: 1215... Loss: 0.248596... Val Loss: 0.213910\n",
      "Epoch: 12/100... Step: 1216... Loss: 0.243219... Val Loss: 0.100322\n",
      "Epoch: 12/100... Step: 1217... Loss: 0.199113... Val Loss: 0.058070\n",
      "Epoch: 12/100... Step: 1218... Loss: 0.261497... Val Loss: 0.053616\n",
      "Epoch: 12/100... Step: 1219... Loss: 0.285311... Val Loss: 0.071146\n",
      "Epoch: 12/100... Step: 1220... Loss: 0.238996... Val Loss: 0.148876\n",
      "Epoch: 12/100... Step: 1221... Loss: 0.108853... Val Loss: 0.262740\n",
      "Epoch: 12/100... Step: 1222... Loss: 0.194314... Val Loss: 0.317155\n",
      "Epoch: 12/100... Step: 1223... Loss: 0.160449... Val Loss: 0.343745\n",
      "Epoch: 12/100... Step: 1224... Loss: 0.259416... Val Loss: 0.410678\n",
      "Epoch: 12/100... Step: 1225... Loss: 0.271798... Val Loss: 0.437250\n",
      "Epoch: 12/100... Step: 1226... Loss: 0.179870... Val Loss: 0.462958\n",
      "Epoch: 12/100... Step: 1227... Loss: 0.177874... Val Loss: 0.488062\n",
      "Epoch: 12/100... Step: 1228... Loss: 0.194142... Val Loss: 0.498659\n",
      "Epoch: 12/100... Step: 1229... Loss: 0.209187... Val Loss: 0.485494\n",
      "Epoch: 12/100... Step: 1230... Loss: 0.203650... Val Loss: 0.456784\n",
      "Epoch: 12/100... Step: 1231... Loss: 0.163680... Val Loss: 0.437528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100... Step: 1232... Loss: 0.185443... Val Loss: 0.457919\n",
      "Epoch: 12/100... Step: 1233... Loss: 0.215648... Val Loss: 0.485116\n",
      "Epoch: 12/100... Step: 1234... Loss: 0.286930... Val Loss: 0.544968\n",
      "Epoch: 12/100... Step: 1235... Loss: 0.363773... Val Loss: 0.602266\n",
      "Epoch: 12/100... Step: 1236... Loss: 0.134582... Val Loss: 0.623044\n",
      "Epoch: 12/100... Step: 1237... Loss: 0.207976... Val Loss: 0.643239\n",
      "Epoch: 12/100... Step: 1238... Loss: 0.126301... Val Loss: 0.664317\n",
      "Epoch: 12/100... Step: 1239... Loss: 0.225748... Val Loss: 0.656390\n",
      "Epoch: 12/100... Step: 1240... Loss: 0.167466... Val Loss: 0.626818\n",
      "Epoch: 12/100... Step: 1241... Loss: 0.214949... Val Loss: 0.578064\n",
      "Epoch: 12/100... Step: 1242... Loss: 0.230260... Val Loss: 0.548167\n",
      "Epoch: 12/100... Step: 1243... Loss: 0.205212... Val Loss: 0.444423\n",
      "Epoch: 12/100... Step: 1244... Loss: 0.207508... Val Loss: 0.343067\n",
      "Epoch: 12/100... Step: 1245... Loss: 0.208622... Val Loss: 0.291755\n",
      "Epoch: 12/100... Step: 1246... Loss: 0.240411... Val Loss: 0.268195\n",
      "Epoch: 12/100... Step: 1247... Loss: 0.164174... Val Loss: 0.255285\n",
      "Epoch: 12/100... Step: 1248... Loss: 0.136881... Val Loss: 0.245529\n",
      "Epoch: 13/100... Step: 1249... Loss: 0.350118... Val Loss: 0.324553\n",
      "Epoch: 13/100... Step: 1250... Loss: 0.320929... Val Loss: 0.155073\n",
      "Epoch: 13/100... Step: 1251... Loss: 0.208539... Val Loss: 0.441876\n",
      "Epoch: 13/100... Step: 1252... Loss: 0.220575... Val Loss: 0.705623\n",
      "Epoch: 13/100... Step: 1253... Loss: 0.239012... Val Loss: 0.850064\n",
      "Epoch: 13/100... Step: 1254... Loss: 0.151814... Val Loss: 0.850712\n",
      "Epoch: 13/100... Step: 1255... Loss: 0.157773... Val Loss: 0.912004\n",
      "Epoch: 13/100... Step: 1256... Loss: 0.194211... Val Loss: 0.916069\n",
      "Epoch: 13/100... Step: 1257... Loss: 0.240287... Val Loss: 0.968786\n",
      "Epoch: 13/100... Step: 1258... Loss: 0.261963... Val Loss: 0.987564\n",
      "Epoch: 13/100... Step: 1259... Loss: 0.252141... Val Loss: 1.048867\n",
      "Epoch: 13/100... Step: 1260... Loss: 0.235642... Val Loss: 1.084792\n",
      "Epoch: 13/100... Step: 1261... Loss: 0.215676... Val Loss: 1.071552\n",
      "Epoch: 13/100... Step: 1262... Loss: 0.135636... Val Loss: 1.123424\n",
      "Epoch: 13/100... Step: 1263... Loss: 0.156660... Val Loss: 1.252141\n",
      "Epoch: 13/100... Step: 1264... Loss: 0.257590... Val Loss: 1.276922\n",
      "Epoch: 13/100... Step: 1265... Loss: 0.230315... Val Loss: 1.265719\n",
      "Epoch: 13/100... Step: 1266... Loss: 0.256209... Val Loss: 1.310201\n",
      "Epoch: 13/100... Step: 1267... Loss: 0.323611... Val Loss: 1.287205\n",
      "Epoch: 13/100... Step: 1268... Loss: 0.243590... Val Loss: 1.313473\n",
      "Epoch: 13/100... Step: 1269... Loss: 0.183260... Val Loss: 1.302382\n",
      "Epoch: 13/100... Step: 1270... Loss: 0.225003... Val Loss: 1.325149\n",
      "Epoch: 13/100... Step: 1271... Loss: 0.186340... Val Loss: 1.302782\n",
      "Epoch: 13/100... Step: 1272... Loss: 0.214869... Val Loss: 1.200438\n",
      "Epoch: 13/100... Step: 1273... Loss: 0.246245... Val Loss: 1.057625\n",
      "Epoch: 13/100... Step: 1274... Loss: 0.256079... Val Loss: 0.977265\n",
      "Epoch: 13/100... Step: 1275... Loss: 0.208389... Val Loss: 0.875635\n",
      "Epoch: 13/100... Step: 1276... Loss: 0.147468... Val Loss: 0.768953\n",
      "Epoch: 13/100... Step: 1277... Loss: 0.205769... Val Loss: 0.626832\n",
      "Epoch: 13/100... Step: 1278... Loss: 0.152779... Val Loss: 0.519761\n",
      "Epoch: 13/100... Step: 1279... Loss: 0.161493... Val Loss: 0.439136\n",
      "Epoch: 13/100... Step: 1280... Loss: 0.127825... Val Loss: 0.294710\n",
      "Epoch: 13/100... Step: 1281... Loss: 0.179338... Val Loss: 0.190687\n",
      "Epoch: 13/100... Step: 1282... Loss: 0.172429... Val Loss: 0.120343\n",
      "Epoch: 13/100... Step: 1283... Loss: 0.247247... Val Loss: 0.056045\n",
      "Epoch: 13/100... Step: 1284... Loss: 0.219109... Val Loss: 0.038460\n",
      "Epoch: 13/100... Step: 1285... Loss: 0.166358... Val Loss: 0.048332\n",
      "Epoch: 13/100... Step: 1286... Loss: 0.151262... Val Loss: 0.074511\n",
      "Epoch: 13/100... Step: 1287... Loss: 0.114792... Val Loss: 0.131041\n",
      "Epoch: 13/100... Step: 1288... Loss: 0.151212... Val Loss: 0.195989\n",
      "Epoch: 13/100... Step: 1289... Loss: 0.126630... Val Loss: 0.310973\n",
      "Epoch: 13/100... Step: 1290... Loss: 0.248153... Val Loss: 0.439703\n",
      "Epoch: 13/100... Step: 1291... Loss: 0.213364... Val Loss: 0.549166\n",
      "Epoch: 13/100... Step: 1292... Loss: 0.207977... Val Loss: 0.682451\n",
      "Epoch: 13/100... Step: 1293... Loss: 0.239913... Val Loss: 0.700174\n",
      "Epoch: 13/100... Step: 1294... Loss: 0.238295... Val Loss: 0.668089\n",
      "Epoch: 13/100... Step: 1295... Loss: 0.246232... Val Loss: 0.705893\n",
      "Epoch: 13/100... Step: 1296... Loss: 0.217347... Val Loss: 0.769036\n",
      "Epoch: 13/100... Step: 1297... Loss: 0.194646... Val Loss: 0.819454\n",
      "Epoch: 13/100... Step: 1298... Loss: 0.137245... Val Loss: 0.850282\n",
      "Epoch: 13/100... Step: 1299... Loss: 0.232053... Val Loss: 0.867559\n",
      "Epoch: 13/100... Step: 1300... Loss: 0.230297... Val Loss: 0.848905\n",
      "Epoch: 13/100... Step: 1301... Loss: 0.182178... Val Loss: 0.831056\n",
      "Epoch: 13/100... Step: 1302... Loss: 0.231749... Val Loss: 0.753901\n",
      "Epoch: 13/100... Step: 1303... Loss: 0.279781... Val Loss: 0.703300\n",
      "Epoch: 13/100... Step: 1304... Loss: 0.243207... Val Loss: 0.679121\n",
      "Epoch: 13/100... Step: 1305... Loss: 0.311889... Val Loss: 0.673593\n",
      "Epoch: 13/100... Step: 1306... Loss: 0.323253... Val Loss: 0.631503\n",
      "Epoch: 13/100... Step: 1307... Loss: 0.125254... Val Loss: 0.574110\n",
      "Epoch: 13/100... Step: 1308... Loss: 0.216223... Val Loss: 0.498407\n",
      "Epoch: 13/100... Step: 1309... Loss: 0.139807... Val Loss: 0.442656\n",
      "Epoch: 13/100... Step: 1310... Loss: 0.080656... Val Loss: 0.428333\n",
      "Epoch: 13/100... Step: 1311... Loss: 0.315938... Val Loss: 0.408542\n",
      "Epoch: 13/100... Step: 1312... Loss: 0.223048... Val Loss: 0.307664\n",
      "Epoch: 13/100... Step: 1313... Loss: 0.233349... Val Loss: 0.233736\n",
      "Epoch: 13/100... Step: 1314... Loss: 0.225088... Val Loss: 0.160622\n",
      "Epoch: 13/100... Step: 1315... Loss: 0.093818... Val Loss: 0.145720\n",
      "Epoch: 13/100... Step: 1316... Loss: 0.188203... Val Loss: 0.196034\n",
      "Epoch: 13/100... Step: 1317... Loss: 0.216086... Val Loss: 0.204609\n",
      "Epoch: 13/100... Step: 1318... Loss: 0.195771... Val Loss: 0.207088\n",
      "Epoch: 13/100... Step: 1319... Loss: 0.245428... Val Loss: 0.199943\n",
      "Epoch: 13/100... Step: 1320... Loss: 0.226325... Val Loss: 0.186936\n",
      "Epoch: 13/100... Step: 1321... Loss: 0.275452... Val Loss: 0.245626\n",
      "Epoch: 13/100... Step: 1322... Loss: 0.207526... Val Loss: 0.287860\n",
      "Epoch: 13/100... Step: 1323... Loss: 0.082321... Val Loss: 0.290594\n",
      "Epoch: 13/100... Step: 1324... Loss: 0.161769... Val Loss: 0.301113\n",
      "Epoch: 13/100... Step: 1325... Loss: 0.200577... Val Loss: 0.294785\n",
      "Epoch: 13/100... Step: 1326... Loss: 0.169192... Val Loss: 0.208145\n",
      "Epoch: 13/100... Step: 1327... Loss: 0.274969... Val Loss: 0.109787\n",
      "Epoch: 13/100... Step: 1328... Loss: 0.153069... Val Loss: 0.087182\n",
      "Epoch: 13/100... Step: 1329... Loss: 0.129135... Val Loss: 0.105735\n",
      "Epoch: 13/100... Step: 1330... Loss: 0.165569... Val Loss: 0.110648\n",
      "Epoch: 13/100... Step: 1331... Loss: 0.125851... Val Loss: 0.043593\n",
      "Epoch: 13/100... Step: 1332... Loss: 0.128610... Val Loss: 0.034209\n",
      "Epoch: 13/100... Step: 1333... Loss: 0.159080... Val Loss: 0.138283\n",
      "Epoch: 13/100... Step: 1334... Loss: 0.181653... Val Loss: 0.205011\n",
      "Epoch: 13/100... Step: 1335... Loss: 0.198406... Val Loss: 0.227681\n",
      "Epoch: 13/100... Step: 1336... Loss: 0.187422... Val Loss: 0.199948\n",
      "Epoch: 13/100... Step: 1337... Loss: 0.202141... Val Loss: 0.207488\n",
      "Epoch: 13/100... Step: 1338... Loss: 0.171184... Val Loss: 0.216826\n",
      "Epoch: 13/100... Step: 1339... Loss: 0.188309... Val Loss: 0.200188\n",
      "Epoch: 13/100... Step: 1340... Loss: 0.181723... Val Loss: 0.161811\n",
      "Epoch: 13/100... Step: 1341... Loss: 0.232257... Val Loss: 0.102665\n",
      "Epoch: 13/100... Step: 1342... Loss: 0.169439... Val Loss: 0.077482\n",
      "Epoch: 13/100... Step: 1343... Loss: 0.150935... Val Loss: 0.070660\n",
      "Epoch: 13/100... Step: 1344... Loss: 0.242406... Val Loss: 0.075599\n",
      "Epoch: 13/100... Step: 1345... Loss: 0.128467... Val Loss: 0.052935\n",
      "Epoch: 13/100... Step: 1346... Loss: 0.228397... Val Loss: 0.070876\n",
      "Epoch: 13/100... Step: 1347... Loss: 0.174812... Val Loss: 0.134928\n",
      "Epoch: 13/100... Step: 1348... Loss: 0.154222... Val Loss: 0.126471\n",
      "Epoch: 13/100... Step: 1349... Loss: 0.230186... Val Loss: 0.077939\n",
      "Epoch: 13/100... Step: 1350... Loss: 0.189784... Val Loss: 0.068645\n",
      "Epoch: 13/100... Step: 1351... Loss: 0.177346... Val Loss: 0.059355\n",
      "Epoch: 13/100... Step: 1352... Loss: 0.115383... Val Loss: 0.070715\n",
      "Epoch: 14/100... Step: 1353... Loss: 0.258064... Val Loss: 0.133102\n",
      "Epoch: 14/100... Step: 1354... Loss: 0.217379... Val Loss: 0.455302\n",
      "Epoch: 14/100... Step: 1355... Loss: 0.295506... Val Loss: 1.189652\n",
      "Epoch: 14/100... Step: 1356... Loss: 0.237609... Val Loss: 1.771276\n",
      "Epoch: 14/100... Step: 1357... Loss: 0.281638... Val Loss: 2.015778\n",
      "Epoch: 14/100... Step: 1358... Loss: 0.186419... Val Loss: 2.185371\n",
      "Epoch: 14/100... Step: 1359... Loss: 0.137555... Val Loss: 2.298125\n",
      "Epoch: 14/100... Step: 1360... Loss: 0.212735... Val Loss: 2.466567\n",
      "Epoch: 14/100... Step: 1361... Loss: 0.290552... Val Loss: 2.649051\n",
      "Epoch: 14/100... Step: 1362... Loss: 0.270041... Val Loss: 2.798281\n",
      "Epoch: 14/100... Step: 1363... Loss: 0.207086... Val Loss: 2.920543\n",
      "Epoch: 14/100... Step: 1364... Loss: 0.162230... Val Loss: 2.993943\n",
      "Epoch: 14/100... Step: 1365... Loss: 0.235461... Val Loss: 3.018925\n",
      "Epoch: 14/100... Step: 1366... Loss: 0.210540... Val Loss: 2.990875\n",
      "Epoch: 14/100... Step: 1367... Loss: 0.222888... Val Loss: 2.970952\n",
      "Epoch: 14/100... Step: 1368... Loss: 0.200089... Val Loss: 2.930283\n",
      "Epoch: 14/100... Step: 1369... Loss: 0.262117... Val Loss: 2.893161\n",
      "Epoch: 14/100... Step: 1370... Loss: 0.247387... Val Loss: 2.806566\n",
      "Epoch: 14/100... Step: 1371... Loss: 0.078611... Val Loss: 2.756108\n",
      "Epoch: 14/100... Step: 1372... Loss: 0.128620... Val Loss: 2.637277\n",
      "Epoch: 14/100... Step: 1373... Loss: 0.116441... Val Loss: 2.482323\n",
      "Epoch: 14/100... Step: 1374... Loss: 0.260796... Val Loss: 2.390870\n",
      "Epoch: 14/100... Step: 1375... Loss: 0.180386... Val Loss: 2.334837\n",
      "Epoch: 14/100... Step: 1376... Loss: 0.153662... Val Loss: 2.232360\n",
      "Epoch: 14/100... Step: 1377... Loss: 0.186743... Val Loss: 2.111017\n",
      "Epoch: 14/100... Step: 1378... Loss: 0.253905... Val Loss: 1.959518\n",
      "Epoch: 14/100... Step: 1379... Loss: 0.168673... Val Loss: 1.770113\n",
      "Epoch: 14/100... Step: 1380... Loss: 0.200395... Val Loss: 1.590044\n",
      "Epoch: 14/100... Step: 1381... Loss: 0.151650... Val Loss: 1.453370\n",
      "Epoch: 14/100... Step: 1382... Loss: 0.180166... Val Loss: 1.311416\n",
      "Epoch: 14/100... Step: 1383... Loss: 0.246349... Val Loss: 1.261489\n",
      "Epoch: 14/100... Step: 1384... Loss: 0.180093... Val Loss: 1.212910\n",
      "Epoch: 14/100... Step: 1385... Loss: 0.121455... Val Loss: 1.128864\n",
      "Epoch: 14/100... Step: 1386... Loss: 0.273072... Val Loss: 0.991714\n",
      "Epoch: 14/100... Step: 1387... Loss: 0.142845... Val Loss: 0.874904\n",
      "Epoch: 14/100... Step: 1388... Loss: 0.307185... Val Loss: 0.706585\n",
      "Epoch: 14/100... Step: 1389... Loss: 0.109321... Val Loss: 0.542061\n",
      "Epoch: 14/100... Step: 1390... Loss: 0.211101... Val Loss: 0.374639\n",
      "Epoch: 14/100... Step: 1391... Loss: 0.219661... Val Loss: 0.191088\n",
      "Epoch: 14/100... Step: 1392... Loss: 0.207595... Val Loss: 0.070566\n",
      "Epoch: 14/100... Step: 1393... Loss: 0.192823... Val Loss: 0.162376\n",
      "Epoch: 14/100... Step: 1394... Loss: 0.195306... Val Loss: 0.302893\n",
      "Epoch: 14/100... Step: 1395... Loss: 0.214437... Val Loss: 0.435508\n",
      "Epoch: 14/100... Step: 1396... Loss: 0.222091... Val Loss: 0.527136\n",
      "Epoch: 14/100... Step: 1397... Loss: 0.327496... Val Loss: 0.550051\n",
      "Epoch: 14/100... Step: 1398... Loss: 0.113826... Val Loss: 0.582159\n",
      "Epoch: 14/100... Step: 1399... Loss: 0.243379... Val Loss: 0.544329\n",
      "Epoch: 14/100... Step: 1400... Loss: 0.139571... Val Loss: 0.570368\n",
      "Epoch: 14/100... Step: 1401... Loss: 0.171304... Val Loss: 0.605302\n",
      "Epoch: 14/100... Step: 1402... Loss: 0.159654... Val Loss: 0.633678\n",
      "Epoch: 14/100... Step: 1403... Loss: 0.173041... Val Loss: 0.605843\n",
      "Epoch: 14/100... Step: 1404... Loss: 0.108901... Val Loss: 0.598823\n",
      "Epoch: 14/100... Step: 1405... Loss: 0.158622... Val Loss: 0.632214\n",
      "Epoch: 14/100... Step: 1406... Loss: 0.286470... Val Loss: 0.686569\n",
      "Epoch: 14/100... Step: 1407... Loss: 0.117542... Val Loss: 0.823367\n",
      "Epoch: 14/100... Step: 1408... Loss: 0.192112... Val Loss: 0.934676\n",
      "Epoch: 14/100... Step: 1409... Loss: 0.193872... Val Loss: 1.081583\n",
      "Epoch: 14/100... Step: 1410... Loss: 0.157677... Val Loss: 1.230246\n",
      "Epoch: 14/100... Step: 1411... Loss: 0.177208... Val Loss: 1.298611\n",
      "Epoch: 14/100... Step: 1412... Loss: 0.175866... Val Loss: 1.308517\n",
      "Epoch: 14/100... Step: 1413... Loss: 0.150692... Val Loss: 1.278636\n",
      "Epoch: 14/100... Step: 1414... Loss: 0.274321... Val Loss: 1.280525\n",
      "Epoch: 14/100... Step: 1415... Loss: 0.147438... Val Loss: 1.332428\n",
      "Epoch: 14/100... Step: 1416... Loss: 0.311592... Val Loss: 1.305080\n",
      "Epoch: 14/100... Step: 1417... Loss: 0.199972... Val Loss: 1.292062\n",
      "Epoch: 14/100... Step: 1418... Loss: 0.191143... Val Loss: 1.323172\n",
      "Epoch: 14/100... Step: 1419... Loss: 0.202275... Val Loss: 1.356171\n",
      "Epoch: 14/100... Step: 1420... Loss: 0.119789... Val Loss: 1.425424\n",
      "Epoch: 14/100... Step: 1421... Loss: 0.198500... Val Loss: 1.458006\n",
      "Epoch: 14/100... Step: 1422... Loss: 0.159127... Val Loss: 1.387014\n",
      "Epoch: 14/100... Step: 1423... Loss: 0.199506... Val Loss: 1.264118\n",
      "Epoch: 14/100... Step: 1424... Loss: 0.218863... Val Loss: 1.184147\n",
      "Epoch: 14/100... Step: 1425... Loss: 0.171693... Val Loss: 1.109298\n",
      "Epoch: 14/100... Step: 1426... Loss: 0.383494... Val Loss: 1.117732\n",
      "Epoch: 14/100... Step: 1427... Loss: 0.174907... Val Loss: 1.167613\n",
      "Epoch: 14/100... Step: 1428... Loss: 0.257829... Val Loss: 1.194237\n",
      "Epoch: 14/100... Step: 1429... Loss: 0.216792... Val Loss: 1.234156\n",
      "Epoch: 14/100... Step: 1430... Loss: 0.255747... Val Loss: 1.236132\n",
      "Epoch: 14/100... Step: 1431... Loss: 0.193241... Val Loss: 1.225727\n",
      "Epoch: 14/100... Step: 1432... Loss: 0.165994... Val Loss: 1.207456\n",
      "Epoch: 14/100... Step: 1433... Loss: 0.175850... Val Loss: 1.169290\n",
      "Epoch: 14/100... Step: 1434... Loss: 0.157155... Val Loss: 1.145054\n",
      "Epoch: 14/100... Step: 1435... Loss: 0.163049... Val Loss: 1.117985\n",
      "Epoch: 14/100... Step: 1436... Loss: 0.093204... Val Loss: 1.071617\n",
      "Epoch: 14/100... Step: 1437... Loss: 0.076695... Val Loss: 0.955698\n",
      "Epoch: 14/100... Step: 1438... Loss: 0.134648... Val Loss: 0.836901\n",
      "Epoch: 14/100... Step: 1439... Loss: 0.139982... Val Loss: 0.740023\n",
      "Epoch: 14/100... Step: 1440... Loss: 0.177030... Val Loss: 0.688806\n",
      "Epoch: 14/100... Step: 1441... Loss: 0.211320... Val Loss: 0.674896\n",
      "Epoch: 14/100... Step: 1442... Loss: 0.218507... Val Loss: 0.596084\n",
      "Epoch: 14/100... Step: 1443... Loss: 0.185443... Val Loss: 0.431111\n",
      "Epoch: 14/100... Step: 1444... Loss: 0.109137... Val Loss: 0.279963\n",
      "Epoch: 14/100... Step: 1445... Loss: 0.193552... Val Loss: 0.177311\n",
      "Epoch: 14/100... Step: 1446... Loss: 0.220265... Val Loss: 0.092656\n",
      "Epoch: 14/100... Step: 1447... Loss: 0.220141... Val Loss: 0.048918\n",
      "Epoch: 14/100... Step: 1448... Loss: 0.157755... Val Loss: 0.058114\n",
      "Epoch: 14/100... Step: 1449... Loss: 0.183007... Val Loss: 0.102736\n",
      "Epoch: 14/100... Step: 1450... Loss: 0.156367... Val Loss: 0.144538\n",
      "Epoch: 14/100... Step: 1451... Loss: 0.169885... Val Loss: 0.135946\n",
      "Epoch: 14/100... Step: 1452... Loss: 0.203988... Val Loss: 0.155128\n",
      "Epoch: 14/100... Step: 1453... Loss: 0.120154... Val Loss: 0.130649\n",
      "Epoch: 14/100... Step: 1454... Loss: 0.122024... Val Loss: 0.064357\n",
      "Epoch: 14/100... Step: 1455... Loss: 0.154983... Val Loss: 0.078287\n",
      "Epoch: 14/100... Step: 1456... Loss: 0.210023... Val Loss: 0.158240\n",
      "Epoch: 15/100... Step: 1457... Loss: 0.252272... Val Loss: 0.158775\n",
      "Epoch: 15/100... Step: 1458... Loss: 0.263689... Val Loss: 0.345378\n",
      "Epoch: 15/100... Step: 1459... Loss: 0.191971... Val Loss: 0.699737\n",
      "Epoch: 15/100... Step: 1460... Loss: 0.117176... Val Loss: 1.238246\n",
      "Epoch: 15/100... Step: 1461... Loss: 0.116900... Val Loss: 1.842102\n",
      "Epoch: 15/100... Step: 1462... Loss: 0.246030... Val Loss: 2.270314\n",
      "Epoch: 15/100... Step: 1463... Loss: 0.124842... Val Loss: 2.603101\n",
      "Epoch: 15/100... Step: 1464... Loss: 0.118282... Val Loss: 2.861509\n",
      "Epoch: 15/100... Step: 1465... Loss: 0.199414... Val Loss: 3.077172\n",
      "Epoch: 15/100... Step: 1466... Loss: 0.115037... Val Loss: 3.247406\n",
      "Epoch: 15/100... Step: 1467... Loss: 0.051593... Val Loss: 3.352160\n",
      "Epoch: 15/100... Step: 1468... Loss: 0.144821... Val Loss: 3.455474\n",
      "Epoch: 15/100... Step: 1469... Loss: 0.195593... Val Loss: 3.502543\n",
      "Epoch: 15/100... Step: 1470... Loss: 0.112082... Val Loss: 3.485679\n",
      "Epoch: 15/100... Step: 1471... Loss: 0.213002... Val Loss: 3.440675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100... Step: 1472... Loss: 0.267294... Val Loss: 3.385672\n",
      "Epoch: 15/100... Step: 1473... Loss: 0.195826... Val Loss: 3.314177\n",
      "Epoch: 15/100... Step: 1474... Loss: 0.175127... Val Loss: 3.211032\n",
      "Epoch: 15/100... Step: 1475... Loss: 0.172597... Val Loss: 3.129733\n",
      "Epoch: 15/100... Step: 1476... Loss: 0.112557... Val Loss: 3.007717\n",
      "Epoch: 15/100... Step: 1477... Loss: 0.160360... Val Loss: 2.855320\n",
      "Epoch: 15/100... Step: 1478... Loss: 0.269091... Val Loss: 2.683506\n",
      "Epoch: 15/100... Step: 1479... Loss: 0.118355... Val Loss: 2.557331\n",
      "Epoch: 15/100... Step: 1480... Loss: 0.089720... Val Loss: 2.397673\n",
      "Epoch: 15/100... Step: 1481... Loss: 0.217206... Val Loss: 2.212157\n",
      "Epoch: 15/100... Step: 1482... Loss: 0.200574... Val Loss: 2.111628\n",
      "Epoch: 15/100... Step: 1483... Loss: 0.190558... Val Loss: 2.009503\n",
      "Epoch: 15/100... Step: 1484... Loss: 0.138207... Val Loss: 1.969058\n",
      "Epoch: 15/100... Step: 1485... Loss: 0.133694... Val Loss: 1.874985\n",
      "Epoch: 15/100... Step: 1486... Loss: 0.203225... Val Loss: 1.725319\n",
      "Epoch: 15/100... Step: 1487... Loss: 0.178153... Val Loss: 1.503336\n",
      "Epoch: 15/100... Step: 1488... Loss: 0.223777... Val Loss: 1.243874\n",
      "Epoch: 15/100... Step: 1489... Loss: 0.173458... Val Loss: 1.037614\n",
      "Epoch: 15/100... Step: 1490... Loss: 0.124836... Val Loss: 0.867986\n",
      "Epoch: 15/100... Step: 1491... Loss: 0.228383... Val Loss: 0.777578\n",
      "Epoch: 15/100... Step: 1492... Loss: 0.128510... Val Loss: 0.680740\n",
      "Epoch: 15/100... Step: 1493... Loss: 0.134962... Val Loss: 0.557368\n",
      "Epoch: 15/100... Step: 1494... Loss: 0.215700... Val Loss: 0.437156\n",
      "Epoch: 15/100... Step: 1495... Loss: 0.198080... Val Loss: 0.401317\n",
      "Epoch: 15/100... Step: 1496... Loss: 0.139487... Val Loss: 0.333852\n",
      "Epoch: 15/100... Step: 1497... Loss: 0.169150... Val Loss: 0.262841\n",
      "Epoch: 15/100... Step: 1498... Loss: 0.152240... Val Loss: 0.213188\n",
      "Epoch: 15/100... Step: 1499... Loss: 0.113174... Val Loss: 0.148380\n",
      "Epoch: 15/100... Step: 1500... Loss: 0.182247... Val Loss: 0.082777\n",
      "Epoch: 15/100... Step: 1501... Loss: 0.134448... Val Loss: 0.070920\n",
      "Epoch: 15/100... Step: 1502... Loss: 0.131343... Val Loss: 0.109959\n",
      "Epoch: 15/100... Step: 1503... Loss: 0.164636... Val Loss: 0.092667\n",
      "Epoch: 15/100... Step: 1504... Loss: 0.239318... Val Loss: 0.096046\n",
      "Epoch: 15/100... Step: 1505... Loss: 0.152585... Val Loss: 0.070383\n",
      "Epoch: 15/100... Step: 1506... Loss: 0.149859... Val Loss: 0.014714\n",
      "Epoch: 15/100... Step: 1507... Loss: 0.202394... Val Loss: 0.030049\n",
      "Epoch: 15/100... Step: 1508... Loss: 0.198800... Val Loss: 0.041427\n",
      "Epoch: 15/100... Step: 1509... Loss: 0.197933... Val Loss: 0.050341\n",
      "Epoch: 15/100... Step: 1510... Loss: 0.121432... Val Loss: 0.070836\n",
      "Epoch: 15/100... Step: 1511... Loss: 0.127200... Val Loss: 0.125138\n",
      "Epoch: 15/100... Step: 1512... Loss: 0.155397... Val Loss: 0.216445\n",
      "Epoch: 15/100... Step: 1513... Loss: 0.166192... Val Loss: 0.311820\n",
      "Epoch: 15/100... Step: 1514... Loss: 0.111818... Val Loss: 0.385938\n",
      "Epoch: 15/100... Step: 1515... Loss: 0.206651... Val Loss: 0.446929\n",
      "Epoch: 15/100... Step: 1516... Loss: 0.234236... Val Loss: 0.480728\n",
      "Epoch: 15/100... Step: 1517... Loss: 0.092964... Val Loss: 0.504174\n",
      "Epoch: 15/100... Step: 1518... Loss: 0.157979... Val Loss: 0.583817\n",
      "Epoch: 15/100... Step: 1519... Loss: 0.187668... Val Loss: 0.703564\n",
      "Epoch: 15/100... Step: 1520... Loss: 0.161040... Val Loss: 0.827181\n",
      "Epoch: 15/100... Step: 1521... Loss: 0.201551... Val Loss: 0.947493\n",
      "Epoch: 15/100... Step: 1522... Loss: 0.163268... Val Loss: 0.979176\n",
      "Epoch: 15/100... Step: 1523... Loss: 0.151203... Val Loss: 0.975202\n",
      "Epoch: 15/100... Step: 1524... Loss: 0.161705... Val Loss: 0.934723\n",
      "Epoch: 15/100... Step: 1525... Loss: 0.166988... Val Loss: 0.868127\n",
      "Epoch: 15/100... Step: 1526... Loss: 0.084646... Val Loss: 0.746417\n",
      "Epoch: 15/100... Step: 1527... Loss: 0.130096... Val Loss: 0.617415\n",
      "Epoch: 15/100... Step: 1528... Loss: 0.183658... Val Loss: 0.532737\n",
      "Epoch: 15/100... Step: 1529... Loss: 0.228322... Val Loss: 0.483337\n",
      "Epoch: 15/100... Step: 1530... Loss: 0.230343... Val Loss: 0.480977\n",
      "Epoch: 15/100... Step: 1531... Loss: 0.132015... Val Loss: 0.512876\n",
      "Epoch: 15/100... Step: 1532... Loss: 0.218751... Val Loss: 0.525792\n",
      "Epoch: 15/100... Step: 1533... Loss: 0.220313... Val Loss: 0.684974\n",
      "Epoch: 15/100... Step: 1534... Loss: 0.191061... Val Loss: 0.798504\n",
      "Epoch: 15/100... Step: 1535... Loss: 0.144704... Val Loss: 0.856599\n",
      "Epoch: 15/100... Step: 1536... Loss: 0.192520... Val Loss: 0.910199\n",
      "Epoch: 15/100... Step: 1537... Loss: 0.177073... Val Loss: 0.918080\n",
      "Epoch: 15/100... Step: 1538... Loss: 0.115485... Val Loss: 0.934801\n",
      "Epoch: 15/100... Step: 1539... Loss: 0.158668... Val Loss: 1.008894\n",
      "Epoch: 15/100... Step: 1540... Loss: 0.171753... Val Loss: 1.025663\n",
      "Epoch: 15/100... Step: 1541... Loss: 0.129167... Val Loss: 1.002567\n",
      "Epoch: 15/100... Step: 1542... Loss: 0.111525... Val Loss: 0.959856\n",
      "Epoch: 15/100... Step: 1543... Loss: 0.154483... Val Loss: 0.971746\n",
      "Epoch: 15/100... Step: 1544... Loss: 0.208429... Val Loss: 0.857360\n",
      "Epoch: 15/100... Step: 1545... Loss: 0.160241... Val Loss: 0.774383\n",
      "Epoch: 15/100... Step: 1546... Loss: 0.129721... Val Loss: 0.674120\n",
      "Epoch: 15/100... Step: 1547... Loss: 0.153738... Val Loss: 0.728136\n",
      "Epoch: 15/100... Step: 1548... Loss: 0.198986... Val Loss: 0.708832\n",
      "Epoch: 15/100... Step: 1549... Loss: 0.242680... Val Loss: 0.690366\n",
      "Epoch: 15/100... Step: 1550... Loss: 0.187865... Val Loss: 0.643777\n",
      "Epoch: 15/100... Step: 1551... Loss: 0.139846... Val Loss: 0.487464\n",
      "Epoch: 15/100... Step: 1552... Loss: 0.145273... Val Loss: 0.318535\n",
      "Epoch: 15/100... Step: 1553... Loss: 0.187328... Val Loss: 0.166447\n",
      "Epoch: 15/100... Step: 1554... Loss: 0.104878... Val Loss: 0.065652\n",
      "Epoch: 15/100... Step: 1555... Loss: 0.148607... Val Loss: 0.053806\n",
      "Epoch: 15/100... Step: 1556... Loss: 0.145478... Val Loss: 0.062574\n",
      "Epoch: 15/100... Step: 1557... Loss: 0.129471... Val Loss: 0.087647\n",
      "Epoch: 15/100... Step: 1558... Loss: 0.068786... Val Loss: 0.106865\n",
      "Epoch: 15/100... Step: 1559... Loss: 0.186334... Val Loss: 0.094110\n",
      "Epoch: 15/100... Step: 1560... Loss: 0.212861... Val Loss: 0.066570\n",
      "Epoch: 16/100... Step: 1561... Loss: 0.171567... Val Loss: 0.355140\n",
      "Epoch: 16/100... Step: 1562... Loss: 0.267233... Val Loss: 0.143607\n",
      "Epoch: 16/100... Step: 1563... Loss: 0.150039... Val Loss: 0.567203\n",
      "Epoch: 16/100... Step: 1564... Loss: 0.148439... Val Loss: 1.234140\n",
      "Epoch: 16/100... Step: 1565... Loss: 0.198496... Val Loss: 1.665531\n",
      "Epoch: 16/100... Step: 1566... Loss: 0.105047... Val Loss: 2.164123\n",
      "Epoch: 16/100... Step: 1567... Loss: 0.118062... Val Loss: 2.565230\n",
      "Epoch: 16/100... Step: 1568... Loss: 0.145885... Val Loss: 2.900970\n",
      "Epoch: 16/100... Step: 1569... Loss: 0.081083... Val Loss: 3.179816\n",
      "Epoch: 16/100... Step: 1570... Loss: 0.134944... Val Loss: 3.387647\n",
      "Epoch: 16/100... Step: 1571... Loss: 0.143570... Val Loss: 3.522548\n",
      "Epoch: 16/100... Step: 1572... Loss: 0.145746... Val Loss: 3.513643\n",
      "Epoch: 16/100... Step: 1573... Loss: 0.129808... Val Loss: 3.434791\n",
      "Epoch: 16/100... Step: 1574... Loss: 0.151958... Val Loss: 3.259351\n",
      "Epoch: 16/100... Step: 1575... Loss: 0.129717... Val Loss: 3.062637\n",
      "Epoch: 16/100... Step: 1576... Loss: 0.114491... Val Loss: 2.901825\n",
      "Epoch: 16/100... Step: 1577... Loss: 0.145440... Val Loss: 2.753424\n",
      "Epoch: 16/100... Step: 1578... Loss: 0.151259... Val Loss: 2.648480\n",
      "Epoch: 16/100... Step: 1579... Loss: 0.164132... Val Loss: 2.579769\n",
      "Epoch: 16/100... Step: 1580... Loss: 0.198368... Val Loss: 2.560649\n",
      "Epoch: 16/100... Step: 1581... Loss: 0.144133... Val Loss: 2.538512\n",
      "Epoch: 16/100... Step: 1582... Loss: 0.143067... Val Loss: 2.526591\n",
      "Epoch: 16/100... Step: 1583... Loss: 0.122157... Val Loss: 2.562258\n",
      "Epoch: 16/100... Step: 1584... Loss: 0.162962... Val Loss: 2.505951\n",
      "Epoch: 16/100... Step: 1585... Loss: 0.160083... Val Loss: 2.396361\n",
      "Epoch: 16/100... Step: 1586... Loss: 0.140839... Val Loss: 2.298499\n",
      "Epoch: 16/100... Step: 1587... Loss: 0.102469... Val Loss: 2.195146\n",
      "Epoch: 16/100... Step: 1588... Loss: 0.194935... Val Loss: 1.978452\n",
      "Epoch: 16/100... Step: 1589... Loss: 0.179444... Val Loss: 1.749796\n",
      "Epoch: 16/100... Step: 1590... Loss: 0.157199... Val Loss: 1.542774\n",
      "Epoch: 16/100... Step: 1591... Loss: 0.095155... Val Loss: 1.301734\n",
      "Epoch: 16/100... Step: 1592... Loss: 0.132265... Val Loss: 1.072512\n",
      "Epoch: 16/100... Step: 1593... Loss: 0.117688... Val Loss: 0.854677\n",
      "Epoch: 16/100... Step: 1594... Loss: 0.213974... Val Loss: 0.655720\n",
      "Epoch: 16/100... Step: 1595... Loss: 0.094833... Val Loss: 0.487402\n",
      "Epoch: 16/100... Step: 1596... Loss: 0.143916... Val Loss: 0.434795\n",
      "Epoch: 16/100... Step: 1597... Loss: 0.174786... Val Loss: 0.423696\n",
      "Epoch: 16/100... Step: 1598... Loss: 0.116586... Val Loss: 0.385352\n",
      "Epoch: 16/100... Step: 1599... Loss: 0.124435... Val Loss: 0.285701\n",
      "Epoch: 16/100... Step: 1600... Loss: 0.120241... Val Loss: 0.143810\n",
      "Epoch: 16/100... Step: 1601... Loss: 0.136756... Val Loss: 0.056579\n",
      "Epoch: 16/100... Step: 1602... Loss: 0.075850... Val Loss: 0.222815\n",
      "Epoch: 16/100... Step: 1603... Loss: 0.168411... Val Loss: 0.296222\n",
      "Epoch: 16/100... Step: 1604... Loss: 0.132292... Val Loss: 0.366295\n",
      "Epoch: 16/100... Step: 1605... Loss: 0.101470... Val Loss: 0.454134\n",
      "Epoch: 16/100... Step: 1606... Loss: 0.118164... Val Loss: 0.536796\n",
      "Epoch: 16/100... Step: 1607... Loss: 0.097590... Val Loss: 0.560174\n",
      "Epoch: 16/100... Step: 1608... Loss: 0.105747... Val Loss: 0.520795\n",
      "Epoch: 16/100... Step: 1609... Loss: 0.243348... Val Loss: 0.500588\n",
      "Epoch: 16/100... Step: 1610... Loss: 0.097908... Val Loss: 0.524670\n",
      "Epoch: 16/100... Step: 1611... Loss: 0.163559... Val Loss: 0.556717\n",
      "Epoch: 16/100... Step: 1612... Loss: 0.144775... Val Loss: 0.567382\n",
      "Epoch: 16/100... Step: 1613... Loss: 0.180931... Val Loss: 0.574662\n",
      "Epoch: 16/100... Step: 1614... Loss: 0.082858... Val Loss: 0.539818\n",
      "Epoch: 16/100... Step: 1615... Loss: 0.156075... Val Loss: 0.488383\n",
      "Epoch: 16/100... Step: 1616... Loss: 0.129740... Val Loss: 0.428738\n",
      "Epoch: 16/100... Step: 1617... Loss: 0.181299... Val Loss: 0.369579\n",
      "Epoch: 16/100... Step: 1618... Loss: 0.103293... Val Loss: 0.359218\n",
      "Epoch: 16/100... Step: 1619... Loss: 0.164912... Val Loss: 0.410700\n",
      "Epoch: 16/100... Step: 1620... Loss: 0.163753... Val Loss: 0.536179\n",
      "Epoch: 16/100... Step: 1621... Loss: 0.119464... Val Loss: 0.747307\n",
      "Epoch: 16/100... Step: 1622... Loss: 0.146840... Val Loss: 0.835451\n",
      "Epoch: 16/100... Step: 1623... Loss: 0.129269... Val Loss: 0.859643\n",
      "Epoch: 16/100... Step: 1624... Loss: 0.093138... Val Loss: 0.884989\n",
      "Epoch: 16/100... Step: 1625... Loss: 0.099148... Val Loss: 0.904731\n",
      "Epoch: 16/100... Step: 1626... Loss: 0.111179... Val Loss: 0.906882\n",
      "Epoch: 16/100... Step: 1627... Loss: 0.152580... Val Loss: 0.912581\n",
      "Epoch: 16/100... Step: 1628... Loss: 0.137032... Val Loss: 0.907031\n",
      "Epoch: 16/100... Step: 1629... Loss: 0.128519... Val Loss: 0.830721\n",
      "Epoch: 16/100... Step: 1630... Loss: 0.096877... Val Loss: 0.747562\n",
      "Epoch: 16/100... Step: 1631... Loss: 0.097540... Val Loss: 0.687565\n",
      "Epoch: 16/100... Step: 1632... Loss: 0.092075... Val Loss: 0.638755\n",
      "Epoch: 16/100... Step: 1633... Loss: 0.109543... Val Loss: 0.579933\n",
      "Epoch: 16/100... Step: 1634... Loss: 0.136976... Val Loss: 0.526109\n",
      "Epoch: 16/100... Step: 1635... Loss: 0.147195... Val Loss: 0.453048\n",
      "Epoch: 16/100... Step: 1636... Loss: 0.118129... Val Loss: 0.369276\n",
      "Epoch: 16/100... Step: 1637... Loss: 0.168052... Val Loss: 0.288134\n",
      "Epoch: 16/100... Step: 1638... Loss: 0.125935... Val Loss: 0.238116\n",
      "Epoch: 16/100... Step: 1639... Loss: 0.133779... Val Loss: 0.242656\n",
      "Epoch: 16/100... Step: 1640... Loss: 0.159858... Val Loss: 0.266672\n",
      "Epoch: 16/100... Step: 1641... Loss: 0.074025... Val Loss: 0.312852\n",
      "Epoch: 16/100... Step: 1642... Loss: 0.111849... Val Loss: 0.350371\n",
      "Epoch: 16/100... Step: 1643... Loss: 0.139500... Val Loss: 0.368750\n",
      "Epoch: 16/100... Step: 1644... Loss: 0.170810... Val Loss: 0.344603\n",
      "Epoch: 16/100... Step: 1645... Loss: 0.087331... Val Loss: 0.363725\n",
      "Epoch: 16/100... Step: 1646... Loss: 0.129510... Val Loss: 0.385665\n",
      "Epoch: 16/100... Step: 1647... Loss: 0.122337... Val Loss: 0.383781\n",
      "Epoch: 16/100... Step: 1648... Loss: 0.083602... Val Loss: 0.379791\n",
      "Epoch: 16/100... Step: 1649... Loss: 0.069210... Val Loss: 0.282046\n",
      "Epoch: 16/100... Step: 1650... Loss: 0.134590... Val Loss: 0.217516\n",
      "Epoch: 16/100... Step: 1651... Loss: 0.072690... Val Loss: 0.182226\n",
      "Epoch: 16/100... Step: 1652... Loss: 0.096991... Val Loss: 0.136776\n",
      "Epoch: 16/100... Step: 1653... Loss: 0.118827... Val Loss: 0.133773\n",
      "Epoch: 16/100... Step: 1654... Loss: 0.096834... Val Loss: 0.117287\n",
      "Epoch: 16/100... Step: 1655... Loss: 0.073474... Val Loss: 0.106879\n",
      "Epoch: 16/100... Step: 1656... Loss: 0.076587... Val Loss: 0.092653\n",
      "Epoch: 16/100... Step: 1657... Loss: 0.121061... Val Loss: 0.123156\n",
      "Epoch: 16/100... Step: 1658... Loss: 0.156273... Val Loss: 0.130079\n",
      "Epoch: 16/100... Step: 1659... Loss: 0.117114... Val Loss: 0.153249\n",
      "Epoch: 16/100... Step: 1660... Loss: 0.078431... Val Loss: 0.190665\n",
      "Epoch: 16/100... Step: 1661... Loss: 0.132210... Val Loss: 0.200898\n",
      "Epoch: 16/100... Step: 1662... Loss: 0.117587... Val Loss: 0.223216\n",
      "Epoch: 16/100... Step: 1663... Loss: 0.076133... Val Loss: 0.211718\n",
      "Epoch: 16/100... Step: 1664... Loss: 0.139819... Val Loss: 0.207639\n",
      "Epoch: 17/100... Step: 1665... Loss: 0.141822... Val Loss: 0.191624\n",
      "Epoch: 17/100... Step: 1666... Loss: 0.129354... Val Loss: 0.207795\n",
      "Epoch: 17/100... Step: 1667... Loss: 0.095286... Val Loss: 0.625093\n",
      "Epoch: 17/100... Step: 1668... Loss: 0.123224... Val Loss: 0.878304\n",
      "Epoch: 17/100... Step: 1669... Loss: 0.074459... Val Loss: 0.953015\n",
      "Epoch: 17/100... Step: 1670... Loss: 0.105269... Val Loss: 0.992421\n",
      "Epoch: 17/100... Step: 1671... Loss: 0.088798... Val Loss: 1.032764\n",
      "Epoch: 17/100... Step: 1672... Loss: 0.161724... Val Loss: 1.164647\n",
      "Epoch: 17/100... Step: 1673... Loss: 0.100160... Val Loss: 1.343479\n",
      "Epoch: 17/100... Step: 1674... Loss: 0.081069... Val Loss: 1.446225\n",
      "Epoch: 17/100... Step: 1675... Loss: 0.088509... Val Loss: 1.496584\n",
      "Epoch: 17/100... Step: 1676... Loss: 0.111590... Val Loss: 1.499833\n",
      "Epoch: 17/100... Step: 1677... Loss: 0.077687... Val Loss: 1.412010\n",
      "Epoch: 17/100... Step: 1678... Loss: 0.144320... Val Loss: 1.378340\n",
      "Epoch: 17/100... Step: 1679... Loss: 0.131200... Val Loss: 1.383490\n",
      "Epoch: 17/100... Step: 1680... Loss: 0.085936... Val Loss: 1.361915\n",
      "Epoch: 17/100... Step: 1681... Loss: 0.105368... Val Loss: 1.351731\n",
      "Epoch: 17/100... Step: 1682... Loss: 0.110823... Val Loss: 1.327006\n",
      "Epoch: 17/100... Step: 1683... Loss: 0.097856... Val Loss: 1.320220\n",
      "Epoch: 17/100... Step: 1684... Loss: 0.186319... Val Loss: 1.327081\n",
      "Epoch: 17/100... Step: 1685... Loss: 0.108342... Val Loss: 1.365187\n",
      "Epoch: 17/100... Step: 1686... Loss: 0.128712... Val Loss: 1.352994\n",
      "Epoch: 17/100... Step: 1687... Loss: 0.119571... Val Loss: 1.315629\n",
      "Epoch: 17/100... Step: 1688... Loss: 0.081009... Val Loss: 1.162566\n",
      "Epoch: 17/100... Step: 1689... Loss: 0.110134... Val Loss: 1.087945\n",
      "Epoch: 17/100... Step: 1690... Loss: 0.078300... Val Loss: 1.028050\n",
      "Epoch: 17/100... Step: 1691... Loss: 0.105692... Val Loss: 0.941306\n",
      "Epoch: 17/100... Step: 1692... Loss: 0.109506... Val Loss: 0.855764\n",
      "Epoch: 17/100... Step: 1693... Loss: 0.096448... Val Loss: 0.791363\n",
      "Epoch: 17/100... Step: 1694... Loss: 0.058165... Val Loss: 0.768167\n",
      "Epoch: 17/100... Step: 1695... Loss: 0.082582... Val Loss: 0.748542\n",
      "Epoch: 17/100... Step: 1696... Loss: 0.114639... Val Loss: 0.755835\n",
      "Epoch: 17/100... Step: 1697... Loss: 0.138136... Val Loss: 0.737656\n",
      "Epoch: 17/100... Step: 1698... Loss: 0.143749... Val Loss: 0.700619\n",
      "Epoch: 17/100... Step: 1699... Loss: 0.072773... Val Loss: 0.647389\n",
      "Epoch: 17/100... Step: 1700... Loss: 0.123840... Val Loss: 0.569450\n",
      "Epoch: 17/100... Step: 1701... Loss: 0.044157... Val Loss: 0.479374\n",
      "Epoch: 17/100... Step: 1702... Loss: 0.123153... Val Loss: 0.384567\n",
      "Epoch: 17/100... Step: 1703... Loss: 0.130644... Val Loss: 0.272366\n",
      "Epoch: 17/100... Step: 1704... Loss: 0.073832... Val Loss: 0.169073\n",
      "Epoch: 17/100... Step: 1705... Loss: 0.089037... Val Loss: 0.034265\n",
      "Epoch: 17/100... Step: 1706... Loss: 0.074706... Val Loss: 0.061793\n",
      "Epoch: 17/100... Step: 1707... Loss: 0.089740... Val Loss: 0.137228\n",
      "Epoch: 17/100... Step: 1708... Loss: 0.137250... Val Loss: 0.199835\n",
      "Epoch: 17/100... Step: 1709... Loss: 0.126382... Val Loss: 0.273935\n",
      "Epoch: 17/100... Step: 1710... Loss: 0.053013... Val Loss: 0.339067\n",
      "Epoch: 17/100... Step: 1711... Loss: 0.103468... Val Loss: 0.384014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Step: 1712... Loss: 0.103355... Val Loss: 0.430717\n",
      "Epoch: 17/100... Step: 1713... Loss: 0.089002... Val Loss: 0.467161\n",
      "Epoch: 17/100... Step: 1714... Loss: 0.060486... Val Loss: 0.490752\n",
      "Epoch: 17/100... Step: 1715... Loss: 0.056364... Val Loss: 0.476739\n",
      "Epoch: 17/100... Step: 1716... Loss: 0.095688... Val Loss: 0.506149\n",
      "Epoch: 17/100... Step: 1717... Loss: 0.095069... Val Loss: 0.524791\n",
      "Epoch: 17/100... Step: 1718... Loss: 0.100725... Val Loss: 0.552516\n",
      "Epoch: 17/100... Step: 1719... Loss: 0.109265... Val Loss: 0.487261\n",
      "Epoch: 17/100... Step: 1720... Loss: 0.072336... Val Loss: 0.462459\n",
      "Epoch: 17/100... Step: 1721... Loss: 0.093049... Val Loss: 0.474343\n",
      "Epoch: 17/100... Step: 1722... Loss: 0.139935... Val Loss: 0.606235\n",
      "Epoch: 17/100... Step: 1723... Loss: 0.117268... Val Loss: 0.597489\n",
      "Epoch: 17/100... Step: 1724... Loss: 0.079318... Val Loss: 0.585488\n",
      "Epoch: 17/100... Step: 1725... Loss: 0.092003... Val Loss: 0.557554\n",
      "Epoch: 17/100... Step: 1726... Loss: 0.139443... Val Loss: 0.528630\n",
      "Epoch: 17/100... Step: 1727... Loss: 0.141421... Val Loss: 0.498057\n",
      "Epoch: 17/100... Step: 1728... Loss: 0.077313... Val Loss: 0.475000\n",
      "Epoch: 17/100... Step: 1729... Loss: 0.085793... Val Loss: 0.430764\n",
      "Epoch: 17/100... Step: 1730... Loss: 0.134739... Val Loss: 0.362366\n",
      "Epoch: 17/100... Step: 1731... Loss: 0.103681... Val Loss: 0.227301\n",
      "Epoch: 17/100... Step: 1732... Loss: 0.103428... Val Loss: 0.116414\n",
      "Epoch: 17/100... Step: 1733... Loss: 0.104596... Val Loss: 0.056412\n",
      "Epoch: 17/100... Step: 1734... Loss: 0.110191... Val Loss: 0.022255\n",
      "Epoch: 17/100... Step: 1735... Loss: 0.091728... Val Loss: 0.015333\n",
      "Epoch: 17/100... Step: 1736... Loss: 0.094713... Val Loss: 0.016736\n",
      "Epoch: 17/100... Step: 1737... Loss: 0.087839... Val Loss: 0.055868\n",
      "Epoch: 17/100... Step: 1738... Loss: 0.099775... Val Loss: 0.080981\n",
      "Epoch: 17/100... Step: 1739... Loss: 0.055332... Val Loss: 0.068736\n",
      "Epoch: 17/100... Step: 1740... Loss: 0.083705... Val Loss: 0.048959\n",
      "Epoch: 17/100... Step: 1741... Loss: 0.082940... Val Loss: 0.019695\n",
      "Epoch: 17/100... Step: 1742... Loss: 0.071308... Val Loss: 0.015999\n",
      "Epoch: 17/100... Step: 1743... Loss: 0.036328... Val Loss: 0.026874\n",
      "Epoch: 17/100... Step: 1744... Loss: 0.085882... Val Loss: 0.061360\n",
      "Epoch: 17/100... Step: 1745... Loss: 0.076227... Val Loss: 0.095128\n",
      "Epoch: 17/100... Step: 1746... Loss: 0.063370... Val Loss: 0.125794\n",
      "Epoch: 17/100... Step: 1747... Loss: 0.081267... Val Loss: 0.163378\n",
      "Epoch: 17/100... Step: 1748... Loss: 0.090636... Val Loss: 0.168627\n",
      "Epoch: 17/100... Step: 1749... Loss: 0.096923... Val Loss: 0.162529\n",
      "Epoch: 17/100... Step: 1750... Loss: 0.085951... Val Loss: 0.167955\n",
      "Epoch: 17/100... Step: 1751... Loss: 0.083652... Val Loss: 0.129959\n",
      "Epoch: 17/100... Step: 1752... Loss: 0.101274... Val Loss: 0.115322\n",
      "Epoch: 17/100... Step: 1753... Loss: 0.085344... Val Loss: 0.113647\n",
      "Epoch: 17/100... Step: 1754... Loss: 0.093459... Val Loss: 0.086627\n",
      "Epoch: 17/100... Step: 1755... Loss: 0.109994... Val Loss: 0.046352\n",
      "Epoch: 17/100... Step: 1756... Loss: 0.060118... Val Loss: 0.017667\n",
      "Epoch: 17/100... Step: 1757... Loss: 0.064289... Val Loss: 0.020878\n",
      "Epoch: 17/100... Step: 1758... Loss: 0.119187... Val Loss: 0.056809\n",
      "Epoch: 17/100... Step: 1759... Loss: 0.102357... Val Loss: 0.072190\n",
      "Epoch: 17/100... Step: 1760... Loss: 0.062034... Val Loss: 0.093217\n",
      "Epoch: 17/100... Step: 1761... Loss: 0.101615... Val Loss: 0.081350\n",
      "Epoch: 17/100... Step: 1762... Loss: 0.107199... Val Loss: 0.021705\n",
      "Epoch: 17/100... Step: 1763... Loss: 0.088000... Val Loss: 0.014529\n",
      "Epoch: 17/100... Step: 1764... Loss: 0.084510... Val Loss: 0.015891\n",
      "Epoch: 17/100... Step: 1765... Loss: 0.067310... Val Loss: 0.014770\n",
      "Epoch: 17/100... Step: 1766... Loss: 0.118885... Val Loss: 0.033103\n",
      "Epoch: 17/100... Step: 1767... Loss: 0.084792... Val Loss: 0.034343\n",
      "Epoch: 17/100... Step: 1768... Loss: 0.163723... Val Loss: 0.050086\n",
      "Epoch: 18/100... Step: 1769... Loss: 0.086239... Val Loss: 0.048021\n",
      "Epoch: 18/100... Step: 1770... Loss: 0.070006... Val Loss: 0.202907\n",
      "Epoch: 18/100... Step: 1771... Loss: 0.104643... Val Loss: 0.465427\n",
      "Epoch: 18/100... Step: 1772... Loss: 0.085137... Val Loss: 0.697316\n",
      "Epoch: 18/100... Step: 1773... Loss: 0.105353... Val Loss: 0.790971\n",
      "Epoch: 18/100... Step: 1774... Loss: 0.076320... Val Loss: 0.800662\n",
      "Epoch: 18/100... Step: 1775... Loss: 0.131361... Val Loss: 0.776226\n",
      "Epoch: 18/100... Step: 1776... Loss: 0.056538... Val Loss: 0.808089\n",
      "Epoch: 18/100... Step: 1777... Loss: 0.076920... Val Loss: 0.803838\n",
      "Epoch: 18/100... Step: 1778... Loss: 0.071427... Val Loss: 0.749848\n",
      "Epoch: 18/100... Step: 1779... Loss: 0.061837... Val Loss: 0.708025\n",
      "Epoch: 18/100... Step: 1780... Loss: 0.088175... Val Loss: 0.647011\n",
      "Epoch: 18/100... Step: 1781... Loss: 0.103229... Val Loss: 0.593964\n",
      "Epoch: 18/100... Step: 1782... Loss: 0.082777... Val Loss: 0.562598\n",
      "Epoch: 18/100... Step: 1783... Loss: 0.065173... Val Loss: 0.535642\n",
      "Epoch: 18/100... Step: 1784... Loss: 0.101843... Val Loss: 0.522314\n",
      "Epoch: 18/100... Step: 1785... Loss: 0.091116... Val Loss: 0.530170\n",
      "Epoch: 18/100... Step: 1786... Loss: 0.087855... Val Loss: 0.524125\n",
      "Epoch: 18/100... Step: 1787... Loss: 0.092542... Val Loss: 0.496972\n",
      "Epoch: 18/100... Step: 1788... Loss: 0.127956... Val Loss: 0.459230\n",
      "Epoch: 18/100... Step: 1789... Loss: 0.093972... Val Loss: 0.409548\n",
      "Epoch: 18/100... Step: 1790... Loss: 0.104730... Val Loss: 0.384135\n",
      "Epoch: 18/100... Step: 1791... Loss: 0.063097... Val Loss: 0.351996\n",
      "Epoch: 18/100... Step: 1792... Loss: 0.074856... Val Loss: 0.262228\n",
      "Epoch: 18/100... Step: 1793... Loss: 0.099393... Val Loss: 0.187995\n",
      "Epoch: 18/100... Step: 1794... Loss: 0.092483... Val Loss: 0.127487\n",
      "Epoch: 18/100... Step: 1795... Loss: 0.088653... Val Loss: 0.046118\n",
      "Epoch: 18/100... Step: 1796... Loss: 0.073603... Val Loss: 0.037004\n",
      "Epoch: 18/100... Step: 1797... Loss: 0.051052... Val Loss: 0.092673\n",
      "Epoch: 18/100... Step: 1798... Loss: 0.066469... Val Loss: 0.144138\n",
      "Epoch: 18/100... Step: 1799... Loss: 0.050650... Val Loss: 0.210472\n",
      "Epoch: 18/100... Step: 1800... Loss: 0.129738... Val Loss: 0.267717\n",
      "Epoch: 18/100... Step: 1801... Loss: 0.072797... Val Loss: 0.300370\n",
      "Epoch: 18/100... Step: 1802... Loss: 0.068877... Val Loss: 0.283001\n",
      "Epoch: 18/100... Step: 1803... Loss: 0.055101... Val Loss: 0.297268\n",
      "Epoch: 18/100... Step: 1804... Loss: 0.050074... Val Loss: 0.285386\n",
      "Epoch: 18/100... Step: 1805... Loss: 0.072185... Val Loss: 0.263848\n",
      "Epoch: 18/100... Step: 1806... Loss: 0.072299... Val Loss: 0.237430\n",
      "Epoch: 18/100... Step: 1807... Loss: 0.109951... Val Loss: 0.199933\n",
      "Epoch: 18/100... Step: 1808... Loss: 0.065500... Val Loss: 0.177539\n",
      "Epoch: 18/100... Step: 1809... Loss: 0.091712... Val Loss: 0.178078\n",
      "Epoch: 18/100... Step: 1810... Loss: 0.059036... Val Loss: 0.194079\n",
      "Epoch: 18/100... Step: 1811... Loss: 0.056641... Val Loss: 0.255033\n",
      "Epoch: 18/100... Step: 1812... Loss: 0.052616... Val Loss: 0.261317\n",
      "Epoch: 18/100... Step: 1813... Loss: 0.054786... Val Loss: 0.272366\n",
      "Epoch: 18/100... Step: 1814... Loss: 0.069312... Val Loss: 0.306459\n",
      "Epoch: 18/100... Step: 1815... Loss: 0.139430... Val Loss: 0.342815\n",
      "Epoch: 18/100... Step: 1816... Loss: 0.068851... Val Loss: 0.354751\n",
      "Epoch: 18/100... Step: 1817... Loss: 0.057764... Val Loss: 0.356633\n",
      "Epoch: 18/100... Step: 1818... Loss: 0.048854... Val Loss: 0.347978\n",
      "Epoch: 18/100... Step: 1819... Loss: 0.105257... Val Loss: 0.340500\n",
      "Epoch: 18/100... Step: 1820... Loss: 0.056898... Val Loss: 0.318275\n",
      "Epoch: 18/100... Step: 1821... Loss: 0.094989... Val Loss: 0.318516\n",
      "Epoch: 18/100... Step: 1822... Loss: 0.082864... Val Loss: 0.310993\n",
      "Epoch: 18/100... Step: 1823... Loss: 0.063483... Val Loss: 0.276621\n",
      "Epoch: 18/100... Step: 1824... Loss: 0.060564... Val Loss: 0.261584\n",
      "Epoch: 18/100... Step: 1825... Loss: 0.074126... Val Loss: 0.255525\n",
      "Epoch: 18/100... Step: 1826... Loss: 0.087791... Val Loss: 0.265694\n",
      "Epoch: 18/100... Step: 1827... Loss: 0.102266... Val Loss: 0.268496\n",
      "Epoch: 18/100... Step: 1828... Loss: 0.081963... Val Loss: 0.277024\n",
      "Epoch: 18/100... Step: 1829... Loss: 0.094076... Val Loss: 0.303407\n",
      "Epoch: 18/100... Step: 1830... Loss: 0.045011... Val Loss: 0.315905\n",
      "Epoch: 18/100... Step: 1831... Loss: 0.096688... Val Loss: 0.306901\n",
      "Epoch: 18/100... Step: 1832... Loss: 0.048288... Val Loss: 0.301505\n",
      "Epoch: 18/100... Step: 1833... Loss: 0.046429... Val Loss: 0.283687\n",
      "Epoch: 18/100... Step: 1834... Loss: 0.054266... Val Loss: 0.232285\n",
      "Epoch: 18/100... Step: 1835... Loss: 0.068244... Val Loss: 0.191619\n",
      "Epoch: 18/100... Step: 1836... Loss: 0.087714... Val Loss: 0.151150\n",
      "Epoch: 18/100... Step: 1837... Loss: 0.055482... Val Loss: 0.099820\n",
      "Epoch: 18/100... Step: 1838... Loss: 0.089768... Val Loss: 0.054843\n",
      "Epoch: 18/100... Step: 1839... Loss: 0.086453... Val Loss: 0.026445\n",
      "Epoch: 18/100... Step: 1840... Loss: 0.045273... Val Loss: 0.020288\n",
      "Epoch: 18/100... Step: 1841... Loss: 0.062193... Val Loss: 0.005086\n",
      "Validation loss decreased (0.006104 --> 0.005086).  Saving model ...\n",
      "Epoch: 18/100... Step: 1842... Loss: 0.057681... Val Loss: 0.009385\n",
      "Epoch: 18/100... Step: 1843... Loss: 0.071575... Val Loss: 0.006600\n",
      "Epoch: 18/100... Step: 1844... Loss: 0.050680... Val Loss: 0.010013\n",
      "Epoch: 18/100... Step: 1845... Loss: 0.086635... Val Loss: 0.017196\n",
      "Epoch: 18/100... Step: 1846... Loss: 0.065662... Val Loss: 0.034927\n",
      "Epoch: 18/100... Step: 1847... Loss: 0.032146... Val Loss: 0.060927\n",
      "Epoch: 18/100... Step: 1848... Loss: 0.073592... Val Loss: 0.079391\n",
      "Epoch: 18/100... Step: 1849... Loss: 0.064746... Val Loss: 0.097132\n",
      "Epoch: 18/100... Step: 1850... Loss: 0.064602... Val Loss: 0.117164\n",
      "Epoch: 18/100... Step: 1851... Loss: 0.082455... Val Loss: 0.113886\n",
      "Epoch: 18/100... Step: 1852... Loss: 0.040820... Val Loss: 0.122767\n",
      "Epoch: 18/100... Step: 1853... Loss: 0.057807... Val Loss: 0.141813\n",
      "Epoch: 18/100... Step: 1854... Loss: 0.091173... Val Loss: 0.134073\n",
      "Epoch: 18/100... Step: 1855... Loss: 0.050852... Val Loss: 0.123946\n",
      "Epoch: 18/100... Step: 1856... Loss: 0.038846... Val Loss: 0.088696\n",
      "Epoch: 18/100... Step: 1857... Loss: 0.073952... Val Loss: 0.044557\n",
      "Epoch: 18/100... Step: 1858... Loss: 0.067624... Val Loss: 0.013907\n",
      "Epoch: 18/100... Step: 1859... Loss: 0.051078... Val Loss: 0.054453\n",
      "Epoch: 18/100... Step: 1860... Loss: 0.064495... Val Loss: 0.097812\n",
      "Epoch: 18/100... Step: 1861... Loss: 0.076699... Val Loss: 0.122728\n",
      "Epoch: 18/100... Step: 1862... Loss: 0.068054... Val Loss: 0.141526\n",
      "Epoch: 18/100... Step: 1863... Loss: 0.045982... Val Loss: 0.158052\n",
      "Epoch: 18/100... Step: 1864... Loss: 0.057023... Val Loss: 0.151320\n",
      "Epoch: 18/100... Step: 1865... Loss: 0.060930... Val Loss: 0.142337\n",
      "Epoch: 18/100... Step: 1866... Loss: 0.064150... Val Loss: 0.125559\n",
      "Epoch: 18/100... Step: 1867... Loss: 0.060164... Val Loss: 0.105652\n",
      "Epoch: 18/100... Step: 1868... Loss: 0.053664... Val Loss: 0.084339\n",
      "Epoch: 18/100... Step: 1869... Loss: 0.070797... Val Loss: 0.058751\n",
      "Epoch: 18/100... Step: 1870... Loss: 0.045788... Val Loss: 0.039327\n",
      "Epoch: 18/100... Step: 1871... Loss: 0.055259... Val Loss: 0.026224\n",
      "Epoch: 18/100... Step: 1872... Loss: 0.061562... Val Loss: 0.028084\n",
      "Epoch: 19/100... Step: 1873... Loss: 0.058223... Val Loss: 0.020444\n",
      "Epoch: 19/100... Step: 1874... Loss: 0.031280... Val Loss: 0.036328\n",
      "Epoch: 19/100... Step: 1875... Loss: 0.041971... Val Loss: 0.056467\n",
      "Epoch: 19/100... Step: 1876... Loss: 0.036585... Val Loss: 0.156775\n",
      "Epoch: 19/100... Step: 1877... Loss: 0.037436... Val Loss: 0.247925\n",
      "Epoch: 19/100... Step: 1878... Loss: 0.051373... Val Loss: 0.324808\n",
      "Epoch: 19/100... Step: 1879... Loss: 0.056628... Val Loss: 0.387273\n",
      "Epoch: 19/100... Step: 1880... Loss: 0.068737... Val Loss: 0.438372\n",
      "Epoch: 19/100... Step: 1881... Loss: 0.033833... Val Loss: 0.488910\n",
      "Epoch: 19/100... Step: 1882... Loss: 0.047960... Val Loss: 0.507432\n",
      "Epoch: 19/100... Step: 1883... Loss: 0.042661... Val Loss: 0.511520\n",
      "Epoch: 19/100... Step: 1884... Loss: 0.052397... Val Loss: 0.552238\n",
      "Epoch: 19/100... Step: 1885... Loss: 0.044061... Val Loss: 0.581413\n",
      "Epoch: 19/100... Step: 1886... Loss: 0.041115... Val Loss: 0.577814\n",
      "Epoch: 19/100... Step: 1887... Loss: 0.060128... Val Loss: 0.559539\n",
      "Epoch: 19/100... Step: 1888... Loss: 0.044653... Val Loss: 0.552377\n",
      "Epoch: 19/100... Step: 1889... Loss: 0.061656... Val Loss: 0.533320\n",
      "Epoch: 19/100... Step: 1890... Loss: 0.048026... Val Loss: 0.527750\n",
      "Epoch: 19/100... Step: 1891... Loss: 0.054132... Val Loss: 0.516123\n",
      "Epoch: 19/100... Step: 1892... Loss: 0.072562... Val Loss: 0.513954\n",
      "Epoch: 19/100... Step: 1893... Loss: 0.047842... Val Loss: 0.522888\n",
      "Epoch: 19/100... Step: 1894... Loss: 0.041018... Val Loss: 0.500914\n",
      "Epoch: 19/100... Step: 1895... Loss: 0.036351... Val Loss: 0.479874\n",
      "Epoch: 19/100... Step: 1896... Loss: 0.054994... Val Loss: 0.445730\n",
      "Epoch: 19/100... Step: 1897... Loss: 0.029065... Val Loss: 0.414315\n",
      "Epoch: 19/100... Step: 1898... Loss: 0.046363... Val Loss: 0.349820\n",
      "Epoch: 19/100... Step: 1899... Loss: 0.031355... Val Loss: 0.298345\n",
      "Epoch: 19/100... Step: 1900... Loss: 0.054122... Val Loss: 0.267340\n",
      "Epoch: 19/100... Step: 1901... Loss: 0.031943... Val Loss: 0.245608\n",
      "Epoch: 19/100... Step: 1902... Loss: 0.056277... Val Loss: 0.218351\n",
      "Epoch: 19/100... Step: 1903... Loss: 0.047807... Val Loss: 0.209112\n",
      "Epoch: 19/100... Step: 1904... Loss: 0.047402... Val Loss: 0.185389\n",
      "Epoch: 19/100... Step: 1905... Loss: 0.069903... Val Loss: 0.135428\n",
      "Epoch: 19/100... Step: 1906... Loss: 0.055462... Val Loss: 0.110277\n",
      "Epoch: 19/100... Step: 1907... Loss: 0.067962... Val Loss: 0.088621\n",
      "Epoch: 19/100... Step: 1908... Loss: 0.052008... Val Loss: 0.060019\n",
      "Epoch: 19/100... Step: 1909... Loss: 0.053951... Val Loss: 0.024595\n",
      "Epoch: 19/100... Step: 1910... Loss: 0.061898... Val Loss: 0.031212\n",
      "Epoch: 19/100... Step: 1911... Loss: 0.042777... Val Loss: 0.044285\n",
      "Epoch: 19/100... Step: 1912... Loss: 0.057586... Val Loss: 0.066889\n",
      "Epoch: 19/100... Step: 1913... Loss: 0.047174... Val Loss: 0.068912\n",
      "Epoch: 19/100... Step: 1914... Loss: 0.055256... Val Loss: 0.083608\n",
      "Epoch: 19/100... Step: 1915... Loss: 0.049985... Val Loss: 0.080760\n",
      "Epoch: 19/100... Step: 1916... Loss: 0.027725... Val Loss: 0.059682\n",
      "Epoch: 19/100... Step: 1917... Loss: 0.048725... Val Loss: 0.030098\n",
      "Epoch: 19/100... Step: 1918... Loss: 0.069652... Val Loss: 0.009368\n",
      "Epoch: 19/100... Step: 1919... Loss: 0.041553... Val Loss: 0.011897\n",
      "Epoch: 19/100... Step: 1920... Loss: 0.047272... Val Loss: 0.014755\n",
      "Epoch: 19/100... Step: 1921... Loss: 0.055506... Val Loss: 0.022014\n",
      "Epoch: 19/100... Step: 1922... Loss: 0.053180... Val Loss: 0.028471\n",
      "Epoch: 19/100... Step: 1923... Loss: 0.064089... Val Loss: 0.036028\n",
      "Epoch: 19/100... Step: 1924... Loss: 0.046651... Val Loss: 0.045774\n",
      "Epoch: 19/100... Step: 1925... Loss: 0.057226... Val Loss: 0.048971\n",
      "Epoch: 19/100... Step: 1926... Loss: 0.046234... Val Loss: 0.041613\n",
      "Epoch: 19/100... Step: 1927... Loss: 0.055961... Val Loss: 0.015396\n",
      "Epoch: 19/100... Step: 1928... Loss: 0.046623... Val Loss: 0.026883\n",
      "Epoch: 19/100... Step: 1929... Loss: 0.049294... Val Loss: 0.078248\n",
      "Epoch: 19/100... Step: 1930... Loss: 0.081586... Val Loss: 0.103909\n",
      "Epoch: 19/100... Step: 1931... Loss: 0.046433... Val Loss: 0.103283\n",
      "Epoch: 19/100... Step: 1932... Loss: 0.060440... Val Loss: 0.119261\n",
      "Epoch: 19/100... Step: 1933... Loss: 0.063811... Val Loss: 0.141601\n",
      "Epoch: 19/100... Step: 1934... Loss: 0.046786... Val Loss: 0.153938\n",
      "Epoch: 19/100... Step: 1935... Loss: 0.055581... Val Loss: 0.147948\n",
      "Epoch: 19/100... Step: 1936... Loss: 0.069442... Val Loss: 0.144974\n",
      "Epoch: 19/100... Step: 1937... Loss: 0.039722... Val Loss: 0.144216\n",
      "Epoch: 19/100... Step: 1938... Loss: 0.045782... Val Loss: 0.147116\n",
      "Epoch: 19/100... Step: 1939... Loss: 0.034329... Val Loss: 0.152551\n",
      "Epoch: 19/100... Step: 1940... Loss: 0.037028... Val Loss: 0.161358\n",
      "Epoch: 19/100... Step: 1941... Loss: 0.038797... Val Loss: 0.157076\n",
      "Epoch: 19/100... Step: 1942... Loss: 0.031738... Val Loss: 0.158565\n",
      "Epoch: 19/100... Step: 1943... Loss: 0.050305... Val Loss: 0.169655\n",
      "Epoch: 19/100... Step: 1944... Loss: 0.059837... Val Loss: 0.172463\n",
      "Epoch: 19/100... Step: 1945... Loss: 0.062746... Val Loss: 0.164851\n",
      "Epoch: 19/100... Step: 1946... Loss: 0.041331... Val Loss: 0.156324\n",
      "Epoch: 19/100... Step: 1947... Loss: 0.025995... Val Loss: 0.136140\n",
      "Epoch: 19/100... Step: 1948... Loss: 0.034197... Val Loss: 0.135529\n",
      "Epoch: 19/100... Step: 1949... Loss: 0.031054... Val Loss: 0.129892\n",
      "Epoch: 19/100... Step: 1950... Loss: 0.041316... Val Loss: 0.109848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Step: 1951... Loss: 0.046399... Val Loss: 0.098203\n",
      "Epoch: 19/100... Step: 1952... Loss: 0.056931... Val Loss: 0.090041\n",
      "Epoch: 19/100... Step: 1953... Loss: 0.048010... Val Loss: 0.071030\n",
      "Epoch: 19/100... Step: 1954... Loss: 0.035230... Val Loss: 0.048172\n",
      "Epoch: 19/100... Step: 1955... Loss: 0.035635... Val Loss: 0.026444\n",
      "Epoch: 19/100... Step: 1956... Loss: 0.039015... Val Loss: 0.008800\n",
      "Epoch: 19/100... Step: 1957... Loss: 0.031923... Val Loss: 0.017138\n",
      "Epoch: 19/100... Step: 1958... Loss: 0.028414... Val Loss: 0.040271\n",
      "Epoch: 19/100... Step: 1959... Loss: 0.030517... Val Loss: 0.044680\n",
      "Epoch: 19/100... Step: 1960... Loss: 0.038041... Val Loss: 0.047291\n",
      "Epoch: 19/100... Step: 1961... Loss: 0.035365... Val Loss: 0.054376\n",
      "Epoch: 19/100... Step: 1962... Loss: 0.041388... Val Loss: 0.060909\n",
      "Epoch: 19/100... Step: 1963... Loss: 0.053030... Val Loss: 0.069099\n",
      "Epoch: 19/100... Step: 1964... Loss: 0.045759... Val Loss: 0.053895\n",
      "Epoch: 19/100... Step: 1965... Loss: 0.043691... Val Loss: 0.044861\n",
      "Epoch: 19/100... Step: 1966... Loss: 0.046210... Val Loss: 0.039362\n",
      "Epoch: 19/100... Step: 1967... Loss: 0.048507... Val Loss: 0.047196\n",
      "Epoch: 19/100... Step: 1968... Loss: 0.040336... Val Loss: 0.047894\n",
      "Epoch: 19/100... Step: 1969... Loss: 0.050885... Val Loss: 0.054290\n",
      "Epoch: 19/100... Step: 1970... Loss: 0.036709... Val Loss: 0.053048\n",
      "Epoch: 19/100... Step: 1971... Loss: 0.043906... Val Loss: 0.056410\n",
      "Epoch: 19/100... Step: 1972... Loss: 0.034965... Val Loss: 0.047000\n",
      "Epoch: 19/100... Step: 1973... Loss: 0.048073... Val Loss: 0.016386\n",
      "Epoch: 19/100... Step: 1974... Loss: 0.048875... Val Loss: 0.021276\n",
      "Epoch: 19/100... Step: 1975... Loss: 0.030606... Val Loss: 0.028757\n",
      "Epoch: 19/100... Step: 1976... Loss: 0.047578... Val Loss: 0.044271\n",
      "Epoch: 20/100... Step: 1977... Loss: 0.046525... Val Loss: 0.072298\n",
      "Epoch: 20/100... Step: 1978... Loss: 0.035731... Val Loss: 0.158835\n",
      "Epoch: 20/100... Step: 1979... Loss: 0.039323... Val Loss: 0.249112\n",
      "Epoch: 20/100... Step: 1980... Loss: 0.054788... Val Loss: 0.243532\n",
      "Epoch: 20/100... Step: 1981... Loss: 0.042742... Val Loss: 0.210871\n",
      "Epoch: 20/100... Step: 1982... Loss: 0.036182... Val Loss: 0.199588\n",
      "Epoch: 20/100... Step: 1983... Loss: 0.044293... Val Loss: 0.199949\n",
      "Epoch: 20/100... Step: 1984... Loss: 0.046197... Val Loss: 0.230616\n",
      "Epoch: 20/100... Step: 1985... Loss: 0.053540... Val Loss: 0.245140\n",
      "Epoch: 20/100... Step: 1986... Loss: 0.052588... Val Loss: 0.258945\n",
      "Epoch: 20/100... Step: 1987... Loss: 0.037976... Val Loss: 0.270389\n",
      "Epoch: 20/100... Step: 1988... Loss: 0.036980... Val Loss: 0.267186\n",
      "Epoch: 20/100... Step: 1989... Loss: 0.052332... Val Loss: 0.251435\n",
      "Epoch: 20/100... Step: 1990... Loss: 0.050551... Val Loss: 0.228186\n",
      "Epoch: 20/100... Step: 1991... Loss: 0.031872... Val Loss: 0.209625\n",
      "Epoch: 20/100... Step: 1992... Loss: 0.030457... Val Loss: 0.191383\n",
      "Epoch: 20/100... Step: 1993... Loss: 0.036872... Val Loss: 0.157917\n",
      "Epoch: 20/100... Step: 1994... Loss: 0.049991... Val Loss: 0.132920\n",
      "Epoch: 20/100... Step: 1995... Loss: 0.029825... Val Loss: 0.128919\n",
      "Epoch: 20/100... Step: 1996... Loss: 0.035290... Val Loss: 0.119689\n",
      "Epoch: 20/100... Step: 1997... Loss: 0.042833... Val Loss: 0.109884\n",
      "Epoch: 20/100... Step: 1998... Loss: 0.050103... Val Loss: 0.102194\n",
      "Epoch: 20/100... Step: 1999... Loss: 0.057571... Val Loss: 0.072989\n",
      "Epoch: 20/100... Step: 2000... Loss: 0.031246... Val Loss: 0.041617\n",
      "Epoch: 20/100... Step: 2001... Loss: 0.036260... Val Loss: 0.016568\n",
      "Epoch: 20/100... Step: 2002... Loss: 0.049791... Val Loss: 0.014424\n",
      "Epoch: 20/100... Step: 2003... Loss: 0.032328... Val Loss: 0.021411\n",
      "Epoch: 20/100... Step: 2004... Loss: 0.042513... Val Loss: 0.016877\n",
      "Epoch: 20/100... Step: 2005... Loss: 0.042706... Val Loss: 0.005329\n",
      "Epoch: 20/100... Step: 2006... Loss: 0.034799... Val Loss: 0.009056\n",
      "Epoch: 20/100... Step: 2007... Loss: 0.031409... Val Loss: 0.014351\n",
      "Epoch: 20/100... Step: 2008... Loss: 0.035235... Val Loss: 0.019307\n",
      "Epoch: 20/100... Step: 2009... Loss: 0.025547... Val Loss: 0.037468\n",
      "Epoch: 20/100... Step: 2010... Loss: 0.024494... Val Loss: 0.030608\n",
      "Epoch: 20/100... Step: 2011... Loss: 0.057555... Val Loss: 0.023971\n",
      "Epoch: 20/100... Step: 2012... Loss: 0.028191... Val Loss: 0.014133\n",
      "Epoch: 20/100... Step: 2013... Loss: 0.037331... Val Loss: 0.012780\n",
      "Epoch: 20/100... Step: 2014... Loss: 0.027295... Val Loss: 0.007285\n",
      "Epoch: 20/100... Step: 2015... Loss: 0.019514... Val Loss: 0.014404\n",
      "Epoch: 20/100... Step: 2016... Loss: 0.048823... Val Loss: 0.047079\n",
      "Epoch: 20/100... Step: 2017... Loss: 0.036367... Val Loss: 0.061215\n",
      "Epoch: 20/100... Step: 2018... Loss: 0.044912... Val Loss: 0.076945\n",
      "Epoch: 20/100... Step: 2019... Loss: 0.043187... Val Loss: 0.076502\n",
      "Epoch: 20/100... Step: 2020... Loss: 0.033888... Val Loss: 0.078574\n",
      "Epoch: 20/100... Step: 2021... Loss: 0.038530... Val Loss: 0.105167\n",
      "Epoch: 20/100... Step: 2022... Loss: 0.041938... Val Loss: 0.118407\n",
      "Epoch: 20/100... Step: 2023... Loss: 0.036641... Val Loss: 0.128642\n",
      "Epoch: 20/100... Step: 2024... Loss: 0.030465... Val Loss: 0.134435\n",
      "Epoch: 20/100... Step: 2025... Loss: 0.045292... Val Loss: 0.122116\n",
      "Epoch: 20/100... Step: 2026... Loss: 0.049169... Val Loss: 0.100083\n",
      "Epoch: 20/100... Step: 2027... Loss: 0.032163... Val Loss: 0.065889\n",
      "Epoch: 20/100... Step: 2028... Loss: 0.041264... Val Loss: 0.019056\n",
      "Epoch: 20/100... Step: 2029... Loss: 0.051655... Val Loss: 0.027057\n",
      "Epoch: 20/100... Step: 2030... Loss: 0.020098... Val Loss: 0.060469\n",
      "Epoch: 20/100... Step: 2031... Loss: 0.024311... Val Loss: 0.073167\n",
      "Epoch: 20/100... Step: 2032... Loss: 0.040215... Val Loss: 0.085897\n",
      "Epoch: 20/100... Step: 2033... Loss: 0.030037... Val Loss: 0.090959\n",
      "Epoch: 20/100... Step: 2034... Loss: 0.028102... Val Loss: 0.098359\n",
      "Epoch: 20/100... Step: 2035... Loss: 0.032930... Val Loss: 0.115585\n",
      "Epoch: 20/100... Step: 2036... Loss: 0.036601... Val Loss: 0.135807\n",
      "Epoch: 20/100... Step: 2037... Loss: 0.038610... Val Loss: 0.165163\n",
      "Epoch: 20/100... Step: 2038... Loss: 0.043817... Val Loss: 0.178292\n",
      "Epoch: 20/100... Step: 2039... Loss: 0.039758... Val Loss: 0.182397\n",
      "Epoch: 20/100... Step: 2040... Loss: 0.047919... Val Loss: 0.173232\n",
      "Epoch: 20/100... Step: 2041... Loss: 0.044611... Val Loss: 0.174802\n",
      "Epoch: 20/100... Step: 2042... Loss: 0.022903... Val Loss: 0.173414\n",
      "Epoch: 20/100... Step: 2043... Loss: 0.047860... Val Loss: 0.175464\n",
      "Epoch: 20/100... Step: 2044... Loss: 0.029331... Val Loss: 0.173856\n",
      "Epoch: 20/100... Step: 2045... Loss: 0.041620... Val Loss: 0.162340\n",
      "Epoch: 20/100... Step: 2046... Loss: 0.026674... Val Loss: 0.137812\n",
      "Epoch: 20/100... Step: 2047... Loss: 0.024580... Val Loss: 0.155282\n",
      "Epoch: 20/100... Step: 2048... Loss: 0.026917... Val Loss: 0.150477\n",
      "Epoch: 20/100... Step: 2049... Loss: 0.027271... Val Loss: 0.134664\n",
      "Epoch: 20/100... Step: 2050... Loss: 0.040200... Val Loss: 0.097496\n",
      "Epoch: 20/100... Step: 2051... Loss: 0.030735... Val Loss: 0.075459\n",
      "Epoch: 20/100... Step: 2052... Loss: 0.039324... Val Loss: 0.054971\n",
      "Epoch: 20/100... Step: 2053... Loss: 0.031715... Val Loss: 0.032442\n",
      "Epoch: 20/100... Step: 2054... Loss: 0.023225... Val Loss: 0.014764\n",
      "Epoch: 20/100... Step: 2055... Loss: 0.028564... Val Loss: 0.004043\n",
      "Validation loss decreased (0.005086 --> 0.004043).  Saving model ...\n",
      "Epoch: 20/100... Step: 2056... Loss: 0.041369... Val Loss: 0.003695\n",
      "Validation loss decreased (0.004043 --> 0.003695).  Saving model ...\n",
      "Epoch: 20/100... Step: 2057... Loss: 0.034779... Val Loss: 0.003664\n",
      "Validation loss decreased (0.003695 --> 0.003664).  Saving model ...\n",
      "Epoch: 20/100... Step: 2058... Loss: 0.027970... Val Loss: 0.008668\n",
      "Epoch: 20/100... Step: 2059... Loss: 0.037981... Val Loss: 0.018150\n",
      "Epoch: 20/100... Step: 2060... Loss: 0.035562... Val Loss: 0.021672\n",
      "Epoch: 20/100... Step: 2061... Loss: 0.035893... Val Loss: 0.024253\n",
      "Epoch: 20/100... Step: 2062... Loss: 0.036351... Val Loss: 0.023911\n",
      "Epoch: 20/100... Step: 2063... Loss: 0.050783... Val Loss: 0.027135\n",
      "Epoch: 20/100... Step: 2064... Loss: 0.037101... Val Loss: 0.038332\n",
      "Epoch: 20/100... Step: 2065... Loss: 0.042077... Val Loss: 0.047910\n",
      "Epoch: 20/100... Step: 2066... Loss: 0.034093... Val Loss: 0.059779\n",
      "Epoch: 20/100... Step: 2067... Loss: 0.041490... Val Loss: 0.064224\n",
      "Epoch: 20/100... Step: 2068... Loss: 0.043317... Val Loss: 0.058136\n",
      "Epoch: 20/100... Step: 2069... Loss: 0.043179... Val Loss: 0.059421\n",
      "Epoch: 20/100... Step: 2070... Loss: 0.040015... Val Loss: 0.064187\n",
      "Epoch: 20/100... Step: 2071... Loss: 0.042092... Val Loss: 0.070202\n",
      "Epoch: 20/100... Step: 2072... Loss: 0.041071... Val Loss: 0.077855\n",
      "Epoch: 20/100... Step: 2073... Loss: 0.025674... Val Loss: 0.094642\n",
      "Epoch: 20/100... Step: 2074... Loss: 0.030762... Val Loss: 0.096013\n",
      "Epoch: 20/100... Step: 2075... Loss: 0.037688... Val Loss: 0.088922\n",
      "Epoch: 20/100... Step: 2076... Loss: 0.043442... Val Loss: 0.073663\n",
      "Epoch: 20/100... Step: 2077... Loss: 0.034106... Val Loss: 0.058360\n",
      "Epoch: 20/100... Step: 2078... Loss: 0.025702... Val Loss: 0.045968\n",
      "Epoch: 20/100... Step: 2079... Loss: 0.044143... Val Loss: 0.035669\n",
      "Epoch: 20/100... Step: 2080... Loss: 0.029124... Val Loss: 0.032258\n",
      "Epoch: 21/100... Step: 2081... Loss: 0.028259... Val Loss: 0.021018\n",
      "Epoch: 21/100... Step: 2082... Loss: 0.032424... Val Loss: 0.073632\n",
      "Epoch: 21/100... Step: 2083... Loss: 0.019781... Val Loss: 0.169481\n",
      "Epoch: 21/100... Step: 2084... Loss: 0.033913... Val Loss: 0.182992\n",
      "Epoch: 21/100... Step: 2085... Loss: 0.032525... Val Loss: 0.167416\n",
      "Epoch: 21/100... Step: 2086... Loss: 0.027876... Val Loss: 0.154919\n",
      "Epoch: 21/100... Step: 2087... Loss: 0.046918... Val Loss: 0.134797\n",
      "Epoch: 21/100... Step: 2088... Loss: 0.021952... Val Loss: 0.122097\n",
      "Epoch: 21/100... Step: 2089... Loss: 0.030600... Val Loss: 0.077101\n",
      "Epoch: 21/100... Step: 2090... Loss: 0.021716... Val Loss: 0.052421\n",
      "Epoch: 21/100... Step: 2091... Loss: 0.028465... Val Loss: 0.038161\n",
      "Epoch: 21/100... Step: 2092... Loss: 0.036470... Val Loss: 0.033549\n",
      "Epoch: 21/100... Step: 2093... Loss: 0.037791... Val Loss: 0.036127\n",
      "Epoch: 21/100... Step: 2094... Loss: 0.024287... Val Loss: 0.033768\n",
      "Epoch: 21/100... Step: 2095... Loss: 0.037186... Val Loss: 0.040894\n",
      "Epoch: 21/100... Step: 2096... Loss: 0.037684... Val Loss: 0.029459\n",
      "Epoch: 21/100... Step: 2097... Loss: 0.026444... Val Loss: 0.028820\n",
      "Epoch: 21/100... Step: 2098... Loss: 0.025303... Val Loss: 0.041063\n",
      "Epoch: 21/100... Step: 2099... Loss: 0.039367... Val Loss: 0.066377\n",
      "Epoch: 21/100... Step: 2100... Loss: 0.030945... Val Loss: 0.073706\n",
      "Epoch: 21/100... Step: 2101... Loss: 0.025297... Val Loss: 0.079787\n",
      "Epoch: 21/100... Step: 2102... Loss: 0.019666... Val Loss: 0.089729\n",
      "Epoch: 21/100... Step: 2103... Loss: 0.033151... Val Loss: 0.110009\n",
      "Epoch: 21/100... Step: 2104... Loss: 0.038552... Val Loss: 0.139573\n",
      "Epoch: 21/100... Step: 2105... Loss: 0.023677... Val Loss: 0.181800\n",
      "Epoch: 21/100... Step: 2106... Loss: 0.029585... Val Loss: 0.169505\n",
      "Epoch: 21/100... Step: 2107... Loss: 0.036542... Val Loss: 0.113555\n",
      "Epoch: 21/100... Step: 2108... Loss: 0.037002... Val Loss: 0.106729\n",
      "Epoch: 21/100... Step: 2109... Loss: 0.047997... Val Loss: 0.089457\n",
      "Epoch: 21/100... Step: 2110... Loss: 0.035322... Val Loss: 0.075244\n",
      "Epoch: 21/100... Step: 2111... Loss: 0.027005... Val Loss: 0.057226\n",
      "Epoch: 21/100... Step: 2112... Loss: 0.035849... Val Loss: 0.049683\n",
      "Epoch: 21/100... Step: 2113... Loss: 0.032377... Val Loss: 0.051614\n",
      "Epoch: 21/100... Step: 2114... Loss: 0.038362... Val Loss: 0.067217\n",
      "Epoch: 21/100... Step: 2115... Loss: 0.043044... Val Loss: 0.088813\n",
      "Epoch: 21/100... Step: 2116... Loss: 0.030638... Val Loss: 0.116625\n",
      "Epoch: 21/100... Step: 2117... Loss: 0.030620... Val Loss: 0.131802\n",
      "Epoch: 21/100... Step: 2118... Loss: 0.048091... Val Loss: 0.125227\n",
      "Epoch: 21/100... Step: 2119... Loss: 0.027438... Val Loss: 0.122300\n",
      "Epoch: 21/100... Step: 2120... Loss: 0.047595... Val Loss: 0.110540\n",
      "Epoch: 21/100... Step: 2121... Loss: 0.021437... Val Loss: 0.085724\n",
      "Epoch: 21/100... Step: 2122... Loss: 0.035503... Val Loss: 0.067138\n",
      "Epoch: 21/100... Step: 2123... Loss: 0.030501... Val Loss: 0.064275\n",
      "Epoch: 21/100... Step: 2124... Loss: 0.035289... Val Loss: 0.059688\n",
      "Epoch: 21/100... Step: 2125... Loss: 0.034805... Val Loss: 0.047658\n",
      "Epoch: 21/100... Step: 2126... Loss: 0.025491... Val Loss: 0.045671\n",
      "Epoch: 21/100... Step: 2127... Loss: 0.028410... Val Loss: 0.026668\n",
      "Epoch: 21/100... Step: 2128... Loss: 0.043236... Val Loss: 0.004255\n",
      "Epoch: 21/100... Step: 2129... Loss: 0.025324... Val Loss: 0.016110\n",
      "Epoch: 21/100... Step: 2130... Loss: 0.047289... Val Loss: 0.040751\n",
      "Epoch: 21/100... Step: 2131... Loss: 0.025069... Val Loss: 0.052591\n",
      "Epoch: 21/100... Step: 2132... Loss: 0.041798... Val Loss: 0.057455\n",
      "Epoch: 21/100... Step: 2133... Loss: 0.032859... Val Loss: 0.045905\n",
      "Epoch: 21/100... Step: 2134... Loss: 0.024591... Val Loss: 0.053569\n",
      "Epoch: 21/100... Step: 2135... Loss: 0.029978... Val Loss: 0.052950\n",
      "Epoch: 21/100... Step: 2136... Loss: 0.033325... Val Loss: 0.054445\n",
      "Epoch: 21/100... Step: 2137... Loss: 0.033436... Val Loss: 0.065151\n",
      "Epoch: 21/100... Step: 2138... Loss: 0.026154... Val Loss: 0.074901\n",
      "Epoch: 21/100... Step: 2139... Loss: 0.032870... Val Loss: 0.085880\n",
      "Epoch: 21/100... Step: 2140... Loss: 0.025494... Val Loss: 0.087353\n",
      "Epoch: 21/100... Step: 2141... Loss: 0.028679... Val Loss: 0.083574\n",
      "Epoch: 21/100... Step: 2142... Loss: 0.032912... Val Loss: 0.065434\n",
      "Epoch: 21/100... Step: 2143... Loss: 0.030216... Val Loss: 0.058483\n",
      "Epoch: 21/100... Step: 2144... Loss: 0.042826... Val Loss: 0.066049\n",
      "Epoch: 21/100... Step: 2145... Loss: 0.027396... Val Loss: 0.066388\n",
      "Epoch: 21/100... Step: 2146... Loss: 0.033564... Val Loss: 0.066678\n",
      "Epoch: 21/100... Step: 2147... Loss: 0.035940... Val Loss: 0.070303\n",
      "Epoch: 21/100... Step: 2148... Loss: 0.042276... Val Loss: 0.067048\n",
      "Epoch: 21/100... Step: 2149... Loss: 0.036746... Val Loss: 0.066983\n",
      "Epoch: 21/100... Step: 2150... Loss: 0.041557... Val Loss: 0.053348\n",
      "Epoch: 21/100... Step: 2151... Loss: 0.024752... Val Loss: 0.043241\n",
      "Epoch: 21/100... Step: 2152... Loss: 0.029919... Val Loss: 0.037734\n",
      "Epoch: 21/100... Step: 2153... Loss: 0.020949... Val Loss: 0.022757\n",
      "Epoch: 21/100... Step: 2154... Loss: 0.036892... Val Loss: 0.016308\n",
      "Epoch: 21/100... Step: 2155... Loss: 0.037861... Val Loss: 0.013702\n",
      "Epoch: 21/100... Step: 2156... Loss: 0.032642... Val Loss: 0.012711\n",
      "Epoch: 21/100... Step: 2157... Loss: 0.028723... Val Loss: 0.013294\n",
      "Epoch: 21/100... Step: 2158... Loss: 0.029262... Val Loss: 0.017926\n",
      "Epoch: 21/100... Step: 2159... Loss: 0.032961... Val Loss: 0.031275\n",
      "Epoch: 21/100... Step: 2160... Loss: 0.020929... Val Loss: 0.043026\n",
      "Epoch: 21/100... Step: 2161... Loss: 0.031806... Val Loss: 0.057608\n",
      "Epoch: 21/100... Step: 2162... Loss: 0.055162... Val Loss: 0.075039\n",
      "Epoch: 21/100... Step: 2163... Loss: 0.036921... Val Loss: 0.081897\n",
      "Epoch: 21/100... Step: 2164... Loss: 0.027317... Val Loss: 0.092035\n",
      "Epoch: 21/100... Step: 2165... Loss: 0.028487... Val Loss: 0.098780\n",
      "Epoch: 21/100... Step: 2166... Loss: 0.028560... Val Loss: 0.107082\n",
      "Epoch: 21/100... Step: 2167... Loss: 0.023393... Val Loss: 0.114643\n",
      "Epoch: 21/100... Step: 2168... Loss: 0.027500... Val Loss: 0.129443\n",
      "Epoch: 21/100... Step: 2169... Loss: 0.026035... Val Loss: 0.134636\n",
      "Epoch: 21/100... Step: 2170... Loss: 0.035303... Val Loss: 0.148711\n",
      "Epoch: 21/100... Step: 2171... Loss: 0.043240... Val Loss: 0.169522\n",
      "Epoch: 21/100... Step: 2172... Loss: 0.036083... Val Loss: 0.175618\n",
      "Epoch: 21/100... Step: 2173... Loss: 0.020746... Val Loss: 0.177175\n",
      "Epoch: 21/100... Step: 2174... Loss: 0.028972... Val Loss: 0.188722\n",
      "Epoch: 21/100... Step: 2175... Loss: 0.034746... Val Loss: 0.186417\n",
      "Epoch: 21/100... Step: 2176... Loss: 0.035979... Val Loss: 0.164534\n",
      "Epoch: 21/100... Step: 2177... Loss: 0.041199... Val Loss: 0.151907\n",
      "Epoch: 21/100... Step: 2178... Loss: 0.029748... Val Loss: 0.148805\n",
      "Epoch: 21/100... Step: 2179... Loss: 0.029941... Val Loss: 0.143262\n",
      "Epoch: 21/100... Step: 2180... Loss: 0.032447... Val Loss: 0.146372\n",
      "Epoch: 21/100... Step: 2181... Loss: 0.031062... Val Loss: 0.154550\n",
      "Epoch: 21/100... Step: 2182... Loss: 0.025176... Val Loss: 0.139298\n",
      "Epoch: 21/100... Step: 2183... Loss: 0.047753... Val Loss: 0.125266\n",
      "Epoch: 21/100... Step: 2184... Loss: 0.046007... Val Loss: 0.121367\n",
      "Epoch: 22/100... Step: 2185... Loss: 0.019233... Val Loss: 0.038610\n",
      "Epoch: 22/100... Step: 2186... Loss: 0.032056... Val Loss: 0.064365\n",
      "Epoch: 22/100... Step: 2187... Loss: 0.020429... Val Loss: 0.085723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Step: 2188... Loss: 0.025776... Val Loss: 0.072789\n",
      "Epoch: 22/100... Step: 2189... Loss: 0.039128... Val Loss: 0.043510\n",
      "Epoch: 22/100... Step: 2190... Loss: 0.020394... Val Loss: 0.006100\n",
      "Epoch: 22/100... Step: 2191... Loss: 0.025895... Val Loss: 0.035346\n",
      "Epoch: 22/100... Step: 2192... Loss: 0.020306... Val Loss: 0.061014\n",
      "Epoch: 22/100... Step: 2193... Loss: 0.036746... Val Loss: 0.072757\n",
      "Epoch: 22/100... Step: 2194... Loss: 0.016939... Val Loss: 0.083446\n",
      "Epoch: 22/100... Step: 2195... Loss: 0.021632... Val Loss: 0.076284\n",
      "Epoch: 22/100... Step: 2196... Loss: 0.025003... Val Loss: 0.083367\n",
      "Epoch: 22/100... Step: 2197... Loss: 0.021359... Val Loss: 0.084251\n",
      "Epoch: 22/100... Step: 2198... Loss: 0.032003... Val Loss: 0.078735\n",
      "Epoch: 22/100... Step: 2199... Loss: 0.025636... Val Loss: 0.076231\n",
      "Epoch: 22/100... Step: 2200... Loss: 0.019619... Val Loss: 0.080070\n",
      "Epoch: 22/100... Step: 2201... Loss: 0.034082... Val Loss: 0.132434\n",
      "Epoch: 22/100... Step: 2202... Loss: 0.040583... Val Loss: 0.134949\n",
      "Epoch: 22/100... Step: 2203... Loss: 0.026588... Val Loss: 0.133551\n",
      "Epoch: 22/100... Step: 2204... Loss: 0.043070... Val Loss: 0.133188\n",
      "Epoch: 22/100... Step: 2205... Loss: 0.023560... Val Loss: 0.158898\n",
      "Epoch: 22/100... Step: 2206... Loss: 0.031523... Val Loss: 0.162852\n",
      "Epoch: 22/100... Step: 2207... Loss: 0.024294... Val Loss: 0.144343\n",
      "Epoch: 22/100... Step: 2208... Loss: 0.029108... Val Loss: 0.137074\n",
      "Epoch: 22/100... Step: 2209... Loss: 0.031183... Val Loss: 0.137072\n",
      "Epoch: 22/100... Step: 2210... Loss: 0.025753... Val Loss: 0.133179\n",
      "Epoch: 22/100... Step: 2211... Loss: 0.034945... Val Loss: 0.125137\n",
      "Epoch: 22/100... Step: 2212... Loss: 0.019845... Val Loss: 0.120256\n",
      "Epoch: 22/100... Step: 2213... Loss: 0.025684... Val Loss: 0.127373\n",
      "Epoch: 22/100... Step: 2214... Loss: 0.026878... Val Loss: 0.137759\n",
      "Epoch: 22/100... Step: 2215... Loss: 0.028075... Val Loss: 0.148437\n",
      "Epoch: 22/100... Step: 2216... Loss: 0.026297... Val Loss: 0.152711\n",
      "Epoch: 22/100... Step: 2217... Loss: 0.042496... Val Loss: 0.135685\n",
      "Epoch: 22/100... Step: 2218... Loss: 0.026220... Val Loss: 0.119625\n",
      "Epoch: 22/100... Step: 2219... Loss: 0.045707... Val Loss: 0.103595\n",
      "Epoch: 22/100... Step: 2220... Loss: 0.036583... Val Loss: 0.097904\n",
      "Epoch: 22/100... Step: 2221... Loss: 0.032919... Val Loss: 0.093198\n",
      "Epoch: 22/100... Step: 2222... Loss: 0.045568... Val Loss: 0.082287\n",
      "Epoch: 22/100... Step: 2223... Loss: 0.029901... Val Loss: 0.069514\n",
      "Epoch: 22/100... Step: 2224... Loss: 0.023791... Val Loss: 0.062505\n",
      "Epoch: 22/100... Step: 2225... Loss: 0.040170... Val Loss: 0.052308\n",
      "Epoch: 22/100... Step: 2226... Loss: 0.034326... Val Loss: 0.025634\n",
      "Epoch: 22/100... Step: 2227... Loss: 0.033961... Val Loss: 0.004350\n",
      "Epoch: 22/100... Step: 2228... Loss: 0.024649... Val Loss: 0.022283\n",
      "Epoch: 22/100... Step: 2229... Loss: 0.051147... Val Loss: 0.034460\n",
      "Epoch: 22/100... Step: 2230... Loss: 0.027307... Val Loss: 0.052487\n",
      "Epoch: 22/100... Step: 2231... Loss: 0.049608... Val Loss: 0.066573\n",
      "Epoch: 22/100... Step: 2232... Loss: 0.042603... Val Loss: 0.072948\n",
      "Epoch: 22/100... Step: 2233... Loss: 0.021039... Val Loss: 0.077225\n",
      "Epoch: 22/100... Step: 2234... Loss: 0.033558... Val Loss: 0.077383\n",
      "Epoch: 22/100... Step: 2235... Loss: 0.035192... Val Loss: 0.059483\n",
      "Epoch: 22/100... Step: 2236... Loss: 0.020084... Val Loss: 0.048904\n",
      "Epoch: 22/100... Step: 2237... Loss: 0.029621... Val Loss: 0.035646\n",
      "Epoch: 22/100... Step: 2238... Loss: 0.019603... Val Loss: 0.028262\n",
      "Epoch: 22/100... Step: 2239... Loss: 0.028714... Val Loss: 0.020644\n",
      "Epoch: 22/100... Step: 2240... Loss: 0.026316... Val Loss: 0.005385\n",
      "Epoch: 22/100... Step: 2241... Loss: 0.021252... Val Loss: 0.016636\n",
      "Epoch: 22/100... Step: 2242... Loss: 0.034825... Val Loss: 0.024426\n",
      "Epoch: 22/100... Step: 2243... Loss: 0.029801... Val Loss: 0.022977\n",
      "Epoch: 22/100... Step: 2244... Loss: 0.021999... Val Loss: 0.019414\n",
      "Epoch: 22/100... Step: 2245... Loss: 0.033207... Val Loss: 0.009769\n",
      "Epoch: 22/100... Step: 2246... Loss: 0.033504... Val Loss: 0.006585\n",
      "Epoch: 22/100... Step: 2247... Loss: 0.036800... Val Loss: 0.014715\n",
      "Epoch: 22/100... Step: 2248... Loss: 0.024666... Val Loss: 0.012975\n",
      "Epoch: 22/100... Step: 2249... Loss: 0.031803... Val Loss: 0.007450\n",
      "Epoch: 22/100... Step: 2250... Loss: 0.019801... Val Loss: 0.014855\n",
      "Epoch: 22/100... Step: 2251... Loss: 0.015287... Val Loss: 0.021051\n",
      "Epoch: 22/100... Step: 2252... Loss: 0.030568... Val Loss: 0.017010\n",
      "Epoch: 22/100... Step: 2253... Loss: 0.035216... Val Loss: 0.025824\n",
      "Epoch: 22/100... Step: 2254... Loss: 0.029629... Val Loss: 0.025039\n",
      "Epoch: 22/100... Step: 2255... Loss: 0.028436... Val Loss: 0.036005\n",
      "Epoch: 22/100... Step: 2256... Loss: 0.031873... Val Loss: 0.041603\n",
      "Epoch: 22/100... Step: 2257... Loss: 0.031048... Val Loss: 0.040658\n",
      "Epoch: 22/100... Step: 2258... Loss: 0.034418... Val Loss: 0.042072\n",
      "Epoch: 22/100... Step: 2259... Loss: 0.019827... Val Loss: 0.042064\n",
      "Epoch: 22/100... Step: 2260... Loss: 0.031443... Val Loss: 0.031160\n",
      "Epoch: 22/100... Step: 2261... Loss: 0.016140... Val Loss: 0.025901\n",
      "Epoch: 22/100... Step: 2262... Loss: 0.033950... Val Loss: 0.043264\n",
      "Epoch: 22/100... Step: 2263... Loss: 0.023226... Val Loss: 0.055656\n",
      "Epoch: 22/100... Step: 2264... Loss: 0.028811... Val Loss: 0.062468\n",
      "Epoch: 22/100... Step: 2265... Loss: 0.026929... Val Loss: 0.053608\n",
      "Epoch: 22/100... Step: 2266... Loss: 0.030258... Val Loss: 0.045938\n",
      "Epoch: 22/100... Step: 2267... Loss: 0.033946... Val Loss: 0.031026\n",
      "Epoch: 22/100... Step: 2268... Loss: 0.031273... Val Loss: 0.021904\n",
      "Epoch: 22/100... Step: 2269... Loss: 0.032369... Val Loss: 0.028484\n",
      "Epoch: 22/100... Step: 2270... Loss: 0.030650... Val Loss: 0.044408\n",
      "Epoch: 22/100... Step: 2271... Loss: 0.033260... Val Loss: 0.065707\n",
      "Epoch: 22/100... Step: 2272... Loss: 0.031082... Val Loss: 0.075046\n",
      "Epoch: 22/100... Step: 2273... Loss: 0.034152... Val Loss: 0.099959\n",
      "Epoch: 22/100... Step: 2274... Loss: 0.044587... Val Loss: 0.117973\n",
      "Epoch: 22/100... Step: 2275... Loss: 0.038222... Val Loss: 0.123990\n",
      "Epoch: 22/100... Step: 2276... Loss: 0.053416... Val Loss: 0.123544\n",
      "Epoch: 22/100... Step: 2277... Loss: 0.024135... Val Loss: 0.124416\n",
      "Epoch: 22/100... Step: 2278... Loss: 0.037425... Val Loss: 0.129862\n",
      "Epoch: 22/100... Step: 2279... Loss: 0.035913... Val Loss: 0.142172\n",
      "Epoch: 22/100... Step: 2280... Loss: 0.024102... Val Loss: 0.143671\n",
      "Epoch: 22/100... Step: 2281... Loss: 0.037591... Val Loss: 0.132047\n",
      "Epoch: 22/100... Step: 2282... Loss: 0.025630... Val Loss: 0.119287\n",
      "Epoch: 22/100... Step: 2283... Loss: 0.020837... Val Loss: 0.110297\n",
      "Epoch: 22/100... Step: 2284... Loss: 0.031275... Val Loss: 0.084534\n",
      "Epoch: 22/100... Step: 2285... Loss: 0.024365... Val Loss: 0.065393\n",
      "Epoch: 22/100... Step: 2286... Loss: 0.015281... Val Loss: 0.053494\n",
      "Epoch: 22/100... Step: 2287... Loss: 0.025158... Val Loss: 0.044133\n",
      "Epoch: 22/100... Step: 2288... Loss: 0.030350... Val Loss: 0.056317\n",
      "Epoch: 23/100... Step: 2289... Loss: 0.027196... Val Loss: 0.107694\n",
      "Epoch: 23/100... Step: 2290... Loss: 0.013488... Val Loss: 0.141825\n",
      "Epoch: 23/100... Step: 2291... Loss: 0.018165... Val Loss: 0.115833\n",
      "Epoch: 23/100... Step: 2292... Loss: 0.031344... Val Loss: 0.057216\n",
      "Epoch: 23/100... Step: 2293... Loss: 0.012557... Val Loss: 0.004805\n",
      "Epoch: 23/100... Step: 2294... Loss: 0.019787... Val Loss: 0.041990\n",
      "Epoch: 23/100... Step: 2295... Loss: 0.031181... Val Loss: 0.098173\n",
      "Epoch: 23/100... Step: 2296... Loss: 0.036029... Val Loss: 0.134865\n",
      "Epoch: 23/100... Step: 2297... Loss: 0.024577... Val Loss: 0.142547\n",
      "Epoch: 23/100... Step: 2298... Loss: 0.029752... Val Loss: 0.146522\n",
      "Epoch: 23/100... Step: 2299... Loss: 0.033968... Val Loss: 0.156490\n",
      "Epoch: 23/100... Step: 2300... Loss: 0.035399... Val Loss: 0.179196\n",
      "Epoch: 23/100... Step: 2301... Loss: 0.043012... Val Loss: 0.191117\n",
      "Epoch: 23/100... Step: 2302... Loss: 0.028703... Val Loss: 0.190688\n",
      "Epoch: 23/100... Step: 2303... Loss: 0.035844... Val Loss: 0.195800\n",
      "Epoch: 23/100... Step: 2304... Loss: 0.026070... Val Loss: 0.202599\n",
      "Epoch: 23/100... Step: 2305... Loss: 0.028975... Val Loss: 0.196020\n",
      "Epoch: 23/100... Step: 2306... Loss: 0.031694... Val Loss: 0.176527\n",
      "Epoch: 23/100... Step: 2307... Loss: 0.026331... Val Loss: 0.145297\n",
      "Epoch: 23/100... Step: 2308... Loss: 0.023955... Val Loss: 0.111611\n",
      "Epoch: 23/100... Step: 2309... Loss: 0.030668... Val Loss: 0.082971\n",
      "Epoch: 23/100... Step: 2310... Loss: 0.029171... Val Loss: 0.062244\n",
      "Epoch: 23/100... Step: 2311... Loss: 0.041237... Val Loss: 0.048328\n",
      "Epoch: 23/100... Step: 2312... Loss: 0.023914... Val Loss: 0.037425\n",
      "Epoch: 23/100... Step: 2313... Loss: 0.036862... Val Loss: 0.039064\n",
      "Epoch: 23/100... Step: 2314... Loss: 0.032487... Val Loss: 0.050430\n",
      "Epoch: 23/100... Step: 2315... Loss: 0.028213... Val Loss: 0.068321\n",
      "Epoch: 23/100... Step: 2316... Loss: 0.053444... Val Loss: 0.085280\n",
      "Epoch: 23/100... Step: 2317... Loss: 0.025081... Val Loss: 0.089624\n",
      "Epoch: 23/100... Step: 2318... Loss: 0.034325... Val Loss: 0.073123\n",
      "Epoch: 23/100... Step: 2319... Loss: 0.033685... Val Loss: 0.036354\n",
      "Epoch: 23/100... Step: 2320... Loss: 0.027868... Val Loss: 0.013742\n",
      "Epoch: 23/100... Step: 2321... Loss: 0.028550... Val Loss: 0.006688\n",
      "Epoch: 23/100... Step: 2322... Loss: 0.040266... Val Loss: 0.009500\n",
      "Epoch: 23/100... Step: 2323... Loss: 0.037393... Val Loss: 0.013247\n",
      "Epoch: 23/100... Step: 2324... Loss: 0.038248... Val Loss: 0.009808\n",
      "Epoch: 23/100... Step: 2325... Loss: 0.024589... Val Loss: 0.009470\n",
      "Epoch: 23/100... Step: 2326... Loss: 0.025469... Val Loss: 0.007206\n",
      "Epoch: 23/100... Step: 2327... Loss: 0.023693... Val Loss: 0.015640\n",
      "Epoch: 23/100... Step: 2328... Loss: 0.029548... Val Loss: 0.020074\n",
      "Epoch: 23/100... Step: 2329... Loss: 0.035188... Val Loss: 0.024528\n",
      "Epoch: 23/100... Step: 2330... Loss: 0.023681... Val Loss: 0.021470\n",
      "Epoch: 23/100... Step: 2331... Loss: 0.028270... Val Loss: 0.021334\n",
      "Epoch: 23/100... Step: 2332... Loss: 0.027327... Val Loss: 0.013541\n",
      "Epoch: 23/100... Step: 2333... Loss: 0.026981... Val Loss: 0.013082\n",
      "Epoch: 23/100... Step: 2334... Loss: 0.019361... Val Loss: 0.013776\n",
      "Epoch: 23/100... Step: 2335... Loss: 0.029866... Val Loss: 0.013097\n",
      "Epoch: 23/100... Step: 2336... Loss: 0.016244... Val Loss: 0.015474\n",
      "Epoch: 23/100... Step: 2337... Loss: 0.038170... Val Loss: 0.019095\n",
      "Epoch: 23/100... Step: 2338... Loss: 0.029330... Val Loss: 0.038430\n",
      "Epoch: 23/100... Step: 2339... Loss: 0.041451... Val Loss: 0.052517\n",
      "Epoch: 23/100... Step: 2340... Loss: 0.033039... Val Loss: 0.062228\n",
      "Epoch: 23/100... Step: 2341... Loss: 0.041168... Val Loss: 0.067445\n",
      "Epoch: 23/100... Step: 2342... Loss: 0.026132... Val Loss: 0.059358\n",
      "Epoch: 23/100... Step: 2343... Loss: 0.031281... Val Loss: 0.085542\n",
      "Epoch: 23/100... Step: 2344... Loss: 0.032191... Val Loss: 0.109923\n",
      "Epoch: 23/100... Step: 2345... Loss: 0.035444... Val Loss: 0.140341\n",
      "Epoch: 23/100... Step: 2346... Loss: 0.031662... Val Loss: 0.167265\n",
      "Epoch: 23/100... Step: 2347... Loss: 0.026466... Val Loss: 0.191659\n",
      "Epoch: 23/100... Step: 2348... Loss: 0.037412... Val Loss: 0.216956\n",
      "Epoch: 23/100... Step: 2349... Loss: 0.018779... Val Loss: 0.243577\n",
      "Epoch: 23/100... Step: 2350... Loss: 0.042636... Val Loss: 0.251097\n",
      "Epoch: 23/100... Step: 2351... Loss: 0.023604... Val Loss: 0.240499\n",
      "Epoch: 23/100... Step: 2352... Loss: 0.035489... Val Loss: 0.224493\n",
      "Epoch: 23/100... Step: 2353... Loss: 0.031417... Val Loss: 0.210033\n",
      "Epoch: 23/100... Step: 2354... Loss: 0.028530... Val Loss: 0.179695\n",
      "Epoch: 23/100... Step: 2355... Loss: 0.035744... Val Loss: 0.162966\n",
      "Epoch: 23/100... Step: 2356... Loss: 0.040572... Val Loss: 0.139990\n",
      "Epoch: 23/100... Step: 2357... Loss: 0.028621... Val Loss: 0.129578\n",
      "Epoch: 23/100... Step: 2358... Loss: 0.034881... Val Loss: 0.119342\n",
      "Epoch: 23/100... Step: 2359... Loss: 0.022409... Val Loss: 0.102015\n",
      "Epoch: 23/100... Step: 2360... Loss: 0.036706... Val Loss: 0.088696\n",
      "Epoch: 23/100... Step: 2361... Loss: 0.037292... Val Loss: 0.075427\n",
      "Epoch: 23/100... Step: 2362... Loss: 0.026639... Val Loss: 0.060311\n",
      "Epoch: 23/100... Step: 2363... Loss: 0.024274... Val Loss: 0.047692\n",
      "Epoch: 23/100... Step: 2364... Loss: 0.029056... Val Loss: 0.031729\n",
      "Epoch: 23/100... Step: 2365... Loss: 0.022400... Val Loss: 0.027851\n",
      "Epoch: 23/100... Step: 2366... Loss: 0.030695... Val Loss: 0.046693\n",
      "Epoch: 23/100... Step: 2367... Loss: 0.036720... Val Loss: 0.050452\n",
      "Epoch: 23/100... Step: 2368... Loss: 0.023377... Val Loss: 0.046397\n",
      "Epoch: 23/100... Step: 2369... Loss: 0.026094... Val Loss: 0.035396\n",
      "Epoch: 23/100... Step: 2370... Loss: 0.026517... Val Loss: 0.020090\n",
      "Epoch: 23/100... Step: 2371... Loss: 0.030346... Val Loss: 0.014270\n",
      "Epoch: 23/100... Step: 2372... Loss: 0.030876... Val Loss: 0.007722\n",
      "Epoch: 23/100... Step: 2373... Loss: 0.036380... Val Loss: 0.007299\n",
      "Epoch: 23/100... Step: 2374... Loss: 0.036493... Val Loss: 0.007297\n",
      "Epoch: 23/100... Step: 2375... Loss: 0.044858... Val Loss: 0.012117\n",
      "Epoch: 23/100... Step: 2376... Loss: 0.019895... Val Loss: 0.013812\n",
      "Epoch: 23/100... Step: 2377... Loss: 0.029252... Val Loss: 0.025780\n",
      "Epoch: 23/100... Step: 2378... Loss: 0.037058... Val Loss: 0.040513\n",
      "Epoch: 23/100... Step: 2379... Loss: 0.027816... Val Loss: 0.051173\n",
      "Epoch: 23/100... Step: 2380... Loss: 0.025017... Val Loss: 0.061414\n",
      "Epoch: 23/100... Step: 2381... Loss: 0.035827... Val Loss: 0.062227\n",
      "Epoch: 23/100... Step: 2382... Loss: 0.027612... Val Loss: 0.050519\n",
      "Epoch: 23/100... Step: 2383... Loss: 0.014936... Val Loss: 0.041124\n",
      "Epoch: 23/100... Step: 2384... Loss: 0.032875... Val Loss: 0.037306\n",
      "Epoch: 23/100... Step: 2385... Loss: 0.029019... Val Loss: 0.036780\n",
      "Epoch: 23/100... Step: 2386... Loss: 0.031518... Val Loss: 0.037920\n",
      "Epoch: 23/100... Step: 2387... Loss: 0.033550... Val Loss: 0.021679\n",
      "Epoch: 23/100... Step: 2388... Loss: 0.034651... Val Loss: 0.009794\n",
      "Epoch: 23/100... Step: 2389... Loss: 0.025132... Val Loss: 0.013245\n",
      "Epoch: 23/100... Step: 2390... Loss: 0.027423... Val Loss: 0.029724\n",
      "Epoch: 23/100... Step: 2391... Loss: 0.020986... Val Loss: 0.049141\n",
      "Epoch: 23/100... Step: 2392... Loss: 0.032482... Val Loss: 0.056953\n",
      "Epoch: 24/100... Step: 2393... Loss: 0.010028... Val Loss: 0.020294\n",
      "Epoch: 24/100... Step: 2394... Loss: 0.026802... Val Loss: 0.060220\n",
      "Epoch: 24/100... Step: 2395... Loss: 0.018683... Val Loss: 0.028000\n",
      "Epoch: 24/100... Step: 2396... Loss: 0.029123... Val Loss: 0.060396\n",
      "Epoch: 24/100... Step: 2397... Loss: 0.033774... Val Loss: 0.092730\n",
      "Epoch: 24/100... Step: 2398... Loss: 0.036566... Val Loss: 0.083881\n",
      "Epoch: 24/100... Step: 2399... Loss: 0.014219... Val Loss: 0.084606\n",
      "Epoch: 24/100... Step: 2400... Loss: 0.030778... Val Loss: 0.088049\n",
      "Epoch: 24/100... Step: 2401... Loss: 0.037396... Val Loss: 0.092038\n",
      "Epoch: 24/100... Step: 2402... Loss: 0.033309... Val Loss: 0.072538\n",
      "Epoch: 24/100... Step: 2403... Loss: 0.042147... Val Loss: 0.074586\n",
      "Epoch: 24/100... Step: 2404... Loss: 0.032848... Val Loss: 0.095893\n",
      "Epoch: 24/100... Step: 2405... Loss: 0.042999... Val Loss: 0.101009\n",
      "Epoch: 24/100... Step: 2406... Loss: 0.031022... Val Loss: 0.092021\n",
      "Epoch: 24/100... Step: 2407... Loss: 0.030487... Val Loss: 0.096966\n",
      "Epoch: 24/100... Step: 2408... Loss: 0.037487... Val Loss: 0.100055\n",
      "Epoch: 24/100... Step: 2409... Loss: 0.033950... Val Loss: 0.098753\n",
      "Epoch: 24/100... Step: 2410... Loss: 0.024915... Val Loss: 0.087413\n",
      "Epoch: 24/100... Step: 2411... Loss: 0.042675... Val Loss: 0.063578\n",
      "Epoch: 24/100... Step: 2412... Loss: 0.023103... Val Loss: 0.065232\n",
      "Epoch: 24/100... Step: 2413... Loss: 0.035386... Val Loss: 0.052455\n",
      "Epoch: 24/100... Step: 2414... Loss: 0.029905... Val Loss: 0.052564\n",
      "Epoch: 24/100... Step: 2415... Loss: 0.036952... Val Loss: 0.034424\n",
      "Epoch: 24/100... Step: 2416... Loss: 0.029604... Val Loss: 0.018795\n",
      "Epoch: 24/100... Step: 2417... Loss: 0.032688... Val Loss: 0.007948\n",
      "Epoch: 24/100... Step: 2418... Loss: 0.020078... Val Loss: 0.008944\n",
      "Epoch: 24/100... Step: 2419... Loss: 0.031624... Val Loss: 0.009026\n",
      "Epoch: 24/100... Step: 2420... Loss: 0.037649... Val Loss: 0.016463\n",
      "Epoch: 24/100... Step: 2421... Loss: 0.022203... Val Loss: 0.021721\n",
      "Epoch: 24/100... Step: 2422... Loss: 0.043292... Val Loss: 0.032182\n",
      "Epoch: 24/100... Step: 2423... Loss: 0.049145... Val Loss: 0.036512\n",
      "Epoch: 24/100... Step: 2424... Loss: 0.029390... Val Loss: 0.033980\n",
      "Epoch: 24/100... Step: 2425... Loss: 0.038765... Val Loss: 0.059493\n",
      "Epoch: 24/100... Step: 2426... Loss: 0.026642... Val Loss: 0.072207\n",
      "Epoch: 24/100... Step: 2427... Loss: 0.016420... Val Loss: 0.058533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Step: 2428... Loss: 0.024549... Val Loss: 0.056846\n",
      "Epoch: 24/100... Step: 2429... Loss: 0.022286... Val Loss: 0.020209\n",
      "Epoch: 24/100... Step: 2430... Loss: 0.021086... Val Loss: 0.059448\n",
      "Epoch: 24/100... Step: 2431... Loss: 0.039567... Val Loss: 0.092441\n",
      "Epoch: 24/100... Step: 2432... Loss: 0.029826... Val Loss: 0.104504\n",
      "Epoch: 24/100... Step: 2433... Loss: 0.028060... Val Loss: 0.088413\n",
      "Epoch: 24/100... Step: 2434... Loss: 0.033703... Val Loss: 0.082437\n",
      "Epoch: 24/100... Step: 2435... Loss: 0.040064... Val Loss: 0.071329\n",
      "Epoch: 24/100... Step: 2436... Loss: 0.033694... Val Loss: 0.063383\n",
      "Epoch: 24/100... Step: 2437... Loss: 0.036292... Val Loss: 0.048523\n",
      "Epoch: 24/100... Step: 2438... Loss: 0.024764... Val Loss: 0.041797\n",
      "Epoch: 24/100... Step: 2439... Loss: 0.027114... Val Loss: 0.031213\n",
      "Epoch: 24/100... Step: 2440... Loss: 0.025837... Val Loss: 0.022504\n",
      "Epoch: 24/100... Step: 2441... Loss: 0.021976... Val Loss: 0.032755\n",
      "Epoch: 24/100... Step: 2442... Loss: 0.036051... Val Loss: 0.013889\n",
      "Epoch: 24/100... Step: 2443... Loss: 0.035185... Val Loss: 0.036401\n",
      "Epoch: 24/100... Step: 2444... Loss: 0.035038... Val Loss: 0.016512\n",
      "Epoch: 24/100... Step: 2445... Loss: 0.033561... Val Loss: 0.042943\n",
      "Epoch: 24/100... Step: 2446... Loss: 0.033772... Val Loss: 0.025207\n",
      "Epoch: 24/100... Step: 2447... Loss: 0.051259... Val Loss: 0.016817\n",
      "Epoch: 24/100... Step: 2448... Loss: 0.035241... Val Loss: 0.013115\n",
      "Epoch: 24/100... Step: 2449... Loss: 0.023224... Val Loss: 0.028062\n",
      "Epoch: 24/100... Step: 2450... Loss: 0.029520... Val Loss: 0.010791\n",
      "Epoch: 24/100... Step: 2451... Loss: 0.026180... Val Loss: 0.008483\n",
      "Epoch: 24/100... Step: 2452... Loss: 0.035360... Val Loss: 0.009702\n",
      "Epoch: 24/100... Step: 2453... Loss: 0.032576... Val Loss: 0.025893\n",
      "Epoch: 24/100... Step: 2454... Loss: 0.034529... Val Loss: 0.041146\n",
      "Epoch: 24/100... Step: 2455... Loss: 0.032111... Val Loss: 0.073082\n",
      "Epoch: 24/100... Step: 2456... Loss: 0.036360... Val Loss: 0.098865\n",
      "Epoch: 24/100... Step: 2457... Loss: 0.031209... Val Loss: 0.136161\n",
      "Epoch: 24/100... Step: 2458... Loss: 0.028400... Val Loss: 0.160133\n",
      "Epoch: 24/100... Step: 2459... Loss: 0.042906... Val Loss: 0.171327\n",
      "Epoch: 24/100... Step: 2460... Loss: 0.019254... Val Loss: 0.171587\n",
      "Epoch: 24/100... Step: 2461... Loss: 0.041651... Val Loss: 0.163983\n",
      "Epoch: 24/100... Step: 2462... Loss: 0.058190... Val Loss: 0.156397\n",
      "Epoch: 24/100... Step: 2463... Loss: 0.028049... Val Loss: 0.146418\n",
      "Epoch: 24/100... Step: 2464... Loss: 0.033432... Val Loss: 0.131064\n",
      "Epoch: 24/100... Step: 2465... Loss: 0.034171... Val Loss: 0.122409\n",
      "Epoch: 24/100... Step: 2466... Loss: 0.031204... Val Loss: 0.106993\n",
      "Epoch: 24/100... Step: 2467... Loss: 0.035103... Val Loss: 0.095346\n",
      "Epoch: 24/100... Step: 2468... Loss: 0.020055... Val Loss: 0.082444\n",
      "Epoch: 24/100... Step: 2469... Loss: 0.028183... Val Loss: 0.076872\n",
      "Epoch: 24/100... Step: 2470... Loss: 0.022949... Val Loss: 0.068440\n",
      "Epoch: 24/100... Step: 2471... Loss: 0.024474... Val Loss: 0.074260\n",
      "Epoch: 24/100... Step: 2472... Loss: 0.034243... Val Loss: 0.091987\n",
      "Epoch: 24/100... Step: 2473... Loss: 0.033063... Val Loss: 0.121558\n",
      "Epoch: 24/100... Step: 2474... Loss: 0.036699... Val Loss: 0.134243\n",
      "Epoch: 24/100... Step: 2475... Loss: 0.033343... Val Loss: 0.121188\n",
      "Epoch: 24/100... Step: 2476... Loss: 0.036833... Val Loss: 0.107647\n",
      "Epoch: 24/100... Step: 2477... Loss: 0.035112... Val Loss: 0.097431\n",
      "Epoch: 24/100... Step: 2478... Loss: 0.040575... Val Loss: 0.084646\n",
      "Epoch: 24/100... Step: 2479... Loss: 0.028288... Val Loss: 0.079737\n",
      "Epoch: 24/100... Step: 2480... Loss: 0.044571... Val Loss: 0.075314\n",
      "Epoch: 24/100... Step: 2481... Loss: 0.032034... Val Loss: 0.068723\n",
      "Epoch: 24/100... Step: 2482... Loss: 0.048229... Val Loss: 0.042917\n",
      "Epoch: 24/100... Step: 2483... Loss: 0.046461... Val Loss: 0.006997\n",
      "Epoch: 24/100... Step: 2484... Loss: 0.030424... Val Loss: 0.011580\n",
      "Epoch: 24/100... Step: 2485... Loss: 0.034385... Val Loss: 0.018202\n",
      "Epoch: 24/100... Step: 2486... Loss: 0.025365... Val Loss: 0.015382\n",
      "Epoch: 24/100... Step: 2487... Loss: 0.030196... Val Loss: 0.039150\n",
      "Epoch: 24/100... Step: 2488... Loss: 0.021144... Val Loss: 0.047904\n",
      "Epoch: 24/100... Step: 2489... Loss: 0.022601... Val Loss: 0.053281\n",
      "Epoch: 24/100... Step: 2490... Loss: 0.042440... Val Loss: 0.066084\n",
      "Epoch: 24/100... Step: 2491... Loss: 0.032143... Val Loss: 0.067483\n",
      "Epoch: 24/100... Step: 2492... Loss: 0.033875... Val Loss: 0.063177\n",
      "Epoch: 24/100... Step: 2493... Loss: 0.033155... Val Loss: 0.048254\n",
      "Epoch: 24/100... Step: 2494... Loss: 0.028749... Val Loss: 0.033348\n",
      "Epoch: 24/100... Step: 2495... Loss: 0.029824... Val Loss: 0.010429\n",
      "Epoch: 24/100... Step: 2496... Loss: 0.043422... Val Loss: 0.058523\n",
      "Epoch: 25/100... Step: 2497... Loss: 0.014143... Val Loss: 0.060243\n",
      "Epoch: 25/100... Step: 2498... Loss: 0.016900... Val Loss: 0.102976\n",
      "Epoch: 25/100... Step: 2499... Loss: 0.026530... Val Loss: 0.233142\n",
      "Epoch: 25/100... Step: 2500... Loss: 0.034696... Val Loss: 0.286176\n",
      "Epoch: 25/100... Step: 2501... Loss: 0.037573... Val Loss: 0.270265\n",
      "Epoch: 25/100... Step: 2502... Loss: 0.022731... Val Loss: 0.292359\n",
      "Epoch: 25/100... Step: 2503... Loss: 0.030746... Val Loss: 0.324300\n",
      "Epoch: 25/100... Step: 2504... Loss: 0.021627... Val Loss: 0.346086\n",
      "Epoch: 25/100... Step: 2505... Loss: 0.018533... Val Loss: 0.336403\n",
      "Epoch: 25/100... Step: 2506... Loss: 0.037541... Val Loss: 0.371745\n",
      "Epoch: 25/100... Step: 2507... Loss: 0.035040... Val Loss: 0.358920\n",
      "Epoch: 25/100... Step: 2508... Loss: 0.028833... Val Loss: 0.340424\n",
      "Epoch: 25/100... Step: 2509... Loss: 0.043249... Val Loss: 0.312597\n",
      "Epoch: 25/100... Step: 2510... Loss: 0.036456... Val Loss: 0.293278\n",
      "Epoch: 25/100... Step: 2511... Loss: 0.041227... Val Loss: 0.278108\n",
      "Epoch: 25/100... Step: 2512... Loss: 0.035497... Val Loss: 0.246255\n",
      "Epoch: 25/100... Step: 2513... Loss: 0.043982... Val Loss: 0.210069\n",
      "Epoch: 25/100... Step: 2514... Loss: 0.037524... Val Loss: 0.211868\n",
      "Epoch: 25/100... Step: 2515... Loss: 0.039252... Val Loss: 0.187949\n",
      "Epoch: 25/100... Step: 2516... Loss: 0.028489... Val Loss: 0.165627\n",
      "Epoch: 25/100... Step: 2517... Loss: 0.042363... Val Loss: 0.135152\n",
      "Epoch: 25/100... Step: 2518... Loss: 0.031564... Val Loss: 0.106908\n",
      "Epoch: 25/100... Step: 2519... Loss: 0.037809... Val Loss: 0.088300\n",
      "Epoch: 25/100... Step: 2520... Loss: 0.026696... Val Loss: 0.085326\n",
      "Epoch: 25/100... Step: 2521... Loss: 0.029992... Val Loss: 0.080738\n",
      "Epoch: 25/100... Step: 2522... Loss: 0.037882... Val Loss: 0.069573\n",
      "Epoch: 25/100... Step: 2523... Loss: 0.046054... Val Loss: 0.063077\n",
      "Epoch: 25/100... Step: 2524... Loss: 0.038769... Val Loss: 0.046373\n",
      "Epoch: 25/100... Step: 2525... Loss: 0.015994... Val Loss: 0.039154\n",
      "Epoch: 25/100... Step: 2526... Loss: 0.037972... Val Loss: 0.035678\n",
      "Epoch: 25/100... Step: 2527... Loss: 0.022575... Val Loss: 0.038966\n",
      "Epoch: 25/100... Step: 2528... Loss: 0.038020... Val Loss: 0.040173\n",
      "Epoch: 25/100... Step: 2529... Loss: 0.023346... Val Loss: 0.040370\n",
      "Epoch: 25/100... Step: 2530... Loss: 0.044624... Val Loss: 0.036479\n",
      "Epoch: 25/100... Step: 2531... Loss: 0.015401... Val Loss: 0.021509\n",
      "Epoch: 25/100... Step: 2532... Loss: 0.039965... Val Loss: 0.008266\n",
      "Epoch: 25/100... Step: 2533... Loss: 0.027303... Val Loss: 0.003940\n",
      "Epoch: 25/100... Step: 2534... Loss: 0.031179... Val Loss: 0.013424\n",
      "Epoch: 25/100... Step: 2535... Loss: 0.029525... Val Loss: 0.017512\n",
      "Epoch: 25/100... Step: 2536... Loss: 0.021781... Val Loss: 0.016116\n",
      "Epoch: 25/100... Step: 2537... Loss: 0.033804... Val Loss: 0.013277\n",
      "Epoch: 25/100... Step: 2538... Loss: 0.031444... Val Loss: 0.031258\n",
      "Epoch: 25/100... Step: 2539... Loss: 0.022297... Val Loss: 0.051197\n",
      "Epoch: 25/100... Step: 2540... Loss: 0.031312... Val Loss: 0.045801\n",
      "Epoch: 25/100... Step: 2541... Loss: 0.033782... Val Loss: 0.053375\n",
      "Epoch: 25/100... Step: 2542... Loss: 0.038342... Val Loss: 0.067482\n",
      "Epoch: 25/100... Step: 2543... Loss: 0.037243... Val Loss: 0.084445\n",
      "Epoch: 25/100... Step: 2544... Loss: 0.025629... Val Loss: 0.109278\n",
      "Epoch: 25/100... Step: 2545... Loss: 0.025934... Val Loss: 0.121220\n",
      "Epoch: 25/100... Step: 2546... Loss: 0.035767... Val Loss: 0.119893\n",
      "Epoch: 25/100... Step: 2547... Loss: 0.045743... Val Loss: 0.110645\n",
      "Epoch: 25/100... Step: 2548... Loss: 0.033676... Val Loss: 0.117123\n",
      "Epoch: 25/100... Step: 2549... Loss: 0.040756... Val Loss: 0.127416\n",
      "Epoch: 25/100... Step: 2550... Loss: 0.036565... Val Loss: 0.107127\n",
      "Epoch: 25/100... Step: 2551... Loss: 0.034419... Val Loss: 0.090566\n",
      "Epoch: 25/100... Step: 2552... Loss: 0.022323... Val Loss: 0.069961\n",
      "Epoch: 25/100... Step: 2553... Loss: 0.021158... Val Loss: 0.051959\n",
      "Epoch: 25/100... Step: 2554... Loss: 0.019204... Val Loss: 0.023615\n",
      "Epoch: 25/100... Step: 2555... Loss: 0.031565... Val Loss: 0.013081\n",
      "Epoch: 25/100... Step: 2556... Loss: 0.022632... Val Loss: 0.013851\n",
      "Epoch: 25/100... Step: 2557... Loss: 0.021269... Val Loss: 0.026321\n",
      "Epoch: 25/100... Step: 2558... Loss: 0.025988... Val Loss: 0.034862\n",
      "Epoch: 25/100... Step: 2559... Loss: 0.029288... Val Loss: 0.037176\n",
      "Epoch: 25/100... Step: 2560... Loss: 0.036985... Val Loss: 0.017743\n",
      "Epoch: 25/100... Step: 2561... Loss: 0.019046... Val Loss: 0.014736\n",
      "Epoch: 25/100... Step: 2562... Loss: 0.031024... Val Loss: 0.007558\n",
      "Epoch: 25/100... Step: 2563... Loss: 0.026891... Val Loss: 0.034958\n",
      "Epoch: 25/100... Step: 2564... Loss: 0.036021... Val Loss: 0.082276\n",
      "Epoch: 25/100... Step: 2565... Loss: 0.049572... Val Loss: 0.118716\n",
      "Epoch: 25/100... Step: 2566... Loss: 0.031263... Val Loss: 0.137205\n",
      "Epoch: 25/100... Step: 2567... Loss: 0.025085... Val Loss: 0.146983\n",
      "Epoch: 25/100... Step: 2568... Loss: 0.029905... Val Loss: 0.142771\n",
      "Epoch: 25/100... Step: 2569... Loss: 0.028016... Val Loss: 0.135990\n",
      "Epoch: 25/100... Step: 2570... Loss: 0.043180... Val Loss: 0.123922\n",
      "Epoch: 25/100... Step: 2571... Loss: 0.016063... Val Loss: 0.111359\n",
      "Epoch: 25/100... Step: 2572... Loss: 0.026953... Val Loss: 0.090675\n",
      "Epoch: 25/100... Step: 2573... Loss: 0.023996... Val Loss: 0.070752\n",
      "Epoch: 25/100... Step: 2574... Loss: 0.028746... Val Loss: 0.070626\n",
      "Epoch: 25/100... Step: 2575... Loss: 0.040758... Val Loss: 0.063822\n",
      "Epoch: 25/100... Step: 2576... Loss: 0.032936... Val Loss: 0.064831\n",
      "Epoch: 25/100... Step: 2577... Loss: 0.031470... Val Loss: 0.064039\n",
      "Epoch: 25/100... Step: 2578... Loss: 0.031034... Val Loss: 0.058470\n",
      "Epoch: 25/100... Step: 2579... Loss: 0.027092... Val Loss: 0.045790\n",
      "Epoch: 25/100... Step: 2580... Loss: 0.026143... Val Loss: 0.043366\n",
      "Epoch: 25/100... Step: 2581... Loss: 0.032871... Val Loss: 0.044585\n",
      "Epoch: 25/100... Step: 2582... Loss: 0.025059... Val Loss: 0.026244\n",
      "Epoch: 25/100... Step: 2583... Loss: 0.029972... Val Loss: 0.007278\n",
      "Epoch: 25/100... Step: 2584... Loss: 0.027499... Val Loss: 0.009407\n",
      "Epoch: 25/100... Step: 2585... Loss: 0.027709... Val Loss: 0.010862\n",
      "Epoch: 25/100... Step: 2586... Loss: 0.030660... Val Loss: 0.018031\n",
      "Epoch: 25/100... Step: 2587... Loss: 0.058494... Val Loss: 0.042883\n",
      "Epoch: 25/100... Step: 2588... Loss: 0.038631... Val Loss: 0.057310\n",
      "Epoch: 25/100... Step: 2589... Loss: 0.028578... Val Loss: 0.060746\n",
      "Epoch: 25/100... Step: 2590... Loss: 0.033560... Val Loss: 0.063915\n",
      "Epoch: 25/100... Step: 2591... Loss: 0.032814... Val Loss: 0.064566\n",
      "Epoch: 25/100... Step: 2592... Loss: 0.031277... Val Loss: 0.061504\n",
      "Epoch: 25/100... Step: 2593... Loss: 0.033276... Val Loss: 0.063220\n",
      "Epoch: 25/100... Step: 2594... Loss: 0.031622... Val Loss: 0.049768\n",
      "Epoch: 25/100... Step: 2595... Loss: 0.029358... Val Loss: 0.055784\n",
      "Epoch: 25/100... Step: 2596... Loss: 0.035546... Val Loss: 0.030295\n",
      "Epoch: 25/100... Step: 2597... Loss: 0.030027... Val Loss: 0.007896\n",
      "Epoch: 25/100... Step: 2598... Loss: 0.019327... Val Loss: 0.017409\n",
      "Epoch: 25/100... Step: 2599... Loss: 0.019945... Val Loss: 0.006294\n",
      "Epoch: 25/100... Step: 2600... Loss: 0.033038... Val Loss: 0.033197\n",
      "Epoch: 26/100... Step: 2601... Loss: 0.021185... Val Loss: 0.035260\n",
      "Epoch: 26/100... Step: 2602... Loss: 0.024945... Val Loss: 0.036656\n",
      "Epoch: 26/100... Step: 2603... Loss: 0.025432... Val Loss: 0.101890\n",
      "Epoch: 26/100... Step: 2604... Loss: 0.023522... Val Loss: 0.093879\n",
      "Epoch: 26/100... Step: 2605... Loss: 0.025508... Val Loss: 0.078886\n",
      "Epoch: 26/100... Step: 2606... Loss: 0.032018... Val Loss: 0.080388\n",
      "Epoch: 26/100... Step: 2607... Loss: 0.016119... Val Loss: 0.088084\n",
      "Epoch: 26/100... Step: 2608... Loss: 0.026694... Val Loss: 0.094182\n",
      "Epoch: 26/100... Step: 2609... Loss: 0.040778... Val Loss: 0.102735\n",
      "Epoch: 26/100... Step: 2610... Loss: 0.015540... Val Loss: 0.104075\n",
      "Epoch: 26/100... Step: 2611... Loss: 0.027129... Val Loss: 0.080429\n",
      "Epoch: 26/100... Step: 2612... Loss: 0.039087... Val Loss: 0.070140\n",
      "Epoch: 26/100... Step: 2613... Loss: 0.033293... Val Loss: 0.072908\n",
      "Epoch: 26/100... Step: 2614... Loss: 0.034189... Val Loss: 0.049427\n",
      "Epoch: 26/100... Step: 2615... Loss: 0.020062... Val Loss: 0.063637\n",
      "Epoch: 26/100... Step: 2616... Loss: 0.029294... Val Loss: 0.070466\n",
      "Epoch: 26/100... Step: 2617... Loss: 0.029265... Val Loss: 0.090176\n",
      "Epoch: 26/100... Step: 2618... Loss: 0.025525... Val Loss: 0.106592\n",
      "Epoch: 26/100... Step: 2619... Loss: 0.038673... Val Loss: 0.094146\n",
      "Epoch: 26/100... Step: 2620... Loss: 0.024406... Val Loss: 0.090147\n",
      "Epoch: 26/100... Step: 2621... Loss: 0.029357... Val Loss: 0.075415\n",
      "Epoch: 26/100... Step: 2622... Loss: 0.026427... Val Loss: 0.048125\n",
      "Epoch: 26/100... Step: 2623... Loss: 0.031038... Val Loss: 0.008024\n",
      "Epoch: 26/100... Step: 2624... Loss: 0.024809... Val Loss: 0.046444\n",
      "Epoch: 26/100... Step: 2625... Loss: 0.023533... Val Loss: 0.076576\n",
      "Epoch: 26/100... Step: 2626... Loss: 0.031318... Val Loss: 0.078490\n",
      "Epoch: 26/100... Step: 2627... Loss: 0.025759... Val Loss: 0.095825\n",
      "Epoch: 26/100... Step: 2628... Loss: 0.027940... Val Loss: 0.119668\n",
      "Epoch: 26/100... Step: 2629... Loss: 0.034053... Val Loss: 0.151363\n",
      "Epoch: 26/100... Step: 2630... Loss: 0.023633... Val Loss: 0.183845\n",
      "Epoch: 26/100... Step: 2631... Loss: 0.037884... Val Loss: 0.188848\n",
      "Epoch: 26/100... Step: 2632... Loss: 0.034754... Val Loss: 0.188876\n",
      "Epoch: 26/100... Step: 2633... Loss: 0.033006... Val Loss: 0.174964\n",
      "Epoch: 26/100... Step: 2634... Loss: 0.037427... Val Loss: 0.164055\n",
      "Epoch: 26/100... Step: 2635... Loss: 0.025528... Val Loss: 0.091840\n",
      "Epoch: 26/100... Step: 2636... Loss: 0.028769... Val Loss: 0.166047\n",
      "Epoch: 26/100... Step: 2637... Loss: 0.040596... Val Loss: 0.148384\n",
      "Epoch: 26/100... Step: 2638... Loss: 0.029429... Val Loss: 0.096069\n",
      "Epoch: 26/100... Step: 2639... Loss: 0.033435... Val Loss: 0.026291\n",
      "Epoch: 26/100... Step: 2640... Loss: 0.042425... Val Loss: 0.023929\n",
      "Epoch: 26/100... Step: 2641... Loss: 0.044482... Val Loss: 0.082812\n",
      "Epoch: 26/100... Step: 2642... Loss: 0.026256... Val Loss: 0.130703\n",
      "Epoch: 26/100... Step: 2643... Loss: 0.036417... Val Loss: 0.147917\n",
      "Epoch: 26/100... Step: 2644... Loss: 0.039923... Val Loss: 0.140669\n",
      "Epoch: 26/100... Step: 2645... Loss: 0.037360... Val Loss: 0.109337\n",
      "Epoch: 26/100... Step: 2646... Loss: 0.022902... Val Loss: 0.074680\n",
      "Epoch: 26/100... Step: 2647... Loss: 0.037979... Val Loss: 0.057906\n",
      "Epoch: 26/100... Step: 2648... Loss: 0.027997... Val Loss: 0.054060\n",
      "Epoch: 26/100... Step: 2649... Loss: 0.040156... Val Loss: 0.064724\n",
      "Epoch: 26/100... Step: 2650... Loss: 0.026008... Val Loss: 0.076387\n",
      "Epoch: 26/100... Step: 2651... Loss: 0.069536... Val Loss: 0.087304\n",
      "Epoch: 26/100... Step: 2652... Loss: 0.042178... Val Loss: 0.090031\n",
      "Epoch: 26/100... Step: 2653... Loss: 0.033364... Val Loss: 0.095173\n",
      "Epoch: 26/100... Step: 2654... Loss: 0.026330... Val Loss: 0.093068\n",
      "Epoch: 26/100... Step: 2655... Loss: 0.037747... Val Loss: 0.083556\n",
      "Epoch: 26/100... Step: 2656... Loss: 0.024702... Val Loss: 0.053197\n",
      "Epoch: 26/100... Step: 2657... Loss: 0.027842... Val Loss: 0.009575\n",
      "Epoch: 26/100... Step: 2658... Loss: 0.038375... Val Loss: 0.034910\n",
      "Epoch: 26/100... Step: 2659... Loss: 0.043764... Val Loss: 0.071043\n",
      "Epoch: 26/100... Step: 2660... Loss: 0.041057... Val Loss: 0.102851\n",
      "Epoch: 26/100... Step: 2661... Loss: 0.029574... Val Loss: 0.124200\n",
      "Epoch: 26/100... Step: 2662... Loss: 0.024603... Val Loss: 0.119129\n",
      "Epoch: 26/100... Step: 2663... Loss: 0.040717... Val Loss: 0.117699\n",
      "Epoch: 26/100... Step: 2664... Loss: 0.053896... Val Loss: 0.099496\n",
      "Epoch: 26/100... Step: 2665... Loss: 0.024815... Val Loss: 0.073607\n",
      "Epoch: 26/100... Step: 2666... Loss: 0.021289... Val Loss: 0.038424\n",
      "Epoch: 26/100... Step: 2667... Loss: 0.024801... Val Loss: 0.021339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100... Step: 2668... Loss: 0.024392... Val Loss: 0.019023\n",
      "Epoch: 26/100... Step: 2669... Loss: 0.036821... Val Loss: 0.015169\n",
      "Epoch: 26/100... Step: 2670... Loss: 0.037455... Val Loss: 0.012256\n",
      "Epoch: 26/100... Step: 2671... Loss: 0.030049... Val Loss: 0.012988\n",
      "Epoch: 26/100... Step: 2672... Loss: 0.022062... Val Loss: 0.012880\n",
      "Epoch: 26/100... Step: 2673... Loss: 0.023546... Val Loss: 0.014880\n",
      "Epoch: 26/100... Step: 2674... Loss: 0.032975... Val Loss: 0.038270\n",
      "Epoch: 26/100... Step: 2675... Loss: 0.046490... Val Loss: 0.058798\n",
      "Epoch: 26/100... Step: 2676... Loss: 0.041659... Val Loss: 0.063825\n",
      "Epoch: 26/100... Step: 2677... Loss: 0.031789... Val Loss: 0.061106\n",
      "Epoch: 26/100... Step: 2678... Loss: 0.031476... Val Loss: 0.054668\n",
      "Epoch: 26/100... Step: 2679... Loss: 0.026430... Val Loss: 0.065702\n",
      "Epoch: 26/100... Step: 2680... Loss: 0.019421... Val Loss: 0.080052\n",
      "Epoch: 26/100... Step: 2681... Loss: 0.054819... Val Loss: 0.102850\n",
      "Epoch: 26/100... Step: 2682... Loss: 0.018729... Val Loss: 0.130421\n",
      "Epoch: 26/100... Step: 2683... Loss: 0.042062... Val Loss: 0.119839\n",
      "Epoch: 26/100... Step: 2684... Loss: 0.029940... Val Loss: 0.101258\n",
      "Epoch: 26/100... Step: 2685... Loss: 0.036397... Val Loss: 0.091932\n",
      "Epoch: 26/100... Step: 2686... Loss: 0.024899... Val Loss: 0.075400\n",
      "Epoch: 26/100... Step: 2687... Loss: 0.034571... Val Loss: 0.058778\n",
      "Epoch: 26/100... Step: 2688... Loss: 0.030069... Val Loss: 0.048853\n",
      "Epoch: 26/100... Step: 2689... Loss: 0.030963... Val Loss: 0.036402\n",
      "Epoch: 26/100... Step: 2690... Loss: 0.048377... Val Loss: 0.024437\n",
      "Epoch: 26/100... Step: 2691... Loss: 0.037228... Val Loss: 0.006905\n",
      "Epoch: 26/100... Step: 2692... Loss: 0.027618... Val Loss: 0.033994\n",
      "Epoch: 26/100... Step: 2693... Loss: 0.041418... Val Loss: 0.069574\n",
      "Epoch: 26/100... Step: 2694... Loss: 0.031907... Val Loss: 0.093830\n",
      "Epoch: 26/100... Step: 2695... Loss: 0.032542... Val Loss: 0.107429\n",
      "Epoch: 26/100... Step: 2696... Loss: 0.026608... Val Loss: 0.099621\n",
      "Epoch: 26/100... Step: 2697... Loss: 0.025739... Val Loss: 0.095924\n",
      "Epoch: 26/100... Step: 2698... Loss: 0.038034... Val Loss: 0.090219\n",
      "Epoch: 26/100... Step: 2699... Loss: 0.032765... Val Loss: 0.085706\n",
      "Epoch: 26/100... Step: 2700... Loss: 0.047833... Val Loss: 0.088329\n",
      "Epoch: 26/100... Step: 2701... Loss: 0.042022... Val Loss: 0.109254\n",
      "Epoch: 26/100... Step: 2702... Loss: 0.048238... Val Loss: 0.139892\n",
      "Epoch: 26/100... Step: 2703... Loss: 0.040269... Val Loss: 0.145777\n",
      "Epoch: 26/100... Step: 2704... Loss: 0.042341... Val Loss: 0.120476\n",
      "Epoch: 27/100... Step: 2705... Loss: 0.025747... Val Loss: 0.148224\n",
      "Epoch: 27/100... Step: 2706... Loss: 0.021267... Val Loss: 0.134014\n",
      "Epoch: 27/100... Step: 2707... Loss: 0.028408... Val Loss: 0.115974\n",
      "Epoch: 27/100... Step: 2708... Loss: 0.027358... Val Loss: 0.134829\n",
      "Epoch: 27/100... Step: 2709... Loss: 0.018771... Val Loss: 0.124826\n",
      "Epoch: 27/100... Step: 2710... Loss: 0.042014... Val Loss: 0.109546\n",
      "Epoch: 27/100... Step: 2711... Loss: 0.029225... Val Loss: 0.088545\n",
      "Epoch: 27/100... Step: 2712... Loss: 0.025143... Val Loss: 0.088367\n",
      "Epoch: 27/100... Step: 2713... Loss: 0.034467... Val Loss: 0.080879\n",
      "Epoch: 27/100... Step: 2714... Loss: 0.038742... Val Loss: 0.059883\n",
      "Epoch: 27/100... Step: 2715... Loss: 0.030803... Val Loss: 0.063298\n",
      "Epoch: 27/100... Step: 2716... Loss: 0.044047... Val Loss: 0.050679\n",
      "Epoch: 27/100... Step: 2717... Loss: 0.019629... Val Loss: 0.010258\n",
      "Epoch: 27/100... Step: 2718... Loss: 0.041259... Val Loss: 0.016603\n",
      "Epoch: 27/100... Step: 2719... Loss: 0.021700... Val Loss: 0.018399\n",
      "Epoch: 27/100... Step: 2720... Loss: 0.034545... Val Loss: 0.012812\n",
      "Epoch: 27/100... Step: 2721... Loss: 0.024274... Val Loss: 0.017691\n",
      "Epoch: 27/100... Step: 2722... Loss: 0.027388... Val Loss: 0.009114\n",
      "Epoch: 27/100... Step: 2723... Loss: 0.023404... Val Loss: 0.019385\n",
      "Epoch: 27/100... Step: 2724... Loss: 0.026251... Val Loss: 0.032382\n",
      "Epoch: 27/100... Step: 2725... Loss: 0.032466... Val Loss: 0.027000\n",
      "Epoch: 27/100... Step: 2726... Loss: 0.027731... Val Loss: 0.027918\n",
      "Epoch: 27/100... Step: 2727... Loss: 0.033832... Val Loss: 0.022513\n",
      "Epoch: 27/100... Step: 2728... Loss: 0.042098... Val Loss: 0.010184\n",
      "Epoch: 27/100... Step: 2729... Loss: 0.037693... Val Loss: 0.020988\n",
      "Epoch: 27/100... Step: 2730... Loss: 0.031534... Val Loss: 0.038180\n",
      "Epoch: 27/100... Step: 2731... Loss: 0.026231... Val Loss: 0.025239\n",
      "Epoch: 27/100... Step: 2732... Loss: 0.042013... Val Loss: 0.005353\n",
      "Epoch: 27/100... Step: 2733... Loss: 0.034857... Val Loss: 0.014439\n",
      "Epoch: 27/100... Step: 2734... Loss: 0.035496... Val Loss: 0.010085\n",
      "Epoch: 27/100... Step: 2735... Loss: 0.035760... Val Loss: 0.009692\n",
      "Epoch: 27/100... Step: 2736... Loss: 0.022496... Val Loss: 0.051433\n",
      "Epoch: 27/100... Step: 2737... Loss: 0.026960... Val Loss: 0.035969\n",
      "Epoch: 27/100... Step: 2738... Loss: 0.025682... Val Loss: 0.010515\n",
      "Epoch: 27/100... Step: 2739... Loss: 0.032151... Val Loss: 0.007226\n",
      "Epoch: 27/100... Step: 2740... Loss: 0.023506... Val Loss: 0.007648\n",
      "Epoch: 27/100... Step: 2741... Loss: 0.029600... Val Loss: 0.005513\n",
      "Epoch: 27/100... Step: 2742... Loss: 0.022647... Val Loss: 0.007047\n",
      "Epoch: 27/100... Step: 2743... Loss: 0.039976... Val Loss: 0.008550\n",
      "Epoch: 27/100... Step: 2744... Loss: 0.017421... Val Loss: 0.031660\n",
      "Epoch: 27/100... Step: 2745... Loss: 0.035932... Val Loss: 0.093831\n",
      "Epoch: 27/100... Step: 2746... Loss: 0.050868... Val Loss: 0.103776\n",
      "Epoch: 27/100... Step: 2747... Loss: 0.029877... Val Loss: 0.104892\n",
      "Epoch: 27/100... Step: 2748... Loss: 0.041733... Val Loss: 0.089504\n",
      "Epoch: 27/100... Step: 2749... Loss: 0.033431... Val Loss: 0.038414\n",
      "Epoch: 27/100... Step: 2750... Loss: 0.033188... Val Loss: 0.021571\n",
      "Epoch: 27/100... Step: 2751... Loss: 0.033231... Val Loss: 0.060478\n",
      "Epoch: 27/100... Step: 2752... Loss: 0.038436... Val Loss: 0.085580\n",
      "Epoch: 27/100... Step: 2753... Loss: 0.030219... Val Loss: 0.083456\n",
      "Epoch: 27/100... Step: 2754... Loss: 0.032606... Val Loss: 0.081628\n",
      "Epoch: 27/100... Step: 2755... Loss: 0.036810... Val Loss: 0.074767\n",
      "Epoch: 27/100... Step: 2756... Loss: 0.029974... Val Loss: 0.078677\n",
      "Epoch: 27/100... Step: 2757... Loss: 0.047487... Val Loss: 0.074206\n",
      "Epoch: 27/100... Step: 2758... Loss: 0.036002... Val Loss: 0.068342\n",
      "Epoch: 27/100... Step: 2759... Loss: 0.030789... Val Loss: 0.059915\n",
      "Epoch: 27/100... Step: 2760... Loss: 0.032499... Val Loss: 0.047194\n",
      "Epoch: 27/100... Step: 2761... Loss: 0.044033... Val Loss: 0.029404\n",
      "Epoch: 27/100... Step: 2762... Loss: 0.027570... Val Loss: 0.019204\n",
      "Epoch: 27/100... Step: 2763... Loss: 0.044500... Val Loss: 0.009816\n",
      "Epoch: 27/100... Step: 2764... Loss: 0.025638... Val Loss: 0.023657\n",
      "Epoch: 27/100... Step: 2765... Loss: 0.028258... Val Loss: 0.056405\n",
      "Epoch: 27/100... Step: 2766... Loss: 0.022295... Val Loss: 0.100578\n",
      "Epoch: 27/100... Step: 2767... Loss: 0.047951... Val Loss: 0.130275\n",
      "Epoch: 27/100... Step: 2768... Loss: 0.037786... Val Loss: 0.153419\n",
      "Epoch: 27/100... Step: 2769... Loss: 0.045143... Val Loss: 0.163646\n",
      "Epoch: 27/100... Step: 2770... Loss: 0.027252... Val Loss: 0.170300\n",
      "Epoch: 27/100... Step: 2771... Loss: 0.026608... Val Loss: 0.182568\n",
      "Epoch: 27/100... Step: 2772... Loss: 0.042426... Val Loss: 0.200731\n",
      "Epoch: 27/100... Step: 2773... Loss: 0.017064... Val Loss: 0.217668\n",
      "Epoch: 27/100... Step: 2774... Loss: 0.040737... Val Loss: 0.229741\n",
      "Epoch: 27/100... Step: 2775... Loss: 0.032434... Val Loss: 0.230455\n",
      "Epoch: 27/100... Step: 2776... Loss: 0.029977... Val Loss: 0.217696\n",
      "Epoch: 27/100... Step: 2777... Loss: 0.036944... Val Loss: 0.181132\n",
      "Epoch: 27/100... Step: 2778... Loss: 0.029956... Val Loss: 0.146704\n",
      "Epoch: 27/100... Step: 2779... Loss: 0.048724... Val Loss: 0.117854\n",
      "Epoch: 27/100... Step: 2780... Loss: 0.040127... Val Loss: 0.094062\n",
      "Epoch: 27/100... Step: 2781... Loss: 0.042182... Val Loss: 0.047414\n",
      "Epoch: 27/100... Step: 2782... Loss: 0.027688... Val Loss: 0.021529\n",
      "Epoch: 27/100... Step: 2783... Loss: 0.029857... Val Loss: 0.006003\n",
      "Epoch: 27/100... Step: 2784... Loss: 0.028563... Val Loss: 0.028524\n",
      "Epoch: 27/100... Step: 2785... Loss: 0.029586... Val Loss: 0.050841\n",
      "Epoch: 27/100... Step: 2786... Loss: 0.036827... Val Loss: 0.065167\n",
      "Epoch: 27/100... Step: 2787... Loss: 0.024812... Val Loss: 0.064440\n",
      "Epoch: 27/100... Step: 2788... Loss: 0.015787... Val Loss: 0.076498\n",
      "Epoch: 27/100... Step: 2789... Loss: 0.026385... Val Loss: 0.080647\n",
      "Epoch: 27/100... Step: 2790... Loss: 0.033279... Val Loss: 0.067328\n",
      "Epoch: 27/100... Step: 2791... Loss: 0.031982... Val Loss: 0.060695\n",
      "Epoch: 27/100... Step: 2792... Loss: 0.030057... Val Loss: 0.050462\n",
      "Epoch: 27/100... Step: 2793... Loss: 0.030028... Val Loss: 0.041245\n",
      "Epoch: 27/100... Step: 2794... Loss: 0.015871... Val Loss: 0.031886\n",
      "Epoch: 27/100... Step: 2795... Loss: 0.035414... Val Loss: 0.025936\n",
      "Epoch: 27/100... Step: 2796... Loss: 0.035198... Val Loss: 0.018839\n",
      "Epoch: 27/100... Step: 2797... Loss: 0.035257... Val Loss: 0.027299\n",
      "Epoch: 27/100... Step: 2798... Loss: 0.036257... Val Loss: 0.034844\n",
      "Epoch: 27/100... Step: 2799... Loss: 0.027204... Val Loss: 0.049066\n",
      "Epoch: 27/100... Step: 2800... Loss: 0.021072... Val Loss: 0.079269\n",
      "Epoch: 27/100... Step: 2801... Loss: 0.033563... Val Loss: 0.091346\n",
      "Epoch: 27/100... Step: 2802... Loss: 0.038505... Val Loss: 0.155893\n",
      "Epoch: 27/100... Step: 2803... Loss: 0.034776... Val Loss: 0.202547\n",
      "Epoch: 27/100... Step: 2804... Loss: 0.041743... Val Loss: 0.229806\n",
      "Epoch: 27/100... Step: 2805... Loss: 0.026283... Val Loss: 0.235004\n",
      "Epoch: 27/100... Step: 2806... Loss: 0.039039... Val Loss: 0.212524\n",
      "Epoch: 27/100... Step: 2807... Loss: 0.043092... Val Loss: 0.185875\n",
      "Epoch: 27/100... Step: 2808... Loss: 0.027015... Val Loss: 0.159151\n",
      "Epoch: 28/100... Step: 2809... Loss: 0.018882... Val Loss: 0.073131\n",
      "Epoch: 28/100... Step: 2810... Loss: 0.028805... Val Loss: 0.010112\n",
      "Epoch: 28/100... Step: 2811... Loss: 0.020113... Val Loss: 0.029065\n",
      "Epoch: 28/100... Step: 2812... Loss: 0.018879... Val Loss: 0.093164\n",
      "Epoch: 28/100... Step: 2813... Loss: 0.025473... Val Loss: 0.107586\n",
      "Epoch: 28/100... Step: 2814... Loss: 0.029844... Val Loss: 0.124537\n",
      "Epoch: 28/100... Step: 2815... Loss: 0.030446... Val Loss: 0.127179\n",
      "Epoch: 28/100... Step: 2816... Loss: 0.020605... Val Loss: 0.127821\n",
      "Epoch: 28/100... Step: 2817... Loss: 0.025677... Val Loss: 0.137038\n",
      "Epoch: 28/100... Step: 2818... Loss: 0.033419... Val Loss: 0.143761\n",
      "Epoch: 28/100... Step: 2819... Loss: 0.050788... Val Loss: 0.140306\n",
      "Epoch: 28/100... Step: 2820... Loss: 0.017013... Val Loss: 0.116868\n",
      "Epoch: 28/100... Step: 2821... Loss: 0.032038... Val Loss: 0.106879\n",
      "Epoch: 28/100... Step: 2822... Loss: 0.032096... Val Loss: 0.097670\n",
      "Epoch: 28/100... Step: 2823... Loss: 0.028422... Val Loss: 0.092961\n",
      "Epoch: 28/100... Step: 2824... Loss: 0.029628... Val Loss: 0.081651\n",
      "Epoch: 28/100... Step: 2825... Loss: 0.032744... Val Loss: 0.076214\n",
      "Epoch: 28/100... Step: 2826... Loss: 0.032359... Val Loss: 0.063947\n",
      "Epoch: 28/100... Step: 2827... Loss: 0.038480... Val Loss: 0.064133\n",
      "Epoch: 28/100... Step: 2828... Loss: 0.031369... Val Loss: 0.061882\n",
      "Epoch: 28/100... Step: 2829... Loss: 0.035424... Val Loss: 0.038050\n",
      "Epoch: 28/100... Step: 2830... Loss: 0.037227... Val Loss: 0.011452\n",
      "Epoch: 28/100... Step: 2831... Loss: 0.014877... Val Loss: 0.011239\n",
      "Epoch: 28/100... Step: 2832... Loss: 0.028645... Val Loss: 0.018726\n",
      "Epoch: 28/100... Step: 2833... Loss: 0.032443... Val Loss: 0.018625\n",
      "Epoch: 28/100... Step: 2834... Loss: 0.029154... Val Loss: 0.007779\n",
      "Epoch: 28/100... Step: 2835... Loss: 0.027429... Val Loss: 0.008404\n",
      "Epoch: 28/100... Step: 2836... Loss: 0.030370... Val Loss: 0.015459\n",
      "Epoch: 28/100... Step: 2837... Loss: 0.031377... Val Loss: 0.010882\n",
      "Epoch: 28/100... Step: 2838... Loss: 0.025466... Val Loss: 0.009366\n",
      "Epoch: 28/100... Step: 2839... Loss: 0.030312... Val Loss: 0.011227\n",
      "Epoch: 28/100... Step: 2840... Loss: 0.036204... Val Loss: 0.018207\n",
      "Epoch: 28/100... Step: 2841... Loss: 0.027070... Val Loss: 0.033131\n",
      "Epoch: 28/100... Step: 2842... Loss: 0.035379... Val Loss: 0.048855\n",
      "Epoch: 28/100... Step: 2843... Loss: 0.040665... Val Loss: 0.051186\n",
      "Epoch: 28/100... Step: 2844... Loss: 0.047925... Val Loss: 0.059600\n",
      "Epoch: 28/100... Step: 2845... Loss: 0.026975... Val Loss: 0.072379\n",
      "Epoch: 28/100... Step: 2846... Loss: 0.030702... Val Loss: 0.080615\n",
      "Epoch: 28/100... Step: 2847... Loss: 0.030141... Val Loss: 0.071920\n",
      "Epoch: 28/100... Step: 2848... Loss: 0.025735... Val Loss: 0.067723\n",
      "Epoch: 28/100... Step: 2849... Loss: 0.034645... Val Loss: 0.038270\n",
      "Epoch: 28/100... Step: 2850... Loss: 0.016845... Val Loss: 0.034928\n",
      "Epoch: 28/100... Step: 2851... Loss: 0.023263... Val Loss: 0.034807\n",
      "Epoch: 28/100... Step: 2852... Loss: 0.045267... Val Loss: 0.011229\n",
      "Epoch: 28/100... Step: 2853... Loss: 0.030103... Val Loss: 0.022186\n",
      "Epoch: 28/100... Step: 2854... Loss: 0.027372... Val Loss: 0.027678\n",
      "Epoch: 28/100... Step: 2855... Loss: 0.017102... Val Loss: 0.018359\n",
      "Epoch: 28/100... Step: 2856... Loss: 0.029188... Val Loss: 0.016219\n",
      "Epoch: 28/100... Step: 2857... Loss: 0.033481... Val Loss: 0.044873\n",
      "Epoch: 28/100... Step: 2858... Loss: 0.030732... Val Loss: 0.050098\n",
      "Epoch: 28/100... Step: 2859... Loss: 0.042010... Val Loss: 0.068397\n",
      "Epoch: 28/100... Step: 2860... Loss: 0.064987... Val Loss: 0.067193\n",
      "Epoch: 28/100... Step: 2861... Loss: 0.040752... Val Loss: 0.056025\n",
      "Epoch: 28/100... Step: 2862... Loss: 0.040634... Val Loss: 0.056256\n",
      "Epoch: 28/100... Step: 2863... Loss: 0.035593... Val Loss: 0.072080\n",
      "Epoch: 28/100... Step: 2864... Loss: 0.048780... Val Loss: 0.106174\n",
      "Epoch: 28/100... Step: 2865... Loss: 0.032893... Val Loss: 0.122153\n",
      "Epoch: 28/100... Step: 2866... Loss: 0.026312... Val Loss: 0.121524\n",
      "Epoch: 28/100... Step: 2867... Loss: 0.031959... Val Loss: 0.114673\n",
      "Epoch: 28/100... Step: 2868... Loss: 0.045364... Val Loss: 0.110491\n",
      "Epoch: 28/100... Step: 2869... Loss: 0.041704... Val Loss: 0.099016\n",
      "Epoch: 28/100... Step: 2870... Loss: 0.036066... Val Loss: 0.083410\n",
      "Epoch: 28/100... Step: 2871... Loss: 0.023345... Val Loss: 0.053196\n",
      "Epoch: 28/100... Step: 2872... Loss: 0.036795... Val Loss: 0.020601\n",
      "Epoch: 28/100... Step: 2873... Loss: 0.036340... Val Loss: 0.009160\n",
      "Epoch: 28/100... Step: 2874... Loss: 0.027467... Val Loss: 0.058350\n",
      "Epoch: 28/100... Step: 2875... Loss: 0.036012... Val Loss: 0.064294\n",
      "Epoch: 28/100... Step: 2876... Loss: 0.025713... Val Loss: 0.050519\n",
      "Epoch: 28/100... Step: 2877... Loss: 0.027574... Val Loss: 0.034676\n",
      "Epoch: 28/100... Step: 2878... Loss: 0.033914... Val Loss: 0.030273\n",
      "Epoch: 28/100... Step: 2879... Loss: 0.032637... Val Loss: 0.025508\n",
      "Epoch: 28/100... Step: 2880... Loss: 0.029877... Val Loss: 0.040459\n",
      "Epoch: 28/100... Step: 2881... Loss: 0.043760... Val Loss: 0.054254\n",
      "Epoch: 28/100... Step: 2882... Loss: 0.025868... Val Loss: 0.040983\n",
      "Epoch: 28/100... Step: 2883... Loss: 0.030439... Val Loss: 0.026207\n",
      "Epoch: 28/100... Step: 2884... Loss: 0.061175... Val Loss: 0.004703\n",
      "Epoch: 28/100... Step: 2885... Loss: 0.050907... Val Loss: 0.009789\n",
      "Epoch: 28/100... Step: 2886... Loss: 0.032117... Val Loss: 0.004646\n",
      "Epoch: 28/100... Step: 2887... Loss: 0.031304... Val Loss: 0.003983\n",
      "Epoch: 28/100... Step: 2888... Loss: 0.042530... Val Loss: 0.002821\n",
      "Validation loss decreased (0.003664 --> 0.002821).  Saving model ...\n",
      "Epoch: 28/100... Step: 2889... Loss: 0.024032... Val Loss: 0.002503\n",
      "Validation loss decreased (0.002821 --> 0.002503).  Saving model ...\n",
      "Epoch: 28/100... Step: 2890... Loss: 0.022844... Val Loss: 0.004621\n",
      "Epoch: 28/100... Step: 2891... Loss: 0.022183... Val Loss: 0.003844\n",
      "Epoch: 28/100... Step: 2892... Loss: 0.054562... Val Loss: 0.005694\n",
      "Epoch: 28/100... Step: 2893... Loss: 0.037084... Val Loss: 0.007801\n",
      "Epoch: 28/100... Step: 2894... Loss: 0.019965... Val Loss: 0.013639\n",
      "Epoch: 28/100... Step: 2895... Loss: 0.023870... Val Loss: 0.016482\n",
      "Epoch: 28/100... Step: 2896... Loss: 0.040597... Val Loss: 0.012473\n",
      "Epoch: 28/100... Step: 2897... Loss: 0.020886... Val Loss: 0.008030\n",
      "Epoch: 28/100... Step: 2898... Loss: 0.046587... Val Loss: 0.006789\n",
      "Epoch: 28/100... Step: 2899... Loss: 0.022560... Val Loss: 0.006491\n",
      "Epoch: 28/100... Step: 2900... Loss: 0.036705... Val Loss: 0.023528\n",
      "Epoch: 28/100... Step: 2901... Loss: 0.031123... Val Loss: 0.032259\n",
      "Epoch: 28/100... Step: 2902... Loss: 0.040853... Val Loss: 0.040528\n",
      "Epoch: 28/100... Step: 2903... Loss: 0.021688... Val Loss: 0.035431\n",
      "Epoch: 28/100... Step: 2904... Loss: 0.027800... Val Loss: 0.036030\n",
      "Epoch: 28/100... Step: 2905... Loss: 0.016049... Val Loss: 0.046109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100... Step: 2906... Loss: 0.032648... Val Loss: 0.069641\n",
      "Epoch: 28/100... Step: 2907... Loss: 0.028247... Val Loss: 0.083018\n",
      "Epoch: 28/100... Step: 2908... Loss: 0.038498... Val Loss: 0.080080\n",
      "Epoch: 28/100... Step: 2909... Loss: 0.030324... Val Loss: 0.057599\n",
      "Epoch: 28/100... Step: 2910... Loss: 0.034682... Val Loss: 0.040118\n",
      "Epoch: 28/100... Step: 2911... Loss: 0.025166... Val Loss: 0.034835\n",
      "Epoch: 28/100... Step: 2912... Loss: 0.034512... Val Loss: 0.024028\n",
      "Epoch: 29/100... Step: 2913... Loss: 0.016060... Val Loss: 0.015942\n",
      "Epoch: 29/100... Step: 2914... Loss: 0.017220... Val Loss: 0.028747\n",
      "Epoch: 29/100... Step: 2915... Loss: 0.019435... Val Loss: 0.128128\n",
      "Epoch: 29/100... Step: 2916... Loss: 0.025187... Val Loss: 0.163192\n",
      "Epoch: 29/100... Step: 2917... Loss: 0.024933... Val Loss: 0.227398\n",
      "Epoch: 29/100... Step: 2918... Loss: 0.021828... Val Loss: 0.250352\n",
      "Epoch: 29/100... Step: 2919... Loss: 0.033397... Val Loss: 0.239195\n",
      "Epoch: 29/100... Step: 2920... Loss: 0.030392... Val Loss: 0.258459\n",
      "Epoch: 29/100... Step: 2921... Loss: 0.027518... Val Loss: 0.281142\n",
      "Epoch: 29/100... Step: 2922... Loss: 0.027410... Val Loss: 0.291114\n",
      "Epoch: 29/100... Step: 2923... Loss: 0.033047... Val Loss: 0.308843\n",
      "Epoch: 29/100... Step: 2924... Loss: 0.037604... Val Loss: 0.326583\n",
      "Epoch: 29/100... Step: 2925... Loss: 0.024777... Val Loss: 0.300670\n",
      "Epoch: 29/100... Step: 2926... Loss: 0.026297... Val Loss: 0.282174\n",
      "Epoch: 29/100... Step: 2927... Loss: 0.035586... Val Loss: 0.265946\n",
      "Epoch: 29/100... Step: 2928... Loss: 0.016719... Val Loss: 0.245079\n",
      "Epoch: 29/100... Step: 2929... Loss: 0.023364... Val Loss: 0.213648\n",
      "Epoch: 29/100... Step: 2930... Loss: 0.037492... Val Loss: 0.192316\n",
      "Epoch: 29/100... Step: 2931... Loss: 0.015820... Val Loss: 0.196580\n",
      "Epoch: 29/100... Step: 2932... Loss: 0.021854... Val Loss: 0.206567\n",
      "Epoch: 29/100... Step: 2933... Loss: 0.021312... Val Loss: 0.199077\n",
      "Epoch: 29/100... Step: 2934... Loss: 0.030033... Val Loss: 0.122754\n",
      "Epoch: 29/100... Step: 2935... Loss: 0.028723... Val Loss: 0.150950\n",
      "Epoch: 29/100... Step: 2936... Loss: 0.039069... Val Loss: 0.142233\n",
      "Epoch: 29/100... Step: 2937... Loss: 0.047931... Val Loss: 0.117475\n",
      "Epoch: 29/100... Step: 2938... Loss: 0.036658... Val Loss: 0.083306\n",
      "Epoch: 29/100... Step: 2939... Loss: 0.025700... Val Loss: 0.040875\n",
      "Epoch: 29/100... Step: 2940... Loss: 0.024888... Val Loss: 0.013670\n",
      "Epoch: 29/100... Step: 2941... Loss: 0.038933... Val Loss: 0.019933\n",
      "Epoch: 29/100... Step: 2942... Loss: 0.040978... Val Loss: 0.014486\n",
      "Epoch: 29/100... Step: 2943... Loss: 0.030854... Val Loss: 0.023674\n",
      "Epoch: 29/100... Step: 2944... Loss: 0.034419... Val Loss: 0.026354\n",
      "Epoch: 29/100... Step: 2945... Loss: 0.037102... Val Loss: 0.016244\n",
      "Epoch: 29/100... Step: 2946... Loss: 0.039179... Val Loss: 0.007096\n",
      "Epoch: 29/100... Step: 2947... Loss: 0.025131... Val Loss: 0.008288\n",
      "Epoch: 29/100... Step: 2948... Loss: 0.028161... Val Loss: 0.031304\n",
      "Epoch: 29/100... Step: 2949... Loss: 0.030902... Val Loss: 0.040720\n",
      "Epoch: 29/100... Step: 2950... Loss: 0.029716... Val Loss: 0.039092\n",
      "Epoch: 29/100... Step: 2951... Loss: 0.029790... Val Loss: 0.026145\n",
      "Epoch: 29/100... Step: 2952... Loss: 0.024700... Val Loss: 0.018980\n",
      "Epoch: 29/100... Step: 2953... Loss: 0.038644... Val Loss: 0.016665\n",
      "Epoch: 29/100... Step: 2954... Loss: 0.033402... Val Loss: 0.009890\n",
      "Epoch: 29/100... Step: 2955... Loss: 0.019908... Val Loss: 0.006747\n",
      "Epoch: 29/100... Step: 2956... Loss: 0.038659... Val Loss: 0.004029\n",
      "Epoch: 29/100... Step: 2957... Loss: 0.032739... Val Loss: 0.017636\n",
      "Epoch: 29/100... Step: 2958... Loss: 0.024633... Val Loss: 0.026192\n",
      "Epoch: 29/100... Step: 2959... Loss: 0.022929... Val Loss: 0.038718\n",
      "Epoch: 29/100... Step: 2960... Loss: 0.030652... Val Loss: 0.044316\n",
      "Epoch: 29/100... Step: 2961... Loss: 0.024959... Val Loss: 0.052043\n",
      "Epoch: 29/100... Step: 2962... Loss: 0.026056... Val Loss: 0.058741\n",
      "Epoch: 29/100... Step: 2963... Loss: 0.032248... Val Loss: 0.040966\n",
      "Epoch: 29/100... Step: 2964... Loss: 0.029953... Val Loss: 0.074646\n",
      "Epoch: 29/100... Step: 2965... Loss: 0.028042... Val Loss: 0.077923\n",
      "Epoch: 29/100... Step: 2966... Loss: 0.025648... Val Loss: 0.064679\n",
      "Epoch: 29/100... Step: 2967... Loss: 0.028894... Val Loss: 0.028205\n",
      "Epoch: 29/100... Step: 2968... Loss: 0.031735... Val Loss: 0.005388\n",
      "Epoch: 29/100... Step: 2969... Loss: 0.029580... Val Loss: 0.008710\n",
      "Epoch: 29/100... Step: 2970... Loss: 0.036673... Val Loss: 0.006560\n",
      "Epoch: 29/100... Step: 2971... Loss: 0.034525... Val Loss: 0.007260\n",
      "Epoch: 29/100... Step: 2972... Loss: 0.034966... Val Loss: 0.031539\n",
      "Epoch: 29/100... Step: 2973... Loss: 0.023183... Val Loss: 0.063726\n",
      "Epoch: 29/100... Step: 2974... Loss: 0.034156... Val Loss: 0.091766\n",
      "Epoch: 29/100... Step: 2975... Loss: 0.031453... Val Loss: 0.081803\n",
      "Epoch: 29/100... Step: 2976... Loss: 0.038310... Val Loss: 0.058576\n",
      "Epoch: 29/100... Step: 2977... Loss: 0.051149... Val Loss: 0.038887\n",
      "Epoch: 29/100... Step: 2978... Loss: 0.027134... Val Loss: 0.018856\n",
      "Epoch: 29/100... Step: 2979... Loss: 0.023346... Val Loss: 0.013741\n",
      "Epoch: 29/100... Step: 2980... Loss: 0.038900... Val Loss: 0.049980\n",
      "Epoch: 29/100... Step: 2981... Loss: 0.032209... Val Loss: 0.090335\n",
      "Epoch: 29/100... Step: 2982... Loss: 0.023614... Val Loss: 0.101798\n",
      "Epoch: 29/100... Step: 2983... Loss: 0.022488... Val Loss: 0.100943\n",
      "Epoch: 29/100... Step: 2984... Loss: 0.045963... Val Loss: 0.130708\n",
      "Epoch: 29/100... Step: 2985... Loss: 0.026169... Val Loss: 0.137879\n",
      "Epoch: 29/100... Step: 2986... Loss: 0.046189... Val Loss: 0.138196\n",
      "Epoch: 29/100... Step: 2987... Loss: 0.029527... Val Loss: 0.112782\n",
      "Epoch: 29/100... Step: 2988... Loss: 0.045125... Val Loss: 0.086784\n",
      "Epoch: 29/100... Step: 2989... Loss: 0.036003... Val Loss: 0.051258\n",
      "Epoch: 29/100... Step: 2990... Loss: 0.031079... Val Loss: 0.017314\n",
      "Epoch: 29/100... Step: 2991... Loss: 0.029636... Val Loss: 0.027734\n",
      "Epoch: 29/100... Step: 2992... Loss: 0.045435... Val Loss: 0.044422\n",
      "Epoch: 29/100... Step: 2993... Loss: 0.031112... Val Loss: 0.035926\n",
      "Epoch: 29/100... Step: 2994... Loss: 0.038101... Val Loss: 0.028665\n",
      "Epoch: 29/100... Step: 2995... Loss: 0.044912... Val Loss: 0.007848\n",
      "Epoch: 29/100... Step: 2996... Loss: 0.034047... Val Loss: 0.011518\n",
      "Epoch: 29/100... Step: 2997... Loss: 0.026653... Val Loss: 0.016536\n",
      "Epoch: 29/100... Step: 2998... Loss: 0.044498... Val Loss: 0.026315\n",
      "Epoch: 29/100... Step: 2999... Loss: 0.032454... Val Loss: 0.039049\n",
      "Epoch: 29/100... Step: 3000... Loss: 0.024255... Val Loss: 0.052019\n",
      "Epoch: 29/100... Step: 3001... Loss: 0.027594... Val Loss: 0.057910\n",
      "Epoch: 29/100... Step: 3002... Loss: 0.041247... Val Loss: 0.063561\n",
      "Epoch: 29/100... Step: 3003... Loss: 0.039952... Val Loss: 0.058774\n",
      "Epoch: 29/100... Step: 3004... Loss: 0.032453... Val Loss: 0.067753\n",
      "Epoch: 29/100... Step: 3005... Loss: 0.037958... Val Loss: 0.057850\n",
      "Epoch: 29/100... Step: 3006... Loss: 0.037907... Val Loss: 0.045350\n",
      "Epoch: 29/100... Step: 3007... Loss: 0.027125... Val Loss: 0.021806\n",
      "Epoch: 29/100... Step: 3008... Loss: 0.046274... Val Loss: 0.005790\n",
      "Epoch: 29/100... Step: 3009... Loss: 0.032223... Val Loss: 0.024708\n",
      "Epoch: 29/100... Step: 3010... Loss: 0.027681... Val Loss: 0.038179\n",
      "Epoch: 29/100... Step: 3011... Loss: 0.039107... Val Loss: 0.043960\n",
      "Epoch: 29/100... Step: 3012... Loss: 0.037147... Val Loss: 0.041244\n",
      "Epoch: 29/100... Step: 3013... Loss: 0.032542... Val Loss: 0.062586\n",
      "Epoch: 29/100... Step: 3014... Loss: 0.034477... Val Loss: 0.110650\n",
      "Epoch: 29/100... Step: 3015... Loss: 0.037022... Val Loss: 0.146904\n",
      "Epoch: 29/100... Step: 3016... Loss: 0.033164... Val Loss: 0.161131\n",
      "Epoch: 30/100... Step: 3017... Loss: 0.023325... Val Loss: 0.197535\n",
      "Epoch: 30/100... Step: 3018... Loss: 0.019380... Val Loss: 0.145419\n",
      "Epoch: 30/100... Step: 3019... Loss: 0.021272... Val Loss: 0.050385\n",
      "Epoch: 30/100... Step: 3020... Loss: 0.022173... Val Loss: 0.013302\n",
      "Epoch: 30/100... Step: 3021... Loss: 0.019917... Val Loss: 0.004259\n",
      "Epoch: 30/100... Step: 3022... Loss: 0.023081... Val Loss: 0.005822\n",
      "Epoch: 30/100... Step: 3023... Loss: 0.041662... Val Loss: 0.007362\n",
      "Epoch: 30/100... Step: 3024... Loss: 0.034576... Val Loss: 0.044669\n",
      "Epoch: 30/100... Step: 3025... Loss: 0.036824... Val Loss: 0.051711\n",
      "Epoch: 30/100... Step: 3026... Loss: 0.027363... Val Loss: 0.049972\n",
      "Epoch: 30/100... Step: 3027... Loss: 0.029479... Val Loss: 0.020241\n",
      "Epoch: 30/100... Step: 3028... Loss: 0.027760... Val Loss: 0.023547\n",
      "Epoch: 30/100... Step: 3029... Loss: 0.032161... Val Loss: 0.020361\n",
      "Epoch: 30/100... Step: 3030... Loss: 0.026658... Val Loss: 0.008858\n",
      "Epoch: 30/100... Step: 3031... Loss: 0.016399... Val Loss: 0.025044\n",
      "Epoch: 30/100... Step: 3032... Loss: 0.024032... Val Loss: 0.040754\n",
      "Epoch: 30/100... Step: 3033... Loss: 0.035139... Val Loss: 0.052648\n",
      "Epoch: 30/100... Step: 3034... Loss: 0.018842... Val Loss: 0.033586\n",
      "Epoch: 30/100... Step: 3035... Loss: 0.034604... Val Loss: 0.012587\n",
      "Epoch: 30/100... Step: 3036... Loss: 0.029009... Val Loss: 0.013131\n",
      "Epoch: 30/100... Step: 3037... Loss: 0.034991... Val Loss: 0.018237\n",
      "Epoch: 30/100... Step: 3038... Loss: 0.033819... Val Loss: 0.033752\n",
      "Epoch: 30/100... Step: 3039... Loss: 0.022142... Val Loss: 0.050928\n",
      "Epoch: 30/100... Step: 3040... Loss: 0.027578... Val Loss: 0.057275\n",
      "Epoch: 30/100... Step: 3041... Loss: 0.026909... Val Loss: 0.069969\n",
      "Epoch: 30/100... Step: 3042... Loss: 0.031913... Val Loss: 0.080358\n",
      "Epoch: 30/100... Step: 3043... Loss: 0.035218... Val Loss: 0.077374\n",
      "Epoch: 30/100... Step: 3044... Loss: 0.029796... Val Loss: 0.077578\n",
      "Epoch: 30/100... Step: 3045... Loss: 0.039815... Val Loss: 0.057941\n",
      "Epoch: 30/100... Step: 3046... Loss: 0.031324... Val Loss: 0.048675\n",
      "Epoch: 30/100... Step: 3047... Loss: 0.026992... Val Loss: 0.053453\n",
      "Epoch: 30/100... Step: 3048... Loss: 0.029651... Val Loss: 0.079135\n",
      "Epoch: 30/100... Step: 3049... Loss: 0.036162... Val Loss: 0.085286\n",
      "Epoch: 30/100... Step: 3050... Loss: 0.025796... Val Loss: 0.109342\n",
      "Epoch: 30/100... Step: 3051... Loss: 0.033080... Val Loss: 0.138684\n",
      "Epoch: 30/100... Step: 3052... Loss: 0.022896... Val Loss: 0.151290\n",
      "Epoch: 30/100... Step: 3053... Loss: 0.043656... Val Loss: 0.167575\n",
      "Epoch: 30/100... Step: 3054... Loss: 0.019555... Val Loss: 0.161047\n",
      "Epoch: 30/100... Step: 3055... Loss: 0.018239... Val Loss: 0.125756\n",
      "Epoch: 30/100... Step: 3056... Loss: 0.030418... Val Loss: 0.101631\n",
      "Epoch: 30/100... Step: 3057... Loss: 0.025880... Val Loss: 0.066338\n",
      "Epoch: 30/100... Step: 3058... Loss: 0.041693... Val Loss: 0.044418\n",
      "Epoch: 30/100... Step: 3059... Loss: 0.024420... Val Loss: 0.038921\n",
      "Epoch: 30/100... Step: 3060... Loss: 0.025035... Val Loss: 0.035621\n",
      "Epoch: 30/100... Step: 3061... Loss: 0.039432... Val Loss: 0.029076\n",
      "Epoch: 30/100... Step: 3062... Loss: 0.046928... Val Loss: 0.035885\n",
      "Epoch: 30/100... Step: 3063... Loss: 0.035473... Val Loss: 0.060152\n",
      "Epoch: 30/100... Step: 3064... Loss: 0.056674... Val Loss: 0.093639\n",
      "Epoch: 30/100... Step: 3065... Loss: 0.024892... Val Loss: 0.107665\n",
      "Epoch: 30/100... Step: 3066... Loss: 0.027267... Val Loss: 0.125816\n",
      "Epoch: 30/100... Step: 3067... Loss: 0.044613... Val Loss: 0.133773\n",
      "Epoch: 30/100... Step: 3068... Loss: 0.039623... Val Loss: 0.132419\n",
      "Epoch: 30/100... Step: 3069... Loss: 0.041655... Val Loss: 0.108869\n",
      "Epoch: 30/100... Step: 3070... Loss: 0.033190... Val Loss: 0.099157\n",
      "Epoch: 30/100... Step: 3071... Loss: 0.039874... Val Loss: 0.065201\n",
      "Epoch: 30/100... Step: 3072... Loss: 0.034066... Val Loss: 0.047893\n",
      "Epoch: 30/100... Step: 3073... Loss: 0.024912... Val Loss: 0.038223\n",
      "Epoch: 30/100... Step: 3074... Loss: 0.037863... Val Loss: 0.008116\n",
      "Epoch: 30/100... Step: 3075... Loss: 0.034000... Val Loss: 0.026056\n",
      "Epoch: 30/100... Step: 3076... Loss: 0.032934... Val Loss: 0.030437\n",
      "Epoch: 30/100... Step: 3077... Loss: 0.037806... Val Loss: 0.073145\n",
      "Epoch: 30/100... Step: 3078... Loss: 0.036091... Val Loss: 0.061633\n",
      "Epoch: 30/100... Step: 3079... Loss: 0.023836... Val Loss: 0.071993\n",
      "Epoch: 30/100... Step: 3080... Loss: 0.032261... Val Loss: 0.078063\n",
      "Epoch: 30/100... Step: 3081... Loss: 0.035410... Val Loss: 0.070249\n",
      "Epoch: 30/100... Step: 3082... Loss: 0.030580... Val Loss: 0.056002\n",
      "Epoch: 30/100... Step: 3083... Loss: 0.037632... Val Loss: 0.028038\n",
      "Epoch: 30/100... Step: 3084... Loss: 0.023352... Val Loss: 0.021331\n",
      "Epoch: 30/100... Step: 3085... Loss: 0.040055... Val Loss: 0.013241\n",
      "Epoch: 30/100... Step: 3086... Loss: 0.039049... Val Loss: 0.007505\n",
      "Epoch: 30/100... Step: 3087... Loss: 0.030442... Val Loss: 0.049945\n",
      "Epoch: 30/100... Step: 3088... Loss: 0.034126... Val Loss: 0.067255\n",
      "Epoch: 30/100... Step: 3089... Loss: 0.033107... Val Loss: 0.098705\n",
      "Epoch: 30/100... Step: 3090... Loss: 0.026983... Val Loss: 0.126007\n",
      "Epoch: 30/100... Step: 3091... Loss: 0.037895... Val Loss: 0.135198\n",
      "Epoch: 30/100... Step: 3092... Loss: 0.043646... Val Loss: 0.106523\n",
      "Epoch: 30/100... Step: 3093... Loss: 0.036722... Val Loss: 0.087551\n",
      "Epoch: 30/100... Step: 3094... Loss: 0.032965... Val Loss: 0.079498\n",
      "Epoch: 30/100... Step: 3095... Loss: 0.015804... Val Loss: 0.062704\n",
      "Epoch: 30/100... Step: 3096... Loss: 0.035482... Val Loss: 0.070481\n",
      "Epoch: 30/100... Step: 3097... Loss: 0.031209... Val Loss: 0.082858\n",
      "Epoch: 30/100... Step: 3098... Loss: 0.037742... Val Loss: 0.071324\n",
      "Epoch: 30/100... Step: 3099... Loss: 0.044828... Val Loss: 0.054473\n",
      "Epoch: 30/100... Step: 3100... Loss: 0.042212... Val Loss: 0.043816\n",
      "Epoch: 30/100... Step: 3101... Loss: 0.044557... Val Loss: 0.033378\n",
      "Epoch: 30/100... Step: 3102... Loss: 0.027427... Val Loss: 0.032413\n",
      "Epoch: 30/100... Step: 3103... Loss: 0.018454... Val Loss: 0.011227\n",
      "Epoch: 30/100... Step: 3104... Loss: 0.040440... Val Loss: 0.005524\n",
      "Epoch: 30/100... Step: 3105... Loss: 0.028125... Val Loss: 0.018969\n",
      "Epoch: 30/100... Step: 3106... Loss: 0.019017... Val Loss: 0.013891\n",
      "Epoch: 30/100... Step: 3107... Loss: 0.033761... Val Loss: 0.013205\n",
      "Epoch: 30/100... Step: 3108... Loss: 0.023077... Val Loss: 0.028994\n",
      "Epoch: 30/100... Step: 3109... Loss: 0.035909... Val Loss: 0.038400\n",
      "Epoch: 30/100... Step: 3110... Loss: 0.025366... Val Loss: 0.035846\n",
      "Epoch: 30/100... Step: 3111... Loss: 0.033569... Val Loss: 0.039811\n",
      "Epoch: 30/100... Step: 3112... Loss: 0.033625... Val Loss: 0.047884\n",
      "Epoch: 30/100... Step: 3113... Loss: 0.035214... Val Loss: 0.044982\n",
      "Epoch: 30/100... Step: 3114... Loss: 0.035373... Val Loss: 0.045317\n",
      "Epoch: 30/100... Step: 3115... Loss: 0.037843... Val Loss: 0.050970\n",
      "Epoch: 30/100... Step: 3116... Loss: 0.045753... Val Loss: 0.052070\n",
      "Epoch: 30/100... Step: 3117... Loss: 0.033900... Val Loss: 0.058021\n",
      "Epoch: 30/100... Step: 3118... Loss: 0.031147... Val Loss: 0.045448\n",
      "Epoch: 30/100... Step: 3119... Loss: 0.031602... Val Loss: 0.075863\n",
      "Epoch: 30/100... Step: 3120... Loss: 0.025412... Val Loss: 0.112749\n",
      "Epoch: 31/100... Step: 3121... Loss: 0.015450... Val Loss: 0.097470\n",
      "Epoch: 31/100... Step: 3122... Loss: 0.013116... Val Loss: 0.133753\n",
      "Epoch: 31/100... Step: 3123... Loss: 0.025263... Val Loss: 0.052367\n",
      "Epoch: 31/100... Step: 3124... Loss: 0.018276... Val Loss: 0.006598\n",
      "Epoch: 31/100... Step: 3125... Loss: 0.036518... Val Loss: 0.034974\n",
      "Epoch: 31/100... Step: 3126... Loss: 0.035025... Val Loss: 0.019059\n",
      "Epoch: 31/100... Step: 3127... Loss: 0.029721... Val Loss: 0.023973\n",
      "Epoch: 31/100... Step: 3128... Loss: 0.020129... Val Loss: 0.085041\n",
      "Epoch: 31/100... Step: 3129... Loss: 0.038661... Val Loss: 0.140577\n",
      "Epoch: 31/100... Step: 3130... Loss: 0.039685... Val Loss: 0.140892\n",
      "Epoch: 31/100... Step: 3131... Loss: 0.022576... Val Loss: 0.125571\n",
      "Epoch: 31/100... Step: 3132... Loss: 0.033582... Val Loss: 0.126538\n",
      "Epoch: 31/100... Step: 3133... Loss: 0.022132... Val Loss: 0.130017\n",
      "Epoch: 31/100... Step: 3134... Loss: 0.018323... Val Loss: 0.108072\n",
      "Epoch: 31/100... Step: 3135... Loss: 0.020873... Val Loss: 0.107838\n",
      "Epoch: 31/100... Step: 3136... Loss: 0.027313... Val Loss: 0.101614\n",
      "Epoch: 31/100... Step: 3137... Loss: 0.026779... Val Loss: 0.083036\n",
      "Epoch: 31/100... Step: 3138... Loss: 0.028490... Val Loss: 0.100008\n",
      "Epoch: 31/100... Step: 3139... Loss: 0.032597... Val Loss: 0.116185\n",
      "Epoch: 31/100... Step: 3140... Loss: 0.040315... Val Loss: 0.049868\n",
      "Epoch: 31/100... Step: 3141... Loss: 0.033900... Val Loss: 0.089245\n",
      "Epoch: 31/100... Step: 3142... Loss: 0.032582... Val Loss: 0.069483\n",
      "Epoch: 31/100... Step: 3143... Loss: 0.030537... Val Loss: 0.039329\n",
      "Epoch: 31/100... Step: 3144... Loss: 0.031834... Val Loss: 0.043416\n",
      "Epoch: 31/100... Step: 3145... Loss: 0.033230... Val Loss: 0.026921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100... Step: 3146... Loss: 0.050334... Val Loss: 0.019777\n",
      "Epoch: 31/100... Step: 3147... Loss: 0.036077... Val Loss: 0.039430\n",
      "Epoch: 31/100... Step: 3148... Loss: 0.051407... Val Loss: 0.053521\n",
      "Epoch: 31/100... Step: 3149... Loss: 0.041021... Val Loss: 0.034610\n",
      "Epoch: 31/100... Step: 3150... Loss: 0.023589... Val Loss: 0.025289\n",
      "Epoch: 31/100... Step: 3151... Loss: 0.031501... Val Loss: 0.029877\n",
      "Epoch: 31/100... Step: 3152... Loss: 0.029137... Val Loss: 0.028860\n",
      "Epoch: 31/100... Step: 3153... Loss: 0.046009... Val Loss: 0.024213\n",
      "Epoch: 31/100... Step: 3154... Loss: 0.035861... Val Loss: 0.022064\n",
      "Epoch: 31/100... Step: 3155... Loss: 0.025591... Val Loss: 0.040080\n",
      "Epoch: 31/100... Step: 3156... Loss: 0.043468... Val Loss: 0.063845\n",
      "Epoch: 31/100... Step: 3157... Loss: 0.027241... Val Loss: 0.073485\n",
      "Epoch: 31/100... Step: 3158... Loss: 0.035479... Val Loss: 0.055227\n",
      "Epoch: 31/100... Step: 3159... Loss: 0.024067... Val Loss: 0.029259\n",
      "Epoch: 31/100... Step: 3160... Loss: 0.030779... Val Loss: 0.026762\n",
      "Epoch: 31/100... Step: 3161... Loss: 0.029144... Val Loss: 0.017752\n",
      "Epoch: 31/100... Step: 3162... Loss: 0.032755... Val Loss: 0.015908\n",
      "Epoch: 31/100... Step: 3163... Loss: 0.036647... Val Loss: 0.021709\n",
      "Epoch: 31/100... Step: 3164... Loss: 0.025025... Val Loss: 0.013436\n",
      "Epoch: 31/100... Step: 3165... Loss: 0.024473... Val Loss: 0.028620\n",
      "Epoch: 31/100... Step: 3166... Loss: 0.027071... Val Loss: 0.029186\n",
      "Epoch: 31/100... Step: 3167... Loss: 0.028823... Val Loss: 0.040893\n",
      "Epoch: 31/100... Step: 3168... Loss: 0.035386... Val Loss: 0.041000\n",
      "Epoch: 31/100... Step: 3169... Loss: 0.025391... Val Loss: 0.046368\n",
      "Epoch: 31/100... Step: 3170... Loss: 0.029634... Val Loss: 0.046449\n",
      "Epoch: 31/100... Step: 3171... Loss: 0.027466... Val Loss: 0.048270\n",
      "Epoch: 31/100... Step: 3172... Loss: 0.023804... Val Loss: 0.061029\n",
      "Epoch: 31/100... Step: 3173... Loss: 0.027450... Val Loss: 0.070974\n",
      "Epoch: 31/100... Step: 3174... Loss: 0.041805... Val Loss: 0.043572\n",
      "Epoch: 31/100... Step: 3175... Loss: 0.031463... Val Loss: 0.039525\n",
      "Epoch: 31/100... Step: 3176... Loss: 0.049766... Val Loss: 0.038714\n",
      "Epoch: 31/100... Step: 3177... Loss: 0.026666... Val Loss: 0.038932\n",
      "Epoch: 31/100... Step: 3178... Loss: 0.019138... Val Loss: 0.048602\n",
      "Epoch: 31/100... Step: 3179... Loss: 0.031788... Val Loss: 0.028233\n",
      "Epoch: 31/100... Step: 3180... Loss: 0.026917... Val Loss: 0.013057\n",
      "Epoch: 31/100... Step: 3181... Loss: 0.017076... Val Loss: 0.032395\n",
      "Epoch: 31/100... Step: 3182... Loss: 0.037297... Val Loss: 0.037342\n",
      "Epoch: 31/100... Step: 3183... Loss: 0.033052... Val Loss: 0.035130\n",
      "Epoch: 31/100... Step: 3184... Loss: 0.046427... Val Loss: 0.031176\n",
      "Epoch: 31/100... Step: 3185... Loss: 0.033033... Val Loss: 0.023773\n",
      "Epoch: 31/100... Step: 3186... Loss: 0.037352... Val Loss: 0.042160\n",
      "Epoch: 31/100... Step: 3187... Loss: 0.018112... Val Loss: 0.041057\n",
      "Epoch: 31/100... Step: 3188... Loss: 0.032535... Val Loss: 0.028037\n",
      "Epoch: 31/100... Step: 3189... Loss: 0.028459... Val Loss: 0.031821\n",
      "Epoch: 31/100... Step: 3190... Loss: 0.033093... Val Loss: 0.040333\n",
      "Epoch: 31/100... Step: 3191... Loss: 0.030195... Val Loss: 0.050434\n",
      "Epoch: 31/100... Step: 3192... Loss: 0.029666... Val Loss: 0.060425\n",
      "Epoch: 31/100... Step: 3193... Loss: 0.028597... Val Loss: 0.067638\n",
      "Epoch: 31/100... Step: 3194... Loss: 0.039991... Val Loss: 0.061128\n",
      "Epoch: 31/100... Step: 3195... Loss: 0.035051... Val Loss: 0.051187\n",
      "Epoch: 31/100... Step: 3196... Loss: 0.032146... Val Loss: 0.030087\n",
      "Epoch: 31/100... Step: 3197... Loss: 0.022746... Val Loss: 0.036951\n",
      "Epoch: 31/100... Step: 3198... Loss: 0.023865... Val Loss: 0.069952\n",
      "Epoch: 31/100... Step: 3199... Loss: 0.022532... Val Loss: 0.114692\n",
      "Epoch: 31/100... Step: 3200... Loss: 0.046393... Val Loss: 0.153061\n",
      "Epoch: 31/100... Step: 3201... Loss: 0.026466... Val Loss: 0.171421\n",
      "Epoch: 31/100... Step: 3202... Loss: 0.029655... Val Loss: 0.189271\n",
      "Epoch: 31/100... Step: 3203... Loss: 0.026425... Val Loss: 0.190246\n",
      "Epoch: 31/100... Step: 3204... Loss: 0.036815... Val Loss: 0.160755\n",
      "Epoch: 31/100... Step: 3205... Loss: 0.034850... Val Loss: 0.134296\n",
      "Epoch: 31/100... Step: 3206... Loss: 0.023550... Val Loss: 0.121672\n",
      "Epoch: 31/100... Step: 3207... Loss: 0.034591... Val Loss: 0.115656\n",
      "Epoch: 31/100... Step: 3208... Loss: 0.042161... Val Loss: 0.106412\n",
      "Epoch: 31/100... Step: 3209... Loss: 0.031933... Val Loss: 0.094267\n",
      "Epoch: 31/100... Step: 3210... Loss: 0.042389... Val Loss: 0.091359\n",
      "Epoch: 31/100... Step: 3211... Loss: 0.028314... Val Loss: 0.101985\n",
      "Epoch: 31/100... Step: 3212... Loss: 0.033402... Val Loss: 0.094609\n",
      "Epoch: 31/100... Step: 3213... Loss: 0.027972... Val Loss: 0.087868\n",
      "Epoch: 31/100... Step: 3214... Loss: 0.027837... Val Loss: 0.076232\n",
      "Epoch: 31/100... Step: 3215... Loss: 0.028902... Val Loss: 0.057081\n",
      "Epoch: 31/100... Step: 3216... Loss: 0.026627... Val Loss: 0.061855\n",
      "Epoch: 31/100... Step: 3217... Loss: 0.033243... Val Loss: 0.056318\n",
      "Epoch: 31/100... Step: 3218... Loss: 0.028154... Val Loss: 0.045470\n",
      "Epoch: 31/100... Step: 3219... Loss: 0.029460... Val Loss: 0.024843\n",
      "Epoch: 31/100... Step: 3220... Loss: 0.021370... Val Loss: 0.021107\n",
      "Epoch: 31/100... Step: 3221... Loss: 0.028625... Val Loss: 0.012625\n",
      "Epoch: 31/100... Step: 3222... Loss: 0.042177... Val Loss: 0.025038\n",
      "Epoch: 31/100... Step: 3223... Loss: 0.038468... Val Loss: 0.063981\n",
      "Epoch: 31/100... Step: 3224... Loss: 0.026763... Val Loss: 0.097256\n",
      "Epoch: 32/100... Step: 3225... Loss: 0.019388... Val Loss: 0.064078\n",
      "Epoch: 32/100... Step: 3226... Loss: 0.026970... Val Loss: 0.179783\n",
      "Epoch: 32/100... Step: 3227... Loss: 0.024160... Val Loss: 0.133315\n",
      "Epoch: 32/100... Step: 3228... Loss: 0.026052... Val Loss: 0.087861\n",
      "Epoch: 32/100... Step: 3229... Loss: 0.019984... Val Loss: 0.066697\n",
      "Epoch: 32/100... Step: 3230... Loss: 0.022990... Val Loss: 0.051631\n",
      "Epoch: 32/100... Step: 3231... Loss: 0.027084... Val Loss: 0.057278\n",
      "Epoch: 32/100... Step: 3232... Loss: 0.034459... Val Loss: 0.042899\n",
      "Epoch: 32/100... Step: 3233... Loss: 0.015660... Val Loss: 0.038649\n",
      "Epoch: 32/100... Step: 3234... Loss: 0.027134... Val Loss: 0.032821\n",
      "Epoch: 32/100... Step: 3235... Loss: 0.039985... Val Loss: 0.006733\n",
      "Epoch: 32/100... Step: 3236... Loss: 0.028460... Val Loss: 0.019886\n",
      "Epoch: 32/100... Step: 3237... Loss: 0.033176... Val Loss: 0.031116\n",
      "Epoch: 32/100... Step: 3238... Loss: 0.022874... Val Loss: 0.026415\n",
      "Epoch: 32/100... Step: 3239... Loss: 0.032236... Val Loss: 0.022759\n",
      "Epoch: 32/100... Step: 3240... Loss: 0.023724... Val Loss: 0.029528\n",
      "Epoch: 32/100... Step: 3241... Loss: 0.018943... Val Loss: 0.049858\n",
      "Epoch: 32/100... Step: 3242... Loss: 0.025698... Val Loss: 0.058522\n",
      "Epoch: 32/100... Step: 3243... Loss: 0.026253... Val Loss: 0.064153\n",
      "Epoch: 32/100... Step: 3244... Loss: 0.017478... Val Loss: 0.064645\n",
      "Epoch: 32/100... Step: 3245... Loss: 0.021298... Val Loss: 0.054170\n",
      "Epoch: 32/100... Step: 3246... Loss: 0.023279... Val Loss: 0.057321\n",
      "Epoch: 32/100... Step: 3247... Loss: 0.026058... Val Loss: 0.081266\n",
      "Epoch: 32/100... Step: 3248... Loss: 0.016222... Val Loss: 0.093805\n",
      "Epoch: 32/100... Step: 3249... Loss: 0.031109... Val Loss: 0.082871\n",
      "Epoch: 32/100... Step: 3250... Loss: 0.033097... Val Loss: 0.100231\n",
      "Epoch: 32/100... Step: 3251... Loss: 0.027095... Val Loss: 0.094455\n",
      "Epoch: 32/100... Step: 3252... Loss: 0.026545... Val Loss: 0.080020\n",
      "Epoch: 32/100... Step: 3253... Loss: 0.037135... Val Loss: 0.089011\n",
      "Epoch: 32/100... Step: 3254... Loss: 0.033030... Val Loss: 0.057503\n",
      "Epoch: 32/100... Step: 3255... Loss: 0.026061... Val Loss: 0.062053\n",
      "Epoch: 32/100... Step: 3256... Loss: 0.022819... Val Loss: 0.067671\n",
      "Epoch: 32/100... Step: 3257... Loss: 0.047893... Val Loss: 0.058158\n",
      "Epoch: 32/100... Step: 3258... Loss: 0.038165... Val Loss: 0.036224\n",
      "Epoch: 32/100... Step: 3259... Loss: 0.043480... Val Loss: 0.095521\n",
      "Epoch: 32/100... Step: 3260... Loss: 0.029622... Val Loss: 0.124143\n",
      "Epoch: 32/100... Step: 3261... Loss: 0.036997... Val Loss: 0.129808\n",
      "Epoch: 32/100... Step: 3262... Loss: 0.027558... Val Loss: 0.136381\n",
      "Epoch: 32/100... Step: 3263... Loss: 0.046241... Val Loss: 0.121624\n",
      "Epoch: 32/100... Step: 3264... Loss: 0.034013... Val Loss: 0.113115\n",
      "Epoch: 32/100... Step: 3265... Loss: 0.036030... Val Loss: 0.113357\n",
      "Epoch: 32/100... Step: 3266... Loss: 0.021492... Val Loss: 0.087518\n",
      "Epoch: 32/100... Step: 3267... Loss: 0.027544... Val Loss: 0.062196\n",
      "Epoch: 32/100... Step: 3268... Loss: 0.039517... Val Loss: 0.045577\n",
      "Epoch: 32/100... Step: 3269... Loss: 0.049973... Val Loss: 0.029553\n",
      "Epoch: 32/100... Step: 3270... Loss: 0.031326... Val Loss: 0.010023\n",
      "Epoch: 32/100... Step: 3271... Loss: 0.037084... Val Loss: 0.010156\n",
      "Epoch: 32/100... Step: 3272... Loss: 0.033788... Val Loss: 0.057825\n",
      "Epoch: 32/100... Step: 3273... Loss: 0.030362... Val Loss: 0.070154\n",
      "Epoch: 32/100... Step: 3274... Loss: 0.041482... Val Loss: 0.093157\n",
      "Epoch: 32/100... Step: 3275... Loss: 0.033977... Val Loss: 0.068386\n",
      "Epoch: 32/100... Step: 3276... Loss: 0.013315... Val Loss: 0.087304\n",
      "Epoch: 32/100... Step: 3277... Loss: 0.042856... Val Loss: 0.079898\n",
      "Epoch: 32/100... Step: 3278... Loss: 0.021459... Val Loss: 0.083200\n",
      "Epoch: 32/100... Step: 3279... Loss: 0.030026... Val Loss: 0.101506\n",
      "Epoch: 32/100... Step: 3280... Loss: 0.029892... Val Loss: 0.104758\n",
      "Epoch: 32/100... Step: 3281... Loss: 0.026278... Val Loss: 0.087853\n",
      "Epoch: 32/100... Step: 3282... Loss: 0.025265... Val Loss: 0.061613\n",
      "Epoch: 32/100... Step: 3283... Loss: 0.040228... Val Loss: 0.023029\n",
      "Epoch: 32/100... Step: 3284... Loss: 0.025033... Val Loss: 0.048265\n",
      "Epoch: 32/100... Step: 3285... Loss: 0.017406... Val Loss: 0.038490\n",
      "Epoch: 32/100... Step: 3286... Loss: 0.026639... Val Loss: 0.022967\n",
      "Epoch: 32/100... Step: 3287... Loss: 0.027430... Val Loss: 0.004553\n",
      "Epoch: 32/100... Step: 3288... Loss: 0.033840... Val Loss: 0.036750\n",
      "Epoch: 32/100... Step: 3289... Loss: 0.036158... Val Loss: 0.065818\n",
      "Epoch: 32/100... Step: 3290... Loss: 0.019853... Val Loss: 0.102440\n",
      "Epoch: 32/100... Step: 3291... Loss: 0.038985... Val Loss: 0.130474\n",
      "Epoch: 32/100... Step: 3292... Loss: 0.042357... Val Loss: 0.151236\n",
      "Epoch: 32/100... Step: 3293... Loss: 0.020852... Val Loss: 0.151457\n",
      "Epoch: 32/100... Step: 3294... Loss: 0.042385... Val Loss: 0.145518\n",
      "Epoch: 32/100... Step: 3295... Loss: 0.040500... Val Loss: 0.147354\n",
      "Epoch: 32/100... Step: 3296... Loss: 0.031859... Val Loss: 0.142532\n",
      "Epoch: 32/100... Step: 3297... Loss: 0.031140... Val Loss: 0.139113\n",
      "Epoch: 32/100... Step: 3298... Loss: 0.034256... Val Loss: 0.161498\n",
      "Epoch: 32/100... Step: 3299... Loss: 0.024214... Val Loss: 0.177798\n",
      "Epoch: 32/100... Step: 3300... Loss: 0.026667... Val Loss: 0.204389\n",
      "Epoch: 32/100... Step: 3301... Loss: 0.030333... Val Loss: 0.197518\n",
      "Epoch: 32/100... Step: 3302... Loss: 0.034230... Val Loss: 0.197323\n",
      "Epoch: 32/100... Step: 3303... Loss: 0.018874... Val Loss: 0.214237\n",
      "Epoch: 32/100... Step: 3304... Loss: 0.033724... Val Loss: 0.227912\n",
      "Epoch: 32/100... Step: 3305... Loss: 0.045703... Val Loss: 0.215132\n",
      "Epoch: 32/100... Step: 3306... Loss: 0.035187... Val Loss: 0.192954\n",
      "Epoch: 32/100... Step: 3307... Loss: 0.046239... Val Loss: 0.197066\n",
      "Epoch: 32/100... Step: 3308... Loss: 0.027362... Val Loss: 0.206798\n",
      "Epoch: 32/100... Step: 3309... Loss: 0.014887... Val Loss: 0.216811\n",
      "Epoch: 32/100... Step: 3310... Loss: 0.026506... Val Loss: 0.207477\n",
      "Epoch: 32/100... Step: 3311... Loss: 0.030687... Val Loss: 0.171539\n",
      "Epoch: 32/100... Step: 3312... Loss: 0.045307... Val Loss: 0.119579\n",
      "Epoch: 32/100... Step: 3313... Loss: 0.037088... Val Loss: 0.093425\n",
      "Epoch: 32/100... Step: 3314... Loss: 0.024538... Val Loss: 0.048174\n",
      "Epoch: 32/100... Step: 3315... Loss: 0.026731... Val Loss: 0.039557\n",
      "Epoch: 32/100... Step: 3316... Loss: 0.022980... Val Loss: 0.035189\n",
      "Epoch: 32/100... Step: 3317... Loss: 0.045981... Val Loss: 0.035570\n",
      "Epoch: 32/100... Step: 3318... Loss: 0.023219... Val Loss: 0.044494\n",
      "Epoch: 32/100... Step: 3319... Loss: 0.030903... Val Loss: 0.047137\n",
      "Epoch: 32/100... Step: 3320... Loss: 0.033027... Val Loss: 0.048930\n",
      "Epoch: 32/100... Step: 3321... Loss: 0.023060... Val Loss: 0.060442\n",
      "Epoch: 32/100... Step: 3322... Loss: 0.033373... Val Loss: 0.060585\n",
      "Epoch: 32/100... Step: 3323... Loss: 0.025107... Val Loss: 0.043884\n",
      "Epoch: 32/100... Step: 3324... Loss: 0.040431... Val Loss: 0.060344\n",
      "Epoch: 32/100... Step: 3325... Loss: 0.029097... Val Loss: 0.074991\n",
      "Epoch: 32/100... Step: 3326... Loss: 0.036819... Val Loss: 0.074280\n",
      "Epoch: 32/100... Step: 3327... Loss: 0.027885... Val Loss: 0.072374\n",
      "Epoch: 32/100... Step: 3328... Loss: 0.033228... Val Loss: 0.064132\n",
      "Epoch: 33/100... Step: 3329... Loss: 0.032329... Val Loss: 0.021046\n",
      "Epoch: 33/100... Step: 3330... Loss: 0.030376... Val Loss: 0.082800\n",
      "Epoch: 33/100... Step: 3331... Loss: 0.018577... Val Loss: 0.080542\n",
      "Epoch: 33/100... Step: 3332... Loss: 0.024418... Val Loss: 0.090232\n",
      "Epoch: 33/100... Step: 3333... Loss: 0.021802... Val Loss: 0.146212\n",
      "Epoch: 33/100... Step: 3334... Loss: 0.038138... Val Loss: 0.203096\n",
      "Epoch: 33/100... Step: 3335... Loss: 0.029211... Val Loss: 0.143634\n",
      "Epoch: 33/100... Step: 3336... Loss: 0.032778... Val Loss: 0.126999\n",
      "Epoch: 33/100... Step: 3337... Loss: 0.046060... Val Loss: 0.094112\n",
      "Epoch: 33/100... Step: 3338... Loss: 0.044371... Val Loss: 0.111158\n",
      "Epoch: 33/100... Step: 3339... Loss: 0.048760... Val Loss: 0.127931\n",
      "Epoch: 33/100... Step: 3340... Loss: 0.031685... Val Loss: 0.109043\n",
      "Epoch: 33/100... Step: 3341... Loss: 0.023710... Val Loss: 0.101296\n",
      "Epoch: 33/100... Step: 3342... Loss: 0.020069... Val Loss: 0.097044\n",
      "Epoch: 33/100... Step: 3343... Loss: 0.037101... Val Loss: 0.101152\n",
      "Epoch: 33/100... Step: 3344... Loss: 0.040104... Val Loss: 0.086934\n",
      "Epoch: 33/100... Step: 3345... Loss: 0.033027... Val Loss: 0.045219\n",
      "Epoch: 33/100... Step: 3346... Loss: 0.042380... Val Loss: 0.049002\n",
      "Epoch: 33/100... Step: 3347... Loss: 0.036150... Val Loss: 0.038286\n",
      "Epoch: 33/100... Step: 3348... Loss: 0.031231... Val Loss: 0.009989\n",
      "Epoch: 33/100... Step: 3349... Loss: 0.017528... Val Loss: 0.024739\n",
      "Epoch: 33/100... Step: 3350... Loss: 0.033653... Val Loss: 0.045092\n",
      "Epoch: 33/100... Step: 3351... Loss: 0.030143... Val Loss: 0.048004\n",
      "Epoch: 33/100... Step: 3352... Loss: 0.034681... Val Loss: 0.032163\n",
      "Epoch: 33/100... Step: 3353... Loss: 0.026275... Val Loss: 0.023115\n",
      "Epoch: 33/100... Step: 3354... Loss: 0.019974... Val Loss: 0.029311\n",
      "Epoch: 33/100... Step: 3355... Loss: 0.024692... Val Loss: 0.047783\n",
      "Epoch: 33/100... Step: 3356... Loss: 0.032236... Val Loss: 0.071670\n",
      "Epoch: 33/100... Step: 3357... Loss: 0.019970... Val Loss: 0.094908\n",
      "Epoch: 33/100... Step: 3358... Loss: 0.042673... Val Loss: 0.101021\n",
      "Epoch: 33/100... Step: 3359... Loss: 0.039951... Val Loss: 0.118958\n",
      "Epoch: 33/100... Step: 3360... Loss: 0.042999... Val Loss: 0.118312\n",
      "Epoch: 33/100... Step: 3361... Loss: 0.013684... Val Loss: 0.113301\n",
      "Epoch: 33/100... Step: 3362... Loss: 0.034389... Val Loss: 0.084958\n",
      "Epoch: 33/100... Step: 3363... Loss: 0.030897... Val Loss: 0.057213\n",
      "Epoch: 33/100... Step: 3364... Loss: 0.025292... Val Loss: 0.042374\n",
      "Epoch: 33/100... Step: 3365... Loss: 0.026785... Val Loss: 0.033776\n",
      "Epoch: 33/100... Step: 3366... Loss: 0.031591... Val Loss: 0.030888\n",
      "Epoch: 33/100... Step: 3367... Loss: 0.022688... Val Loss: 0.029220\n",
      "Epoch: 33/100... Step: 3368... Loss: 0.029117... Val Loss: 0.033564\n",
      "Epoch: 33/100... Step: 3369... Loss: 0.025350... Val Loss: 0.035236\n",
      "Epoch: 33/100... Step: 3370... Loss: 0.020363... Val Loss: 0.027442\n",
      "Epoch: 33/100... Step: 3371... Loss: 0.026148... Val Loss: 0.044595\n",
      "Epoch: 33/100... Step: 3372... Loss: 0.028789... Val Loss: 0.042923\n",
      "Epoch: 33/100... Step: 3373... Loss: 0.015378... Val Loss: 0.026298\n",
      "Epoch: 33/100... Step: 3374... Loss: 0.023045... Val Loss: 0.009227\n",
      "Epoch: 33/100... Step: 3375... Loss: 0.027165... Val Loss: 0.037809\n",
      "Epoch: 33/100... Step: 3376... Loss: 0.033456... Val Loss: 0.070284\n",
      "Epoch: 33/100... Step: 3377... Loss: 0.037727... Val Loss: 0.088144\n",
      "Epoch: 33/100... Step: 3378... Loss: 0.022498... Val Loss: 0.058939\n",
      "Epoch: 33/100... Step: 3379... Loss: 0.040586... Val Loss: 0.038507\n",
      "Epoch: 33/100... Step: 3380... Loss: 0.022540... Val Loss: 0.020630\n",
      "Epoch: 33/100... Step: 3381... Loss: 0.030570... Val Loss: 0.010532\n",
      "Epoch: 33/100... Step: 3382... Loss: 0.021167... Val Loss: 0.009972\n",
      "Epoch: 33/100... Step: 3383... Loss: 0.022301... Val Loss: 0.011833\n",
      "Epoch: 33/100... Step: 3384... Loss: 0.026625... Val Loss: 0.013836\n",
      "Epoch: 33/100... Step: 3385... Loss: 0.023823... Val Loss: 0.012738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100... Step: 3386... Loss: 0.020526... Val Loss: 0.009793\n",
      "Epoch: 33/100... Step: 3387... Loss: 0.031656... Val Loss: 0.009509\n",
      "Epoch: 33/100... Step: 3388... Loss: 0.034028... Val Loss: 0.038941\n",
      "Epoch: 33/100... Step: 3389... Loss: 0.024634... Val Loss: 0.064503\n",
      "Epoch: 33/100... Step: 3390... Loss: 0.027844... Val Loss: 0.054228\n",
      "Epoch: 33/100... Step: 3391... Loss: 0.040285... Val Loss: 0.026430\n",
      "Epoch: 33/100... Step: 3392... Loss: 0.029328... Val Loss: 0.021504\n",
      "Epoch: 33/100... Step: 3393... Loss: 0.029138... Val Loss: 0.054315\n",
      "Epoch: 33/100... Step: 3394... Loss: 0.036574... Val Loss: 0.057548\n",
      "Epoch: 33/100... Step: 3395... Loss: 0.029442... Val Loss: 0.061215\n",
      "Epoch: 33/100... Step: 3396... Loss: 0.032697... Val Loss: 0.064337\n",
      "Epoch: 33/100... Step: 3397... Loss: 0.025007... Val Loss: 0.055640\n",
      "Epoch: 33/100... Step: 3398... Loss: 0.028414... Val Loss: 0.043328\n",
      "Epoch: 33/100... Step: 3399... Loss: 0.041849... Val Loss: 0.034160\n",
      "Epoch: 33/100... Step: 3400... Loss: 0.029591... Val Loss: 0.015264\n",
      "Epoch: 33/100... Step: 3401... Loss: 0.028306... Val Loss: 0.026205\n",
      "Epoch: 33/100... Step: 3402... Loss: 0.024303... Val Loss: 0.036116\n",
      "Epoch: 33/100... Step: 3403... Loss: 0.036314... Val Loss: 0.036628\n",
      "Epoch: 33/100... Step: 3404... Loss: 0.026099... Val Loss: 0.023370\n",
      "Epoch: 33/100... Step: 3405... Loss: 0.037511... Val Loss: 0.013334\n",
      "Epoch: 33/100... Step: 3406... Loss: 0.037717... Val Loss: 0.011443\n",
      "Epoch: 33/100... Step: 3407... Loss: 0.035224... Val Loss: 0.009549\n",
      "Epoch: 33/100... Step: 3408... Loss: 0.031232... Val Loss: 0.031178\n",
      "Epoch: 33/100... Step: 3409... Loss: 0.037042... Val Loss: 0.032351\n",
      "Epoch: 33/100... Step: 3410... Loss: 0.028413... Val Loss: 0.028445\n",
      "Epoch: 33/100... Step: 3411... Loss: 0.035327... Val Loss: 0.034594\n",
      "Epoch: 33/100... Step: 3412... Loss: 0.048907... Val Loss: 0.031044\n",
      "Epoch: 33/100... Step: 3413... Loss: 0.031104... Val Loss: 0.036112\n",
      "Epoch: 33/100... Step: 3414... Loss: 0.022927... Val Loss: 0.032013\n",
      "Epoch: 33/100... Step: 3415... Loss: 0.027715... Val Loss: 0.019070\n",
      "Epoch: 33/100... Step: 3416... Loss: 0.047640... Val Loss: 0.034667\n",
      "Epoch: 33/100... Step: 3417... Loss: 0.021895... Val Loss: 0.047831\n",
      "Epoch: 33/100... Step: 3418... Loss: 0.015826... Val Loss: 0.055467\n",
      "Epoch: 33/100... Step: 3419... Loss: 0.039720... Val Loss: 0.066186\n",
      "Epoch: 33/100... Step: 3420... Loss: 0.023008... Val Loss: 0.068263\n",
      "Epoch: 33/100... Step: 3421... Loss: 0.027339... Val Loss: 0.064960\n",
      "Epoch: 33/100... Step: 3422... Loss: 0.021648... Val Loss: 0.047888\n",
      "Epoch: 33/100... Step: 3423... Loss: 0.037206... Val Loss: 0.026341\n",
      "Epoch: 33/100... Step: 3424... Loss: 0.021762... Val Loss: 0.042133\n",
      "Epoch: 33/100... Step: 3425... Loss: 0.039961... Val Loss: 0.065697\n",
      "Epoch: 33/100... Step: 3426... Loss: 0.042068... Val Loss: 0.075597\n",
      "Epoch: 33/100... Step: 3427... Loss: 0.019370... Val Loss: 0.073733\n",
      "Epoch: 33/100... Step: 3428... Loss: 0.040120... Val Loss: 0.076104\n",
      "Epoch: 33/100... Step: 3429... Loss: 0.032934... Val Loss: 0.075097\n",
      "Epoch: 33/100... Step: 3430... Loss: 0.035200... Val Loss: 0.077124\n",
      "Epoch: 33/100... Step: 3431... Loss: 0.016470... Val Loss: 0.066711\n",
      "Epoch: 33/100... Step: 3432... Loss: 0.028330... Val Loss: 0.072072\n",
      "Epoch: 34/100... Step: 3433... Loss: 0.028438... Val Loss: 0.081631\n",
      "Epoch: 34/100... Step: 3434... Loss: 0.017476... Val Loss: 0.081166\n",
      "Epoch: 34/100... Step: 3435... Loss: 0.026560... Val Loss: 0.049910\n",
      "Epoch: 34/100... Step: 3436... Loss: 0.020416... Val Loss: 0.160398\n",
      "Epoch: 34/100... Step: 3437... Loss: 0.032183... Val Loss: 0.192029\n",
      "Epoch: 34/100... Step: 3438... Loss: 0.015757... Val Loss: 0.193940\n",
      "Epoch: 34/100... Step: 3439... Loss: 0.021247... Val Loss: 0.199128\n",
      "Epoch: 34/100... Step: 3440... Loss: 0.018232... Val Loss: 0.197280\n",
      "Epoch: 34/100... Step: 3441... Loss: 0.016656... Val Loss: 0.177606\n",
      "Epoch: 34/100... Step: 3442... Loss: 0.030040... Val Loss: 0.195499\n",
      "Epoch: 34/100... Step: 3443... Loss: 0.029520... Val Loss: 0.193516\n",
      "Epoch: 34/100... Step: 3444... Loss: 0.050013... Val Loss: 0.212933\n",
      "Epoch: 34/100... Step: 3445... Loss: 0.043176... Val Loss: 0.224852\n",
      "Epoch: 34/100... Step: 3446... Loss: 0.045146... Val Loss: 0.221561\n",
      "Epoch: 34/100... Step: 3447... Loss: 0.020198... Val Loss: 0.225447\n",
      "Epoch: 34/100... Step: 3448... Loss: 0.025011... Val Loss: 0.164023\n",
      "Epoch: 34/100... Step: 3449... Loss: 0.037771... Val Loss: 0.174949\n",
      "Epoch: 34/100... Step: 3450... Loss: 0.018979... Val Loss: 0.184531\n",
      "Epoch: 34/100... Step: 3451... Loss: 0.022568... Val Loss: 0.181927\n",
      "Epoch: 34/100... Step: 3452... Loss: 0.031801... Val Loss: 0.174517\n",
      "Epoch: 34/100... Step: 3453... Loss: 0.032192... Val Loss: 0.178357\n",
      "Epoch: 34/100... Step: 3454... Loss: 0.032286... Val Loss: 0.187243\n",
      "Epoch: 34/100... Step: 3455... Loss: 0.029445... Val Loss: 0.190893\n",
      "Epoch: 34/100... Step: 3456... Loss: 0.034794... Val Loss: 0.187604\n",
      "Epoch: 34/100... Step: 3457... Loss: 0.022384... Val Loss: 0.173093\n",
      "Epoch: 34/100... Step: 3458... Loss: 0.028164... Val Loss: 0.159324\n",
      "Epoch: 34/100... Step: 3459... Loss: 0.034758... Val Loss: 0.160362\n",
      "Epoch: 34/100... Step: 3460... Loss: 0.025161... Val Loss: 0.169002\n",
      "Epoch: 34/100... Step: 3461... Loss: 0.024584... Val Loss: 0.177622\n",
      "Epoch: 34/100... Step: 3462... Loss: 0.028502... Val Loss: 0.175557\n",
      "Epoch: 34/100... Step: 3463... Loss: 0.024211... Val Loss: 0.180100\n",
      "Epoch: 34/100... Step: 3464... Loss: 0.029462... Val Loss: 0.181293\n",
      "Epoch: 34/100... Step: 3465... Loss: 0.025884... Val Loss: 0.177844\n",
      "Epoch: 34/100... Step: 3466... Loss: 0.012632... Val Loss: 0.150136\n",
      "Epoch: 34/100... Step: 3467... Loss: 0.031796... Val Loss: 0.120593\n",
      "Epoch: 34/100... Step: 3468... Loss: 0.020729... Val Loss: 0.094366\n",
      "Epoch: 34/100... Step: 3469... Loss: 0.041514... Val Loss: 0.078379\n",
      "Epoch: 34/100... Step: 3470... Loss: 0.016251... Val Loss: 0.098927\n",
      "Epoch: 34/100... Step: 3471... Loss: 0.029972... Val Loss: 0.107553\n",
      "Epoch: 34/100... Step: 3472... Loss: 0.014894... Val Loss: 0.074510\n",
      "Epoch: 34/100... Step: 3473... Loss: 0.039935... Val Loss: 0.010187\n",
      "Epoch: 34/100... Step: 3474... Loss: 0.045843... Val Loss: 0.044024\n",
      "Epoch: 34/100... Step: 3475... Loss: 0.031051... Val Loss: 0.027323\n",
      "Epoch: 34/100... Step: 3476... Loss: 0.019281... Val Loss: 0.008366\n",
      "Epoch: 34/100... Step: 3477... Loss: 0.032758... Val Loss: 0.056048\n",
      "Epoch: 34/100... Step: 3478... Loss: 0.031665... Val Loss: 0.083980\n",
      "Epoch: 34/100... Step: 3479... Loss: 0.046666... Val Loss: 0.093381\n",
      "Epoch: 34/100... Step: 3480... Loss: 0.034210... Val Loss: 0.105131\n",
      "Epoch: 34/100... Step: 3481... Loss: 0.020213... Val Loss: 0.102194\n",
      "Epoch: 34/100... Step: 3482... Loss: 0.026694... Val Loss: 0.078921\n",
      "Epoch: 34/100... Step: 3483... Loss: 0.027500... Val Loss: 0.077042\n",
      "Epoch: 34/100... Step: 3484... Loss: 0.029777... Val Loss: 0.103364\n",
      "Epoch: 34/100... Step: 3485... Loss: 0.029435... Val Loss: 0.142992\n",
      "Epoch: 34/100... Step: 3486... Loss: 0.042882... Val Loss: 0.159594\n",
      "Epoch: 34/100... Step: 3487... Loss: 0.025476... Val Loss: 0.135723\n",
      "Epoch: 34/100... Step: 3488... Loss: 0.031311... Val Loss: 0.079669\n",
      "Epoch: 34/100... Step: 3489... Loss: 0.037434... Val Loss: 0.051156\n",
      "Epoch: 34/100... Step: 3490... Loss: 0.041947... Val Loss: 0.047435\n",
      "Epoch: 34/100... Step: 3491... Loss: 0.037119... Val Loss: 0.057882\n",
      "Epoch: 34/100... Step: 3492... Loss: 0.028724... Val Loss: 0.033233\n",
      "Epoch: 34/100... Step: 3493... Loss: 0.031118... Val Loss: 0.013757\n",
      "Epoch: 34/100... Step: 3494... Loss: 0.013811... Val Loss: 0.011565\n",
      "Epoch: 34/100... Step: 3495... Loss: 0.022247... Val Loss: 0.015251\n",
      "Epoch: 34/100... Step: 3496... Loss: 0.037568... Val Loss: 0.023144\n",
      "Epoch: 34/100... Step: 3497... Loss: 0.025831... Val Loss: 0.020031\n",
      "Epoch: 34/100... Step: 3498... Loss: 0.044798... Val Loss: 0.012099\n",
      "Epoch: 34/100... Step: 3499... Loss: 0.016106... Val Loss: 0.011923\n",
      "Epoch: 34/100... Step: 3500... Loss: 0.038681... Val Loss: 0.016737\n",
      "Epoch: 34/100... Step: 3501... Loss: 0.028078... Val Loss: 0.018408\n",
      "Epoch: 34/100... Step: 3502... Loss: 0.032637... Val Loss: 0.009924\n",
      "Epoch: 34/100... Step: 3503... Loss: 0.030753... Val Loss: 0.023989\n",
      "Epoch: 34/100... Step: 3504... Loss: 0.024495... Val Loss: 0.044947\n",
      "Epoch: 34/100... Step: 3505... Loss: 0.027086... Val Loss: 0.054188\n",
      "Epoch: 34/100... Step: 3506... Loss: 0.032633... Val Loss: 0.028509\n",
      "Epoch: 34/100... Step: 3507... Loss: 0.032192... Val Loss: 0.023866\n",
      "Epoch: 34/100... Step: 3508... Loss: 0.036742... Val Loss: 0.029310\n",
      "Epoch: 34/100... Step: 3509... Loss: 0.025360... Val Loss: 0.021842\n",
      "Epoch: 34/100... Step: 3510... Loss: 0.036759... Val Loss: 0.010440\n",
      "Epoch: 34/100... Step: 3511... Loss: 0.034741... Val Loss: 0.030131\n",
      "Epoch: 34/100... Step: 3512... Loss: 0.024941... Val Loss: 0.055197\n",
      "Epoch: 34/100... Step: 3513... Loss: 0.032206... Val Loss: 0.067514\n",
      "Epoch: 34/100... Step: 3514... Loss: 0.030297... Val Loss: 0.069300\n",
      "Epoch: 34/100... Step: 3515... Loss: 0.029189... Val Loss: 0.064792\n",
      "Epoch: 34/100... Step: 3516... Loss: 0.022602... Val Loss: 0.014762\n",
      "Epoch: 34/100... Step: 3517... Loss: 0.037827... Val Loss: 0.023273\n",
      "Epoch: 34/100... Step: 3518... Loss: 0.032072... Val Loss: 0.040077\n",
      "Epoch: 34/100... Step: 3519... Loss: 0.043307... Val Loss: 0.040380\n",
      "Epoch: 34/100... Step: 3520... Loss: 0.033130... Val Loss: 0.030209\n",
      "Epoch: 34/100... Step: 3521... Loss: 0.032594... Val Loss: 0.031441\n",
      "Epoch: 34/100... Step: 3522... Loss: 0.022288... Val Loss: 0.037012\n",
      "Epoch: 34/100... Step: 3523... Loss: 0.020873... Val Loss: 0.040397\n",
      "Epoch: 34/100... Step: 3524... Loss: 0.026656... Val Loss: 0.031121\n",
      "Epoch: 34/100... Step: 3525... Loss: 0.021618... Val Loss: 0.015990\n",
      "Epoch: 34/100... Step: 3526... Loss: 0.041176... Val Loss: 0.029723\n",
      "Epoch: 34/100... Step: 3527... Loss: 0.041375... Val Loss: 0.046156\n",
      "Epoch: 34/100... Step: 3528... Loss: 0.030027... Val Loss: 0.062883\n",
      "Epoch: 34/100... Step: 3529... Loss: 0.040412... Val Loss: 0.066139\n",
      "Epoch: 34/100... Step: 3530... Loss: 0.018732... Val Loss: 0.059244\n",
      "Epoch: 34/100... Step: 3531... Loss: 0.021923... Val Loss: 0.053054\n",
      "Epoch: 34/100... Step: 3532... Loss: 0.021421... Val Loss: 0.066315\n",
      "Epoch: 34/100... Step: 3533... Loss: 0.036757... Val Loss: 0.073400\n",
      "Epoch: 34/100... Step: 3534... Loss: 0.025788... Val Loss: 0.084862\n",
      "Epoch: 34/100... Step: 3535... Loss: 0.035395... Val Loss: 0.091992\n",
      "Epoch: 34/100... Step: 3536... Loss: 0.021933... Val Loss: 0.098856\n",
      "Epoch: 35/100... Step: 3537... Loss: 0.016736... Val Loss: 0.145483\n",
      "Epoch: 35/100... Step: 3538... Loss: 0.027350... Val Loss: 0.149754\n",
      "Epoch: 35/100... Step: 3539... Loss: 0.025276... Val Loss: 0.065164\n",
      "Epoch: 35/100... Step: 3540... Loss: 0.026520... Val Loss: 0.097979\n",
      "Epoch: 35/100... Step: 3541... Loss: 0.019100... Val Loss: 0.145144\n",
      "Epoch: 35/100... Step: 3542... Loss: 0.025763... Val Loss: 0.184509\n",
      "Epoch: 35/100... Step: 3543... Loss: 0.015907... Val Loss: 0.198365\n",
      "Epoch: 35/100... Step: 3544... Loss: 0.023148... Val Loss: 0.222226\n",
      "Epoch: 35/100... Step: 3545... Loss: 0.033996... Val Loss: 0.212914\n",
      "Epoch: 35/100... Step: 3546... Loss: 0.025635... Val Loss: 0.214646\n",
      "Epoch: 35/100... Step: 3547... Loss: 0.032642... Val Loss: 0.177809\n",
      "Epoch: 35/100... Step: 3548... Loss: 0.022297... Val Loss: 0.169343\n",
      "Epoch: 35/100... Step: 3549... Loss: 0.049716... Val Loss: 0.169586\n",
      "Epoch: 35/100... Step: 3550... Loss: 0.028211... Val Loss: 0.168709\n",
      "Epoch: 35/100... Step: 3551... Loss: 0.032803... Val Loss: 0.165817\n",
      "Epoch: 35/100... Step: 3552... Loss: 0.030643... Val Loss: 0.174036\n",
      "Epoch: 35/100... Step: 3553... Loss: 0.024655... Val Loss: 0.175935\n",
      "Epoch: 35/100... Step: 3554... Loss: 0.047485... Val Loss: 0.171549\n",
      "Epoch: 35/100... Step: 3555... Loss: 0.025022... Val Loss: 0.176255\n",
      "Epoch: 35/100... Step: 3556... Loss: 0.026276... Val Loss: 0.189776\n",
      "Epoch: 35/100... Step: 3557... Loss: 0.027798... Val Loss: 0.192230\n",
      "Epoch: 35/100... Step: 3558... Loss: 0.022590... Val Loss: 0.195373\n",
      "Epoch: 35/100... Step: 3559... Loss: 0.021469... Val Loss: 0.215296\n",
      "Epoch: 35/100... Step: 3560... Loss: 0.030524... Val Loss: 0.226180\n",
      "Epoch: 35/100... Step: 3561... Loss: 0.028535... Val Loss: 0.216651\n",
      "Epoch: 35/100... Step: 3562... Loss: 0.023984... Val Loss: 0.228090\n",
      "Epoch: 35/100... Step: 3563... Loss: 0.026186... Val Loss: 0.226634\n",
      "Epoch: 35/100... Step: 3564... Loss: 0.041391... Val Loss: 0.226230\n",
      "Epoch: 35/100... Step: 3565... Loss: 0.023923... Val Loss: 0.239861\n",
      "Epoch: 35/100... Step: 3566... Loss: 0.028771... Val Loss: 0.265665\n",
      "Epoch: 35/100... Step: 3567... Loss: 0.036487... Val Loss: 0.257712\n",
      "Epoch: 35/100... Step: 3568... Loss: 0.024315... Val Loss: 0.238200\n",
      "Epoch: 35/100... Step: 3569... Loss: 0.032711... Val Loss: 0.204941\n",
      "Epoch: 35/100... Step: 3570... Loss: 0.027973... Val Loss: 0.186590\n",
      "Epoch: 35/100... Step: 3571... Loss: 0.033499... Val Loss: 0.176050\n",
      "Epoch: 35/100... Step: 3572... Loss: 0.040331... Val Loss: 0.120321\n",
      "Epoch: 35/100... Step: 3573... Loss: 0.040803... Val Loss: 0.096426\n",
      "Epoch: 35/100... Step: 3574... Loss: 0.038429... Val Loss: 0.098119\n",
      "Epoch: 35/100... Step: 3575... Loss: 0.049527... Val Loss: 0.085131\n",
      "Epoch: 35/100... Step: 3576... Loss: 0.041353... Val Loss: 0.071637\n",
      "Epoch: 35/100... Step: 3577... Loss: 0.027803... Val Loss: 0.057705\n",
      "Epoch: 35/100... Step: 3578... Loss: 0.034864... Val Loss: 0.064078\n",
      "Epoch: 35/100... Step: 3579... Loss: 0.035881... Val Loss: 0.057670\n",
      "Epoch: 35/100... Step: 3580... Loss: 0.030162... Val Loss: 0.028646\n",
      "Epoch: 35/100... Step: 3581... Loss: 0.026892... Val Loss: 0.046464\n",
      "Epoch: 35/100... Step: 3582... Loss: 0.023019... Val Loss: 0.065383\n",
      "Epoch: 35/100... Step: 3583... Loss: 0.017214... Val Loss: 0.074590\n",
      "Epoch: 35/100... Step: 3584... Loss: 0.017900... Val Loss: 0.107811\n",
      "Epoch: 35/100... Step: 3585... Loss: 0.024998... Val Loss: 0.143302\n",
      "Epoch: 35/100... Step: 3586... Loss: 0.026606... Val Loss: 0.181640\n",
      "Epoch: 35/100... Step: 3587... Loss: 0.015029... Val Loss: 0.220529\n",
      "Epoch: 35/100... Step: 3588... Loss: 0.026122... Val Loss: 0.264249\n",
      "Epoch: 35/100... Step: 3589... Loss: 0.032162... Val Loss: 0.281084\n",
      "Epoch: 35/100... Step: 3590... Loss: 0.042799... Val Loss: 0.258243\n",
      "Epoch: 35/100... Step: 3591... Loss: 0.022639... Val Loss: 0.248088\n",
      "Epoch: 35/100... Step: 3592... Loss: 0.030434... Val Loss: 0.239998\n",
      "Epoch: 35/100... Step: 3593... Loss: 0.020258... Val Loss: 0.221099\n",
      "Epoch: 35/100... Step: 3594... Loss: 0.027198... Val Loss: 0.184349\n",
      "Epoch: 35/100... Step: 3595... Loss: 0.027188... Val Loss: 0.157470\n",
      "Epoch: 35/100... Step: 3596... Loss: 0.028394... Val Loss: 0.114013\n",
      "Epoch: 35/100... Step: 3597... Loss: 0.032177... Val Loss: 0.066931\n",
      "Epoch: 35/100... Step: 3598... Loss: 0.034692... Val Loss: 0.042255\n",
      "Epoch: 35/100... Step: 3599... Loss: 0.036715... Val Loss: 0.042268\n",
      "Epoch: 35/100... Step: 3600... Loss: 0.024747... Val Loss: 0.068247\n",
      "Epoch: 35/100... Step: 3601... Loss: 0.028105... Val Loss: 0.073866\n",
      "Epoch: 35/100... Step: 3602... Loss: 0.033611... Val Loss: 0.052371\n",
      "Epoch: 35/100... Step: 3603... Loss: 0.034415... Val Loss: 0.025848\n",
      "Epoch: 35/100... Step: 3604... Loss: 0.034729... Val Loss: 0.007923\n",
      "Epoch: 35/100... Step: 3605... Loss: 0.030657... Val Loss: 0.030372\n",
      "Epoch: 35/100... Step: 3606... Loss: 0.033806... Val Loss: 0.054625\n",
      "Epoch: 35/100... Step: 3607... Loss: 0.023685... Val Loss: 0.089031\n",
      "Epoch: 35/100... Step: 3608... Loss: 0.028210... Val Loss: 0.120106\n",
      "Epoch: 35/100... Step: 3609... Loss: 0.016345... Val Loss: 0.142168\n",
      "Epoch: 35/100... Step: 3610... Loss: 0.017229... Val Loss: 0.147642\n",
      "Epoch: 35/100... Step: 3611... Loss: 0.032339... Val Loss: 0.147341\n",
      "Epoch: 35/100... Step: 3612... Loss: 0.036921... Val Loss: 0.160116\n",
      "Epoch: 35/100... Step: 3613... Loss: 0.027355... Val Loss: 0.169615\n",
      "Epoch: 35/100... Step: 3614... Loss: 0.022599... Val Loss: 0.167696\n",
      "Epoch: 35/100... Step: 3615... Loss: 0.039802... Val Loss: 0.140810\n",
      "Epoch: 35/100... Step: 3616... Loss: 0.021113... Val Loss: 0.142161\n",
      "Epoch: 35/100... Step: 3617... Loss: 0.027333... Val Loss: 0.135957\n",
      "Epoch: 35/100... Step: 3618... Loss: 0.025939... Val Loss: 0.133678\n",
      "Epoch: 35/100... Step: 3619... Loss: 0.022756... Val Loss: 0.129671\n",
      "Epoch: 35/100... Step: 3620... Loss: 0.037042... Val Loss: 0.120368\n",
      "Epoch: 35/100... Step: 3621... Loss: 0.032016... Val Loss: 0.131902\n",
      "Epoch: 35/100... Step: 3622... Loss: 0.027825... Val Loss: 0.129986\n",
      "Epoch: 35/100... Step: 3623... Loss: 0.032555... Val Loss: 0.132605\n",
      "Epoch: 35/100... Step: 3624... Loss: 0.023027... Val Loss: 0.122356\n",
      "Epoch: 35/100... Step: 3625... Loss: 0.030750... Val Loss: 0.105132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100... Step: 3626... Loss: 0.028954... Val Loss: 0.035178\n",
      "Epoch: 35/100... Step: 3627... Loss: 0.029871... Val Loss: 0.013914\n",
      "Epoch: 35/100... Step: 3628... Loss: 0.022384... Val Loss: 0.018744\n",
      "Epoch: 35/100... Step: 3629... Loss: 0.031621... Val Loss: 0.009824\n",
      "Epoch: 35/100... Step: 3630... Loss: 0.026413... Val Loss: 0.006839\n",
      "Epoch: 35/100... Step: 3631... Loss: 0.036992... Val Loss: 0.007359\n",
      "Epoch: 35/100... Step: 3632... Loss: 0.024357... Val Loss: 0.018227\n",
      "Epoch: 35/100... Step: 3633... Loss: 0.046910... Val Loss: 0.010761\n",
      "Epoch: 35/100... Step: 3634... Loss: 0.029153... Val Loss: 0.010153\n",
      "Epoch: 35/100... Step: 3635... Loss: 0.030362... Val Loss: 0.020995\n",
      "Epoch: 35/100... Step: 3636... Loss: 0.034914... Val Loss: 0.031525\n",
      "Epoch: 35/100... Step: 3637... Loss: 0.026052... Val Loss: 0.044943\n",
      "Epoch: 35/100... Step: 3638... Loss: 0.016681... Val Loss: 0.071932\n",
      "Epoch: 35/100... Step: 3639... Loss: 0.022607... Val Loss: 0.104834\n",
      "Epoch: 35/100... Step: 3640... Loss: 0.028885... Val Loss: 0.116469\n",
      "Epoch: 36/100... Step: 3641... Loss: 0.011251... Val Loss: 0.095297\n",
      "Epoch: 36/100... Step: 3642... Loss: 0.019893... Val Loss: 0.118643\n",
      "Epoch: 36/100... Step: 3643... Loss: 0.012483... Val Loss: 0.120920\n",
      "Epoch: 36/100... Step: 3644... Loss: 0.024810... Val Loss: 0.069375\n",
      "Epoch: 36/100... Step: 3645... Loss: 0.031294... Val Loss: 0.061895\n",
      "Epoch: 36/100... Step: 3646... Loss: 0.028431... Val Loss: 0.068205\n",
      "Epoch: 36/100... Step: 3647... Loss: 0.019631... Val Loss: 0.055376\n",
      "Epoch: 36/100... Step: 3648... Loss: 0.025725... Val Loss: 0.017318\n",
      "Epoch: 36/100... Step: 3649... Loss: 0.023529... Val Loss: 0.010164\n",
      "Epoch: 36/100... Step: 3650... Loss: 0.017380... Val Loss: 0.012287\n",
      "Epoch: 36/100... Step: 3651... Loss: 0.031962... Val Loss: 0.005674\n",
      "Epoch: 36/100... Step: 3652... Loss: 0.027747... Val Loss: 0.007369\n",
      "Epoch: 36/100... Step: 3653... Loss: 0.031086... Val Loss: 0.008300\n",
      "Epoch: 36/100... Step: 3654... Loss: 0.032754... Val Loss: 0.010075\n",
      "Epoch: 36/100... Step: 3655... Loss: 0.025235... Val Loss: 0.017086\n",
      "Epoch: 36/100... Step: 3656... Loss: 0.024857... Val Loss: 0.052702\n",
      "Epoch: 36/100... Step: 3657... Loss: 0.034454... Val Loss: 0.069294\n",
      "Epoch: 36/100... Step: 3658... Loss: 0.024672... Val Loss: 0.079532\n",
      "Epoch: 36/100... Step: 3659... Loss: 0.020780... Val Loss: 0.060640\n",
      "Epoch: 36/100... Step: 3660... Loss: 0.027964... Val Loss: 0.054268\n",
      "Epoch: 36/100... Step: 3661... Loss: 0.018821... Val Loss: 0.037319\n",
      "Epoch: 36/100... Step: 3662... Loss: 0.031335... Val Loss: 0.029990\n",
      "Epoch: 36/100... Step: 3663... Loss: 0.033835... Val Loss: 0.026477\n",
      "Epoch: 36/100... Step: 3664... Loss: 0.035550... Val Loss: 0.016794\n",
      "Epoch: 36/100... Step: 3665... Loss: 0.023691... Val Loss: 0.012103\n",
      "Epoch: 36/100... Step: 3666... Loss: 0.023153... Val Loss: 0.024411\n",
      "Epoch: 36/100... Step: 3667... Loss: 0.034484... Val Loss: 0.030150\n",
      "Epoch: 36/100... Step: 3668... Loss: 0.017639... Val Loss: 0.034962\n",
      "Epoch: 36/100... Step: 3669... Loss: 0.033236... Val Loss: 0.010222\n",
      "Epoch: 36/100... Step: 3670... Loss: 0.036122... Val Loss: 0.014663\n",
      "Epoch: 36/100... Step: 3671... Loss: 0.021027... Val Loss: 0.037623\n",
      "Epoch: 36/100... Step: 3672... Loss: 0.021338... Val Loss: 0.081995\n",
      "Epoch: 36/100... Step: 3673... Loss: 0.039118... Val Loss: 0.138397\n",
      "Epoch: 36/100... Step: 3674... Loss: 0.036171... Val Loss: 0.179308\n",
      "Epoch: 36/100... Step: 3675... Loss: 0.034566... Val Loss: 0.208780\n",
      "Epoch: 36/100... Step: 3676... Loss: 0.027706... Val Loss: 0.152857\n",
      "Epoch: 36/100... Step: 3677... Loss: 0.041363... Val Loss: 0.122491\n",
      "Epoch: 36/100... Step: 3678... Loss: 0.035928... Val Loss: 0.093229\n",
      "Epoch: 36/100... Step: 3679... Loss: 0.037304... Val Loss: 0.085378\n",
      "Epoch: 36/100... Step: 3680... Loss: 0.045571... Val Loss: 0.073474\n",
      "Epoch: 36/100... Step: 3681... Loss: 0.033632... Val Loss: 0.048094\n",
      "Epoch: 36/100... Step: 3682... Loss: 0.038169... Val Loss: 0.026802\n",
      "Epoch: 36/100... Step: 3683... Loss: 0.024569... Val Loss: 0.014567\n",
      "Epoch: 36/100... Step: 3684... Loss: 0.045665... Val Loss: 0.014102\n",
      "Epoch: 36/100... Step: 3685... Loss: 0.045369... Val Loss: 0.017629\n",
      "Epoch: 36/100... Step: 3686... Loss: 0.038961... Val Loss: 0.023168\n",
      "Epoch: 36/100... Step: 3687... Loss: 0.039388... Val Loss: 0.040574\n",
      "Epoch: 36/100... Step: 3688... Loss: 0.026334... Val Loss: 0.056601\n",
      "Epoch: 36/100... Step: 3689... Loss: 0.025007... Val Loss: 0.066538\n",
      "Epoch: 36/100... Step: 3690... Loss: 0.036822... Val Loss: 0.074135\n",
      "Epoch: 36/100... Step: 3691... Loss: 0.034461... Val Loss: 0.079528\n",
      "Epoch: 36/100... Step: 3692... Loss: 0.018086... Val Loss: 0.075722\n",
      "Epoch: 36/100... Step: 3693... Loss: 0.023118... Val Loss: 0.072124\n",
      "Epoch: 36/100... Step: 3694... Loss: 0.021232... Val Loss: 0.070150\n",
      "Epoch: 36/100... Step: 3695... Loss: 0.041198... Val Loss: 0.045793\n",
      "Epoch: 36/100... Step: 3696... Loss: 0.034919... Val Loss: 0.038673\n",
      "Epoch: 36/100... Step: 3697... Loss: 0.020928... Val Loss: 0.035370\n",
      "Epoch: 36/100... Step: 3698... Loss: 0.044503... Val Loss: 0.026085\n",
      "Epoch: 36/100... Step: 3699... Loss: 0.019675... Val Loss: 0.024745\n",
      "Epoch: 36/100... Step: 3700... Loss: 0.026976... Val Loss: 0.020137\n",
      "Epoch: 36/100... Step: 3701... Loss: 0.030220... Val Loss: 0.028311\n",
      "Epoch: 36/100... Step: 3702... Loss: 0.024462... Val Loss: 0.033119\n",
      "Epoch: 36/100... Step: 3703... Loss: 0.026218... Val Loss: 0.036637\n",
      "Epoch: 36/100... Step: 3704... Loss: 0.027101... Val Loss: 0.013920\n",
      "Epoch: 36/100... Step: 3705... Loss: 0.032926... Val Loss: 0.016049\n",
      "Epoch: 36/100... Step: 3706... Loss: 0.018557... Val Loss: 0.027541\n",
      "Epoch: 36/100... Step: 3707... Loss: 0.031979... Val Loss: 0.066717\n",
      "Epoch: 36/100... Step: 3708... Loss: 0.023225... Val Loss: 0.105717\n",
      "Epoch: 36/100... Step: 3709... Loss: 0.030408... Val Loss: 0.113166\n",
      "Epoch: 36/100... Step: 3710... Loss: 0.038335... Val Loss: 0.099755\n",
      "Epoch: 36/100... Step: 3711... Loss: 0.039851... Val Loss: 0.105475\n",
      "Epoch: 36/100... Step: 3712... Loss: 0.027891... Val Loss: 0.102769\n",
      "Epoch: 36/100... Step: 3713... Loss: 0.022839... Val Loss: 0.094666\n",
      "Epoch: 36/100... Step: 3714... Loss: 0.030043... Val Loss: 0.085893\n",
      "Epoch: 36/100... Step: 3715... Loss: 0.039013... Val Loss: 0.075134\n",
      "Epoch: 36/100... Step: 3716... Loss: 0.029200... Val Loss: 0.049358\n",
      "Epoch: 36/100... Step: 3717... Loss: 0.033945... Val Loss: 0.023924\n",
      "Epoch: 36/100... Step: 3718... Loss: 0.052811... Val Loss: 0.013684\n",
      "Epoch: 36/100... Step: 3719... Loss: 0.029133... Val Loss: 0.015451\n",
      "Epoch: 36/100... Step: 3720... Loss: 0.016516... Val Loss: 0.044659\n",
      "Epoch: 36/100... Step: 3721... Loss: 0.023551... Val Loss: 0.056278\n",
      "Epoch: 36/100... Step: 3722... Loss: 0.038795... Val Loss: 0.065288\n",
      "Epoch: 36/100... Step: 3723... Loss: 0.014919... Val Loss: 0.060080\n",
      "Epoch: 36/100... Step: 3724... Loss: 0.021921... Val Loss: 0.044667\n",
      "Epoch: 36/100... Step: 3725... Loss: 0.037074... Val Loss: 0.018136\n",
      "Epoch: 36/100... Step: 3726... Loss: 0.032805... Val Loss: 0.010304\n",
      "Epoch: 36/100... Step: 3727... Loss: 0.037984... Val Loss: 0.012924\n",
      "Epoch: 36/100... Step: 3728... Loss: 0.023326... Val Loss: 0.010750\n",
      "Epoch: 36/100... Step: 3729... Loss: 0.027662... Val Loss: 0.009614\n",
      "Epoch: 36/100... Step: 3730... Loss: 0.035746... Val Loss: 0.020114\n",
      "Epoch: 36/100... Step: 3731... Loss: 0.022759... Val Loss: 0.033160\n",
      "Epoch: 36/100... Step: 3732... Loss: 0.039399... Val Loss: 0.053341\n",
      "Epoch: 36/100... Step: 3733... Loss: 0.031057... Val Loss: 0.077904\n",
      "Epoch: 36/100... Step: 3734... Loss: 0.026517... Val Loss: 0.110379\n",
      "Epoch: 36/100... Step: 3735... Loss: 0.047083... Val Loss: 0.142229\n",
      "Epoch: 36/100... Step: 3736... Loss: 0.044985... Val Loss: 0.172136\n",
      "Epoch: 36/100... Step: 3737... Loss: 0.036470... Val Loss: 0.170971\n",
      "Epoch: 36/100... Step: 3738... Loss: 0.027150... Val Loss: 0.155646\n",
      "Epoch: 36/100... Step: 3739... Loss: 0.034131... Val Loss: 0.155542\n",
      "Epoch: 36/100... Step: 3740... Loss: 0.023259... Val Loss: 0.121224\n",
      "Epoch: 36/100... Step: 3741... Loss: 0.024067... Val Loss: 0.109383\n",
      "Epoch: 36/100... Step: 3742... Loss: 0.029632... Val Loss: 0.095690\n",
      "Epoch: 36/100... Step: 3743... Loss: 0.023823... Val Loss: 0.088450\n",
      "Epoch: 36/100... Step: 3744... Loss: 0.033939... Val Loss: 0.078033\n",
      "Epoch: 37/100... Step: 3745... Loss: 0.025267... Val Loss: 0.038117\n",
      "Epoch: 37/100... Step: 3746... Loss: 0.022124... Val Loss: 0.217719\n",
      "Epoch: 37/100... Step: 3747... Loss: 0.025186... Val Loss: 0.182699\n",
      "Epoch: 37/100... Step: 3748... Loss: 0.019348... Val Loss: 0.168663\n",
      "Epoch: 37/100... Step: 3749... Loss: 0.015487... Val Loss: 0.144058\n",
      "Epoch: 37/100... Step: 3750... Loss: 0.035883... Val Loss: 0.084758\n",
      "Epoch: 37/100... Step: 3751... Loss: 0.025689... Val Loss: 0.076681\n",
      "Epoch: 37/100... Step: 3752... Loss: 0.035751... Val Loss: 0.037437\n",
      "Epoch: 37/100... Step: 3753... Loss: 0.030454... Val Loss: 0.013755\n",
      "Epoch: 37/100... Step: 3754... Loss: 0.027231... Val Loss: 0.014191\n",
      "Epoch: 37/100... Step: 3755... Loss: 0.039963... Val Loss: 0.015684\n",
      "Epoch: 37/100... Step: 3756... Loss: 0.022644... Val Loss: 0.012977\n",
      "Epoch: 37/100... Step: 3757... Loss: 0.023190... Val Loss: 0.016403\n",
      "Epoch: 37/100... Step: 3758... Loss: 0.023281... Val Loss: 0.008166\n",
      "Epoch: 37/100... Step: 3759... Loss: 0.030758... Val Loss: 0.004970\n",
      "Epoch: 37/100... Step: 3760... Loss: 0.023671... Val Loss: 0.007038\n",
      "Epoch: 37/100... Step: 3761... Loss: 0.023617... Val Loss: 0.012634\n",
      "Epoch: 37/100... Step: 3762... Loss: 0.028699... Val Loss: 0.023212\n",
      "Epoch: 37/100... Step: 3763... Loss: 0.025336... Val Loss: 0.030528\n",
      "Epoch: 37/100... Step: 3764... Loss: 0.032643... Val Loss: 0.022333\n",
      "Epoch: 37/100... Step: 3765... Loss: 0.030389... Val Loss: 0.027732\n",
      "Epoch: 37/100... Step: 3766... Loss: 0.019664... Val Loss: 0.024379\n",
      "Epoch: 37/100... Step: 3767... Loss: 0.033177... Val Loss: 0.012102\n",
      "Epoch: 37/100... Step: 3768... Loss: 0.034376... Val Loss: 0.012741\n",
      "Epoch: 37/100... Step: 3769... Loss: 0.021995... Val Loss: 0.016071\n",
      "Epoch: 37/100... Step: 3770... Loss: 0.028486... Val Loss: 0.021212\n",
      "Epoch: 37/100... Step: 3771... Loss: 0.037608... Val Loss: 0.021423\n",
      "Epoch: 37/100... Step: 3772... Loss: 0.040553... Val Loss: 0.027841\n",
      "Epoch: 37/100... Step: 3773... Loss: 0.032151... Val Loss: 0.034947\n",
      "Epoch: 37/100... Step: 3774... Loss: 0.027965... Val Loss: 0.031708\n",
      "Epoch: 37/100... Step: 3775... Loss: 0.020676... Val Loss: 0.043294\n",
      "Epoch: 37/100... Step: 3776... Loss: 0.037092... Val Loss: 0.067410\n",
      "Epoch: 37/100... Step: 3777... Loss: 0.020028... Val Loss: 0.088520\n",
      "Epoch: 37/100... Step: 3778... Loss: 0.026940... Val Loss: 0.083908\n",
      "Epoch: 37/100... Step: 3779... Loss: 0.028736... Val Loss: 0.073551\n",
      "Epoch: 37/100... Step: 3780... Loss: 0.025230... Val Loss: 0.059953\n",
      "Epoch: 37/100... Step: 3781... Loss: 0.024537... Val Loss: 0.056228\n",
      "Epoch: 37/100... Step: 3782... Loss: 0.017795... Val Loss: 0.048871\n",
      "Epoch: 37/100... Step: 3783... Loss: 0.016019... Val Loss: 0.036993\n",
      "Epoch: 37/100... Step: 3784... Loss: 0.023657... Val Loss: 0.025137\n",
      "Epoch: 37/100... Step: 3785... Loss: 0.022295... Val Loss: 0.010196\n",
      "Epoch: 37/100... Step: 3786... Loss: 0.014504... Val Loss: 0.019136\n",
      "Epoch: 37/100... Step: 3787... Loss: 0.019400... Val Loss: 0.031987\n",
      "Epoch: 37/100... Step: 3788... Loss: 0.026781... Val Loss: 0.042015\n",
      "Epoch: 37/100... Step: 3789... Loss: 0.030314... Val Loss: 0.042637\n",
      "Epoch: 37/100... Step: 3790... Loss: 0.020849... Val Loss: 0.046969\n",
      "Epoch: 37/100... Step: 3791... Loss: 0.021326... Val Loss: 0.039044\n",
      "Epoch: 37/100... Step: 3792... Loss: 0.023066... Val Loss: 0.030677\n",
      "Epoch: 37/100... Step: 3793... Loss: 0.019119... Val Loss: 0.022442\n",
      "Epoch: 37/100... Step: 3794... Loss: 0.023741... Val Loss: 0.022746\n",
      "Epoch: 37/100... Step: 3795... Loss: 0.026285... Val Loss: 0.014029\n",
      "Epoch: 37/100... Step: 3796... Loss: 0.023374... Val Loss: 0.026189\n",
      "Epoch: 37/100... Step: 3797... Loss: 0.016336... Val Loss: 0.042473\n",
      "Epoch: 37/100... Step: 3798... Loss: 0.026684... Val Loss: 0.055380\n",
      "Epoch: 37/100... Step: 3799... Loss: 0.029941... Val Loss: 0.077935\n",
      "Epoch: 37/100... Step: 3800... Loss: 0.024723... Val Loss: 0.088357\n",
      "Epoch: 37/100... Step: 3801... Loss: 0.023220... Val Loss: 0.070836\n",
      "Epoch: 37/100... Step: 3802... Loss: 0.016674... Val Loss: 0.062894\n",
      "Epoch: 37/100... Step: 3803... Loss: 0.023587... Val Loss: 0.071805\n",
      "Epoch: 37/100... Step: 3804... Loss: 0.021948... Val Loss: 0.079665\n",
      "Epoch: 37/100... Step: 3805... Loss: 0.025560... Val Loss: 0.069016\n",
      "Epoch: 37/100... Step: 3806... Loss: 0.036537... Val Loss: 0.071949\n",
      "Epoch: 37/100... Step: 3807... Loss: 0.030966... Val Loss: 0.058149\n",
      "Epoch: 37/100... Step: 3808... Loss: 0.029863... Val Loss: 0.047127\n",
      "Epoch: 37/100... Step: 3809... Loss: 0.033267... Val Loss: 0.036258\n",
      "Epoch: 37/100... Step: 3810... Loss: 0.032021... Val Loss: 0.026736\n",
      "Epoch: 37/100... Step: 3811... Loss: 0.034395... Val Loss: 0.023497\n",
      "Epoch: 37/100... Step: 3812... Loss: 0.043871... Val Loss: 0.011754\n",
      "Epoch: 37/100... Step: 3813... Loss: 0.023732... Val Loss: 0.011270\n",
      "Epoch: 37/100... Step: 3814... Loss: 0.034471... Val Loss: 0.019292\n",
      "Epoch: 37/100... Step: 3815... Loss: 0.037498... Val Loss: 0.051455\n",
      "Epoch: 37/100... Step: 3816... Loss: 0.029568... Val Loss: 0.064052\n",
      "Epoch: 37/100... Step: 3817... Loss: 0.022835... Val Loss: 0.090531\n",
      "Epoch: 37/100... Step: 3818... Loss: 0.033652... Val Loss: 0.115309\n",
      "Epoch: 37/100... Step: 3819... Loss: 0.046085... Val Loss: 0.131360\n",
      "Epoch: 37/100... Step: 3820... Loss: 0.040136... Val Loss: 0.092892\n",
      "Epoch: 37/100... Step: 3821... Loss: 0.033625... Val Loss: 0.091861\n",
      "Epoch: 37/100... Step: 3822... Loss: 0.011390... Val Loss: 0.086432\n",
      "Epoch: 37/100... Step: 3823... Loss: 0.016931... Val Loss: 0.079123\n",
      "Epoch: 37/100... Step: 3824... Loss: 0.024566... Val Loss: 0.068627\n",
      "Epoch: 37/100... Step: 3825... Loss: 0.024722... Val Loss: 0.043907\n",
      "Epoch: 37/100... Step: 3826... Loss: 0.027482... Val Loss: 0.023990\n",
      "Epoch: 37/100... Step: 3827... Loss: 0.031582... Val Loss: 0.020110\n",
      "Epoch: 37/100... Step: 3828... Loss: 0.029152... Val Loss: 0.015291\n",
      "Epoch: 37/100... Step: 3829... Loss: 0.021547... Val Loss: 0.041777\n",
      "Epoch: 37/100... Step: 3830... Loss: 0.048512... Val Loss: 0.058629\n",
      "Epoch: 37/100... Step: 3831... Loss: 0.028345... Val Loss: 0.056097\n",
      "Epoch: 37/100... Step: 3832... Loss: 0.023724... Val Loss: 0.059187\n",
      "Epoch: 37/100... Step: 3833... Loss: 0.020736... Val Loss: 0.048924\n",
      "Epoch: 37/100... Step: 3834... Loss: 0.026507... Val Loss: 0.045044\n",
      "Epoch: 37/100... Step: 3835... Loss: 0.024049... Val Loss: 0.032644\n",
      "Epoch: 37/100... Step: 3836... Loss: 0.022336... Val Loss: 0.008419\n",
      "Epoch: 37/100... Step: 3837... Loss: 0.015849... Val Loss: 0.017967\n",
      "Epoch: 37/100... Step: 3838... Loss: 0.024050... Val Loss: 0.029546\n",
      "Epoch: 37/100... Step: 3839... Loss: 0.035364... Val Loss: 0.028777\n",
      "Epoch: 37/100... Step: 3840... Loss: 0.037684... Val Loss: 0.021827\n",
      "Epoch: 37/100... Step: 3841... Loss: 0.026059... Val Loss: 0.021222\n",
      "Epoch: 37/100... Step: 3842... Loss: 0.034239... Val Loss: 0.007983\n",
      "Epoch: 37/100... Step: 3843... Loss: 0.023717... Val Loss: 0.006751\n",
      "Epoch: 37/100... Step: 3844... Loss: 0.030743... Val Loss: 0.013258\n",
      "Epoch: 37/100... Step: 3845... Loss: 0.017267... Val Loss: 0.021210\n",
      "Epoch: 37/100... Step: 3846... Loss: 0.024658... Val Loss: 0.029490\n",
      "Epoch: 37/100... Step: 3847... Loss: 0.034165... Val Loss: 0.032297\n",
      "Epoch: 37/100... Step: 3848... Loss: 0.036832... Val Loss: 0.025233\n",
      "Epoch: 38/100... Step: 3849... Loss: 0.021740... Val Loss: 0.091311\n",
      "Epoch: 38/100... Step: 3850... Loss: 0.020993... Val Loss: 0.189617\n",
      "Epoch: 38/100... Step: 3851... Loss: 0.020816... Val Loss: 0.090261\n",
      "Epoch: 38/100... Step: 3852... Loss: 0.016015... Val Loss: 0.062828\n",
      "Epoch: 38/100... Step: 3853... Loss: 0.035894... Val Loss: 0.058110\n",
      "Epoch: 38/100... Step: 3854... Loss: 0.019414... Val Loss: 0.032105\n",
      "Epoch: 38/100... Step: 3855... Loss: 0.029996... Val Loss: 0.018302\n",
      "Epoch: 38/100... Step: 3856... Loss: 0.016001... Val Loss: 0.007545\n",
      "Epoch: 38/100... Step: 3857... Loss: 0.029236... Val Loss: 0.015285\n",
      "Epoch: 38/100... Step: 3858... Loss: 0.015641... Val Loss: 0.024106\n",
      "Epoch: 38/100... Step: 3859... Loss: 0.025807... Val Loss: 0.024169\n",
      "Epoch: 38/100... Step: 3860... Loss: 0.020485... Val Loss: 0.022938\n",
      "Epoch: 38/100... Step: 3861... Loss: 0.030798... Val Loss: 0.007418\n",
      "Epoch: 38/100... Step: 3862... Loss: 0.032562... Val Loss: 0.004994\n",
      "Epoch: 38/100... Step: 3863... Loss: 0.024029... Val Loss: 0.005657\n",
      "Epoch: 38/100... Step: 3864... Loss: 0.011391... Val Loss: 0.011973\n",
      "Epoch: 38/100... Step: 3865... Loss: 0.022880... Val Loss: 0.019145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100... Step: 3866... Loss: 0.020777... Val Loss: 0.021546\n",
      "Epoch: 38/100... Step: 3867... Loss: 0.027936... Val Loss: 0.031174\n",
      "Epoch: 38/100... Step: 3868... Loss: 0.027118... Val Loss: 0.048550\n",
      "Epoch: 38/100... Step: 3869... Loss: 0.014705... Val Loss: 0.046905\n",
      "Epoch: 38/100... Step: 3870... Loss: 0.028168... Val Loss: 0.022192\n",
      "Epoch: 38/100... Step: 3871... Loss: 0.030526... Val Loss: 0.021741\n",
      "Epoch: 38/100... Step: 3872... Loss: 0.016612... Val Loss: 0.015840\n",
      "Epoch: 38/100... Step: 3873... Loss: 0.041767... Val Loss: 0.009608\n",
      "Epoch: 38/100... Step: 3874... Loss: 0.035756... Val Loss: 0.011125\n",
      "Epoch: 38/100... Step: 3875... Loss: 0.028970... Val Loss: 0.029595\n",
      "Epoch: 38/100... Step: 3876... Loss: 0.029453... Val Loss: 0.034514\n",
      "Epoch: 38/100... Step: 3877... Loss: 0.025969... Val Loss: 0.027749\n",
      "Epoch: 38/100... Step: 3878... Loss: 0.030860... Val Loss: 0.024536\n",
      "Epoch: 38/100... Step: 3879... Loss: 0.038649... Val Loss: 0.021468\n",
      "Epoch: 38/100... Step: 3880... Loss: 0.040115... Val Loss: 0.018099\n",
      "Epoch: 38/100... Step: 3881... Loss: 0.030214... Val Loss: 0.016448\n",
      "Epoch: 38/100... Step: 3882... Loss: 0.039780... Val Loss: 0.011933\n",
      "Epoch: 38/100... Step: 3883... Loss: 0.028525... Val Loss: 0.012065\n",
      "Epoch: 38/100... Step: 3884... Loss: 0.027566... Val Loss: 0.022743\n",
      "Epoch: 38/100... Step: 3885... Loss: 0.022630... Val Loss: 0.059093\n",
      "Epoch: 38/100... Step: 3886... Loss: 0.026801... Val Loss: 0.083850\n",
      "Epoch: 38/100... Step: 3887... Loss: 0.040126... Val Loss: 0.095787\n",
      "Epoch: 38/100... Step: 3888... Loss: 0.021809... Val Loss: 0.090186\n",
      "Epoch: 38/100... Step: 3889... Loss: 0.026127... Val Loss: 0.084316\n",
      "Epoch: 38/100... Step: 3890... Loss: 0.033195... Val Loss: 0.089472\n",
      "Epoch: 38/100... Step: 3891... Loss: 0.016539... Val Loss: 0.117467\n",
      "Epoch: 38/100... Step: 3892... Loss: 0.040205... Val Loss: 0.127976\n",
      "Epoch: 38/100... Step: 3893... Loss: 0.030624... Val Loss: 0.125024\n",
      "Epoch: 38/100... Step: 3894... Loss: 0.040589... Val Loss: 0.110936\n",
      "Epoch: 38/100... Step: 3895... Loss: 0.023787... Val Loss: 0.094446\n",
      "Epoch: 38/100... Step: 3896... Loss: 0.038976... Val Loss: 0.076998\n",
      "Epoch: 38/100... Step: 3897... Loss: 0.018869... Val Loss: 0.039140\n",
      "Epoch: 38/100... Step: 3898... Loss: 0.020349... Val Loss: 0.017019\n",
      "Epoch: 38/100... Step: 3899... Loss: 0.029216... Val Loss: 0.020435\n",
      "Epoch: 38/100... Step: 3900... Loss: 0.022345... Val Loss: 0.034597\n",
      "Epoch: 38/100... Step: 3901... Loss: 0.018286... Val Loss: 0.051128\n",
      "Epoch: 38/100... Step: 3902... Loss: 0.033645... Val Loss: 0.050778\n",
      "Epoch: 38/100... Step: 3903... Loss: 0.019312... Val Loss: 0.053279\n",
      "Epoch: 38/100... Step: 3904... Loss: 0.029320... Val Loss: 0.031109\n",
      "Epoch: 38/100... Step: 3905... Loss: 0.028689... Val Loss: 0.015223\n",
      "Epoch: 38/100... Step: 3906... Loss: 0.025755... Val Loss: 0.022584\n",
      "Epoch: 38/100... Step: 3907... Loss: 0.042535... Val Loss: 0.026363\n",
      "Epoch: 38/100... Step: 3908... Loss: 0.031701... Val Loss: 0.016265\n",
      "Epoch: 38/100... Step: 3909... Loss: 0.018303... Val Loss: 0.034759\n",
      "Epoch: 38/100... Step: 3910... Loss: 0.027149... Val Loss: 0.061105\n",
      "Epoch: 38/100... Step: 3911... Loss: 0.042976... Val Loss: 0.066342\n",
      "Epoch: 38/100... Step: 3912... Loss: 0.024521... Val Loss: 0.084216\n",
      "Epoch: 38/100... Step: 3913... Loss: 0.030445... Val Loss: 0.107889\n",
      "Epoch: 38/100... Step: 3914... Loss: 0.041208... Val Loss: 0.038729\n",
      "Epoch: 38/100... Step: 3915... Loss: 0.021422... Val Loss: 0.037649\n",
      "Epoch: 38/100... Step: 3916... Loss: 0.036293... Val Loss: 0.042988\n",
      "Epoch: 38/100... Step: 3917... Loss: 0.035069... Val Loss: 0.034818\n",
      "Epoch: 38/100... Step: 3918... Loss: 0.035429... Val Loss: 0.041320\n",
      "Epoch: 38/100... Step: 3919... Loss: 0.026829... Val Loss: 0.046021\n",
      "Epoch: 38/100... Step: 3920... Loss: 0.024157... Val Loss: 0.059677\n",
      "Epoch: 38/100... Step: 3921... Loss: 0.026395... Val Loss: 0.075325\n",
      "Epoch: 38/100... Step: 3922... Loss: 0.023263... Val Loss: 0.104113\n",
      "Epoch: 38/100... Step: 3923... Loss: 0.024105... Val Loss: 0.123757\n",
      "Epoch: 38/100... Step: 3924... Loss: 0.032283... Val Loss: 0.133406\n",
      "Epoch: 38/100... Step: 3925... Loss: 0.022466... Val Loss: 0.135153\n",
      "Epoch: 38/100... Step: 3926... Loss: 0.023866... Val Loss: 0.125012\n",
      "Epoch: 38/100... Step: 3927... Loss: 0.018338... Val Loss: 0.121402\n",
      "Epoch: 38/100... Step: 3928... Loss: 0.034031... Val Loss: 0.119067\n",
      "Epoch: 38/100... Step: 3929... Loss: 0.026139... Val Loss: 0.107714\n",
      "Epoch: 38/100... Step: 3930... Loss: 0.022270... Val Loss: 0.081006\n",
      "Epoch: 38/100... Step: 3931... Loss: 0.023951... Val Loss: 0.058189\n",
      "Epoch: 38/100... Step: 3932... Loss: 0.028957... Val Loss: 0.025215\n",
      "Epoch: 38/100... Step: 3933... Loss: 0.027675... Val Loss: 0.014062\n",
      "Epoch: 38/100... Step: 3934... Loss: 0.037524... Val Loss: 0.018783\n",
      "Epoch: 38/100... Step: 3935... Loss: 0.020342... Val Loss: 0.032704\n",
      "Epoch: 38/100... Step: 3936... Loss: 0.024029... Val Loss: 0.019370\n",
      "Epoch: 38/100... Step: 3937... Loss: 0.042736... Val Loss: 0.018078\n",
      "Epoch: 38/100... Step: 3938... Loss: 0.039663... Val Loss: 0.017074\n",
      "Epoch: 38/100... Step: 3939... Loss: 0.030516... Val Loss: 0.014007\n",
      "Epoch: 38/100... Step: 3940... Loss: 0.023536... Val Loss: 0.009953\n",
      "Epoch: 38/100... Step: 3941... Loss: 0.024205... Val Loss: 0.011984\n",
      "Epoch: 38/100... Step: 3942... Loss: 0.032534... Val Loss: 0.025673\n",
      "Epoch: 38/100... Step: 3943... Loss: 0.028079... Val Loss: 0.061718\n",
      "Epoch: 38/100... Step: 3944... Loss: 0.023008... Val Loss: 0.075417\n",
      "Epoch: 38/100... Step: 3945... Loss: 0.044038... Val Loss: 0.068639\n",
      "Epoch: 38/100... Step: 3946... Loss: 0.038675... Val Loss: 0.053668\n",
      "Epoch: 38/100... Step: 3947... Loss: 0.024464... Val Loss: 0.015139\n",
      "Epoch: 38/100... Step: 3948... Loss: 0.024303... Val Loss: 0.009573\n",
      "Epoch: 38/100... Step: 3949... Loss: 0.024981... Val Loss: 0.047615\n",
      "Epoch: 38/100... Step: 3950... Loss: 0.024812... Val Loss: 0.079072\n",
      "Epoch: 38/100... Step: 3951... Loss: 0.025535... Val Loss: 0.080741\n",
      "Epoch: 38/100... Step: 3952... Loss: 0.031135... Val Loss: 0.067635\n",
      "Epoch: 39/100... Step: 3953... Loss: 0.015461... Val Loss: 0.165095\n",
      "Epoch: 39/100... Step: 3954... Loss: 0.029145... Val Loss: 0.057984\n",
      "Epoch: 39/100... Step: 3955... Loss: 0.020605... Val Loss: 0.038354\n",
      "Epoch: 39/100... Step: 3956... Loss: 0.021764... Val Loss: 0.126932\n",
      "Epoch: 39/100... Step: 3957... Loss: 0.029754... Val Loss: 0.194626\n",
      "Epoch: 39/100... Step: 3958... Loss: 0.019884... Val Loss: 0.197584\n",
      "Epoch: 39/100... Step: 3959... Loss: 0.028813... Val Loss: 0.198715\n",
      "Epoch: 39/100... Step: 3960... Loss: 0.019299... Val Loss: 0.223069\n",
      "Epoch: 39/100... Step: 3961... Loss: 0.022905... Val Loss: 0.243398\n",
      "Epoch: 39/100... Step: 3962... Loss: 0.029001... Val Loss: 0.255405\n",
      "Epoch: 39/100... Step: 3963... Loss: 0.021309... Val Loss: 0.251738\n",
      "Epoch: 39/100... Step: 3964... Loss: 0.031994... Val Loss: 0.251371\n",
      "Epoch: 39/100... Step: 3965... Loss: 0.026298... Val Loss: 0.220876\n",
      "Epoch: 39/100... Step: 3966... Loss: 0.033299... Val Loss: 0.196882\n",
      "Epoch: 39/100... Step: 3967... Loss: 0.024728... Val Loss: 0.142832\n",
      "Epoch: 39/100... Step: 3968... Loss: 0.028287... Val Loss: 0.106565\n",
      "Epoch: 39/100... Step: 3969... Loss: 0.021499... Val Loss: 0.102890\n",
      "Epoch: 39/100... Step: 3970... Loss: 0.018752... Val Loss: 0.095705\n",
      "Epoch: 39/100... Step: 3971... Loss: 0.025051... Val Loss: 0.099303\n",
      "Epoch: 39/100... Step: 3972... Loss: 0.026415... Val Loss: 0.099562\n",
      "Epoch: 39/100... Step: 3973... Loss: 0.033049... Val Loss: 0.093358\n",
      "Epoch: 39/100... Step: 3974... Loss: 0.034571... Val Loss: 0.072086\n",
      "Epoch: 39/100... Step: 3975... Loss: 0.018172... Val Loss: 0.065485\n",
      "Epoch: 39/100... Step: 3976... Loss: 0.029035... Val Loss: 0.069631\n",
      "Epoch: 39/100... Step: 3977... Loss: 0.034180... Val Loss: 0.085249\n",
      "Epoch: 39/100... Step: 3978... Loss: 0.026711... Val Loss: 0.105903\n",
      "Epoch: 39/100... Step: 3979... Loss: 0.023110... Val Loss: 0.131006\n",
      "Epoch: 39/100... Step: 3980... Loss: 0.029551... Val Loss: 0.144677\n",
      "Epoch: 39/100... Step: 3981... Loss: 0.031600... Val Loss: 0.150330\n",
      "Epoch: 39/100... Step: 3982... Loss: 0.027264... Val Loss: 0.161858\n",
      "Epoch: 39/100... Step: 3983... Loss: 0.018696... Val Loss: 0.147936\n",
      "Epoch: 39/100... Step: 3984... Loss: 0.033721... Val Loss: 0.122492\n",
      "Epoch: 39/100... Step: 3985... Loss: 0.022012... Val Loss: 0.112761\n",
      "Epoch: 39/100... Step: 3986... Loss: 0.027472... Val Loss: 0.092948\n",
      "Epoch: 39/100... Step: 3987... Loss: 0.030443... Val Loss: 0.078254\n",
      "Epoch: 39/100... Step: 3988... Loss: 0.021406... Val Loss: 0.066410\n",
      "Epoch: 39/100... Step: 3989... Loss: 0.020525... Val Loss: 0.057377\n",
      "Epoch: 39/100... Step: 3990... Loss: 0.015115... Val Loss: 0.023888\n",
      "Epoch: 39/100... Step: 3991... Loss: 0.026926... Val Loss: 0.023674\n",
      "Epoch: 39/100... Step: 3992... Loss: 0.031807... Val Loss: 0.039643\n",
      "Epoch: 39/100... Step: 3993... Loss: 0.027223... Val Loss: 0.053626\n",
      "Epoch: 39/100... Step: 3994... Loss: 0.020014... Val Loss: 0.066671\n",
      "Epoch: 39/100... Step: 3995... Loss: 0.041666... Val Loss: 0.093477\n",
      "Epoch: 39/100... Step: 3996... Loss: 0.035195... Val Loss: 0.118142\n",
      "Epoch: 39/100... Step: 3997... Loss: 0.032557... Val Loss: 0.118850\n",
      "Epoch: 39/100... Step: 3998... Loss: 0.026107... Val Loss: 0.096879\n",
      "Epoch: 39/100... Step: 3999... Loss: 0.028076... Val Loss: 0.075457\n",
      "Epoch: 39/100... Step: 4000... Loss: 0.023544... Val Loss: 0.041969\n",
      "Epoch: 39/100... Step: 4001... Loss: 0.031479... Val Loss: 0.018700\n",
      "Epoch: 39/100... Step: 4002... Loss: 0.034497... Val Loss: 0.027617\n",
      "Epoch: 39/100... Step: 4003... Loss: 0.031625... Val Loss: 0.065941\n",
      "Epoch: 39/100... Step: 4004... Loss: 0.034499... Val Loss: 0.103115\n",
      "Epoch: 39/100... Step: 4005... Loss: 0.035185... Val Loss: 0.116770\n",
      "Epoch: 39/100... Step: 4006... Loss: 0.029848... Val Loss: 0.113333\n",
      "Epoch: 39/100... Step: 4007... Loss: 0.035688... Val Loss: 0.091644\n",
      "Epoch: 39/100... Step: 4008... Loss: 0.034166... Val Loss: 0.058800\n",
      "Epoch: 39/100... Step: 4009... Loss: 0.029570... Val Loss: 0.056832\n",
      "Epoch: 39/100... Step: 4010... Loss: 0.017925... Val Loss: 0.070944\n",
      "Epoch: 39/100... Step: 4011... Loss: 0.023878... Val Loss: 0.083419\n",
      "Epoch: 39/100... Step: 4012... Loss: 0.025879... Val Loss: 0.085580\n",
      "Epoch: 39/100... Step: 4013... Loss: 0.015123... Val Loss: 0.081771\n",
      "Epoch: 39/100... Step: 4014... Loss: 0.018804... Val Loss: 0.093849\n",
      "Epoch: 39/100... Step: 4015... Loss: 0.028997... Val Loss: 0.116296\n",
      "Epoch: 39/100... Step: 4016... Loss: 0.025527... Val Loss: 0.133606\n",
      "Epoch: 39/100... Step: 4017... Loss: 0.028704... Val Loss: 0.138854\n",
      "Epoch: 39/100... Step: 4018... Loss: 0.027967... Val Loss: 0.142013\n",
      "Epoch: 39/100... Step: 4019... Loss: 0.022394... Val Loss: 0.153733\n",
      "Epoch: 39/100... Step: 4020... Loss: 0.040515... Val Loss: 0.157696\n",
      "Epoch: 39/100... Step: 4021... Loss: 0.044203... Val Loss: 0.136726\n",
      "Epoch: 39/100... Step: 4022... Loss: 0.027742... Val Loss: 0.106315\n",
      "Epoch: 39/100... Step: 4023... Loss: 0.026532... Val Loss: 0.065124\n",
      "Epoch: 39/100... Step: 4024... Loss: 0.046130... Val Loss: 0.017246\n",
      "Epoch: 39/100... Step: 4025... Loss: 0.047603... Val Loss: 0.022705\n",
      "Epoch: 39/100... Step: 4026... Loss: 0.024179... Val Loss: 0.040262\n",
      "Epoch: 39/100... Step: 4027... Loss: 0.025657... Val Loss: 0.014769\n",
      "Epoch: 39/100... Step: 4028... Loss: 0.013821... Val Loss: 0.013698\n",
      "Epoch: 39/100... Step: 4029... Loss: 0.028330... Val Loss: 0.009865\n",
      "Epoch: 39/100... Step: 4030... Loss: 0.045881... Val Loss: 0.008791\n",
      "Epoch: 39/100... Step: 4031... Loss: 0.033651... Val Loss: 0.009779\n",
      "Epoch: 39/100... Step: 4032... Loss: 0.025165... Val Loss: 0.008481\n",
      "Epoch: 39/100... Step: 4033... Loss: 0.025808... Val Loss: 0.014910\n",
      "Epoch: 39/100... Step: 4034... Loss: 0.035537... Val Loss: 0.008827\n",
      "Epoch: 39/100... Step: 4035... Loss: 0.026074... Val Loss: 0.010617\n",
      "Epoch: 39/100... Step: 4036... Loss: 0.031344... Val Loss: 0.011970\n",
      "Epoch: 39/100... Step: 4037... Loss: 0.041079... Val Loss: 0.015043\n",
      "Epoch: 39/100... Step: 4038... Loss: 0.026517... Val Loss: 0.013311\n",
      "Epoch: 39/100... Step: 4039... Loss: 0.020630... Val Loss: 0.013434\n",
      "Epoch: 39/100... Step: 4040... Loss: 0.035443... Val Loss: 0.014277\n",
      "Epoch: 39/100... Step: 4041... Loss: 0.039013... Val Loss: 0.020316\n",
      "Epoch: 39/100... Step: 4042... Loss: 0.022385... Val Loss: 0.030887\n",
      "Epoch: 39/100... Step: 4043... Loss: 0.022563... Val Loss: 0.042238\n",
      "Epoch: 39/100... Step: 4044... Loss: 0.022658... Val Loss: 0.054688\n",
      "Epoch: 39/100... Step: 4045... Loss: 0.036459... Val Loss: 0.061944\n",
      "Epoch: 39/100... Step: 4046... Loss: 0.027846... Val Loss: 0.045237\n",
      "Epoch: 39/100... Step: 4047... Loss: 0.020004... Val Loss: 0.030216\n",
      "Epoch: 39/100... Step: 4048... Loss: 0.034060... Val Loss: 0.014251\n",
      "Epoch: 39/100... Step: 4049... Loss: 0.031040... Val Loss: 0.011331\n",
      "Epoch: 39/100... Step: 4050... Loss: 0.018818... Val Loss: 0.013129\n",
      "Epoch: 39/100... Step: 4051... Loss: 0.018315... Val Loss: 0.026418\n",
      "Epoch: 39/100... Step: 4052... Loss: 0.019069... Val Loss: 0.026149\n",
      "Epoch: 39/100... Step: 4053... Loss: 0.016721... Val Loss: 0.022994\n",
      "Epoch: 39/100... Step: 4054... Loss: 0.030933... Val Loss: 0.018812\n",
      "Epoch: 39/100... Step: 4055... Loss: 0.026450... Val Loss: 0.032371\n",
      "Epoch: 39/100... Step: 4056... Loss: 0.025822... Val Loss: 0.041191\n",
      "Epoch: 40/100... Step: 4057... Loss: 0.017018... Val Loss: 0.087947\n",
      "Epoch: 40/100... Step: 4058... Loss: 0.021239... Val Loss: 0.024178\n",
      "Epoch: 40/100... Step: 4059... Loss: 0.033071... Val Loss: 0.042387\n",
      "Epoch: 40/100... Step: 4060... Loss: 0.019506... Val Loss: 0.065377\n",
      "Epoch: 40/100... Step: 4061... Loss: 0.018113... Val Loss: 0.042819\n",
      "Epoch: 40/100... Step: 4062... Loss: 0.020210... Val Loss: 0.052044\n",
      "Epoch: 40/100... Step: 4063... Loss: 0.025162... Val Loss: 0.050742\n",
      "Epoch: 40/100... Step: 4064... Loss: 0.019774... Val Loss: 0.072468\n",
      "Epoch: 40/100... Step: 4065... Loss: 0.031801... Val Loss: 0.087569\n",
      "Epoch: 40/100... Step: 4066... Loss: 0.017940... Val Loss: 0.090507\n",
      "Epoch: 40/100... Step: 4067... Loss: 0.032634... Val Loss: 0.087204\n",
      "Epoch: 40/100... Step: 4068... Loss: 0.029861... Val Loss: 0.084820\n",
      "Epoch: 40/100... Step: 4069... Loss: 0.028450... Val Loss: 0.087684\n",
      "Epoch: 40/100... Step: 4070... Loss: 0.021589... Val Loss: 0.099980\n",
      "Epoch: 40/100... Step: 4071... Loss: 0.018555... Val Loss: 0.100762\n",
      "Epoch: 40/100... Step: 4072... Loss: 0.021963... Val Loss: 0.110660\n",
      "Epoch: 40/100... Step: 4073... Loss: 0.020889... Val Loss: 0.094341\n",
      "Epoch: 40/100... Step: 4074... Loss: 0.013827... Val Loss: 0.091436\n",
      "Epoch: 40/100... Step: 4075... Loss: 0.025262... Val Loss: 0.084206\n",
      "Epoch: 40/100... Step: 4076... Loss: 0.041022... Val Loss: 0.103119\n",
      "Epoch: 40/100... Step: 4077... Loss: 0.022060... Val Loss: 0.103840\n",
      "Epoch: 40/100... Step: 4078... Loss: 0.021053... Val Loss: 0.101538\n",
      "Epoch: 40/100... Step: 4079... Loss: 0.021494... Val Loss: 0.103460\n",
      "Epoch: 40/100... Step: 4080... Loss: 0.029062... Val Loss: 0.103539\n",
      "Epoch: 40/100... Step: 4081... Loss: 0.032104... Val Loss: 0.107470\n",
      "Epoch: 40/100... Step: 4082... Loss: 0.031193... Val Loss: 0.118756\n",
      "Epoch: 40/100... Step: 4083... Loss: 0.022054... Val Loss: 0.128804\n",
      "Epoch: 40/100... Step: 4084... Loss: 0.029007... Val Loss: 0.137086\n",
      "Epoch: 40/100... Step: 4085... Loss: 0.023752... Val Loss: 0.140197\n",
      "Epoch: 40/100... Step: 4086... Loss: 0.033989... Val Loss: 0.152100\n",
      "Epoch: 40/100... Step: 4087... Loss: 0.025231... Val Loss: 0.136080\n",
      "Epoch: 40/100... Step: 4088... Loss: 0.019184... Val Loss: 0.131960\n",
      "Epoch: 40/100... Step: 4089... Loss: 0.028418... Val Loss: 0.132343\n",
      "Epoch: 40/100... Step: 4090... Loss: 0.022463... Val Loss: 0.136509\n",
      "Epoch: 40/100... Step: 4091... Loss: 0.020737... Val Loss: 0.147970\n",
      "Epoch: 40/100... Step: 4092... Loss: 0.021334... Val Loss: 0.149759\n",
      "Epoch: 40/100... Step: 4093... Loss: 0.032264... Val Loss: 0.137439\n",
      "Epoch: 40/100... Step: 4094... Loss: 0.025226... Val Loss: 0.119441\n",
      "Epoch: 40/100... Step: 4095... Loss: 0.031679... Val Loss: 0.106804\n",
      "Epoch: 40/100... Step: 4096... Loss: 0.042866... Val Loss: 0.065784\n",
      "Epoch: 40/100... Step: 4097... Loss: 0.017075... Val Loss: 0.038512\n",
      "Epoch: 40/100... Step: 4098... Loss: 0.033077... Val Loss: 0.026672\n",
      "Epoch: 40/100... Step: 4099... Loss: 0.021518... Val Loss: 0.017252\n",
      "Epoch: 40/100... Step: 4100... Loss: 0.022642... Val Loss: 0.009383\n",
      "Epoch: 40/100... Step: 4101... Loss: 0.032545... Val Loss: 0.006933\n",
      "Epoch: 40/100... Step: 4102... Loss: 0.026536... Val Loss: 0.007472\n",
      "Epoch: 40/100... Step: 4103... Loss: 0.037243... Val Loss: 0.011349\n",
      "Epoch: 40/100... Step: 4104... Loss: 0.021436... Val Loss: 0.009748\n",
      "Epoch: 40/100... Step: 4105... Loss: 0.028631... Val Loss: 0.019306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100... Step: 4106... Loss: 0.026443... Val Loss: 0.035694\n",
      "Epoch: 40/100... Step: 4107... Loss: 0.024724... Val Loss: 0.061593\n",
      "Epoch: 40/100... Step: 4108... Loss: 0.021810... Val Loss: 0.081023\n",
      "Epoch: 40/100... Step: 4109... Loss: 0.020862... Val Loss: 0.118723\n",
      "Epoch: 40/100... Step: 4110... Loss: 0.029776... Val Loss: 0.127372\n",
      "Epoch: 40/100... Step: 4111... Loss: 0.034622... Val Loss: 0.123705\n",
      "Epoch: 40/100... Step: 4112... Loss: 0.024335... Val Loss: 0.118577\n",
      "Epoch: 40/100... Step: 4113... Loss: 0.024458... Val Loss: 0.129369\n",
      "Epoch: 40/100... Step: 4114... Loss: 0.033311... Val Loss: 0.141749\n",
      "Epoch: 40/100... Step: 4115... Loss: 0.034370... Val Loss: 0.136921\n",
      "Epoch: 40/100... Step: 4116... Loss: 0.046436... Val Loss: 0.140905\n",
      "Epoch: 40/100... Step: 4117... Loss: 0.024449... Val Loss: 0.128967\n",
      "Epoch: 40/100... Step: 4118... Loss: 0.030923... Val Loss: 0.104993\n",
      "Epoch: 40/100... Step: 4119... Loss: 0.021332... Val Loss: 0.085767\n",
      "Epoch: 40/100... Step: 4120... Loss: 0.022872... Val Loss: 0.053678\n",
      "Epoch: 40/100... Step: 4121... Loss: 0.021546... Val Loss: 0.036502\n",
      "Epoch: 40/100... Step: 4122... Loss: 0.024679... Val Loss: 0.007875\n",
      "Epoch: 40/100... Step: 4123... Loss: 0.016012... Val Loss: 0.028113\n",
      "Epoch: 40/100... Step: 4124... Loss: 0.026726... Val Loss: 0.044928\n",
      "Epoch: 40/100... Step: 4125... Loss: 0.027172... Val Loss: 0.012576\n",
      "Epoch: 40/100... Step: 4126... Loss: 0.035673... Val Loss: 0.010054\n",
      "Epoch: 40/100... Step: 4127... Loss: 0.021862... Val Loss: 0.009369\n",
      "Epoch: 40/100... Step: 4128... Loss: 0.027068... Val Loss: 0.009462\n",
      "Epoch: 40/100... Step: 4129... Loss: 0.023200... Val Loss: 0.010492\n",
      "Epoch: 40/100... Step: 4130... Loss: 0.019594... Val Loss: 0.010526\n",
      "Epoch: 40/100... Step: 4131... Loss: 0.037053... Val Loss: 0.011943\n",
      "Epoch: 40/100... Step: 4132... Loss: 0.025946... Val Loss: 0.006975\n",
      "Epoch: 40/100... Step: 4133... Loss: 0.030208... Val Loss: 0.021317\n",
      "Epoch: 40/100... Step: 4134... Loss: 0.020852... Val Loss: 0.032155\n",
      "Epoch: 40/100... Step: 4135... Loss: 0.027800... Val Loss: 0.046498\n",
      "Epoch: 40/100... Step: 4136... Loss: 0.022517... Val Loss: 0.061158\n",
      "Epoch: 40/100... Step: 4137... Loss: 0.023065... Val Loss: 0.076412\n",
      "Epoch: 40/100... Step: 4138... Loss: 0.027531... Val Loss: 0.088723\n",
      "Epoch: 40/100... Step: 4139... Loss: 0.019378... Val Loss: 0.086934\n",
      "Epoch: 40/100... Step: 4140... Loss: 0.030959... Val Loss: 0.094747\n",
      "Epoch: 40/100... Step: 4141... Loss: 0.021125... Val Loss: 0.090947\n",
      "Epoch: 40/100... Step: 4142... Loss: 0.025871... Val Loss: 0.080968\n",
      "Epoch: 40/100... Step: 4143... Loss: 0.033654... Val Loss: 0.082500\n",
      "Epoch: 40/100... Step: 4144... Loss: 0.018747... Val Loss: 0.061276\n",
      "Epoch: 40/100... Step: 4145... Loss: 0.022891... Val Loss: 0.047055\n",
      "Epoch: 40/100... Step: 4146... Loss: 0.026204... Val Loss: 0.034613\n",
      "Epoch: 40/100... Step: 4147... Loss: 0.019879... Val Loss: 0.019174\n",
      "Epoch: 40/100... Step: 4148... Loss: 0.032249... Val Loss: 0.008208\n",
      "Epoch: 40/100... Step: 4149... Loss: 0.023751... Val Loss: 0.011150\n",
      "Epoch: 40/100... Step: 4150... Loss: 0.015539... Val Loss: 0.017669\n",
      "Epoch: 40/100... Step: 4151... Loss: 0.022283... Val Loss: 0.029659\n",
      "Epoch: 40/100... Step: 4152... Loss: 0.015307... Val Loss: 0.041952\n",
      "Epoch: 40/100... Step: 4153... Loss: 0.024622... Val Loss: 0.050649\n",
      "Epoch: 40/100... Step: 4154... Loss: 0.027999... Val Loss: 0.056307\n",
      "Epoch: 40/100... Step: 4155... Loss: 0.029618... Val Loss: 0.125034\n",
      "Epoch: 40/100... Step: 4156... Loss: 0.029558... Val Loss: 0.148255\n",
      "Epoch: 40/100... Step: 4157... Loss: 0.031540... Val Loss: 0.161772\n",
      "Epoch: 40/100... Step: 4158... Loss: 0.032985... Val Loss: 0.177118\n",
      "Epoch: 40/100... Step: 4159... Loss: 0.034571... Val Loss: 0.171759\n",
      "Epoch: 40/100... Step: 4160... Loss: 0.026715... Val Loss: 0.155753\n",
      "Epoch: 41/100... Step: 4161... Loss: 0.021433... Val Loss: 0.078316\n",
      "Epoch: 41/100... Step: 4162... Loss: 0.016951... Val Loss: 0.128041\n",
      "Epoch: 41/100... Step: 4163... Loss: 0.018167... Val Loss: 0.180496\n",
      "Epoch: 41/100... Step: 4164... Loss: 0.017013... Val Loss: 0.233563\n",
      "Epoch: 41/100... Step: 4165... Loss: 0.029519... Val Loss: 0.232369\n",
      "Epoch: 41/100... Step: 4166... Loss: 0.015449... Val Loss: 0.216946\n",
      "Epoch: 41/100... Step: 4167... Loss: 0.028214... Val Loss: 0.196362\n",
      "Epoch: 41/100... Step: 4168... Loss: 0.023585... Val Loss: 0.196175\n",
      "Epoch: 41/100... Step: 4169... Loss: 0.024339... Val Loss: 0.240659\n",
      "Epoch: 41/100... Step: 4170... Loss: 0.025034... Val Loss: 0.230989\n",
      "Epoch: 41/100... Step: 4171... Loss: 0.017229... Val Loss: 0.256042\n",
      "Epoch: 41/100... Step: 4172... Loss: 0.032351... Val Loss: 0.251069\n",
      "Epoch: 41/100... Step: 4173... Loss: 0.011711... Val Loss: 0.251643\n",
      "Epoch: 41/100... Step: 4174... Loss: 0.037526... Val Loss: 0.237304\n",
      "Epoch: 41/100... Step: 4175... Loss: 0.032740... Val Loss: 0.204054\n",
      "Epoch: 41/100... Step: 4176... Loss: 0.019757... Val Loss: 0.189781\n",
      "Epoch: 41/100... Step: 4177... Loss: 0.022946... Val Loss: 0.183713\n",
      "Epoch: 41/100... Step: 4178... Loss: 0.021197... Val Loss: 0.172702\n",
      "Epoch: 41/100... Step: 4179... Loss: 0.018939... Val Loss: 0.161371\n",
      "Epoch: 41/100... Step: 4180... Loss: 0.022870... Val Loss: 0.158717\n",
      "Epoch: 41/100... Step: 4181... Loss: 0.032689... Val Loss: 0.125134\n",
      "Epoch: 41/100... Step: 4182... Loss: 0.023119... Val Loss: 0.096057\n",
      "Epoch: 41/100... Step: 4183... Loss: 0.038098... Val Loss: 0.043079\n",
      "Epoch: 41/100... Step: 4184... Loss: 0.033768... Val Loss: 0.035759\n",
      "Epoch: 41/100... Step: 4185... Loss: 0.023185... Val Loss: 0.014653\n",
      "Epoch: 41/100... Step: 4186... Loss: 0.022562... Val Loss: 0.010446\n",
      "Epoch: 41/100... Step: 4187... Loss: 0.018592... Val Loss: 0.042980\n",
      "Epoch: 41/100... Step: 4188... Loss: 0.018044... Val Loss: 0.079981\n",
      "Epoch: 41/100... Step: 4189... Loss: 0.029966... Val Loss: 0.084775\n",
      "Epoch: 41/100... Step: 4190... Loss: 0.021635... Val Loss: 0.094045\n",
      "Epoch: 41/100... Step: 4191... Loss: 0.012839... Val Loss: 0.100601\n",
      "Epoch: 41/100... Step: 4192... Loss: 0.032485... Val Loss: 0.102144\n",
      "Epoch: 41/100... Step: 4193... Loss: 0.035049... Val Loss: 0.085066\n",
      "Epoch: 41/100... Step: 4194... Loss: 0.021670... Val Loss: 0.049582\n",
      "Epoch: 41/100... Step: 4195... Loss: 0.022831... Val Loss: 0.029726\n",
      "Epoch: 41/100... Step: 4196... Loss: 0.021053... Val Loss: 0.012248\n",
      "Epoch: 41/100... Step: 4197... Loss: 0.026723... Val Loss: 0.019789\n",
      "Epoch: 41/100... Step: 4198... Loss: 0.034257... Val Loss: 0.019178\n",
      "Epoch: 41/100... Step: 4199... Loss: 0.048939... Val Loss: 0.012595\n",
      "Epoch: 41/100... Step: 4200... Loss: 0.037263... Val Loss: 0.014457\n",
      "Epoch: 41/100... Step: 4201... Loss: 0.029751... Val Loss: 0.022636\n",
      "Epoch: 41/100... Step: 4202... Loss: 0.033501... Val Loss: 0.031828\n",
      "Epoch: 41/100... Step: 4203... Loss: 0.033019... Val Loss: 0.033802\n",
      "Epoch: 41/100... Step: 4204... Loss: 0.018950... Val Loss: 0.018891\n",
      "Epoch: 41/100... Step: 4205... Loss: 0.033148... Val Loss: 0.012911\n",
      "Epoch: 41/100... Step: 4206... Loss: 0.029988... Val Loss: 0.014959\n",
      "Epoch: 41/100... Step: 4207... Loss: 0.046275... Val Loss: 0.016691\n",
      "Epoch: 41/100... Step: 4208... Loss: 0.025370... Val Loss: 0.011287\n",
      "Epoch: 41/100... Step: 4209... Loss: 0.026203... Val Loss: 0.012607\n",
      "Epoch: 41/100... Step: 4210... Loss: 0.022858... Val Loss: 0.022648\n",
      "Epoch: 41/100... Step: 4211... Loss: 0.017757... Val Loss: 0.046626\n",
      "Epoch: 41/100... Step: 4212... Loss: 0.027488... Val Loss: 0.065235\n",
      "Epoch: 41/100... Step: 4213... Loss: 0.036674... Val Loss: 0.047937\n",
      "Epoch: 41/100... Step: 4214... Loss: 0.037256... Val Loss: 0.029592\n",
      "Epoch: 41/100... Step: 4215... Loss: 0.025477... Val Loss: 0.025784\n",
      "Epoch: 41/100... Step: 4216... Loss: 0.031147... Val Loss: 0.026741\n",
      "Epoch: 41/100... Step: 4217... Loss: 0.021163... Val Loss: 0.016603\n",
      "Epoch: 41/100... Step: 4218... Loss: 0.024028... Val Loss: 0.009913\n",
      "Epoch: 41/100... Step: 4219... Loss: 0.049160... Val Loss: 0.009768\n",
      "Epoch: 41/100... Step: 4220... Loss: 0.047216... Val Loss: 0.008811\n",
      "Epoch: 41/100... Step: 4221... Loss: 0.022326... Val Loss: 0.011697\n",
      "Epoch: 41/100... Step: 4222... Loss: 0.030073... Val Loss: 0.023421\n",
      "Epoch: 41/100... Step: 4223... Loss: 0.034809... Val Loss: 0.013935\n",
      "Epoch: 41/100... Step: 4224... Loss: 0.031080... Val Loss: 0.013996\n",
      "Epoch: 41/100... Step: 4225... Loss: 0.021679... Val Loss: 0.020188\n",
      "Epoch: 41/100... Step: 4226... Loss: 0.025929... Val Loss: 0.021223\n",
      "Epoch: 41/100... Step: 4227... Loss: 0.036210... Val Loss: 0.020969\n",
      "Epoch: 41/100... Step: 4228... Loss: 0.027765... Val Loss: 0.043081\n",
      "Epoch: 41/100... Step: 4229... Loss: 0.020636... Val Loss: 0.065451\n",
      "Epoch: 41/100... Step: 4230... Loss: 0.032148... Val Loss: 0.071642\n",
      "Epoch: 41/100... Step: 4231... Loss: 0.025374... Val Loss: 0.106659\n",
      "Epoch: 41/100... Step: 4232... Loss: 0.052808... Val Loss: 0.089957\n",
      "Epoch: 41/100... Step: 4233... Loss: 0.014895... Val Loss: 0.053827\n",
      "Epoch: 41/100... Step: 4234... Loss: 0.031123... Val Loss: 0.022809\n",
      "Epoch: 41/100... Step: 4235... Loss: 0.028740... Val Loss: 0.029840\n",
      "Epoch: 41/100... Step: 4236... Loss: 0.029253... Val Loss: 0.034855\n",
      "Epoch: 41/100... Step: 4237... Loss: 0.033894... Val Loss: 0.044345\n",
      "Epoch: 41/100... Step: 4238... Loss: 0.032466... Val Loss: 0.044875\n",
      "Epoch: 41/100... Step: 4239... Loss: 0.022439... Val Loss: 0.055324\n",
      "Epoch: 41/100... Step: 4240... Loss: 0.022055... Val Loss: 0.052117\n",
      "Epoch: 41/100... Step: 4241... Loss: 0.031558... Val Loss: 0.050947\n",
      "Epoch: 41/100... Step: 4242... Loss: 0.021197... Val Loss: 0.054470\n",
      "Epoch: 41/100... Step: 4243... Loss: 0.027614... Val Loss: 0.040545\n",
      "Epoch: 41/100... Step: 4244... Loss: 0.021752... Val Loss: 0.036510\n",
      "Epoch: 41/100... Step: 4245... Loss: 0.031211... Val Loss: 0.043656\n",
      "Epoch: 41/100... Step: 4246... Loss: 0.021860... Val Loss: 0.050699\n",
      "Epoch: 41/100... Step: 4247... Loss: 0.017331... Val Loss: 0.050856\n",
      "Epoch: 41/100... Step: 4248... Loss: 0.021196... Val Loss: 0.050881\n",
      "Epoch: 41/100... Step: 4249... Loss: 0.027726... Val Loss: 0.058466\n",
      "Epoch: 41/100... Step: 4250... Loss: 0.026531... Val Loss: 0.058142\n",
      "Epoch: 41/100... Step: 4251... Loss: 0.021282... Val Loss: 0.064792\n",
      "Epoch: 41/100... Step: 4252... Loss: 0.025874... Val Loss: 0.070675\n",
      "Epoch: 41/100... Step: 4253... Loss: 0.024325... Val Loss: 0.079617\n",
      "Epoch: 41/100... Step: 4254... Loss: 0.031524... Val Loss: 0.104275\n",
      "Epoch: 41/100... Step: 4255... Loss: 0.023005... Val Loss: 0.148242\n",
      "Epoch: 41/100... Step: 4256... Loss: 0.020497... Val Loss: 0.198073\n",
      "Epoch: 41/100... Step: 4257... Loss: 0.032991... Val Loss: 0.217787\n",
      "Epoch: 41/100... Step: 4258... Loss: 0.039909... Val Loss: 0.234324\n",
      "Epoch: 41/100... Step: 4259... Loss: 0.013474... Val Loss: 0.257868\n",
      "Epoch: 41/100... Step: 4260... Loss: 0.033994... Val Loss: 0.225949\n",
      "Epoch: 41/100... Step: 4261... Loss: 0.022876... Val Loss: 0.190830\n",
      "Epoch: 41/100... Step: 4262... Loss: 0.023691... Val Loss: 0.167986\n",
      "Epoch: 41/100... Step: 4263... Loss: 0.044560... Val Loss: 0.139565\n",
      "Epoch: 41/100... Step: 4264... Loss: 0.022606... Val Loss: 0.094868\n",
      "Epoch: 42/100... Step: 4265... Loss: 0.020028... Val Loss: 0.009567\n",
      "Epoch: 42/100... Step: 4266... Loss: 0.015787... Val Loss: 0.216059\n",
      "Epoch: 42/100... Step: 4267... Loss: 0.015939... Val Loss: 0.358310\n",
      "Epoch: 42/100... Step: 4268... Loss: 0.020860... Val Loss: 0.360687\n",
      "Epoch: 42/100... Step: 4269... Loss: 0.016833... Val Loss: 0.352761\n",
      "Epoch: 42/100... Step: 4270... Loss: 0.030745... Val Loss: 0.383863\n",
      "Epoch: 42/100... Step: 4271... Loss: 0.029004... Val Loss: 0.348891\n",
      "Epoch: 42/100... Step: 4272... Loss: 0.029176... Val Loss: 0.353025\n",
      "Epoch: 42/100... Step: 4273... Loss: 0.016115... Val Loss: 0.307585\n",
      "Epoch: 42/100... Step: 4274... Loss: 0.028993... Val Loss: 0.293844\n",
      "Epoch: 42/100... Step: 4275... Loss: 0.038164... Val Loss: 0.297739\n",
      "Epoch: 42/100... Step: 4276... Loss: 0.028042... Val Loss: 0.284551\n",
      "Epoch: 42/100... Step: 4277... Loss: 0.027799... Val Loss: 0.266520\n",
      "Epoch: 42/100... Step: 4278... Loss: 0.027296... Val Loss: 0.270900\n",
      "Epoch: 42/100... Step: 4279... Loss: 0.022227... Val Loss: 0.254323\n",
      "Epoch: 42/100... Step: 4280... Loss: 0.021481... Val Loss: 0.229831\n",
      "Epoch: 42/100... Step: 4281... Loss: 0.025278... Val Loss: 0.206372\n",
      "Epoch: 42/100... Step: 4282... Loss: 0.033846... Val Loss: 0.188277\n",
      "Epoch: 42/100... Step: 4283... Loss: 0.022303... Val Loss: 0.162462\n",
      "Epoch: 42/100... Step: 4284... Loss: 0.022521... Val Loss: 0.166101\n",
      "Epoch: 42/100... Step: 4285... Loss: 0.032888... Val Loss: 0.184129\n",
      "Epoch: 42/100... Step: 4286... Loss: 0.038203... Val Loss: 0.203430\n",
      "Epoch: 42/100... Step: 4287... Loss: 0.027370... Val Loss: 0.214188\n",
      "Epoch: 42/100... Step: 4288... Loss: 0.023931... Val Loss: 0.218486\n",
      "Epoch: 42/100... Step: 4289... Loss: 0.017861... Val Loss: 0.211845\n",
      "Epoch: 42/100... Step: 4290... Loss: 0.025998... Val Loss: 0.201919\n",
      "Epoch: 42/100... Step: 4291... Loss: 0.015350... Val Loss: 0.178748\n",
      "Epoch: 42/100... Step: 4292... Loss: 0.016291... Val Loss: 0.150064\n",
      "Epoch: 42/100... Step: 4293... Loss: 0.021831... Val Loss: 0.120784\n",
      "Epoch: 42/100... Step: 4294... Loss: 0.037280... Val Loss: 0.080427\n",
      "Epoch: 42/100... Step: 4295... Loss: 0.020039... Val Loss: 0.040485\n",
      "Epoch: 42/100... Step: 4296... Loss: 0.027967... Val Loss: 0.017003\n",
      "Epoch: 42/100... Step: 4297... Loss: 0.027235... Val Loss: 0.014784\n",
      "Epoch: 42/100... Step: 4298... Loss: 0.030789... Val Loss: 0.027755\n",
      "Epoch: 42/100... Step: 4299... Loss: 0.030131... Val Loss: 0.026589\n",
      "Epoch: 42/100... Step: 4300... Loss: 0.029953... Val Loss: 0.012292\n",
      "Epoch: 42/100... Step: 4301... Loss: 0.021588... Val Loss: 0.012066\n",
      "Epoch: 42/100... Step: 4302... Loss: 0.030061... Val Loss: 0.039291\n",
      "Epoch: 42/100... Step: 4303... Loss: 0.025792... Val Loss: 0.061401\n",
      "Epoch: 42/100... Step: 4304... Loss: 0.023426... Val Loss: 0.079524\n",
      "Epoch: 42/100... Step: 4305... Loss: 0.014980... Val Loss: 0.098891\n",
      "Epoch: 42/100... Step: 4306... Loss: 0.028237... Val Loss: 0.100406\n",
      "Epoch: 42/100... Step: 4307... Loss: 0.033783... Val Loss: 0.114514\n",
      "Epoch: 42/100... Step: 4308... Loss: 0.034790... Val Loss: 0.139262\n",
      "Epoch: 42/100... Step: 4309... Loss: 0.024488... Val Loss: 0.133691\n",
      "Epoch: 42/100... Step: 4310... Loss: 0.038576... Val Loss: 0.100962\n",
      "Epoch: 42/100... Step: 4311... Loss: 0.025179... Val Loss: 0.043312\n",
      "Epoch: 42/100... Step: 4312... Loss: 0.038578... Val Loss: 0.017807\n",
      "Epoch: 42/100... Step: 4313... Loss: 0.022990... Val Loss: 0.044197\n",
      "Epoch: 42/100... Step: 4314... Loss: 0.018878... Val Loss: 0.068082\n",
      "Epoch: 42/100... Step: 4315... Loss: 0.024524... Val Loss: 0.074931\n",
      "Epoch: 42/100... Step: 4316... Loss: 0.034891... Val Loss: 0.070695\n",
      "Epoch: 42/100... Step: 4317... Loss: 0.027508... Val Loss: 0.068195\n",
      "Epoch: 42/100... Step: 4318... Loss: 0.032672... Val Loss: 0.040619\n",
      "Epoch: 42/100... Step: 4319... Loss: 0.031522... Val Loss: 0.015917\n",
      "Epoch: 42/100... Step: 4320... Loss: 0.024854... Val Loss: 0.009603\n",
      "Epoch: 42/100... Step: 4321... Loss: 0.036313... Val Loss: 0.035368\n",
      "Epoch: 42/100... Step: 4322... Loss: 0.019562... Val Loss: 0.053380\n",
      "Epoch: 42/100... Step: 4323... Loss: 0.024745... Val Loss: 0.062949\n",
      "Epoch: 42/100... Step: 4324... Loss: 0.023608... Val Loss: 0.080902\n",
      "Epoch: 42/100... Step: 4325... Loss: 0.029262... Val Loss: 0.085882\n",
      "Epoch: 42/100... Step: 4326... Loss: 0.028241... Val Loss: 0.074744\n",
      "Epoch: 42/100... Step: 4327... Loss: 0.033736... Val Loss: 0.049133\n",
      "Epoch: 42/100... Step: 4328... Loss: 0.024502... Val Loss: 0.030641\n",
      "Epoch: 42/100... Step: 4329... Loss: 0.017181... Val Loss: 0.022765\n",
      "Epoch: 42/100... Step: 4330... Loss: 0.022477... Val Loss: 0.010772\n",
      "Epoch: 42/100... Step: 4331... Loss: 0.025592... Val Loss: 0.011226\n",
      "Epoch: 42/100... Step: 4332... Loss: 0.024936... Val Loss: 0.018643\n",
      "Epoch: 42/100... Step: 4333... Loss: 0.014918... Val Loss: 0.035225\n",
      "Epoch: 42/100... Step: 4334... Loss: 0.025502... Val Loss: 0.054451\n",
      "Epoch: 42/100... Step: 4335... Loss: 0.026839... Val Loss: 0.065563\n",
      "Epoch: 42/100... Step: 4336... Loss: 0.028927... Val Loss: 0.060671\n",
      "Epoch: 42/100... Step: 4337... Loss: 0.027868... Val Loss: 0.049619\n",
      "Epoch: 42/100... Step: 4338... Loss: 0.030430... Val Loss: 0.023299\n",
      "Epoch: 42/100... Step: 4339... Loss: 0.026082... Val Loss: 0.012954\n",
      "Epoch: 42/100... Step: 4340... Loss: 0.021280... Val Loss: 0.035097\n",
      "Epoch: 42/100... Step: 4341... Loss: 0.019082... Val Loss: 0.046153\n",
      "Epoch: 42/100... Step: 4342... Loss: 0.032034... Val Loss: 0.061953\n",
      "Epoch: 42/100... Step: 4343... Loss: 0.031217... Val Loss: 0.073625\n",
      "Epoch: 42/100... Step: 4344... Loss: 0.024452... Val Loss: 0.069355\n",
      "Epoch: 42/100... Step: 4345... Loss: 0.037617... Val Loss: 0.042491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Step: 4346... Loss: 0.030600... Val Loss: 0.012613\n",
      "Epoch: 42/100... Step: 4347... Loss: 0.018600... Val Loss: 0.026129\n",
      "Epoch: 42/100... Step: 4348... Loss: 0.021920... Val Loss: 0.052413\n",
      "Epoch: 42/100... Step: 4349... Loss: 0.023869... Val Loss: 0.075610\n",
      "Epoch: 42/100... Step: 4350... Loss: 0.028553... Val Loss: 0.056042\n",
      "Epoch: 42/100... Step: 4351... Loss: 0.037480... Val Loss: 0.098074\n",
      "Epoch: 42/100... Step: 4352... Loss: 0.034866... Val Loss: 0.145012\n",
      "Epoch: 42/100... Step: 4353... Loss: 0.024083... Val Loss: 0.143525\n",
      "Epoch: 42/100... Step: 4354... Loss: 0.021158... Val Loss: 0.105585\n",
      "Epoch: 42/100... Step: 4355... Loss: 0.034522... Val Loss: 0.063496\n",
      "Epoch: 42/100... Step: 4356... Loss: 0.031367... Val Loss: 0.020926\n",
      "Epoch: 42/100... Step: 4357... Loss: 0.038535... Val Loss: 0.014544\n",
      "Epoch: 42/100... Step: 4358... Loss: 0.024609... Val Loss: 0.025936\n",
      "Epoch: 42/100... Step: 4359... Loss: 0.020854... Val Loss: 0.037195\n",
      "Epoch: 42/100... Step: 4360... Loss: 0.023870... Val Loss: 0.050437\n",
      "Epoch: 42/100... Step: 4361... Loss: 0.021969... Val Loss: 0.066169\n",
      "Epoch: 42/100... Step: 4362... Loss: 0.018035... Val Loss: 0.079694\n",
      "Epoch: 42/100... Step: 4363... Loss: 0.029754... Val Loss: 0.078149\n",
      "Epoch: 42/100... Step: 4364... Loss: 0.024368... Val Loss: 0.047082\n",
      "Epoch: 42/100... Step: 4365... Loss: 0.022632... Val Loss: 0.024364\n",
      "Epoch: 42/100... Step: 4366... Loss: 0.025374... Val Loss: 0.008071\n",
      "Epoch: 42/100... Step: 4367... Loss: 0.023173... Val Loss: 0.019249\n",
      "Epoch: 42/100... Step: 4368... Loss: 0.024877... Val Loss: 0.062500\n",
      "Epoch: 43/100... Step: 4369... Loss: 0.030310... Val Loss: 0.127339\n",
      "Epoch: 43/100... Step: 4370... Loss: 0.024858... Val Loss: 0.337927\n",
      "Epoch: 43/100... Step: 4371... Loss: 0.033612... Val Loss: 0.392252\n",
      "Epoch: 43/100... Step: 4372... Loss: 0.014139... Val Loss: 0.451177\n",
      "Epoch: 43/100... Step: 4373... Loss: 0.026939... Val Loss: 0.445036\n",
      "Epoch: 43/100... Step: 4374... Loss: 0.040589... Val Loss: 0.367408\n",
      "Epoch: 43/100... Step: 4375... Loss: 0.025982... Val Loss: 0.365699\n",
      "Epoch: 43/100... Step: 4376... Loss: 0.024169... Val Loss: 0.372336\n",
      "Epoch: 43/100... Step: 4377... Loss: 0.028071... Val Loss: 0.384639\n",
      "Epoch: 43/100... Step: 4378... Loss: 0.026244... Val Loss: 0.402082\n",
      "Epoch: 43/100... Step: 4379... Loss: 0.028810... Val Loss: 0.392415\n",
      "Epoch: 43/100... Step: 4380... Loss: 0.017262... Val Loss: 0.376899\n",
      "Epoch: 43/100... Step: 4381... Loss: 0.018201... Val Loss: 0.377954\n",
      "Epoch: 43/100... Step: 4382... Loss: 0.016767... Val Loss: 0.375377\n",
      "Epoch: 43/100... Step: 4383... Loss: 0.018816... Val Loss: 0.373019\n",
      "Epoch: 43/100... Step: 4384... Loss: 0.017757... Val Loss: 0.343631\n",
      "Epoch: 43/100... Step: 4385... Loss: 0.030617... Val Loss: 0.326047\n",
      "Epoch: 43/100... Step: 4386... Loss: 0.024447... Val Loss: 0.305769\n",
      "Epoch: 43/100... Step: 4387... Loss: 0.025349... Val Loss: 0.284409\n",
      "Epoch: 43/100... Step: 4388... Loss: 0.039239... Val Loss: 0.244265\n",
      "Epoch: 43/100... Step: 4389... Loss: 0.027080... Val Loss: 0.208085\n",
      "Epoch: 43/100... Step: 4390... Loss: 0.012705... Val Loss: 0.193528\n",
      "Epoch: 43/100... Step: 4391... Loss: 0.022070... Val Loss: 0.163603\n",
      "Epoch: 43/100... Step: 4392... Loss: 0.021653... Val Loss: 0.143181\n",
      "Epoch: 43/100... Step: 4393... Loss: 0.019194... Val Loss: 0.116029\n",
      "Epoch: 43/100... Step: 4394... Loss: 0.036538... Val Loss: 0.084043\n",
      "Epoch: 43/100... Step: 4395... Loss: 0.030013... Val Loss: 0.064667\n",
      "Epoch: 43/100... Step: 4396... Loss: 0.036902... Val Loss: 0.053393\n",
      "Epoch: 43/100... Step: 4397... Loss: 0.029950... Val Loss: 0.037412\n",
      "Epoch: 43/100... Step: 4398... Loss: 0.034118... Val Loss: 0.019611\n",
      "Epoch: 43/100... Step: 4399... Loss: 0.020647... Val Loss: 0.011589\n",
      "Epoch: 43/100... Step: 4400... Loss: 0.012451... Val Loss: 0.030470\n",
      "Epoch: 43/100... Step: 4401... Loss: 0.025308... Val Loss: 0.068236\n",
      "Epoch: 43/100... Step: 4402... Loss: 0.027068... Val Loss: 0.099536\n",
      "Epoch: 43/100... Step: 4403... Loss: 0.024844... Val Loss: 0.111127\n",
      "Epoch: 43/100... Step: 4404... Loss: 0.025730... Val Loss: 0.101962\n",
      "Epoch: 43/100... Step: 4405... Loss: 0.034032... Val Loss: 0.075436\n",
      "Epoch: 43/100... Step: 4406... Loss: 0.033555... Val Loss: 0.061313\n",
      "Epoch: 43/100... Step: 4407... Loss: 0.036133... Val Loss: 0.043326\n",
      "Epoch: 43/100... Step: 4408... Loss: 0.033525... Val Loss: 0.019657\n",
      "Epoch: 43/100... Step: 4409... Loss: 0.025593... Val Loss: 0.019419\n",
      "Epoch: 43/100... Step: 4410... Loss: 0.020180... Val Loss: 0.055130\n",
      "Epoch: 43/100... Step: 4411... Loss: 0.027355... Val Loss: 0.075040\n",
      "Epoch: 43/100... Step: 4412... Loss: 0.033882... Val Loss: 0.076460\n",
      "Epoch: 43/100... Step: 4413... Loss: 0.015976... Val Loss: 0.055116\n",
      "Epoch: 43/100... Step: 4414... Loss: 0.023649... Val Loss: 0.034789\n",
      "Epoch: 43/100... Step: 4415... Loss: 0.021770... Val Loss: 0.009774\n",
      "Epoch: 43/100... Step: 4416... Loss: 0.016573... Val Loss: 0.025912\n",
      "Epoch: 43/100... Step: 4417... Loss: 0.035349... Val Loss: 0.049346\n",
      "Epoch: 43/100... Step: 4418... Loss: 0.021824... Val Loss: 0.073001\n",
      "Epoch: 43/100... Step: 4419... Loss: 0.030096... Val Loss: 0.089379\n",
      "Epoch: 43/100... Step: 4420... Loss: 0.025085... Val Loss: 0.102650\n",
      "Epoch: 43/100... Step: 4421... Loss: 0.019367... Val Loss: 0.112490\n",
      "Epoch: 43/100... Step: 4422... Loss: 0.028934... Val Loss: 0.108835\n",
      "Epoch: 43/100... Step: 4423... Loss: 0.032530... Val Loss: 0.099272\n",
      "Epoch: 43/100... Step: 4424... Loss: 0.025602... Val Loss: 0.099013\n",
      "Epoch: 43/100... Step: 4425... Loss: 0.021229... Val Loss: 0.112558\n",
      "Epoch: 43/100... Step: 4426... Loss: 0.035985... Val Loss: 0.123316\n",
      "Epoch: 43/100... Step: 4427... Loss: 0.031612... Val Loss: 0.142709\n",
      "Epoch: 43/100... Step: 4428... Loss: 0.029117... Val Loss: 0.141712\n",
      "Epoch: 43/100... Step: 4429... Loss: 0.019720... Val Loss: 0.115477\n",
      "Epoch: 43/100... Step: 4430... Loss: 0.021865... Val Loss: 0.073453\n",
      "Epoch: 43/100... Step: 4431... Loss: 0.020416... Val Loss: 0.032185\n",
      "Epoch: 43/100... Step: 4432... Loss: 0.018914... Val Loss: 0.018863\n",
      "Epoch: 43/100... Step: 4433... Loss: 0.029741... Val Loss: 0.049547\n",
      "Epoch: 43/100... Step: 4434... Loss: 0.042259... Val Loss: 0.079458\n",
      "Epoch: 43/100... Step: 4435... Loss: 0.039435... Val Loss: 0.080853\n",
      "Epoch: 43/100... Step: 4436... Loss: 0.023588... Val Loss: 0.075070\n",
      "Epoch: 43/100... Step: 4437... Loss: 0.032341... Val Loss: 0.069461\n",
      "Epoch: 43/100... Step: 4438... Loss: 0.028826... Val Loss: 0.049147\n",
      "Epoch: 43/100... Step: 4439... Loss: 0.015968... Val Loss: 0.043692\n",
      "Epoch: 43/100... Step: 4440... Loss: 0.025767... Val Loss: 0.044041\n",
      "Epoch: 43/100... Step: 4441... Loss: 0.023575... Val Loss: 0.044899\n",
      "Epoch: 43/100... Step: 4442... Loss: 0.017829... Val Loss: 0.042437\n",
      "Epoch: 43/100... Step: 4443... Loss: 0.035025... Val Loss: 0.040408\n",
      "Epoch: 43/100... Step: 4444... Loss: 0.028600... Val Loss: 0.031889\n",
      "Epoch: 43/100... Step: 4445... Loss: 0.029325... Val Loss: 0.051378\n",
      "Epoch: 43/100... Step: 4446... Loss: 0.037332... Val Loss: 0.074415\n",
      "Epoch: 43/100... Step: 4447... Loss: 0.027525... Val Loss: 0.097686\n",
      "Epoch: 43/100... Step: 4448... Loss: 0.016103... Val Loss: 0.127972\n",
      "Epoch: 43/100... Step: 4449... Loss: 0.030794... Val Loss: 0.152523\n",
      "Epoch: 43/100... Step: 4450... Loss: 0.038146... Val Loss: 0.168467\n",
      "Epoch: 43/100... Step: 4451... Loss: 0.047322... Val Loss: 0.174542\n",
      "Epoch: 43/100... Step: 4452... Loss: 0.023408... Val Loss: 0.181179\n",
      "Epoch: 43/100... Step: 4453... Loss: 0.025657... Val Loss: 0.197053\n",
      "Epoch: 43/100... Step: 4454... Loss: 0.025599... Val Loss: 0.203106\n",
      "Epoch: 43/100... Step: 4455... Loss: 0.026513... Val Loss: 0.173166\n",
      "Epoch: 43/100... Step: 4456... Loss: 0.031154... Val Loss: 0.140327\n",
      "Epoch: 43/100... Step: 4457... Loss: 0.019610... Val Loss: 0.107493\n",
      "Epoch: 43/100... Step: 4458... Loss: 0.018781... Val Loss: 0.097613\n",
      "Epoch: 43/100... Step: 4459... Loss: 0.029749... Val Loss: 0.089251\n",
      "Epoch: 43/100... Step: 4460... Loss: 0.029493... Val Loss: 0.077291\n",
      "Epoch: 43/100... Step: 4461... Loss: 0.037407... Val Loss: 0.046006\n",
      "Epoch: 43/100... Step: 4462... Loss: 0.024405... Val Loss: 0.011469\n",
      "Epoch: 43/100... Step: 4463... Loss: 0.015639... Val Loss: 0.039740\n",
      "Epoch: 43/100... Step: 4464... Loss: 0.029579... Val Loss: 0.082988\n",
      "Epoch: 43/100... Step: 4465... Loss: 0.017252... Val Loss: 0.112373\n",
      "Epoch: 43/100... Step: 4466... Loss: 0.031110... Val Loss: 0.132890\n",
      "Epoch: 43/100... Step: 4467... Loss: 0.022466... Val Loss: 0.149127\n",
      "Epoch: 43/100... Step: 4468... Loss: 0.037596... Val Loss: 0.148926\n",
      "Epoch: 43/100... Step: 4469... Loss: 0.022760... Val Loss: 0.131153\n",
      "Epoch: 43/100... Step: 4470... Loss: 0.025197... Val Loss: 0.112761\n",
      "Epoch: 43/100... Step: 4471... Loss: 0.025625... Val Loss: 0.111431\n",
      "Epoch: 43/100... Step: 4472... Loss: 0.029150... Val Loss: 0.113594\n",
      "Epoch: 44/100... Step: 4473... Loss: 0.031966... Val Loss: 0.142233\n",
      "Epoch: 44/100... Step: 4474... Loss: 0.014129... Val Loss: 0.176939\n",
      "Epoch: 44/100... Step: 4475... Loss: 0.019546... Val Loss: 0.157517\n",
      "Epoch: 44/100... Step: 4476... Loss: 0.011602... Val Loss: 0.108437\n",
      "Epoch: 44/100... Step: 4477... Loss: 0.027874... Val Loss: 0.036869\n",
      "Epoch: 44/100... Step: 4478... Loss: 0.017706... Val Loss: 0.025983\n",
      "Epoch: 44/100... Step: 4479... Loss: 0.023703... Val Loss: 0.007423\n",
      "Epoch: 44/100... Step: 4480... Loss: 0.018296... Val Loss: 0.014688\n",
      "Epoch: 44/100... Step: 4481... Loss: 0.009795... Val Loss: 0.026904\n",
      "Epoch: 44/100... Step: 4482... Loss: 0.021009... Val Loss: 0.053470\n",
      "Epoch: 44/100... Step: 4483... Loss: 0.038158... Val Loss: 0.064061\n",
      "Epoch: 44/100... Step: 4484... Loss: 0.038186... Val Loss: 0.081591\n",
      "Epoch: 44/100... Step: 4485... Loss: 0.020909... Val Loss: 0.070118\n",
      "Epoch: 44/100... Step: 4486... Loss: 0.021023... Val Loss: 0.074935\n",
      "Epoch: 44/100... Step: 4487... Loss: 0.033908... Val Loss: 0.070282\n",
      "Epoch: 44/100... Step: 4488... Loss: 0.030042... Val Loss: 0.083564\n",
      "Epoch: 44/100... Step: 4489... Loss: 0.023925... Val Loss: 0.091460\n",
      "Epoch: 44/100... Step: 4490... Loss: 0.013576... Val Loss: 0.092318\n",
      "Epoch: 44/100... Step: 4491... Loss: 0.017015... Val Loss: 0.100298\n",
      "Epoch: 44/100... Step: 4492... Loss: 0.026169... Val Loss: 0.096078\n",
      "Epoch: 44/100... Step: 4493... Loss: 0.026442... Val Loss: 0.092896\n",
      "Epoch: 44/100... Step: 4494... Loss: 0.021662... Val Loss: 0.090477\n",
      "Epoch: 44/100... Step: 4495... Loss: 0.024031... Val Loss: 0.086072\n",
      "Epoch: 44/100... Step: 4496... Loss: 0.029966... Val Loss: 0.084950\n",
      "Epoch: 44/100... Step: 4497... Loss: 0.026306... Val Loss: 0.082125\n",
      "Epoch: 44/100... Step: 4498... Loss: 0.023232... Val Loss: 0.090890\n",
      "Epoch: 44/100... Step: 4499... Loss: 0.028746... Val Loss: 0.092498\n",
      "Epoch: 44/100... Step: 4500... Loss: 0.024090... Val Loss: 0.088275\n",
      "Epoch: 44/100... Step: 4501... Loss: 0.020025... Val Loss: 0.064374\n",
      "Epoch: 44/100... Step: 4502... Loss: 0.022383... Val Loss: 0.025380\n",
      "Epoch: 44/100... Step: 4503... Loss: 0.019821... Val Loss: 0.014687\n",
      "Epoch: 44/100... Step: 4504... Loss: 0.022578... Val Loss: 0.014104\n",
      "Epoch: 44/100... Step: 4505... Loss: 0.019578... Val Loss: 0.015009\n",
      "Epoch: 44/100... Step: 4506... Loss: 0.023584... Val Loss: 0.018954\n",
      "Epoch: 44/100... Step: 4507... Loss: 0.028307... Val Loss: 0.020702\n",
      "Epoch: 44/100... Step: 4508... Loss: 0.034392... Val Loss: 0.015644\n",
      "Epoch: 44/100... Step: 4509... Loss: 0.019169... Val Loss: 0.008769\n",
      "Epoch: 44/100... Step: 4510... Loss: 0.019832... Val Loss: 0.016141\n",
      "Epoch: 44/100... Step: 4511... Loss: 0.017131... Val Loss: 0.031455\n",
      "Epoch: 44/100... Step: 4512... Loss: 0.029041... Val Loss: 0.035814\n",
      "Epoch: 44/100... Step: 4513... Loss: 0.026864... Val Loss: 0.043446\n",
      "Epoch: 44/100... Step: 4514... Loss: 0.019856... Val Loss: 0.033870\n",
      "Epoch: 44/100... Step: 4515... Loss: 0.034802... Val Loss: 0.027029\n",
      "Epoch: 44/100... Step: 4516... Loss: 0.022368... Val Loss: 0.023230\n",
      "Epoch: 44/100... Step: 4517... Loss: 0.018234... Val Loss: 0.024307\n",
      "Epoch: 44/100... Step: 4518... Loss: 0.017885... Val Loss: 0.020968\n",
      "Epoch: 44/100... Step: 4519... Loss: 0.019880... Val Loss: 0.006915\n",
      "Epoch: 44/100... Step: 4520... Loss: 0.016241... Val Loss: 0.011640\n",
      "Epoch: 44/100... Step: 4521... Loss: 0.021771... Val Loss: 0.022183\n",
      "Epoch: 44/100... Step: 4522... Loss: 0.022958... Val Loss: 0.024897\n",
      "Epoch: 44/100... Step: 4523... Loss: 0.016830... Val Loss: 0.012583\n",
      "Epoch: 44/100... Step: 4524... Loss: 0.030733... Val Loss: 0.014457\n",
      "Epoch: 44/100... Step: 4525... Loss: 0.024593... Val Loss: 0.027433\n",
      "Epoch: 44/100... Step: 4526... Loss: 0.027196... Val Loss: 0.040364\n",
      "Epoch: 44/100... Step: 4527... Loss: 0.018395... Val Loss: 0.049548\n",
      "Epoch: 44/100... Step: 4528... Loss: 0.030043... Val Loss: 0.057702\n",
      "Epoch: 44/100... Step: 4529... Loss: 0.031720... Val Loss: 0.063131\n",
      "Epoch: 44/100... Step: 4530... Loss: 0.032348... Val Loss: 0.093771\n",
      "Epoch: 44/100... Step: 4531... Loss: 0.018422... Val Loss: 0.119250\n",
      "Epoch: 44/100... Step: 4532... Loss: 0.027652... Val Loss: 0.112116\n",
      "Epoch: 44/100... Step: 4533... Loss: 0.033725... Val Loss: 0.102800\n",
      "Epoch: 44/100... Step: 4534... Loss: 0.025712... Val Loss: 0.084417\n",
      "Epoch: 44/100... Step: 4535... Loss: 0.023996... Val Loss: 0.067854\n",
      "Epoch: 44/100... Step: 4536... Loss: 0.028915... Val Loss: 0.079939\n",
      "Epoch: 44/100... Step: 4537... Loss: 0.021269... Val Loss: 0.096432\n",
      "Epoch: 44/100... Step: 4538... Loss: 0.024540... Val Loss: 0.105618\n",
      "Epoch: 44/100... Step: 4539... Loss: 0.025978... Val Loss: 0.117562\n",
      "Epoch: 44/100... Step: 4540... Loss: 0.026662... Val Loss: 0.118389\n",
      "Epoch: 44/100... Step: 4541... Loss: 0.020495... Val Loss: 0.119221\n",
      "Epoch: 44/100... Step: 4542... Loss: 0.019671... Val Loss: 0.136293\n",
      "Epoch: 44/100... Step: 4543... Loss: 0.020347... Val Loss: 0.117838\n",
      "Epoch: 44/100... Step: 4544... Loss: 0.028168... Val Loss: 0.079267\n",
      "Epoch: 44/100... Step: 4545... Loss: 0.022733... Val Loss: 0.044423\n",
      "Epoch: 44/100... Step: 4546... Loss: 0.030905... Val Loss: 0.027330\n",
      "Epoch: 44/100... Step: 4547... Loss: 0.033626... Val Loss: 0.014073\n",
      "Epoch: 44/100... Step: 4548... Loss: 0.024087... Val Loss: 0.010854\n",
      "Epoch: 44/100... Step: 4549... Loss: 0.032748... Val Loss: 0.011580\n",
      "Epoch: 44/100... Step: 4550... Loss: 0.026208... Val Loss: 0.012651\n",
      "Epoch: 44/100... Step: 4551... Loss: 0.026210... Val Loss: 0.010631\n",
      "Epoch: 44/100... Step: 4552... Loss: 0.025687... Val Loss: 0.010090\n",
      "Epoch: 44/100... Step: 4553... Loss: 0.016748... Val Loss: 0.008174\n",
      "Epoch: 44/100... Step: 4554... Loss: 0.034134... Val Loss: 0.019932\n",
      "Epoch: 44/100... Step: 4555... Loss: 0.013622... Val Loss: 0.028552\n",
      "Epoch: 44/100... Step: 4556... Loss: 0.033998... Val Loss: 0.026047\n",
      "Epoch: 44/100... Step: 4557... Loss: 0.036142... Val Loss: 0.020929\n",
      "Epoch: 44/100... Step: 4558... Loss: 0.030154... Val Loss: 0.014093\n",
      "Epoch: 44/100... Step: 4559... Loss: 0.013884... Val Loss: 0.018078\n",
      "Epoch: 44/100... Step: 4560... Loss: 0.036919... Val Loss: 0.026724\n",
      "Epoch: 44/100... Step: 4561... Loss: 0.024061... Val Loss: 0.029547\n",
      "Epoch: 44/100... Step: 4562... Loss: 0.023536... Val Loss: 0.021115\n",
      "Epoch: 44/100... Step: 4563... Loss: 0.016948... Val Loss: 0.017075\n",
      "Epoch: 44/100... Step: 4564... Loss: 0.025818... Val Loss: 0.019606\n",
      "Epoch: 44/100... Step: 4565... Loss: 0.016674... Val Loss: 0.016886\n",
      "Epoch: 44/100... Step: 4566... Loss: 0.026483... Val Loss: 0.008958\n",
      "Epoch: 44/100... Step: 4567... Loss: 0.019159... Val Loss: 0.032352\n",
      "Epoch: 44/100... Step: 4568... Loss: 0.020494... Val Loss: 0.041226\n",
      "Epoch: 44/100... Step: 4569... Loss: 0.018786... Val Loss: 0.045753\n",
      "Epoch: 44/100... Step: 4570... Loss: 0.021817... Val Loss: 0.039950\n",
      "Epoch: 44/100... Step: 4571... Loss: 0.020318... Val Loss: 0.030265\n",
      "Epoch: 44/100... Step: 4572... Loss: 0.029411... Val Loss: 0.020053\n",
      "Epoch: 44/100... Step: 4573... Loss: 0.024038... Val Loss: 0.016952\n",
      "Epoch: 44/100... Step: 4574... Loss: 0.034237... Val Loss: 0.017655\n",
      "Epoch: 44/100... Step: 4575... Loss: 0.022588... Val Loss: 0.016316\n",
      "Epoch: 44/100... Step: 4576... Loss: 0.016141... Val Loss: 0.012881\n",
      "Epoch: 45/100... Step: 4577... Loss: 0.019641... Val Loss: 0.055883\n",
      "Epoch: 45/100... Step: 4578... Loss: 0.014799... Val Loss: 0.049572\n",
      "Epoch: 45/100... Step: 4579... Loss: 0.017482... Val Loss: 0.008015\n",
      "Epoch: 45/100... Step: 4580... Loss: 0.018134... Val Loss: 0.089539\n",
      "Epoch: 45/100... Step: 4581... Loss: 0.018321... Val Loss: 0.137722\n",
      "Epoch: 45/100... Step: 4582... Loss: 0.019789... Val Loss: 0.171611\n",
      "Epoch: 45/100... Step: 4583... Loss: 0.031696... Val Loss: 0.183337\n",
      "Epoch: 45/100... Step: 4584... Loss: 0.020412... Val Loss: 0.188045\n",
      "Epoch: 45/100... Step: 4585... Loss: 0.020967... Val Loss: 0.180524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100... Step: 4586... Loss: 0.021802... Val Loss: 0.187579\n",
      "Epoch: 45/100... Step: 4587... Loss: 0.025447... Val Loss: 0.178845\n",
      "Epoch: 45/100... Step: 4588... Loss: 0.018561... Val Loss: 0.155798\n",
      "Epoch: 45/100... Step: 4589... Loss: 0.027579... Val Loss: 0.140065\n",
      "Epoch: 45/100... Step: 4590... Loss: 0.034030... Val Loss: 0.132307\n",
      "Epoch: 45/100... Step: 4591... Loss: 0.018613... Val Loss: 0.119851\n",
      "Epoch: 45/100... Step: 4592... Loss: 0.036473... Val Loss: 0.108357\n",
      "Epoch: 45/100... Step: 4593... Loss: 0.029940... Val Loss: 0.086277\n",
      "Epoch: 45/100... Step: 4594... Loss: 0.030781... Val Loss: 0.066841\n",
      "Epoch: 45/100... Step: 4595... Loss: 0.025200... Val Loss: 0.057387\n",
      "Epoch: 45/100... Step: 4596... Loss: 0.034131... Val Loss: 0.052118\n",
      "Epoch: 45/100... Step: 4597... Loss: 0.023861... Val Loss: 0.047577\n",
      "Epoch: 45/100... Step: 4598... Loss: 0.021488... Val Loss: 0.043688\n",
      "Epoch: 45/100... Step: 4599... Loss: 0.026324... Val Loss: 0.034270\n",
      "Epoch: 45/100... Step: 4600... Loss: 0.017605... Val Loss: 0.039094\n",
      "Epoch: 45/100... Step: 4601... Loss: 0.030372... Val Loss: 0.029909\n",
      "Epoch: 45/100... Step: 4602... Loss: 0.028303... Val Loss: 0.020860\n",
      "Epoch: 45/100... Step: 4603... Loss: 0.027890... Val Loss: 0.020748\n",
      "Epoch: 45/100... Step: 4604... Loss: 0.023051... Val Loss: 0.024223\n",
      "Epoch: 45/100... Step: 4605... Loss: 0.025756... Val Loss: 0.009483\n",
      "Epoch: 45/100... Step: 4606... Loss: 0.033063... Val Loss: 0.041421\n",
      "Epoch: 45/100... Step: 4607... Loss: 0.026548... Val Loss: 0.052298\n",
      "Epoch: 45/100... Step: 4608... Loss: 0.025299... Val Loss: 0.065532\n",
      "Epoch: 45/100... Step: 4609... Loss: 0.025359... Val Loss: 0.083639\n",
      "Epoch: 45/100... Step: 4610... Loss: 0.013146... Val Loss: 0.087164\n",
      "Epoch: 45/100... Step: 4611... Loss: 0.024729... Val Loss: 0.092737\n",
      "Epoch: 45/100... Step: 4612... Loss: 0.032757... Val Loss: 0.101456\n",
      "Epoch: 45/100... Step: 4613... Loss: 0.018365... Val Loss: 0.104213\n",
      "Epoch: 45/100... Step: 4614... Loss: 0.024215... Val Loss: 0.094256\n",
      "Epoch: 45/100... Step: 4615... Loss: 0.024078... Val Loss: 0.086078\n",
      "Epoch: 45/100... Step: 4616... Loss: 0.022055... Val Loss: 0.078548\n",
      "Epoch: 45/100... Step: 4617... Loss: 0.023806... Val Loss: 0.069862\n",
      "Epoch: 45/100... Step: 4618... Loss: 0.022685... Val Loss: 0.069145\n",
      "Epoch: 45/100... Step: 4619... Loss: 0.029089... Val Loss: 0.075078\n",
      "Epoch: 45/100... Step: 4620... Loss: 0.023245... Val Loss: 0.076881\n",
      "Epoch: 45/100... Step: 4621... Loss: 0.026803... Val Loss: 0.079455\n",
      "Epoch: 45/100... Step: 4622... Loss: 0.027686... Val Loss: 0.082223\n",
      "Epoch: 45/100... Step: 4623... Loss: 0.029109... Val Loss: 0.071736\n",
      "Epoch: 45/100... Step: 4624... Loss: 0.030188... Val Loss: 0.065281\n",
      "Epoch: 45/100... Step: 4625... Loss: 0.018579... Val Loss: 0.073130\n",
      "Epoch: 45/100... Step: 4626... Loss: 0.029940... Val Loss: 0.076907\n",
      "Epoch: 45/100... Step: 4627... Loss: 0.032280... Val Loss: 0.083195\n",
      "Epoch: 45/100... Step: 4628... Loss: 0.015855... Val Loss: 0.103272\n",
      "Epoch: 45/100... Step: 4629... Loss: 0.033480... Val Loss: 0.100668\n",
      "Epoch: 45/100... Step: 4630... Loss: 0.033324... Val Loss: 0.083220\n",
      "Epoch: 45/100... Step: 4631... Loss: 0.024096... Val Loss: 0.032021\n",
      "Epoch: 45/100... Step: 4632... Loss: 0.028168... Val Loss: 0.037021\n",
      "Epoch: 45/100... Step: 4633... Loss: 0.014742... Val Loss: 0.056821\n",
      "Epoch: 45/100... Step: 4634... Loss: 0.032528... Val Loss: 0.045938\n",
      "Epoch: 45/100... Step: 4635... Loss: 0.031193... Val Loss: 0.070536\n",
      "Epoch: 45/100... Step: 4636... Loss: 0.017928... Val Loss: 0.087625\n",
      "Epoch: 45/100... Step: 4637... Loss: 0.027887... Val Loss: 0.109854\n",
      "Epoch: 45/100... Step: 4638... Loss: 0.028973... Val Loss: 0.126539\n",
      "Epoch: 45/100... Step: 4639... Loss: 0.038223... Val Loss: 0.115862\n",
      "Epoch: 45/100... Step: 4640... Loss: 0.020549... Val Loss: 0.118930\n",
      "Epoch: 45/100... Step: 4641... Loss: 0.024355... Val Loss: 0.131083\n",
      "Epoch: 45/100... Step: 4642... Loss: 0.026139... Val Loss: 0.120023\n",
      "Epoch: 45/100... Step: 4643... Loss: 0.024777... Val Loss: 0.114276\n",
      "Epoch: 45/100... Step: 4644... Loss: 0.021423... Val Loss: 0.115304\n",
      "Epoch: 45/100... Step: 4645... Loss: 0.024453... Val Loss: 0.090477\n",
      "Epoch: 45/100... Step: 4646... Loss: 0.027181... Val Loss: 0.093075\n",
      "Epoch: 45/100... Step: 4647... Loss: 0.030333... Val Loss: 0.096634\n",
      "Epoch: 45/100... Step: 4648... Loss: 0.025513... Val Loss: 0.104499\n",
      "Epoch: 45/100... Step: 4649... Loss: 0.019916... Val Loss: 0.100542\n",
      "Epoch: 45/100... Step: 4650... Loss: 0.017361... Val Loss: 0.084852\n",
      "Epoch: 45/100... Step: 4651... Loss: 0.013968... Val Loss: 0.087056\n",
      "Epoch: 45/100... Step: 4652... Loss: 0.021376... Val Loss: 0.083664\n",
      "Epoch: 45/100... Step: 4653... Loss: 0.023512... Val Loss: 0.084426\n",
      "Epoch: 45/100... Step: 4654... Loss: 0.024109... Val Loss: 0.079197\n",
      "Epoch: 45/100... Step: 4655... Loss: 0.023398... Val Loss: 0.070274\n",
      "Epoch: 45/100... Step: 4656... Loss: 0.027159... Val Loss: 0.040456\n",
      "Epoch: 45/100... Step: 4657... Loss: 0.019624... Val Loss: 0.016414\n",
      "Epoch: 45/100... Step: 4658... Loss: 0.017321... Val Loss: 0.020712\n",
      "Epoch: 45/100... Step: 4659... Loss: 0.025218... Val Loss: 0.020586\n",
      "Epoch: 45/100... Step: 4660... Loss: 0.025775... Val Loss: 0.015335\n",
      "Epoch: 45/100... Step: 4661... Loss: 0.017050... Val Loss: 0.022425\n",
      "Epoch: 45/100... Step: 4662... Loss: 0.033570... Val Loss: 0.039993\n",
      "Epoch: 45/100... Step: 4663... Loss: 0.026876... Val Loss: 0.048244\n",
      "Epoch: 45/100... Step: 4664... Loss: 0.024131... Val Loss: 0.052857\n",
      "Epoch: 45/100... Step: 4665... Loss: 0.022680... Val Loss: 0.072145\n",
      "Epoch: 45/100... Step: 4666... Loss: 0.023457... Val Loss: 0.065765\n",
      "Epoch: 45/100... Step: 4667... Loss: 0.024108... Val Loss: 0.057371\n",
      "Epoch: 45/100... Step: 4668... Loss: 0.025299... Val Loss: 0.048423\n",
      "Epoch: 45/100... Step: 4669... Loss: 0.017061... Val Loss: 0.039683\n",
      "Epoch: 45/100... Step: 4670... Loss: 0.023408... Val Loss: 0.038837\n",
      "Epoch: 45/100... Step: 4671... Loss: 0.015661... Val Loss: 0.014877\n",
      "Epoch: 45/100... Step: 4672... Loss: 0.024359... Val Loss: 0.018149\n",
      "Epoch: 45/100... Step: 4673... Loss: 0.024883... Val Loss: 0.032528\n",
      "Epoch: 45/100... Step: 4674... Loss: 0.032093... Val Loss: 0.017645\n",
      "Epoch: 45/100... Step: 4675... Loss: 0.032069... Val Loss: 0.015285\n",
      "Epoch: 45/100... Step: 4676... Loss: 0.012504... Val Loss: 0.042541\n",
      "Epoch: 45/100... Step: 4677... Loss: 0.046160... Val Loss: 0.085814\n",
      "Epoch: 45/100... Step: 4678... Loss: 0.034964... Val Loss: 0.119167\n",
      "Epoch: 45/100... Step: 4679... Loss: 0.023956... Val Loss: 0.143049\n",
      "Epoch: 45/100... Step: 4680... Loss: 0.033695... Val Loss: 0.188512\n",
      "Epoch: 46/100... Step: 4681... Loss: 0.019134... Val Loss: 0.111595\n",
      "Epoch: 46/100... Step: 4682... Loss: 0.012589... Val Loss: 0.071189\n",
      "Epoch: 46/100... Step: 4683... Loss: 0.022186... Val Loss: 0.045608\n",
      "Epoch: 46/100... Step: 4684... Loss: 0.012447... Val Loss: 0.099032\n",
      "Epoch: 46/100... Step: 4685... Loss: 0.014051... Val Loss: 0.153160\n",
      "Epoch: 46/100... Step: 4686... Loss: 0.030122... Val Loss: 0.163363\n",
      "Epoch: 46/100... Step: 4687... Loss: 0.024378... Val Loss: 0.195995\n",
      "Epoch: 46/100... Step: 4688... Loss: 0.034676... Val Loss: 0.200928\n",
      "Epoch: 46/100... Step: 4689... Loss: 0.021615... Val Loss: 0.207029\n",
      "Epoch: 46/100... Step: 4690... Loss: 0.021538... Val Loss: 0.228774\n",
      "Epoch: 46/100... Step: 4691... Loss: 0.021780... Val Loss: 0.265488\n",
      "Epoch: 46/100... Step: 4692... Loss: 0.022540... Val Loss: 0.275530\n",
      "Epoch: 46/100... Step: 4693... Loss: 0.021700... Val Loss: 0.278948\n",
      "Epoch: 46/100... Step: 4694... Loss: 0.029562... Val Loss: 0.277467\n",
      "Epoch: 46/100... Step: 4695... Loss: 0.015997... Val Loss: 0.260501\n",
      "Epoch: 46/100... Step: 4696... Loss: 0.014722... Val Loss: 0.247188\n",
      "Epoch: 46/100... Step: 4697... Loss: 0.022913... Val Loss: 0.202212\n",
      "Epoch: 46/100... Step: 4698... Loss: 0.028970... Val Loss: 0.128800\n",
      "Epoch: 46/100... Step: 4699... Loss: 0.024065... Val Loss: 0.160312\n",
      "Epoch: 46/100... Step: 4700... Loss: 0.026630... Val Loss: 0.152210\n",
      "Epoch: 46/100... Step: 4701... Loss: 0.013094... Val Loss: 0.132258\n",
      "Epoch: 46/100... Step: 4702... Loss: 0.033052... Val Loss: 0.119932\n",
      "Epoch: 46/100... Step: 4703... Loss: 0.024122... Val Loss: 0.115818\n",
      "Epoch: 46/100... Step: 4704... Loss: 0.015094... Val Loss: 0.117977\n",
      "Epoch: 46/100... Step: 4705... Loss: 0.018610... Val Loss: 0.120288\n",
      "Epoch: 46/100... Step: 4706... Loss: 0.025322... Val Loss: 0.119101\n",
      "Epoch: 46/100... Step: 4707... Loss: 0.024917... Val Loss: 0.124235\n",
      "Epoch: 46/100... Step: 4708... Loss: 0.020035... Val Loss: 0.123183\n",
      "Epoch: 46/100... Step: 4709... Loss: 0.020869... Val Loss: 0.119068\n",
      "Epoch: 46/100... Step: 4710... Loss: 0.012665... Val Loss: 0.117120\n",
      "Epoch: 46/100... Step: 4711... Loss: 0.020866... Val Loss: 0.122724\n",
      "Epoch: 46/100... Step: 4712... Loss: 0.021191... Val Loss: 0.130695\n",
      "Epoch: 46/100... Step: 4713... Loss: 0.035017... Val Loss: 0.121203\n",
      "Epoch: 46/100... Step: 4714... Loss: 0.027094... Val Loss: 0.100313\n",
      "Epoch: 46/100... Step: 4715... Loss: 0.024920... Val Loss: 0.081774\n",
      "Epoch: 46/100... Step: 4716... Loss: 0.024598... Val Loss: 0.068399\n",
      "Epoch: 46/100... Step: 4717... Loss: 0.021831... Val Loss: 0.055302\n",
      "Epoch: 46/100... Step: 4718... Loss: 0.019673... Val Loss: 0.053796\n",
      "Epoch: 46/100... Step: 4719... Loss: 0.024351... Val Loss: 0.061144\n",
      "Epoch: 46/100... Step: 4720... Loss: 0.022866... Val Loss: 0.070310\n",
      "Epoch: 46/100... Step: 4721... Loss: 0.020055... Val Loss: 0.084635\n",
      "Epoch: 46/100... Step: 4722... Loss: 0.025264... Val Loss: 0.095309\n",
      "Epoch: 46/100... Step: 4723... Loss: 0.015753... Val Loss: 0.101558\n",
      "Epoch: 46/100... Step: 4724... Loss: 0.029618... Val Loss: 0.094117\n",
      "Epoch: 46/100... Step: 4725... Loss: 0.022341... Val Loss: 0.089076\n",
      "Epoch: 46/100... Step: 4726... Loss: 0.039075... Val Loss: 0.087953\n",
      "Epoch: 46/100... Step: 4727... Loss: 0.033188... Val Loss: 0.086720\n",
      "Epoch: 46/100... Step: 4728... Loss: 0.027976... Val Loss: 0.071769\n",
      "Epoch: 46/100... Step: 4729... Loss: 0.021772... Val Loss: 0.060851\n",
      "Epoch: 46/100... Step: 4730... Loss: 0.016773... Val Loss: 0.045043\n",
      "Epoch: 46/100... Step: 4731... Loss: 0.021389... Val Loss: 0.032670\n",
      "Epoch: 46/100... Step: 4732... Loss: 0.019884... Val Loss: 0.018553\n",
      "Epoch: 46/100... Step: 4733... Loss: 0.023862... Val Loss: 0.021213\n",
      "Epoch: 46/100... Step: 4734... Loss: 0.029214... Val Loss: 0.031656\n",
      "Epoch: 46/100... Step: 4735... Loss: 0.028770... Val Loss: 0.040979\n",
      "Epoch: 46/100... Step: 4736... Loss: 0.024588... Val Loss: 0.050331\n",
      "Epoch: 46/100... Step: 4737... Loss: 0.015310... Val Loss: 0.049226\n",
      "Epoch: 46/100... Step: 4738... Loss: 0.021334... Val Loss: 0.023441\n",
      "Epoch: 46/100... Step: 4739... Loss: 0.012657... Val Loss: 0.011660\n",
      "Epoch: 46/100... Step: 4740... Loss: 0.024611... Val Loss: 0.011792\n",
      "Epoch: 46/100... Step: 4741... Loss: 0.019637... Val Loss: 0.013474\n",
      "Epoch: 46/100... Step: 4742... Loss: 0.034478... Val Loss: 0.014917\n",
      "Epoch: 46/100... Step: 4743... Loss: 0.033600... Val Loss: 0.023725\n",
      "Epoch: 46/100... Step: 4744... Loss: 0.014797... Val Loss: 0.045111\n",
      "Epoch: 46/100... Step: 4745... Loss: 0.032747... Val Loss: 0.064891\n",
      "Epoch: 46/100... Step: 4746... Loss: 0.017370... Val Loss: 0.079503\n",
      "Epoch: 46/100... Step: 4747... Loss: 0.014707... Val Loss: 0.089707\n",
      "Epoch: 46/100... Step: 4748... Loss: 0.020637... Val Loss: 0.081988\n",
      "Epoch: 46/100... Step: 4749... Loss: 0.018406... Val Loss: 0.055303\n",
      "Epoch: 46/100... Step: 4750... Loss: 0.016152... Val Loss: 0.042317\n",
      "Epoch: 46/100... Step: 4751... Loss: 0.021040... Val Loss: 0.045008\n",
      "Epoch: 46/100... Step: 4752... Loss: 0.012533... Val Loss: 0.019424\n",
      "Epoch: 46/100... Step: 4753... Loss: 0.018257... Val Loss: 0.012405\n",
      "Epoch: 46/100... Step: 4754... Loss: 0.015306... Val Loss: 0.015408\n",
      "Epoch: 46/100... Step: 4755... Loss: 0.020965... Val Loss: 0.039465\n",
      "Epoch: 46/100... Step: 4756... Loss: 0.028045... Val Loss: 0.065175\n",
      "Epoch: 46/100... Step: 4757... Loss: 0.018939... Val Loss: 0.088965\n",
      "Epoch: 46/100... Step: 4758... Loss: 0.020485... Val Loss: 0.094815\n",
      "Epoch: 46/100... Step: 4759... Loss: 0.022317... Val Loss: 0.092225\n",
      "Epoch: 46/100... Step: 4760... Loss: 0.014919... Val Loss: 0.092023\n",
      "Epoch: 46/100... Step: 4761... Loss: 0.024829... Val Loss: 0.071797\n",
      "Epoch: 46/100... Step: 4762... Loss: 0.023219... Val Loss: 0.040896\n",
      "Epoch: 46/100... Step: 4763... Loss: 0.011878... Val Loss: 0.028718\n",
      "Epoch: 46/100... Step: 4764... Loss: 0.024377... Val Loss: 0.030152\n",
      "Epoch: 46/100... Step: 4765... Loss: 0.032954... Val Loss: 0.039617\n",
      "Epoch: 46/100... Step: 4766... Loss: 0.023650... Val Loss: 0.053113\n",
      "Epoch: 46/100... Step: 4767... Loss: 0.027173... Val Loss: 0.069891\n",
      "Epoch: 46/100... Step: 4768... Loss: 0.026305... Val Loss: 0.073322\n",
      "Epoch: 46/100... Step: 4769... Loss: 0.021740... Val Loss: 0.088895\n",
      "Epoch: 46/100... Step: 4770... Loss: 0.033880... Val Loss: 0.098680\n",
      "Epoch: 46/100... Step: 4771... Loss: 0.031265... Val Loss: 0.088637\n",
      "Epoch: 46/100... Step: 4772... Loss: 0.023308... Val Loss: 0.064885\n",
      "Epoch: 46/100... Step: 4773... Loss: 0.031735... Val Loss: 0.044125\n",
      "Epoch: 46/100... Step: 4774... Loss: 0.020038... Val Loss: 0.031892\n",
      "Epoch: 46/100... Step: 4775... Loss: 0.026275... Val Loss: 0.026808\n",
      "Epoch: 46/100... Step: 4776... Loss: 0.024238... Val Loss: 0.020092\n",
      "Epoch: 46/100... Step: 4777... Loss: 0.027079... Val Loss: 0.018750\n",
      "Epoch: 46/100... Step: 4778... Loss: 0.021146... Val Loss: 0.015440\n",
      "Epoch: 46/100... Step: 4779... Loss: 0.020040... Val Loss: 0.011060\n",
      "Epoch: 46/100... Step: 4780... Loss: 0.025717... Val Loss: 0.008079\n",
      "Epoch: 46/100... Step: 4781... Loss: 0.031364... Val Loss: 0.017205\n",
      "Epoch: 46/100... Step: 4782... Loss: 0.033348... Val Loss: 0.016091\n",
      "Epoch: 46/100... Step: 4783... Loss: 0.033138... Val Loss: 0.012695\n",
      "Epoch: 46/100... Step: 4784... Loss: 0.028086... Val Loss: 0.013796\n",
      "Epoch: 47/100... Step: 4785... Loss: 0.013145... Val Loss: 0.027712\n",
      "Epoch: 47/100... Step: 4786... Loss: 0.028158... Val Loss: 0.032321\n",
      "Epoch: 47/100... Step: 4787... Loss: 0.018894... Val Loss: 0.023102\n",
      "Epoch: 47/100... Step: 4788... Loss: 0.017717... Val Loss: 0.007950\n",
      "Epoch: 47/100... Step: 4789... Loss: 0.014374... Val Loss: 0.017489\n",
      "Epoch: 47/100... Step: 4790... Loss: 0.023190... Val Loss: 0.027415\n",
      "Epoch: 47/100... Step: 4791... Loss: 0.031469... Val Loss: 0.024970\n",
      "Epoch: 47/100... Step: 4792... Loss: 0.020625... Val Loss: 0.010499\n",
      "Epoch: 47/100... Step: 4793... Loss: 0.019785... Val Loss: 0.007502\n",
      "Epoch: 47/100... Step: 4794... Loss: 0.021553... Val Loss: 0.006209\n",
      "Epoch: 47/100... Step: 4795... Loss: 0.032358... Val Loss: 0.008722\n",
      "Epoch: 47/100... Step: 4796... Loss: 0.024332... Val Loss: 0.013842\n",
      "Epoch: 47/100... Step: 4797... Loss: 0.012033... Val Loss: 0.013071\n",
      "Epoch: 47/100... Step: 4798... Loss: 0.020214... Val Loss: 0.011480\n",
      "Epoch: 47/100... Step: 4799... Loss: 0.026934... Val Loss: 0.013992\n",
      "Epoch: 47/100... Step: 4800... Loss: 0.025908... Val Loss: 0.030526\n",
      "Epoch: 47/100... Step: 4801... Loss: 0.021868... Val Loss: 0.042484\n",
      "Epoch: 47/100... Step: 4802... Loss: 0.032279... Val Loss: 0.053514\n",
      "Epoch: 47/100... Step: 4803... Loss: 0.020147... Val Loss: 0.064898\n",
      "Epoch: 47/100... Step: 4804... Loss: 0.024019... Val Loss: 0.056765\n",
      "Epoch: 47/100... Step: 4805... Loss: 0.020743... Val Loss: 0.051977\n",
      "Epoch: 47/100... Step: 4806... Loss: 0.035564... Val Loss: 0.044795\n",
      "Epoch: 47/100... Step: 4807... Loss: 0.019720... Val Loss: 0.041695\n",
      "Epoch: 47/100... Step: 4808... Loss: 0.032717... Val Loss: 0.043377\n",
      "Epoch: 47/100... Step: 4809... Loss: 0.035267... Val Loss: 0.041593\n",
      "Epoch: 47/100... Step: 4810... Loss: 0.026557... Val Loss: 0.030412\n",
      "Epoch: 47/100... Step: 4811... Loss: 0.019209... Val Loss: 0.020551\n",
      "Epoch: 47/100... Step: 4812... Loss: 0.016720... Val Loss: 0.011596\n",
      "Epoch: 47/100... Step: 4813... Loss: 0.029923... Val Loss: 0.020954\n",
      "Epoch: 47/100... Step: 4814... Loss: 0.025351... Val Loss: 0.031742\n",
      "Epoch: 47/100... Step: 4815... Loss: 0.017820... Val Loss: 0.011058\n",
      "Epoch: 47/100... Step: 4816... Loss: 0.024234... Val Loss: 0.008830\n",
      "Epoch: 47/100... Step: 4817... Loss: 0.021987... Val Loss: 0.023217\n",
      "Epoch: 47/100... Step: 4818... Loss: 0.017456... Val Loss: 0.015119\n",
      "Epoch: 47/100... Step: 4819... Loss: 0.016000... Val Loss: 0.025819\n",
      "Epoch: 47/100... Step: 4820... Loss: 0.026293... Val Loss: 0.040893\n",
      "Epoch: 47/100... Step: 4821... Loss: 0.017805... Val Loss: 0.060577\n",
      "Epoch: 47/100... Step: 4822... Loss: 0.019616... Val Loss: 0.074831\n",
      "Epoch: 47/100... Step: 4823... Loss: 0.024180... Val Loss: 0.089348\n",
      "Epoch: 47/100... Step: 4824... Loss: 0.021788... Val Loss: 0.110415\n",
      "Epoch: 47/100... Step: 4825... Loss: 0.023544... Val Loss: 0.123465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Step: 4826... Loss: 0.033003... Val Loss: 0.146756\n",
      "Epoch: 47/100... Step: 4827... Loss: 0.014683... Val Loss: 0.160723\n",
      "Epoch: 47/100... Step: 4828... Loss: 0.022207... Val Loss: 0.158566\n",
      "Epoch: 47/100... Step: 4829... Loss: 0.025664... Val Loss: 0.158228\n",
      "Epoch: 47/100... Step: 4830... Loss: 0.022287... Val Loss: 0.171394\n",
      "Epoch: 47/100... Step: 4831... Loss: 0.020377... Val Loss: 0.183896\n",
      "Epoch: 47/100... Step: 4832... Loss: 0.022666... Val Loss: 0.181865\n",
      "Epoch: 47/100... Step: 4833... Loss: 0.026676... Val Loss: 0.180393\n",
      "Epoch: 47/100... Step: 4834... Loss: 0.019559... Val Loss: 0.178452\n",
      "Epoch: 47/100... Step: 4835... Loss: 0.028427... Val Loss: 0.156001\n",
      "Epoch: 47/100... Step: 4836... Loss: 0.026763... Val Loss: 0.134625\n",
      "Epoch: 47/100... Step: 4837... Loss: 0.029606... Val Loss: 0.119928\n",
      "Epoch: 47/100... Step: 4838... Loss: 0.025649... Val Loss: 0.102527\n",
      "Epoch: 47/100... Step: 4839... Loss: 0.030245... Val Loss: 0.087033\n",
      "Epoch: 47/100... Step: 4840... Loss: 0.018348... Val Loss: 0.072172\n",
      "Epoch: 47/100... Step: 4841... Loss: 0.017265... Val Loss: 0.064071\n",
      "Epoch: 47/100... Step: 4842... Loss: 0.027878... Val Loss: 0.066636\n",
      "Epoch: 47/100... Step: 4843... Loss: 0.016311... Val Loss: 0.063341\n",
      "Epoch: 47/100... Step: 4844... Loss: 0.019753... Val Loss: 0.051464\n",
      "Epoch: 47/100... Step: 4845... Loss: 0.024573... Val Loss: 0.026340\n",
      "Epoch: 47/100... Step: 4846... Loss: 0.022460... Val Loss: 0.013393\n",
      "Epoch: 47/100... Step: 4847... Loss: 0.028848... Val Loss: 0.029922\n",
      "Epoch: 47/100... Step: 4848... Loss: 0.018969... Val Loss: 0.048200\n",
      "Epoch: 47/100... Step: 4849... Loss: 0.011127... Val Loss: 0.071198\n",
      "Epoch: 47/100... Step: 4850... Loss: 0.023588... Val Loss: 0.084917\n",
      "Epoch: 47/100... Step: 4851... Loss: 0.026721... Val Loss: 0.087454\n",
      "Epoch: 47/100... Step: 4852... Loss: 0.024100... Val Loss: 0.089695\n",
      "Epoch: 47/100... Step: 4853... Loss: 0.015676... Val Loss: 0.079073\n",
      "Epoch: 47/100... Step: 4854... Loss: 0.033246... Val Loss: 0.069845\n",
      "Epoch: 47/100... Step: 4855... Loss: 0.029169... Val Loss: 0.067006\n",
      "Epoch: 47/100... Step: 4856... Loss: 0.017387... Val Loss: 0.047322\n",
      "Epoch: 47/100... Step: 4857... Loss: 0.023360... Val Loss: 0.033090\n",
      "Epoch: 47/100... Step: 4858... Loss: 0.026112... Val Loss: 0.020875\n",
      "Epoch: 47/100... Step: 4859... Loss: 0.021023... Val Loss: 0.011959\n",
      "Epoch: 47/100... Step: 4860... Loss: 0.019762... Val Loss: 0.014243\n",
      "Epoch: 47/100... Step: 4861... Loss: 0.021271... Val Loss: 0.015909\n",
      "Epoch: 47/100... Step: 4862... Loss: 0.026907... Val Loss: 0.022921\n",
      "Epoch: 47/100... Step: 4863... Loss: 0.018678... Val Loss: 0.031275\n",
      "Epoch: 47/100... Step: 4864... Loss: 0.020772... Val Loss: 0.049668\n",
      "Epoch: 47/100... Step: 4865... Loss: 0.014680... Val Loss: 0.040627\n",
      "Epoch: 47/100... Step: 4866... Loss: 0.019412... Val Loss: 0.031407\n",
      "Epoch: 47/100... Step: 4867... Loss: 0.033581... Val Loss: 0.028824\n",
      "Epoch: 47/100... Step: 4868... Loss: 0.020659... Val Loss: 0.016300\n",
      "Epoch: 47/100... Step: 4869... Loss: 0.024575... Val Loss: 0.011495\n",
      "Epoch: 47/100... Step: 4870... Loss: 0.018677... Val Loss: 0.009707\n",
      "Epoch: 47/100... Step: 4871... Loss: 0.018429... Val Loss: 0.017583\n",
      "Epoch: 47/100... Step: 4872... Loss: 0.025677... Val Loss: 0.015236\n",
      "Epoch: 47/100... Step: 4873... Loss: 0.023109... Val Loss: 0.008490\n",
      "Epoch: 47/100... Step: 4874... Loss: 0.021192... Val Loss: 0.010988\n",
      "Epoch: 47/100... Step: 4875... Loss: 0.028729... Val Loss: 0.014010\n",
      "Epoch: 47/100... Step: 4876... Loss: 0.024740... Val Loss: 0.057096\n",
      "Epoch: 47/100... Step: 4877... Loss: 0.039001... Val Loss: 0.072095\n",
      "Epoch: 47/100... Step: 4878... Loss: 0.037717... Val Loss: 0.076398\n",
      "Epoch: 47/100... Step: 4879... Loss: 0.023010... Val Loss: 0.067634\n",
      "Epoch: 47/100... Step: 4880... Loss: 0.028499... Val Loss: 0.059611\n",
      "Epoch: 47/100... Step: 4881... Loss: 0.020860... Val Loss: 0.036502\n",
      "Epoch: 47/100... Step: 4882... Loss: 0.015257... Val Loss: 0.015448\n",
      "Epoch: 47/100... Step: 4883... Loss: 0.011977... Val Loss: 0.012728\n",
      "Epoch: 47/100... Step: 4884... Loss: 0.029688... Val Loss: 0.023612\n",
      "Epoch: 47/100... Step: 4885... Loss: 0.016956... Val Loss: 0.030344\n",
      "Epoch: 47/100... Step: 4886... Loss: 0.022570... Val Loss: 0.044466\n",
      "Epoch: 47/100... Step: 4887... Loss: 0.034929... Val Loss: 0.049562\n",
      "Epoch: 47/100... Step: 4888... Loss: 0.025140... Val Loss: 0.052338\n",
      "Epoch: 48/100... Step: 4889... Loss: 0.022799... Val Loss: 0.028210\n",
      "Epoch: 48/100... Step: 4890... Loss: 0.018423... Val Loss: 0.022299\n",
      "Epoch: 48/100... Step: 4891... Loss: 0.021567... Val Loss: 0.024659\n",
      "Epoch: 48/100... Step: 4892... Loss: 0.008741... Val Loss: 0.008113\n",
      "Epoch: 48/100... Step: 4893... Loss: 0.016846... Val Loss: 0.007784\n",
      "Epoch: 48/100... Step: 4894... Loss: 0.020432... Val Loss: 0.011144\n",
      "Epoch: 48/100... Step: 4895... Loss: 0.018831... Val Loss: 0.020896\n",
      "Epoch: 48/100... Step: 4896... Loss: 0.018297... Val Loss: 0.009404\n",
      "Epoch: 48/100... Step: 4897... Loss: 0.025560... Val Loss: 0.033585\n",
      "Epoch: 48/100... Step: 4898... Loss: 0.019500... Val Loss: 0.026846\n",
      "Epoch: 48/100... Step: 4899... Loss: 0.018017... Val Loss: 0.013630\n",
      "Epoch: 48/100... Step: 4900... Loss: 0.022599... Val Loss: 0.013147\n",
      "Epoch: 48/100... Step: 4901... Loss: 0.028204... Val Loss: 0.014493\n",
      "Epoch: 48/100... Step: 4902... Loss: 0.024015... Val Loss: 0.019008\n",
      "Epoch: 48/100... Step: 4903... Loss: 0.020486... Val Loss: 0.010163\n",
      "Epoch: 48/100... Step: 4904... Loss: 0.032006... Val Loss: 0.008568\n",
      "Epoch: 48/100... Step: 4905... Loss: 0.027256... Val Loss: 0.012867\n",
      "Epoch: 48/100... Step: 4906... Loss: 0.021227... Val Loss: 0.015348\n",
      "Epoch: 48/100... Step: 4907... Loss: 0.011726... Val Loss: 0.021535\n",
      "Epoch: 48/100... Step: 4908... Loss: 0.023104... Val Loss: 0.032000\n",
      "Epoch: 48/100... Step: 4909... Loss: 0.011564... Val Loss: 0.038302\n",
      "Epoch: 48/100... Step: 4910... Loss: 0.017346... Val Loss: 0.040199\n",
      "Epoch: 48/100... Step: 4911... Loss: 0.014536... Val Loss: 0.033413\n",
      "Epoch: 48/100... Step: 4912... Loss: 0.019530... Val Loss: 0.014791\n",
      "Epoch: 48/100... Step: 4913... Loss: 0.020055... Val Loss: 0.012393\n",
      "Epoch: 48/100... Step: 4914... Loss: 0.020563... Val Loss: 0.018257\n",
      "Epoch: 48/100... Step: 4915... Loss: 0.018998... Val Loss: 0.024123\n",
      "Epoch: 48/100... Step: 4916... Loss: 0.030104... Val Loss: 0.032923\n",
      "Epoch: 48/100... Step: 4917... Loss: 0.015906... Val Loss: 0.049009\n",
      "Epoch: 48/100... Step: 4918... Loss: 0.014797... Val Loss: 0.061115\n",
      "Epoch: 48/100... Step: 4919... Loss: 0.020731... Val Loss: 0.076338\n",
      "Epoch: 48/100... Step: 4920... Loss: 0.026529... Val Loss: 0.075587\n",
      "Epoch: 48/100... Step: 4921... Loss: 0.027705... Val Loss: 0.079451\n",
      "Epoch: 48/100... Step: 4922... Loss: 0.014652... Val Loss: 0.071907\n",
      "Epoch: 48/100... Step: 4923... Loss: 0.015007... Val Loss: 0.073839\n",
      "Epoch: 48/100... Step: 4924... Loss: 0.043641... Val Loss: 0.077364\n",
      "Epoch: 48/100... Step: 4925... Loss: 0.028120... Val Loss: 0.054569\n",
      "Epoch: 48/100... Step: 4926... Loss: 0.018998... Val Loss: 0.043417\n",
      "Epoch: 48/100... Step: 4927... Loss: 0.014442... Val Loss: 0.047660\n",
      "Epoch: 48/100... Step: 4928... Loss: 0.024194... Val Loss: 0.053063\n",
      "Epoch: 48/100... Step: 4929... Loss: 0.019961... Val Loss: 0.069022\n",
      "Epoch: 48/100... Step: 4930... Loss: 0.021786... Val Loss: 0.087693\n",
      "Epoch: 48/100... Step: 4931... Loss: 0.017753... Val Loss: 0.111041\n",
      "Epoch: 48/100... Step: 4932... Loss: 0.019748... Val Loss: 0.146606\n",
      "Epoch: 48/100... Step: 4933... Loss: 0.023582... Val Loss: 0.170501\n",
      "Epoch: 48/100... Step: 4934... Loss: 0.026516... Val Loss: 0.177692\n",
      "Epoch: 48/100... Step: 4935... Loss: 0.018224... Val Loss: 0.195902\n",
      "Epoch: 48/100... Step: 4936... Loss: 0.037857... Val Loss: 0.196064\n",
      "Epoch: 48/100... Step: 4937... Loss: 0.022645... Val Loss: 0.185128\n",
      "Epoch: 48/100... Step: 4938... Loss: 0.010538... Val Loss: 0.159409\n",
      "Epoch: 48/100... Step: 4939... Loss: 0.028856... Val Loss: 0.140132\n",
      "Epoch: 48/100... Step: 4940... Loss: 0.024165... Val Loss: 0.111615\n",
      "Epoch: 48/100... Step: 4941... Loss: 0.021519... Val Loss: 0.103237\n",
      "Epoch: 48/100... Step: 4942... Loss: 0.033973... Val Loss: 0.087247\n",
      "Epoch: 48/100... Step: 4943... Loss: 0.027738... Val Loss: 0.074117\n",
      "Epoch: 48/100... Step: 4944... Loss: 0.021168... Val Loss: 0.067272\n",
      "Epoch: 48/100... Step: 4945... Loss: 0.022997... Val Loss: 0.070163\n",
      "Epoch: 48/100... Step: 4946... Loss: 0.015424... Val Loss: 0.060520\n",
      "Epoch: 48/100... Step: 4947... Loss: 0.018885... Val Loss: 0.045673\n",
      "Epoch: 48/100... Step: 4948... Loss: 0.021750... Val Loss: 0.030751\n",
      "Epoch: 48/100... Step: 4949... Loss: 0.017780... Val Loss: 0.022209\n",
      "Epoch: 48/100... Step: 4950... Loss: 0.019339... Val Loss: 0.048049\n",
      "Epoch: 48/100... Step: 4951... Loss: 0.015895... Val Loss: 0.080535\n",
      "Epoch: 48/100... Step: 4952... Loss: 0.015855... Val Loss: 0.101737\n",
      "Epoch: 48/100... Step: 4953... Loss: 0.019431... Val Loss: 0.111601\n",
      "Epoch: 48/100... Step: 4954... Loss: 0.013037... Val Loss: 0.090943\n",
      "Epoch: 48/100... Step: 4955... Loss: 0.024128... Val Loss: 0.111109\n",
      "Epoch: 48/100... Step: 4956... Loss: 0.018200... Val Loss: 0.096493\n",
      "Epoch: 48/100... Step: 4957... Loss: 0.021613... Val Loss: 0.086289\n",
      "Epoch: 48/100... Step: 4958... Loss: 0.020080... Val Loss: 0.035086\n",
      "Epoch: 48/100... Step: 4959... Loss: 0.025756... Val Loss: 0.016460\n",
      "Epoch: 48/100... Step: 4960... Loss: 0.024353... Val Loss: 0.009847\n",
      "Epoch: 48/100... Step: 4961... Loss: 0.027200... Val Loss: 0.015009\n",
      "Epoch: 48/100... Step: 4962... Loss: 0.034442... Val Loss: 0.019772\n",
      "Epoch: 48/100... Step: 4963... Loss: 0.026136... Val Loss: 0.013307\n",
      "Epoch: 48/100... Step: 4964... Loss: 0.026235... Val Loss: 0.009401\n",
      "Epoch: 48/100... Step: 4965... Loss: 0.031563... Val Loss: 0.013401\n",
      "Epoch: 48/100... Step: 4966... Loss: 0.026999... Val Loss: 0.017942\n",
      "Epoch: 48/100... Step: 4967... Loss: 0.030445... Val Loss: 0.023545\n",
      "Epoch: 48/100... Step: 4968... Loss: 0.044959... Val Loss: 0.028054\n",
      "Epoch: 48/100... Step: 4969... Loss: 0.033210... Val Loss: 0.033311\n",
      "Epoch: 48/100... Step: 4970... Loss: 0.030460... Val Loss: 0.032391\n",
      "Epoch: 48/100... Step: 4971... Loss: 0.028620... Val Loss: 0.029125\n",
      "Epoch: 48/100... Step: 4972... Loss: 0.044009... Val Loss: 0.029207\n",
      "Epoch: 48/100... Step: 4973... Loss: 0.031285... Val Loss: 0.031724\n",
      "Epoch: 48/100... Step: 4974... Loss: 0.035545... Val Loss: 0.042599\n",
      "Epoch: 48/100... Step: 4975... Loss: 0.023942... Val Loss: 0.056310\n",
      "Epoch: 48/100... Step: 4976... Loss: 0.018791... Val Loss: 0.056399\n",
      "Epoch: 48/100... Step: 4977... Loss: 0.025006... Val Loss: 0.043906\n",
      "Epoch: 48/100... Step: 4978... Loss: 0.020363... Val Loss: 0.041975\n",
      "Epoch: 48/100... Step: 4979... Loss: 0.017049... Val Loss: 0.028465\n",
      "Epoch: 48/100... Step: 4980... Loss: 0.027693... Val Loss: 0.009744\n",
      "Epoch: 48/100... Step: 4981... Loss: 0.018718... Val Loss: 0.016072\n",
      "Epoch: 48/100... Step: 4982... Loss: 0.021991... Val Loss: 0.044245\n",
      "Epoch: 48/100... Step: 4983... Loss: 0.013550... Val Loss: 0.062796\n",
      "Epoch: 48/100... Step: 4984... Loss: 0.015004... Val Loss: 0.064376\n",
      "Epoch: 48/100... Step: 4985... Loss: 0.023162... Val Loss: 0.060711\n",
      "Epoch: 48/100... Step: 4986... Loss: 0.024939... Val Loss: 0.057064\n",
      "Epoch: 48/100... Step: 4987... Loss: 0.020053... Val Loss: 0.068072\n",
      "Epoch: 48/100... Step: 4988... Loss: 0.017408... Val Loss: 0.076153\n",
      "Epoch: 48/100... Step: 4989... Loss: 0.020324... Val Loss: 0.075356\n",
      "Epoch: 48/100... Step: 4990... Loss: 0.014695... Val Loss: 0.074378\n",
      "Epoch: 48/100... Step: 4991... Loss: 0.018995... Val Loss: 0.065452\n",
      "Epoch: 48/100... Step: 4992... Loss: 0.034278... Val Loss: 0.038489\n",
      "Epoch: 49/100... Step: 4993... Loss: 0.021296... Val Loss: 0.046525\n",
      "Epoch: 49/100... Step: 4994... Loss: 0.014362... Val Loss: 0.024785\n",
      "Epoch: 49/100... Step: 4995... Loss: 0.012504... Val Loss: 0.044600\n",
      "Epoch: 49/100... Step: 4996... Loss: 0.012821... Val Loss: 0.128020\n",
      "Epoch: 49/100... Step: 4997... Loss: 0.026783... Val Loss: 0.193549\n",
      "Epoch: 49/100... Step: 4998... Loss: 0.021307... Val Loss: 0.218248\n",
      "Epoch: 49/100... Step: 4999... Loss: 0.008820... Val Loss: 0.238387\n",
      "Epoch: 49/100... Step: 5000... Loss: 0.021022... Val Loss: 0.254532\n",
      "Epoch: 49/100... Step: 5001... Loss: 0.033125... Val Loss: 0.266900\n",
      "Epoch: 49/100... Step: 5002... Loss: 0.026725... Val Loss: 0.290152\n",
      "Epoch: 49/100... Step: 5003... Loss: 0.026654... Val Loss: 0.290936\n",
      "Epoch: 49/100... Step: 5004... Loss: 0.025067... Val Loss: 0.285251\n",
      "Epoch: 49/100... Step: 5005... Loss: 0.035451... Val Loss: 0.257576\n",
      "Epoch: 49/100... Step: 5006... Loss: 0.032550... Val Loss: 0.233409\n",
      "Epoch: 49/100... Step: 5007... Loss: 0.029655... Val Loss: 0.221664\n",
      "Epoch: 49/100... Step: 5008... Loss: 0.024332... Val Loss: 0.193905\n",
      "Epoch: 49/100... Step: 5009... Loss: 0.020777... Val Loss: 0.171417\n",
      "Epoch: 49/100... Step: 5010... Loss: 0.015128... Val Loss: 0.152634\n",
      "Epoch: 49/100... Step: 5011... Loss: 0.023643... Val Loss: 0.119644\n",
      "Epoch: 49/100... Step: 5012... Loss: 0.017764... Val Loss: 0.090775\n",
      "Epoch: 49/100... Step: 5013... Loss: 0.025552... Val Loss: 0.079061\n",
      "Epoch: 49/100... Step: 5014... Loss: 0.023669... Val Loss: 0.093290\n",
      "Epoch: 49/100... Step: 5015... Loss: 0.022889... Val Loss: 0.104680\n",
      "Epoch: 49/100... Step: 5016... Loss: 0.018853... Val Loss: 0.108820\n",
      "Epoch: 49/100... Step: 5017... Loss: 0.014356... Val Loss: 0.104145\n",
      "Epoch: 49/100... Step: 5018... Loss: 0.030708... Val Loss: 0.081629\n",
      "Epoch: 49/100... Step: 5019... Loss: 0.033626... Val Loss: 0.068996\n",
      "Epoch: 49/100... Step: 5020... Loss: 0.026791... Val Loss: 0.065332\n",
      "Epoch: 49/100... Step: 5021... Loss: 0.028788... Val Loss: 0.084733\n",
      "Epoch: 49/100... Step: 5022... Loss: 0.031757... Val Loss: 0.124702\n",
      "Epoch: 49/100... Step: 5023... Loss: 0.024337... Val Loss: 0.139733\n",
      "Epoch: 49/100... Step: 5024... Loss: 0.019814... Val Loss: 0.128326\n",
      "Epoch: 49/100... Step: 5025... Loss: 0.025154... Val Loss: 0.102414\n",
      "Epoch: 49/100... Step: 5026... Loss: 0.028032... Val Loss: 0.082580\n",
      "Epoch: 49/100... Step: 5027... Loss: 0.028223... Val Loss: 0.087167\n",
      "Epoch: 49/100... Step: 5028... Loss: 0.019337... Val Loss: 0.101595\n",
      "Epoch: 49/100... Step: 5029... Loss: 0.017263... Val Loss: 0.105841\n",
      "Epoch: 49/100... Step: 5030... Loss: 0.019306... Val Loss: 0.095778\n",
      "Epoch: 49/100... Step: 5031... Loss: 0.013178... Val Loss: 0.083554\n",
      "Epoch: 49/100... Step: 5032... Loss: 0.011786... Val Loss: 0.081981\n",
      "Epoch: 49/100... Step: 5033... Loss: 0.020460... Val Loss: 0.080795\n",
      "Epoch: 49/100... Step: 5034... Loss: 0.022079... Val Loss: 0.072166\n",
      "Epoch: 49/100... Step: 5035... Loss: 0.035266... Val Loss: 0.066779\n",
      "Epoch: 49/100... Step: 5036... Loss: 0.026765... Val Loss: 0.065521\n",
      "Epoch: 49/100... Step: 5037... Loss: 0.026416... Val Loss: 0.057318\n",
      "Epoch: 49/100... Step: 5038... Loss: 0.026314... Val Loss: 0.051642\n",
      "Epoch: 49/100... Step: 5039... Loss: 0.026544... Val Loss: 0.058619\n",
      "Epoch: 49/100... Step: 5040... Loss: 0.024289... Val Loss: 0.063991\n",
      "Epoch: 49/100... Step: 5041... Loss: 0.024614... Val Loss: 0.075431\n",
      "Epoch: 49/100... Step: 5042... Loss: 0.024570... Val Loss: 0.085558\n",
      "Epoch: 49/100... Step: 5043... Loss: 0.018443... Val Loss: 0.088344\n",
      "Epoch: 49/100... Step: 5044... Loss: 0.024781... Val Loss: 0.094147\n",
      "Epoch: 49/100... Step: 5045... Loss: 0.020766... Val Loss: 0.080776\n",
      "Epoch: 49/100... Step: 5046... Loss: 0.022846... Val Loss: 0.051462\n",
      "Epoch: 49/100... Step: 5047... Loss: 0.013467... Val Loss: 0.025824\n",
      "Epoch: 49/100... Step: 5048... Loss: 0.015614... Val Loss: 0.011397\n",
      "Epoch: 49/100... Step: 5049... Loss: 0.021450... Val Loss: 0.014108\n",
      "Epoch: 49/100... Step: 5050... Loss: 0.021304... Val Loss: 0.010927\n",
      "Epoch: 49/100... Step: 5051... Loss: 0.020351... Val Loss: 0.017132\n",
      "Epoch: 49/100... Step: 5052... Loss: 0.023741... Val Loss: 0.046104\n",
      "Epoch: 49/100... Step: 5053... Loss: 0.025668... Val Loss: 0.055348\n",
      "Epoch: 49/100... Step: 5054... Loss: 0.020316... Val Loss: 0.053439\n",
      "Epoch: 49/100... Step: 5055... Loss: 0.029047... Val Loss: 0.050443\n",
      "Epoch: 49/100... Step: 5056... Loss: 0.029865... Val Loss: 0.032505\n",
      "Epoch: 49/100... Step: 5057... Loss: 0.013866... Val Loss: 0.008676\n",
      "Epoch: 49/100... Step: 5058... Loss: 0.017665... Val Loss: 0.017697\n",
      "Epoch: 49/100... Step: 5059... Loss: 0.018359... Val Loss: 0.035908\n",
      "Epoch: 49/100... Step: 5060... Loss: 0.016296... Val Loss: 0.051768\n",
      "Epoch: 49/100... Step: 5061... Loss: 0.024101... Val Loss: 0.053632\n",
      "Epoch: 49/100... Step: 5062... Loss: 0.026052... Val Loss: 0.054475\n",
      "Epoch: 49/100... Step: 5063... Loss: 0.028770... Val Loss: 0.065769\n",
      "Epoch: 49/100... Step: 5064... Loss: 0.021517... Val Loss: 0.084987\n",
      "Epoch: 49/100... Step: 5065... Loss: 0.017265... Val Loss: 0.096414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100... Step: 5066... Loss: 0.018217... Val Loss: 0.104355\n",
      "Epoch: 49/100... Step: 5067... Loss: 0.019886... Val Loss: 0.095217\n",
      "Epoch: 49/100... Step: 5068... Loss: 0.017678... Val Loss: 0.087165\n",
      "Epoch: 49/100... Step: 5069... Loss: 0.026578... Val Loss: 0.077779\n",
      "Epoch: 49/100... Step: 5070... Loss: 0.019207... Val Loss: 0.062449\n",
      "Epoch: 49/100... Step: 5071... Loss: 0.014542... Val Loss: 0.053936\n",
      "Epoch: 49/100... Step: 5072... Loss: 0.028340... Val Loss: 0.045843\n",
      "Epoch: 49/100... Step: 5073... Loss: 0.027036... Val Loss: 0.034091\n",
      "Epoch: 49/100... Step: 5074... Loss: 0.018423... Val Loss: 0.032167\n",
      "Epoch: 49/100... Step: 5075... Loss: 0.029057... Val Loss: 0.032244\n",
      "Epoch: 49/100... Step: 5076... Loss: 0.025793... Val Loss: 0.036728\n",
      "Epoch: 49/100... Step: 5077... Loss: 0.020614... Val Loss: 0.043589\n",
      "Epoch: 49/100... Step: 5078... Loss: 0.018737... Val Loss: 0.046689\n",
      "Epoch: 49/100... Step: 5079... Loss: 0.021772... Val Loss: 0.037291\n",
      "Epoch: 49/100... Step: 5080... Loss: 0.011973... Val Loss: 0.038560\n",
      "Epoch: 49/100... Step: 5081... Loss: 0.019990... Val Loss: 0.029144\n",
      "Epoch: 49/100... Step: 5082... Loss: 0.014864... Val Loss: 0.011611\n",
      "Epoch: 49/100... Step: 5083... Loss: 0.018215... Val Loss: 0.027512\n",
      "Epoch: 49/100... Step: 5084... Loss: 0.020155... Val Loss: 0.034959\n",
      "Epoch: 49/100... Step: 5085... Loss: 0.023510... Val Loss: 0.033321\n",
      "Epoch: 49/100... Step: 5086... Loss: 0.011860... Val Loss: 0.028573\n",
      "Epoch: 49/100... Step: 5087... Loss: 0.025259... Val Loss: 0.034719\n",
      "Epoch: 49/100... Step: 5088... Loss: 0.032845... Val Loss: 0.045422\n",
      "Epoch: 49/100... Step: 5089... Loss: 0.020335... Val Loss: 0.069141\n",
      "Epoch: 49/100... Step: 5090... Loss: 0.021665... Val Loss: 0.086617\n",
      "Epoch: 49/100... Step: 5091... Loss: 0.025431... Val Loss: 0.085503\n",
      "Epoch: 49/100... Step: 5092... Loss: 0.027405... Val Loss: 0.088877\n",
      "Epoch: 49/100... Step: 5093... Loss: 0.023786... Val Loss: 0.106350\n",
      "Epoch: 49/100... Step: 5094... Loss: 0.027265... Val Loss: 0.101870\n",
      "Epoch: 49/100... Step: 5095... Loss: 0.014171... Val Loss: 0.093312\n",
      "Epoch: 49/100... Step: 5096... Loss: 0.019003... Val Loss: 0.088225\n",
      "Epoch: 50/100... Step: 5097... Loss: 0.011776... Val Loss: 0.052068\n",
      "Epoch: 50/100... Step: 5098... Loss: 0.015241... Val Loss: 0.013685\n",
      "Epoch: 50/100... Step: 5099... Loss: 0.018047... Val Loss: 0.089617\n",
      "Epoch: 50/100... Step: 5100... Loss: 0.017369... Val Loss: 0.168172\n",
      "Epoch: 50/100... Step: 5101... Loss: 0.030257... Val Loss: 0.202841\n",
      "Epoch: 50/100... Step: 5102... Loss: 0.019289... Val Loss: 0.231494\n",
      "Epoch: 50/100... Step: 5103... Loss: 0.027731... Val Loss: 0.257961\n",
      "Epoch: 50/100... Step: 5104... Loss: 0.026758... Val Loss: 0.275586\n",
      "Epoch: 50/100... Step: 5105... Loss: 0.022921... Val Loss: 0.269971\n",
      "Epoch: 50/100... Step: 5106... Loss: 0.021996... Val Loss: 0.258634\n",
      "Epoch: 50/100... Step: 5107... Loss: 0.025437... Val Loss: 0.268145\n",
      "Epoch: 50/100... Step: 5108... Loss: 0.019979... Val Loss: 0.282022\n",
      "Epoch: 50/100... Step: 5109... Loss: 0.026313... Val Loss: 0.280453\n",
      "Epoch: 50/100... Step: 5110... Loss: 0.017023... Val Loss: 0.304085\n",
      "Epoch: 50/100... Step: 5111... Loss: 0.020764... Val Loss: 0.307530\n",
      "Epoch: 50/100... Step: 5112... Loss: 0.018240... Val Loss: 0.309744\n",
      "Epoch: 50/100... Step: 5113... Loss: 0.024537... Val Loss: 0.297951\n",
      "Epoch: 50/100... Step: 5114... Loss: 0.032083... Val Loss: 0.260927\n",
      "Epoch: 50/100... Step: 5115... Loss: 0.019579... Val Loss: 0.232361\n",
      "Epoch: 50/100... Step: 5116... Loss: 0.012788... Val Loss: 0.197087\n",
      "Epoch: 50/100... Step: 5117... Loss: 0.016019... Val Loss: 0.171876\n",
      "Epoch: 50/100... Step: 5118... Loss: 0.021239... Val Loss: 0.148757\n",
      "Epoch: 50/100... Step: 5119... Loss: 0.021413... Val Loss: 0.129754\n",
      "Epoch: 50/100... Step: 5120... Loss: 0.020227... Val Loss: 0.109189\n",
      "Epoch: 50/100... Step: 5121... Loss: 0.020028... Val Loss: 0.089649\n",
      "Epoch: 50/100... Step: 5122... Loss: 0.020439... Val Loss: 0.064036\n",
      "Epoch: 50/100... Step: 5123... Loss: 0.015483... Val Loss: 0.045586\n",
      "Epoch: 50/100... Step: 5124... Loss: 0.028374... Val Loss: 0.023723\n",
      "Epoch: 50/100... Step: 5125... Loss: 0.021099... Val Loss: 0.006900\n",
      "Epoch: 50/100... Step: 5126... Loss: 0.021823... Val Loss: 0.008214\n",
      "Epoch: 50/100... Step: 5127... Loss: 0.013010... Val Loss: 0.013034\n",
      "Epoch: 50/100... Step: 5128... Loss: 0.020096... Val Loss: 0.024982\n",
      "Epoch: 50/100... Step: 5129... Loss: 0.021889... Val Loss: 0.046629\n",
      "Epoch: 50/100... Step: 5130... Loss: 0.024538... Val Loss: 0.030994\n",
      "Epoch: 50/100... Step: 5131... Loss: 0.017684... Val Loss: 0.016089\n",
      "Epoch: 50/100... Step: 5132... Loss: 0.026933... Val Loss: 0.011394\n",
      "Epoch: 50/100... Step: 5133... Loss: 0.014177... Val Loss: 0.012540\n",
      "Epoch: 50/100... Step: 5134... Loss: 0.017490... Val Loss: 0.020698\n",
      "Epoch: 50/100... Step: 5135... Loss: 0.024275... Val Loss: 0.018982\n",
      "Epoch: 50/100... Step: 5136... Loss: 0.016051... Val Loss: 0.029691\n",
      "Epoch: 50/100... Step: 5137... Loss: 0.021895... Val Loss: 0.041379\n",
      "Epoch: 50/100... Step: 5138... Loss: 0.014113... Val Loss: 0.061125\n",
      "Epoch: 50/100... Step: 5139... Loss: 0.023798... Val Loss: 0.078719\n",
      "Epoch: 50/100... Step: 5140... Loss: 0.016869... Val Loss: 0.092579\n",
      "Epoch: 50/100... Step: 5141... Loss: 0.023720... Val Loss: 0.090939\n",
      "Epoch: 50/100... Step: 5142... Loss: 0.020027... Val Loss: 0.097416\n",
      "Epoch: 50/100... Step: 5143... Loss: 0.023629... Val Loss: 0.106298\n",
      "Epoch: 50/100... Step: 5144... Loss: 0.018776... Val Loss: 0.115500\n",
      "Epoch: 50/100... Step: 5145... Loss: 0.030711... Val Loss: 0.109934\n",
      "Epoch: 50/100... Step: 5146... Loss: 0.018247... Val Loss: 0.094335\n",
      "Epoch: 50/100... Step: 5147... Loss: 0.028671... Val Loss: 0.070830\n",
      "Epoch: 50/100... Step: 5148... Loss: 0.034595... Val Loss: 0.070498\n",
      "Epoch: 50/100... Step: 5149... Loss: 0.029716... Val Loss: 0.078105\n",
      "Epoch: 50/100... Step: 5150... Loss: 0.028045... Val Loss: 0.102319\n",
      "Epoch: 50/100... Step: 5151... Loss: 0.019071... Val Loss: 0.111083\n",
      "Epoch: 50/100... Step: 5152... Loss: 0.020737... Val Loss: 0.108630\n",
      "Epoch: 50/100... Step: 5153... Loss: 0.022685... Val Loss: 0.111288\n",
      "Epoch: 50/100... Step: 5154... Loss: 0.027860... Val Loss: 0.096250\n",
      "Epoch: 50/100... Step: 5155... Loss: 0.019854... Val Loss: 0.084267\n",
      "Epoch: 50/100... Step: 5156... Loss: 0.025788... Val Loss: 0.072507\n",
      "Epoch: 50/100... Step: 5157... Loss: 0.023201... Val Loss: 0.070555\n",
      "Epoch: 50/100... Step: 5158... Loss: 0.023321... Val Loss: 0.071282\n",
      "Epoch: 50/100... Step: 5159... Loss: 0.024165... Val Loss: 0.070389\n",
      "Epoch: 50/100... Step: 5160... Loss: 0.033963... Val Loss: 0.066693\n",
      "Epoch: 50/100... Step: 5161... Loss: 0.029968... Val Loss: 0.038247\n",
      "Epoch: 50/100... Step: 5162... Loss: 0.025620... Val Loss: 0.011477\n",
      "Epoch: 50/100... Step: 5163... Loss: 0.025524... Val Loss: 0.015259\n",
      "Epoch: 50/100... Step: 5164... Loss: 0.016196... Val Loss: 0.024234\n",
      "Epoch: 50/100... Step: 5165... Loss: 0.025166... Val Loss: 0.049045\n",
      "Epoch: 50/100... Step: 5166... Loss: 0.024860... Val Loss: 0.055355\n",
      "Epoch: 50/100... Step: 5167... Loss: 0.017797... Val Loss: 0.049160\n",
      "Epoch: 50/100... Step: 5168... Loss: 0.018074... Val Loss: 0.057478\n",
      "Epoch: 50/100... Step: 5169... Loss: 0.018511... Val Loss: 0.065011\n",
      "Epoch: 50/100... Step: 5170... Loss: 0.025440... Val Loss: 0.062739\n",
      "Epoch: 50/100... Step: 5171... Loss: 0.018419... Val Loss: 0.055934\n",
      "Epoch: 50/100... Step: 5172... Loss: 0.015293... Val Loss: 0.051814\n",
      "Epoch: 50/100... Step: 5173... Loss: 0.022379... Val Loss: 0.053205\n",
      "Epoch: 50/100... Step: 5174... Loss: 0.017417... Val Loss: 0.055051\n",
      "Epoch: 50/100... Step: 5175... Loss: 0.017333... Val Loss: 0.053621\n",
      "Epoch: 50/100... Step: 5176... Loss: 0.017564... Val Loss: 0.042837\n",
      "Epoch: 50/100... Step: 5177... Loss: 0.017335... Val Loss: 0.038473\n",
      "Epoch: 50/100... Step: 5178... Loss: 0.015556... Val Loss: 0.040569\n",
      "Epoch: 50/100... Step: 5179... Loss: 0.017260... Val Loss: 0.045218\n",
      "Epoch: 50/100... Step: 5180... Loss: 0.011213... Val Loss: 0.046500\n",
      "Epoch: 50/100... Step: 5181... Loss: 0.024759... Val Loss: 0.041207\n",
      "Epoch: 50/100... Step: 5182... Loss: 0.029095... Val Loss: 0.040815\n",
      "Epoch: 50/100... Step: 5183... Loss: 0.036624... Val Loss: 0.037179\n",
      "Epoch: 50/100... Step: 5184... Loss: 0.017334... Val Loss: 0.034161\n",
      "Epoch: 50/100... Step: 5185... Loss: 0.020872... Val Loss: 0.031033\n",
      "Epoch: 50/100... Step: 5186... Loss: 0.028186... Val Loss: 0.035217\n",
      "Epoch: 50/100... Step: 5187... Loss: 0.018418... Val Loss: 0.037913\n",
      "Epoch: 50/100... Step: 5188... Loss: 0.037993... Val Loss: 0.045435\n",
      "Epoch: 50/100... Step: 5189... Loss: 0.038093... Val Loss: 0.043466\n",
      "Epoch: 50/100... Step: 5190... Loss: 0.021203... Val Loss: 0.045000\n",
      "Epoch: 50/100... Step: 5191... Loss: 0.027126... Val Loss: 0.052738\n",
      "Epoch: 50/100... Step: 5192... Loss: 0.029712... Val Loss: 0.058234\n",
      "Epoch: 50/100... Step: 5193... Loss: 0.018512... Val Loss: 0.050370\n",
      "Epoch: 50/100... Step: 5194... Loss: 0.017282... Val Loss: 0.046871\n",
      "Epoch: 50/100... Step: 5195... Loss: 0.023449... Val Loss: 0.040490\n",
      "Epoch: 50/100... Step: 5196... Loss: 0.022111... Val Loss: 0.045529\n",
      "Epoch: 50/100... Step: 5197... Loss: 0.021003... Val Loss: 0.049336\n",
      "Epoch: 50/100... Step: 5198... Loss: 0.022242... Val Loss: 0.044601\n",
      "Epoch: 50/100... Step: 5199... Loss: 0.025262... Val Loss: 0.048650\n",
      "Epoch: 50/100... Step: 5200... Loss: 0.033266... Val Loss: 0.059903\n",
      "Epoch: 51/100... Step: 5201... Loss: 0.022753... Val Loss: 0.027366\n",
      "Epoch: 51/100... Step: 5202... Loss: 0.018597... Val Loss: 0.059513\n",
      "Epoch: 51/100... Step: 5203... Loss: 0.018822... Val Loss: 0.028720\n",
      "Epoch: 51/100... Step: 5204... Loss: 0.026510... Val Loss: 0.033044\n",
      "Epoch: 51/100... Step: 5205... Loss: 0.017515... Val Loss: 0.025429\n",
      "Epoch: 51/100... Step: 5206... Loss: 0.023689... Val Loss: 0.063738\n",
      "Epoch: 51/100... Step: 5207... Loss: 0.032841... Val Loss: 0.064820\n",
      "Epoch: 51/100... Step: 5208... Loss: 0.028837... Val Loss: 0.057023\n",
      "Epoch: 51/100... Step: 5209... Loss: 0.019028... Val Loss: 0.061161\n",
      "Epoch: 51/100... Step: 5210... Loss: 0.017613... Val Loss: 0.062193\n",
      "Epoch: 51/100... Step: 5211... Loss: 0.017446... Val Loss: 0.067221\n",
      "Epoch: 51/100... Step: 5212... Loss: 0.020411... Val Loss: 0.056371\n",
      "Epoch: 51/100... Step: 5213... Loss: 0.020204... Val Loss: 0.030247\n",
      "Epoch: 51/100... Step: 5214... Loss: 0.017027... Val Loss: 0.009344\n",
      "Epoch: 51/100... Step: 5215... Loss: 0.021742... Val Loss: 0.013787\n",
      "Epoch: 51/100... Step: 5216... Loss: 0.019907... Val Loss: 0.015757\n",
      "Epoch: 51/100... Step: 5217... Loss: 0.014798... Val Loss: 0.026403\n",
      "Epoch: 51/100... Step: 5218... Loss: 0.025945... Val Loss: 0.034192\n",
      "Epoch: 51/100... Step: 5219... Loss: 0.022142... Val Loss: 0.047060\n",
      "Epoch: 51/100... Step: 5220... Loss: 0.018649... Val Loss: 0.055037\n",
      "Epoch: 51/100... Step: 5221... Loss: 0.013101... Val Loss: 0.063328\n",
      "Epoch: 51/100... Step: 5222... Loss: 0.021564... Val Loss: 0.073507\n",
      "Epoch: 51/100... Step: 5223... Loss: 0.025415... Val Loss: 0.078391\n",
      "Epoch: 51/100... Step: 5224... Loss: 0.017467... Val Loss: 0.079765\n",
      "Epoch: 51/100... Step: 5225... Loss: 0.015657... Val Loss: 0.079260\n",
      "Epoch: 51/100... Step: 5226... Loss: 0.021982... Val Loss: 0.077958\n",
      "Epoch: 51/100... Step: 5227... Loss: 0.018881... Val Loss: 0.073744\n",
      "Epoch: 51/100... Step: 5228... Loss: 0.016773... Val Loss: 0.055818\n",
      "Epoch: 51/100... Step: 5229... Loss: 0.019311... Val Loss: 0.037108\n",
      "Epoch: 51/100... Step: 5230... Loss: 0.018827... Val Loss: 0.023076\n",
      "Epoch: 51/100... Step: 5231... Loss: 0.024172... Val Loss: 0.016940\n",
      "Epoch: 51/100... Step: 5232... Loss: 0.013287... Val Loss: 0.020266\n",
      "Epoch: 51/100... Step: 5233... Loss: 0.018638... Val Loss: 0.015489\n",
      "Epoch: 51/100... Step: 5234... Loss: 0.025767... Val Loss: 0.012227\n",
      "Epoch: 51/100... Step: 5235... Loss: 0.021043... Val Loss: 0.010787\n",
      "Epoch: 51/100... Step: 5236... Loss: 0.021163... Val Loss: 0.007789\n",
      "Epoch: 51/100... Step: 5237... Loss: 0.026711... Val Loss: 0.010201\n",
      "Epoch: 51/100... Step: 5238... Loss: 0.032370... Val Loss: 0.012420\n",
      "Epoch: 51/100... Step: 5239... Loss: 0.016800... Val Loss: 0.018733\n",
      "Epoch: 51/100... Step: 5240... Loss: 0.025335... Val Loss: 0.042306\n",
      "Epoch: 51/100... Step: 5241... Loss: 0.020734... Val Loss: 0.054094\n",
      "Epoch: 51/100... Step: 5242... Loss: 0.032448... Val Loss: 0.053757\n",
      "Epoch: 51/100... Step: 5243... Loss: 0.021464... Val Loss: 0.051426\n",
      "Epoch: 51/100... Step: 5244... Loss: 0.029163... Val Loss: 0.037228\n",
      "Epoch: 51/100... Step: 5245... Loss: 0.019164... Val Loss: 0.029147\n",
      "Epoch: 51/100... Step: 5246... Loss: 0.012813... Val Loss: 0.024349\n",
      "Epoch: 51/100... Step: 5247... Loss: 0.018497... Val Loss: 0.023553\n",
      "Epoch: 51/100... Step: 5248... Loss: 0.027399... Val Loss: 0.022584\n",
      "Epoch: 51/100... Step: 5249... Loss: 0.024732... Val Loss: 0.019821\n",
      "Epoch: 51/100... Step: 5250... Loss: 0.015709... Val Loss: 0.014309\n",
      "Epoch: 51/100... Step: 5251... Loss: 0.015946... Val Loss: 0.009141\n",
      "Epoch: 51/100... Step: 5252... Loss: 0.019036... Val Loss: 0.011871\n",
      "Epoch: 51/100... Step: 5253... Loss: 0.028286... Val Loss: 0.016997\n",
      "Epoch: 51/100... Step: 5254... Loss: 0.024912... Val Loss: 0.035430\n",
      "Epoch: 51/100... Step: 5255... Loss: 0.014362... Val Loss: 0.058195\n",
      "Epoch: 51/100... Step: 5256... Loss: 0.020508... Val Loss: 0.067540\n",
      "Epoch: 51/100... Step: 5257... Loss: 0.021509... Val Loss: 0.077462\n",
      "Epoch: 51/100... Step: 5258... Loss: 0.025596... Val Loss: 0.078759\n",
      "Epoch: 51/100... Step: 5259... Loss: 0.014097... Val Loss: 0.069039\n",
      "Epoch: 51/100... Step: 5260... Loss: 0.028115... Val Loss: 0.051928\n",
      "Epoch: 51/100... Step: 5261... Loss: 0.023668... Val Loss: 0.025235\n",
      "Epoch: 51/100... Step: 5262... Loss: 0.020228... Val Loss: 0.011674\n",
      "Epoch: 51/100... Step: 5263... Loss: 0.015331... Val Loss: 0.013310\n",
      "Epoch: 51/100... Step: 5264... Loss: 0.015941... Val Loss: 0.041593\n",
      "Epoch: 51/100... Step: 5265... Loss: 0.019339... Val Loss: 0.061028\n",
      "Epoch: 51/100... Step: 5266... Loss: 0.023992... Val Loss: 0.074480\n",
      "Epoch: 51/100... Step: 5267... Loss: 0.015414... Val Loss: 0.072962\n",
      "Epoch: 51/100... Step: 5268... Loss: 0.018502... Val Loss: 0.076311\n",
      "Epoch: 51/100... Step: 5269... Loss: 0.014510... Val Loss: 0.073915\n",
      "Epoch: 51/100... Step: 5270... Loss: 0.022254... Val Loss: 0.068315\n",
      "Epoch: 51/100... Step: 5271... Loss: 0.013670... Val Loss: 0.070999\n",
      "Epoch: 51/100... Step: 5272... Loss: 0.016619... Val Loss: 0.074915\n",
      "Epoch: 51/100... Step: 5273... Loss: 0.020482... Val Loss: 0.082383\n",
      "Epoch: 51/100... Step: 5274... Loss: 0.025319... Val Loss: 0.072432\n",
      "Epoch: 51/100... Step: 5275... Loss: 0.026209... Val Loss: 0.054142\n",
      "Epoch: 51/100... Step: 5276... Loss: 0.020305... Val Loss: 0.040335\n",
      "Epoch: 51/100... Step: 5277... Loss: 0.030738... Val Loss: 0.034203\n",
      "Epoch: 51/100... Step: 5278... Loss: 0.024784... Val Loss: 0.037190\n",
      "Epoch: 51/100... Step: 5279... Loss: 0.031945... Val Loss: 0.051734\n",
      "Epoch: 51/100... Step: 5280... Loss: 0.027424... Val Loss: 0.080997\n",
      "Epoch: 51/100... Step: 5281... Loss: 0.030382... Val Loss: 0.092146\n",
      "Epoch: 51/100... Step: 5282... Loss: 0.020650... Val Loss: 0.108834\n",
      "Epoch: 51/100... Step: 5283... Loss: 0.019046... Val Loss: 0.110077\n",
      "Epoch: 51/100... Step: 5284... Loss: 0.025739... Val Loss: 0.099311\n",
      "Epoch: 51/100... Step: 5285... Loss: 0.022453... Val Loss: 0.087505\n",
      "Epoch: 51/100... Step: 5286... Loss: 0.015391... Val Loss: 0.077196\n",
      "Epoch: 51/100... Step: 5287... Loss: 0.025487... Val Loss: 0.083429\n",
      "Epoch: 51/100... Step: 5288... Loss: 0.012554... Val Loss: 0.079794\n",
      "Epoch: 51/100... Step: 5289... Loss: 0.017312... Val Loss: 0.061776\n",
      "Epoch: 51/100... Step: 5290... Loss: 0.028004... Val Loss: 0.039446\n",
      "Epoch: 51/100... Step: 5291... Loss: 0.025551... Val Loss: 0.025687\n",
      "Epoch: 51/100... Step: 5292... Loss: 0.032250... Val Loss: 0.012738\n",
      "Epoch: 51/100... Step: 5293... Loss: 0.025046... Val Loss: 0.009831\n",
      "Epoch: 51/100... Step: 5294... Loss: 0.017021... Val Loss: 0.016242\n",
      "Epoch: 51/100... Step: 5295... Loss: 0.015311... Val Loss: 0.016891\n",
      "Epoch: 51/100... Step: 5296... Loss: 0.014811... Val Loss: 0.010854\n",
      "Epoch: 51/100... Step: 5297... Loss: 0.017894... Val Loss: 0.008683\n",
      "Epoch: 51/100... Step: 5298... Loss: 0.008949... Val Loss: 0.042852\n",
      "Epoch: 51/100... Step: 5299... Loss: 0.015578... Val Loss: 0.073635\n",
      "Epoch: 51/100... Step: 5300... Loss: 0.025351... Val Loss: 0.097884\n",
      "Epoch: 51/100... Step: 5301... Loss: 0.018283... Val Loss: 0.109679\n",
      "Epoch: 51/100... Step: 5302... Loss: 0.026262... Val Loss: 0.108766\n",
      "Epoch: 51/100... Step: 5303... Loss: 0.026363... Val Loss: 0.089188\n",
      "Epoch: 51/100... Step: 5304... Loss: 0.024072... Val Loss: 0.074194\n",
      "Epoch: 52/100... Step: 5305... Loss: 0.013356... Val Loss: 0.047178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Step: 5306... Loss: 0.018163... Val Loss: 0.042431\n",
      "Epoch: 52/100... Step: 5307... Loss: 0.022470... Val Loss: 0.015665\n",
      "Epoch: 52/100... Step: 5308... Loss: 0.031234... Val Loss: 0.039702\n",
      "Epoch: 52/100... Step: 5309... Loss: 0.015151... Val Loss: 0.084369\n",
      "Epoch: 52/100... Step: 5310... Loss: 0.022590... Val Loss: 0.122405\n",
      "Epoch: 52/100... Step: 5311... Loss: 0.024762... Val Loss: 0.143154\n",
      "Epoch: 52/100... Step: 5312... Loss: 0.020514... Val Loss: 0.132447\n",
      "Epoch: 52/100... Step: 5313... Loss: 0.020879... Val Loss: 0.133137\n",
      "Epoch: 52/100... Step: 5314... Loss: 0.021381... Val Loss: 0.143388\n",
      "Epoch: 52/100... Step: 5315... Loss: 0.012160... Val Loss: 0.147279\n",
      "Epoch: 52/100... Step: 5316... Loss: 0.014590... Val Loss: 0.138573\n",
      "Epoch: 52/100... Step: 5317... Loss: 0.018265... Val Loss: 0.130111\n",
      "Epoch: 52/100... Step: 5318... Loss: 0.023085... Val Loss: 0.139210\n",
      "Epoch: 52/100... Step: 5319... Loss: 0.033018... Val Loss: 0.135138\n",
      "Epoch: 52/100... Step: 5320... Loss: 0.016881... Val Loss: 0.121313\n",
      "Epoch: 52/100... Step: 5321... Loss: 0.020777... Val Loss: 0.109252\n",
      "Epoch: 52/100... Step: 5322... Loss: 0.017306... Val Loss: 0.102262\n",
      "Epoch: 52/100... Step: 5323... Loss: 0.013498... Val Loss: 0.089238\n",
      "Epoch: 52/100... Step: 5324... Loss: 0.011998... Val Loss: 0.065236\n",
      "Epoch: 52/100... Step: 5325... Loss: 0.013470... Val Loss: 0.046351\n",
      "Epoch: 52/100... Step: 5326... Loss: 0.028328... Val Loss: 0.046823\n",
      "Epoch: 52/100... Step: 5327... Loss: 0.019326... Val Loss: 0.042346\n",
      "Epoch: 52/100... Step: 5328... Loss: 0.024030... Val Loss: 0.033351\n",
      "Epoch: 52/100... Step: 5329... Loss: 0.027161... Val Loss: 0.018353\n",
      "Epoch: 52/100... Step: 5330... Loss: 0.021358... Val Loss: 0.018987\n",
      "Epoch: 52/100... Step: 5331... Loss: 0.032943... Val Loss: 0.046909\n",
      "Epoch: 52/100... Step: 5332... Loss: 0.024688... Val Loss: 0.057170\n",
      "Epoch: 52/100... Step: 5333... Loss: 0.022601... Val Loss: 0.060006\n",
      "Epoch: 52/100... Step: 5334... Loss: 0.022854... Val Loss: 0.052428\n",
      "Epoch: 52/100... Step: 5335... Loss: 0.027437... Val Loss: 0.031807\n",
      "Epoch: 52/100... Step: 5336... Loss: 0.020558... Val Loss: 0.013313\n",
      "Epoch: 52/100... Step: 5337... Loss: 0.023391... Val Loss: 0.019029\n",
      "Epoch: 52/100... Step: 5338... Loss: 0.026922... Val Loss: 0.028332\n",
      "Epoch: 52/100... Step: 5339... Loss: 0.020930... Val Loss: 0.031294\n",
      "Epoch: 52/100... Step: 5340... Loss: 0.027822... Val Loss: 0.028158\n",
      "Epoch: 52/100... Step: 5341... Loss: 0.019125... Val Loss: 0.026835\n",
      "Epoch: 52/100... Step: 5342... Loss: 0.020106... Val Loss: 0.021977\n",
      "Epoch: 52/100... Step: 5343... Loss: 0.025901... Val Loss: 0.020364\n",
      "Epoch: 52/100... Step: 5344... Loss: 0.017396... Val Loss: 0.026231\n",
      "Epoch: 52/100... Step: 5345... Loss: 0.022318... Val Loss: 0.028720\n",
      "Epoch: 52/100... Step: 5346... Loss: 0.030071... Val Loss: 0.030103\n",
      "Epoch: 52/100... Step: 5347... Loss: 0.014926... Val Loss: 0.044288\n",
      "Epoch: 52/100... Step: 5348... Loss: 0.019302... Val Loss: 0.064308\n",
      "Epoch: 52/100... Step: 5349... Loss: 0.019076... Val Loss: 0.071147\n",
      "Epoch: 52/100... Step: 5350... Loss: 0.027200... Val Loss: 0.074459\n",
      "Epoch: 52/100... Step: 5351... Loss: 0.021195... Val Loss: 0.077107\n",
      "Epoch: 52/100... Step: 5352... Loss: 0.014489... Val Loss: 0.081633\n",
      "Epoch: 52/100... Step: 5353... Loss: 0.019953... Val Loss: 0.084740\n",
      "Epoch: 52/100... Step: 5354... Loss: 0.027693... Val Loss: 0.090281\n",
      "Epoch: 52/100... Step: 5355... Loss: 0.016832... Val Loss: 0.084848\n",
      "Epoch: 52/100... Step: 5356... Loss: 0.014347... Val Loss: 0.076904\n",
      "Epoch: 52/100... Step: 5357... Loss: 0.020613... Val Loss: 0.067071\n",
      "Epoch: 52/100... Step: 5358... Loss: 0.017979... Val Loss: 0.052660\n",
      "Epoch: 52/100... Step: 5359... Loss: 0.017873... Val Loss: 0.035232\n",
      "Epoch: 52/100... Step: 5360... Loss: 0.010499... Val Loss: 0.010557\n",
      "Epoch: 52/100... Step: 5361... Loss: 0.018279... Val Loss: 0.012334\n",
      "Epoch: 52/100... Step: 5362... Loss: 0.019118... Val Loss: 0.025283\n",
      "Epoch: 52/100... Step: 5363... Loss: 0.020966... Val Loss: 0.036280\n",
      "Epoch: 52/100... Step: 5364... Loss: 0.025369... Val Loss: 0.046125\n",
      "Epoch: 52/100... Step: 5365... Loss: 0.022583... Val Loss: 0.055998\n",
      "Epoch: 52/100... Step: 5366... Loss: 0.009829... Val Loss: 0.060714\n",
      "Epoch: 52/100... Step: 5367... Loss: 0.017683... Val Loss: 0.073569\n",
      "Epoch: 52/100... Step: 5368... Loss: 0.021586... Val Loss: 0.070942\n",
      "Epoch: 52/100... Step: 5369... Loss: 0.018853... Val Loss: 0.073182\n",
      "Epoch: 52/100... Step: 5370... Loss: 0.020367... Val Loss: 0.058341\n",
      "Epoch: 52/100... Step: 5371... Loss: 0.025683... Val Loss: 0.041123\n",
      "Epoch: 52/100... Step: 5372... Loss: 0.018433... Val Loss: 0.025118\n",
      "Epoch: 52/100... Step: 5373... Loss: 0.024155... Val Loss: 0.017496\n",
      "Epoch: 52/100... Step: 5374... Loss: 0.015875... Val Loss: 0.011610\n",
      "Epoch: 52/100... Step: 5375... Loss: 0.022835... Val Loss: 0.012989\n",
      "Epoch: 52/100... Step: 5376... Loss: 0.022819... Val Loss: 0.016308\n",
      "Epoch: 52/100... Step: 5377... Loss: 0.021026... Val Loss: 0.017169\n",
      "Epoch: 52/100... Step: 5378... Loss: 0.030881... Val Loss: 0.025708\n",
      "Epoch: 52/100... Step: 5379... Loss: 0.021124... Val Loss: 0.034547\n",
      "Epoch: 52/100... Step: 5380... Loss: 0.023938... Val Loss: 0.048473\n",
      "Epoch: 52/100... Step: 5381... Loss: 0.025115... Val Loss: 0.048360\n",
      "Epoch: 52/100... Step: 5382... Loss: 0.017562... Val Loss: 0.044450\n",
      "Epoch: 52/100... Step: 5383... Loss: 0.027132... Val Loss: 0.035692\n",
      "Epoch: 52/100... Step: 5384... Loss: 0.018444... Val Loss: 0.022522\n",
      "Epoch: 52/100... Step: 5385... Loss: 0.035057... Val Loss: 0.017952\n",
      "Epoch: 52/100... Step: 5386... Loss: 0.028773... Val Loss: 0.013113\n",
      "Epoch: 52/100... Step: 5387... Loss: 0.012292... Val Loss: 0.012953\n",
      "Epoch: 52/100... Step: 5388... Loss: 0.018574... Val Loss: 0.013034\n",
      "Epoch: 52/100... Step: 5389... Loss: 0.012557... Val Loss: 0.013538\n",
      "Epoch: 52/100... Step: 5390... Loss: 0.016622... Val Loss: 0.012145\n",
      "Epoch: 52/100... Step: 5391... Loss: 0.022730... Val Loss: 0.021517\n",
      "Epoch: 52/100... Step: 5392... Loss: 0.022997... Val Loss: 0.042368\n",
      "Epoch: 52/100... Step: 5393... Loss: 0.017247... Val Loss: 0.066978\n",
      "Epoch: 52/100... Step: 5394... Loss: 0.023917... Val Loss: 0.079536\n",
      "Epoch: 52/100... Step: 5395... Loss: 0.020190... Val Loss: 0.084563\n",
      "Epoch: 52/100... Step: 5396... Loss: 0.018722... Val Loss: 0.089482\n",
      "Epoch: 52/100... Step: 5397... Loss: 0.016179... Val Loss: 0.080673\n",
      "Epoch: 52/100... Step: 5398... Loss: 0.020843... Val Loss: 0.075972\n",
      "Epoch: 52/100... Step: 5399... Loss: 0.017204... Val Loss: 0.077014\n",
      "Epoch: 52/100... Step: 5400... Loss: 0.026126... Val Loss: 0.078092\n",
      "Epoch: 52/100... Step: 5401... Loss: 0.016002... Val Loss: 0.066166\n",
      "Epoch: 52/100... Step: 5402... Loss: 0.019335... Val Loss: 0.057170\n",
      "Epoch: 52/100... Step: 5403... Loss: 0.012741... Val Loss: 0.052468\n",
      "Epoch: 52/100... Step: 5404... Loss: 0.022201... Val Loss: 0.045511\n",
      "Epoch: 52/100... Step: 5405... Loss: 0.026069... Val Loss: 0.042630\n",
      "Epoch: 52/100... Step: 5406... Loss: 0.020294... Val Loss: 0.047460\n",
      "Epoch: 52/100... Step: 5407... Loss: 0.015712... Val Loss: 0.063704\n",
      "Epoch: 52/100... Step: 5408... Loss: 0.015596... Val Loss: 0.070178\n",
      "Epoch: 53/100... Step: 5409... Loss: 0.018926... Val Loss: 0.038225\n",
      "Epoch: 53/100... Step: 5410... Loss: 0.014876... Val Loss: 0.081084\n",
      "Epoch: 53/100... Step: 5411... Loss: 0.017501... Val Loss: 0.094485\n",
      "Epoch: 53/100... Step: 5412... Loss: 0.020101... Val Loss: 0.104734\n",
      "Epoch: 53/100... Step: 5413... Loss: 0.026798... Val Loss: 0.147600\n",
      "Epoch: 53/100... Step: 5414... Loss: 0.027167... Val Loss: 0.160209\n",
      "Epoch: 53/100... Step: 5415... Loss: 0.016160... Val Loss: 0.167857\n",
      "Epoch: 53/100... Step: 5416... Loss: 0.017059... Val Loss: 0.179515\n",
      "Epoch: 53/100... Step: 5417... Loss: 0.020193... Val Loss: 0.197788\n",
      "Epoch: 53/100... Step: 5418... Loss: 0.024235... Val Loss: 0.203196\n",
      "Epoch: 53/100... Step: 5419... Loss: 0.017931... Val Loss: 0.181325\n",
      "Epoch: 53/100... Step: 5420... Loss: 0.016695... Val Loss: 0.170559\n",
      "Epoch: 53/100... Step: 5421... Loss: 0.026728... Val Loss: 0.176607\n",
      "Epoch: 53/100... Step: 5422... Loss: 0.016302... Val Loss: 0.152281\n",
      "Epoch: 53/100... Step: 5423... Loss: 0.024894... Val Loss: 0.139902\n",
      "Epoch: 53/100... Step: 5424... Loss: 0.014607... Val Loss: 0.133018\n",
      "Epoch: 53/100... Step: 5425... Loss: 0.019667... Val Loss: 0.119850\n",
      "Epoch: 53/100... Step: 5426... Loss: 0.023007... Val Loss: 0.099506\n",
      "Epoch: 53/100... Step: 5427... Loss: 0.025170... Val Loss: 0.083368\n",
      "Epoch: 53/100... Step: 5428... Loss: 0.013928... Val Loss: 0.079104\n",
      "Epoch: 53/100... Step: 5429... Loss: 0.015537... Val Loss: 0.082933\n",
      "Epoch: 53/100... Step: 5430... Loss: 0.013281... Val Loss: 0.081383\n",
      "Epoch: 53/100... Step: 5431... Loss: 0.015333... Val Loss: 0.077148\n",
      "Epoch: 53/100... Step: 5432... Loss: 0.019598... Val Loss: 0.071826\n",
      "Epoch: 53/100... Step: 5433... Loss: 0.024363... Val Loss: 0.063994\n",
      "Epoch: 53/100... Step: 5434... Loss: 0.015978... Val Loss: 0.061366\n",
      "Epoch: 53/100... Step: 5435... Loss: 0.025324... Val Loss: 0.060593\n",
      "Epoch: 53/100... Step: 5436... Loss: 0.024585... Val Loss: 0.066862\n",
      "Epoch: 53/100... Step: 5437... Loss: 0.023371... Val Loss: 0.055868\n",
      "Epoch: 53/100... Step: 5438... Loss: 0.021869... Val Loss: 0.042567\n",
      "Epoch: 53/100... Step: 5439... Loss: 0.025055... Val Loss: 0.032722\n",
      "Epoch: 53/100... Step: 5440... Loss: 0.020095... Val Loss: 0.030586\n",
      "Epoch: 53/100... Step: 5441... Loss: 0.014655... Val Loss: 0.040615\n",
      "Epoch: 53/100... Step: 5442... Loss: 0.022056... Val Loss: 0.052288\n",
      "Epoch: 53/100... Step: 5443... Loss: 0.023323... Val Loss: 0.052454\n",
      "Epoch: 53/100... Step: 5444... Loss: 0.035586... Val Loss: 0.048892\n",
      "Epoch: 53/100... Step: 5445... Loss: 0.030080... Val Loss: 0.039145\n",
      "Epoch: 53/100... Step: 5446... Loss: 0.021597... Val Loss: 0.030606\n",
      "Epoch: 53/100... Step: 5447... Loss: 0.029009... Val Loss: 0.022589\n",
      "Epoch: 53/100... Step: 5448... Loss: 0.021192... Val Loss: 0.015338\n",
      "Epoch: 53/100... Step: 5449... Loss: 0.022251... Val Loss: 0.008797\n",
      "Epoch: 53/100... Step: 5450... Loss: 0.018758... Val Loss: 0.018353\n",
      "Epoch: 53/100... Step: 5451... Loss: 0.020379... Val Loss: 0.024336\n",
      "Epoch: 53/100... Step: 5452... Loss: 0.036572... Val Loss: 0.025701\n",
      "Epoch: 53/100... Step: 5453... Loss: 0.015766... Val Loss: 0.023578\n",
      "Epoch: 53/100... Step: 5454... Loss: 0.019220... Val Loss: 0.029996\n",
      "Epoch: 53/100... Step: 5455... Loss: 0.017708... Val Loss: 0.040158\n",
      "Epoch: 53/100... Step: 5456... Loss: 0.011289... Val Loss: 0.038903\n",
      "Epoch: 53/100... Step: 5457... Loss: 0.019330... Val Loss: 0.041269\n",
      "Epoch: 53/100... Step: 5458... Loss: 0.021964... Val Loss: 0.045910\n",
      "Epoch: 53/100... Step: 5459... Loss: 0.015577... Val Loss: 0.046844\n",
      "Epoch: 53/100... Step: 5460... Loss: 0.016543... Val Loss: 0.033209\n",
      "Epoch: 53/100... Step: 5461... Loss: 0.019607... Val Loss: 0.020487\n",
      "Epoch: 53/100... Step: 5462... Loss: 0.026310... Val Loss: 0.010920\n",
      "Epoch: 53/100... Step: 5463... Loss: 0.012518... Val Loss: 0.014630\n",
      "Epoch: 53/100... Step: 5464... Loss: 0.014246... Val Loss: 0.012446\n",
      "Epoch: 53/100... Step: 5465... Loss: 0.013165... Val Loss: 0.018904\n",
      "Epoch: 53/100... Step: 5466... Loss: 0.014465... Val Loss: 0.026044\n",
      "Epoch: 53/100... Step: 5467... Loss: 0.016896... Val Loss: 0.034092\n",
      "Epoch: 53/100... Step: 5468... Loss: 0.011883... Val Loss: 0.038893\n",
      "Epoch: 53/100... Step: 5469... Loss: 0.018453... Val Loss: 0.034546\n",
      "Epoch: 53/100... Step: 5470... Loss: 0.021690... Val Loss: 0.032052\n",
      "Epoch: 53/100... Step: 5471... Loss: 0.015681... Val Loss: 0.038020\n",
      "Epoch: 53/100... Step: 5472... Loss: 0.023530... Val Loss: 0.049748\n",
      "Epoch: 53/100... Step: 5473... Loss: 0.022475... Val Loss: 0.058840\n",
      "Epoch: 53/100... Step: 5474... Loss: 0.018635... Val Loss: 0.061633\n",
      "Epoch: 53/100... Step: 5475... Loss: 0.024730... Val Loss: 0.058645\n",
      "Epoch: 53/100... Step: 5476... Loss: 0.025954... Val Loss: 0.057427\n",
      "Epoch: 53/100... Step: 5477... Loss: 0.023796... Val Loss: 0.054444\n",
      "Epoch: 53/100... Step: 5478... Loss: 0.023784... Val Loss: 0.045054\n",
      "Epoch: 53/100... Step: 5479... Loss: 0.029974... Val Loss: 0.033931\n",
      "Epoch: 53/100... Step: 5480... Loss: 0.021115... Val Loss: 0.028596\n",
      "Epoch: 53/100... Step: 5481... Loss: 0.022743... Val Loss: 0.025286\n",
      "Epoch: 53/100... Step: 5482... Loss: 0.029923... Val Loss: 0.023961\n",
      "Epoch: 53/100... Step: 5483... Loss: 0.021827... Val Loss: 0.023688\n",
      "Epoch: 53/100... Step: 5484... Loss: 0.008784... Val Loss: 0.026095\n",
      "Epoch: 53/100... Step: 5485... Loss: 0.019143... Val Loss: 0.037618\n",
      "Epoch: 53/100... Step: 5486... Loss: 0.018610... Val Loss: 0.043717\n",
      "Epoch: 53/100... Step: 5487... Loss: 0.019697... Val Loss: 0.032257\n",
      "Epoch: 53/100... Step: 5488... Loss: 0.023953... Val Loss: 0.013045\n",
      "Epoch: 53/100... Step: 5489... Loss: 0.018888... Val Loss: 0.007440\n",
      "Epoch: 53/100... Step: 5490... Loss: 0.019220... Val Loss: 0.013988\n",
      "Epoch: 53/100... Step: 5491... Loss: 0.019231... Val Loss: 0.019527\n",
      "Epoch: 53/100... Step: 5492... Loss: 0.018018... Val Loss: 0.019050\n",
      "Epoch: 53/100... Step: 5493... Loss: 0.013257... Val Loss: 0.016329\n",
      "Epoch: 53/100... Step: 5494... Loss: 0.018496... Val Loss: 0.015692\n",
      "Epoch: 53/100... Step: 5495... Loss: 0.020174... Val Loss: 0.015110\n",
      "Epoch: 53/100... Step: 5496... Loss: 0.023763... Val Loss: 0.012694\n",
      "Epoch: 53/100... Step: 5497... Loss: 0.022052... Val Loss: 0.019098\n",
      "Epoch: 53/100... Step: 5498... Loss: 0.019688... Val Loss: 0.029145\n",
      "Epoch: 53/100... Step: 5499... Loss: 0.017568... Val Loss: 0.038868\n",
      "Epoch: 53/100... Step: 5500... Loss: 0.019051... Val Loss: 0.040904\n",
      "Epoch: 53/100... Step: 5501... Loss: 0.014168... Val Loss: 0.044080\n",
      "Epoch: 53/100... Step: 5502... Loss: 0.016954... Val Loss: 0.045201\n",
      "Epoch: 53/100... Step: 5503... Loss: 0.024280... Val Loss: 0.045784\n",
      "Epoch: 53/100... Step: 5504... Loss: 0.019927... Val Loss: 0.037415\n",
      "Epoch: 53/100... Step: 5505... Loss: 0.016364... Val Loss: 0.021767\n",
      "Epoch: 53/100... Step: 5506... Loss: 0.018962... Val Loss: 0.011530\n",
      "Epoch: 53/100... Step: 5507... Loss: 0.028210... Val Loss: 0.015773\n",
      "Epoch: 53/100... Step: 5508... Loss: 0.018957... Val Loss: 0.022710\n",
      "Epoch: 53/100... Step: 5509... Loss: 0.035184... Val Loss: 0.026038\n",
      "Epoch: 53/100... Step: 5510... Loss: 0.017277... Val Loss: 0.021814\n",
      "Epoch: 53/100... Step: 5511... Loss: 0.017603... Val Loss: 0.020221\n",
      "Epoch: 53/100... Step: 5512... Loss: 0.014923... Val Loss: 0.019886\n",
      "Epoch: 54/100... Step: 5513... Loss: 0.021890... Val Loss: 0.045787\n",
      "Epoch: 54/100... Step: 5514... Loss: 0.027775... Val Loss: 0.027373\n",
      "Epoch: 54/100... Step: 5515... Loss: 0.017460... Val Loss: 0.136319\n",
      "Epoch: 54/100... Step: 5516... Loss: 0.017615... Val Loss: 0.217088\n",
      "Epoch: 54/100... Step: 5517... Loss: 0.021784... Val Loss: 0.279830\n",
      "Epoch: 54/100... Step: 5518... Loss: 0.025063... Val Loss: 0.311335\n",
      "Epoch: 54/100... Step: 5519... Loss: 0.019135... Val Loss: 0.326817\n",
      "Epoch: 54/100... Step: 5520... Loss: 0.017058... Val Loss: 0.346244\n",
      "Epoch: 54/100... Step: 5521... Loss: 0.015089... Val Loss: 0.354404\n",
      "Epoch: 54/100... Step: 5522... Loss: 0.015739... Val Loss: 0.349706\n",
      "Epoch: 54/100... Step: 5523... Loss: 0.020559... Val Loss: 0.350445\n",
      "Epoch: 54/100... Step: 5524... Loss: 0.019853... Val Loss: 0.339061\n",
      "Epoch: 54/100... Step: 5525... Loss: 0.017313... Val Loss: 0.335346\n",
      "Epoch: 54/100... Step: 5526... Loss: 0.016580... Val Loss: 0.332777\n",
      "Epoch: 54/100... Step: 5527... Loss: 0.017504... Val Loss: 0.330342\n",
      "Epoch: 54/100... Step: 5528... Loss: 0.017934... Val Loss: 0.329980\n",
      "Epoch: 54/100... Step: 5529... Loss: 0.029661... Val Loss: 0.323438\n",
      "Epoch: 54/100... Step: 5530... Loss: 0.022365... Val Loss: 0.304232\n",
      "Epoch: 54/100... Step: 5531... Loss: 0.015140... Val Loss: 0.282732\n",
      "Epoch: 54/100... Step: 5532... Loss: 0.026697... Val Loss: 0.261862\n",
      "Epoch: 54/100... Step: 5533... Loss: 0.026770... Val Loss: 0.233538\n",
      "Epoch: 54/100... Step: 5534... Loss: 0.022397... Val Loss: 0.194099\n",
      "Epoch: 54/100... Step: 5535... Loss: 0.023770... Val Loss: 0.167222\n",
      "Epoch: 54/100... Step: 5536... Loss: 0.018180... Val Loss: 0.159258\n",
      "Epoch: 54/100... Step: 5537... Loss: 0.025796... Val Loss: 0.165165\n",
      "Epoch: 54/100... Step: 5538... Loss: 0.015812... Val Loss: 0.165317\n",
      "Epoch: 54/100... Step: 5539... Loss: 0.011500... Val Loss: 0.152210\n",
      "Epoch: 54/100... Step: 5540... Loss: 0.015241... Val Loss: 0.141846\n",
      "Epoch: 54/100... Step: 5541... Loss: 0.011537... Val Loss: 0.127083\n",
      "Epoch: 54/100... Step: 5542... Loss: 0.022533... Val Loss: 0.124415\n",
      "Epoch: 54/100... Step: 5543... Loss: 0.025667... Val Loss: 0.113415\n",
      "Epoch: 54/100... Step: 5544... Loss: 0.019299... Val Loss: 0.065107\n",
      "Epoch: 54/100... Step: 5545... Loss: 0.021115... Val Loss: 0.061197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Step: 5546... Loss: 0.020441... Val Loss: 0.051419\n",
      "Epoch: 54/100... Step: 5547... Loss: 0.021842... Val Loss: 0.020808\n",
      "Epoch: 54/100... Step: 5548... Loss: 0.024204... Val Loss: 0.012181\n",
      "Epoch: 54/100... Step: 5549... Loss: 0.016851... Val Loss: 0.015010\n",
      "Epoch: 54/100... Step: 5550... Loss: 0.018926... Val Loss: 0.020773\n",
      "Epoch: 54/100... Step: 5551... Loss: 0.017655... Val Loss: 0.026895\n",
      "Epoch: 54/100... Step: 5552... Loss: 0.020455... Val Loss: 0.038274\n",
      "Epoch: 54/100... Step: 5553... Loss: 0.025269... Val Loss: 0.047913\n",
      "Epoch: 54/100... Step: 5554... Loss: 0.021325... Val Loss: 0.054657\n",
      "Epoch: 54/100... Step: 5555... Loss: 0.029498... Val Loss: 0.058250\n",
      "Epoch: 54/100... Step: 5556... Loss: 0.023523... Val Loss: 0.057781\n",
      "Epoch: 54/100... Step: 5557... Loss: 0.021960... Val Loss: 0.052312\n",
      "Epoch: 54/100... Step: 5558... Loss: 0.015094... Val Loss: 0.040053\n",
      "Epoch: 54/100... Step: 5559... Loss: 0.024561... Val Loss: 0.019076\n",
      "Epoch: 54/100... Step: 5560... Loss: 0.022300... Val Loss: 0.017141\n",
      "Epoch: 54/100... Step: 5561... Loss: 0.016817... Val Loss: 0.014690\n",
      "Epoch: 54/100... Step: 5562... Loss: 0.018038... Val Loss: 0.016584\n",
      "Epoch: 54/100... Step: 5563... Loss: 0.020716... Val Loss: 0.021150\n",
      "Epoch: 54/100... Step: 5564... Loss: 0.013126... Val Loss: 0.023668\n",
      "Epoch: 54/100... Step: 5565... Loss: 0.019118... Val Loss: 0.023269\n",
      "Epoch: 54/100... Step: 5566... Loss: 0.017772... Val Loss: 0.021754\n",
      "Epoch: 54/100... Step: 5567... Loss: 0.017747... Val Loss: 0.016629\n",
      "Epoch: 54/100... Step: 5568... Loss: 0.026624... Val Loss: 0.016824\n",
      "Epoch: 54/100... Step: 5569... Loss: 0.025496... Val Loss: 0.020928\n",
      "Epoch: 54/100... Step: 5570... Loss: 0.014903... Val Loss: 0.023475\n",
      "Epoch: 54/100... Step: 5571... Loss: 0.017399... Val Loss: 0.031556\n",
      "Epoch: 54/100... Step: 5572... Loss: 0.025793... Val Loss: 0.046515\n",
      "Epoch: 54/100... Step: 5573... Loss: 0.010292... Val Loss: 0.058942\n",
      "Epoch: 54/100... Step: 5574... Loss: 0.016687... Val Loss: 0.084891\n",
      "Epoch: 54/100... Step: 5575... Loss: 0.015262... Val Loss: 0.101889\n",
      "Epoch: 54/100... Step: 5576... Loss: 0.015297... Val Loss: 0.108327\n",
      "Epoch: 54/100... Step: 5577... Loss: 0.016690... Val Loss: 0.107230\n",
      "Epoch: 54/100... Step: 5578... Loss: 0.012877... Val Loss: 0.102583\n",
      "Epoch: 54/100... Step: 5579... Loss: 0.022094... Val Loss: 0.098886\n",
      "Epoch: 54/100... Step: 5580... Loss: 0.025239... Val Loss: 0.100974\n",
      "Epoch: 54/100... Step: 5581... Loss: 0.017266... Val Loss: 0.095760\n",
      "Epoch: 54/100... Step: 5582... Loss: 0.015998... Val Loss: 0.092001\n",
      "Epoch: 54/100... Step: 5583... Loss: 0.017049... Val Loss: 0.094939\n",
      "Epoch: 54/100... Step: 5584... Loss: 0.021745... Val Loss: 0.093003\n",
      "Epoch: 54/100... Step: 5585... Loss: 0.019653... Val Loss: 0.082379\n",
      "Epoch: 54/100... Step: 5586... Loss: 0.023671... Val Loss: 0.074314\n",
      "Epoch: 54/100... Step: 5587... Loss: 0.017851... Val Loss: 0.069537\n",
      "Epoch: 54/100... Step: 5588... Loss: 0.020792... Val Loss: 0.072244\n",
      "Epoch: 54/100... Step: 5589... Loss: 0.031073... Val Loss: 0.060472\n",
      "Epoch: 54/100... Step: 5590... Loss: 0.022150... Val Loss: 0.055363\n",
      "Epoch: 54/100... Step: 5591... Loss: 0.011126... Val Loss: 0.045886\n",
      "Epoch: 54/100... Step: 5592... Loss: 0.015093... Val Loss: 0.037979\n",
      "Epoch: 54/100... Step: 5593... Loss: 0.017639... Val Loss: 0.023930\n",
      "Epoch: 54/100... Step: 5594... Loss: 0.026826... Val Loss: 0.012230\n",
      "Epoch: 54/100... Step: 5595... Loss: 0.012182... Val Loss: 0.012167\n",
      "Epoch: 54/100... Step: 5596... Loss: 0.019100... Val Loss: 0.014166\n",
      "Epoch: 54/100... Step: 5597... Loss: 0.024592... Val Loss: 0.025175\n",
      "Epoch: 54/100... Step: 5598... Loss: 0.017225... Val Loss: 0.033328\n",
      "Epoch: 54/100... Step: 5599... Loss: 0.016174... Val Loss: 0.037542\n",
      "Epoch: 54/100... Step: 5600... Loss: 0.027263... Val Loss: 0.032462\n",
      "Epoch: 54/100... Step: 5601... Loss: 0.015285... Val Loss: 0.020228\n",
      "Epoch: 54/100... Step: 5602... Loss: 0.016635... Val Loss: 0.009705\n",
      "Epoch: 54/100... Step: 5603... Loss: 0.011347... Val Loss: 0.012951\n",
      "Epoch: 54/100... Step: 5604... Loss: 0.015360... Val Loss: 0.018026\n",
      "Epoch: 54/100... Step: 5605... Loss: 0.021090... Val Loss: 0.011058\n",
      "Epoch: 54/100... Step: 5606... Loss: 0.015945... Val Loss: 0.007425\n",
      "Epoch: 54/100... Step: 5607... Loss: 0.019428... Val Loss: 0.010190\n",
      "Epoch: 54/100... Step: 5608... Loss: 0.023623... Val Loss: 0.012511\n",
      "Epoch: 54/100... Step: 5609... Loss: 0.017734... Val Loss: 0.012697\n",
      "Epoch: 54/100... Step: 5610... Loss: 0.019647... Val Loss: 0.014985\n",
      "Epoch: 54/100... Step: 5611... Loss: 0.024648... Val Loss: 0.012331\n",
      "Epoch: 54/100... Step: 5612... Loss: 0.019896... Val Loss: 0.008742\n",
      "Epoch: 54/100... Step: 5613... Loss: 0.016442... Val Loss: 0.006847\n",
      "Epoch: 54/100... Step: 5614... Loss: 0.014397... Val Loss: 0.008005\n",
      "Epoch: 54/100... Step: 5615... Loss: 0.018612... Val Loss: 0.009911\n",
      "Epoch: 54/100... Step: 5616... Loss: 0.014885... Val Loss: 0.022810\n",
      "Epoch: 55/100... Step: 5617... Loss: 0.024726... Val Loss: 0.029234\n",
      "Epoch: 55/100... Step: 5618... Loss: 0.021036... Val Loss: 0.051462\n",
      "Epoch: 55/100... Step: 5619... Loss: 0.016893... Val Loss: 0.164099\n",
      "Epoch: 55/100... Step: 5620... Loss: 0.009555... Val Loss: 0.242183\n",
      "Epoch: 55/100... Step: 5621... Loss: 0.012309... Val Loss: 0.293695\n",
      "Epoch: 55/100... Step: 5622... Loss: 0.019950... Val Loss: 0.306137\n",
      "Epoch: 55/100... Step: 5623... Loss: 0.018655... Val Loss: 0.334732\n",
      "Epoch: 55/100... Step: 5624... Loss: 0.019773... Val Loss: 0.308622\n",
      "Epoch: 55/100... Step: 5625... Loss: 0.017174... Val Loss: 0.344823\n",
      "Epoch: 55/100... Step: 5626... Loss: 0.017026... Val Loss: 0.341380\n",
      "Epoch: 55/100... Step: 5627... Loss: 0.010336... Val Loss: 0.312993\n",
      "Epoch: 55/100... Step: 5628... Loss: 0.014692... Val Loss: 0.296774\n",
      "Epoch: 55/100... Step: 5629... Loss: 0.015207... Val Loss: 0.295264\n",
      "Epoch: 55/100... Step: 5630... Loss: 0.022818... Val Loss: 0.297586\n",
      "Epoch: 55/100... Step: 5631... Loss: 0.014070... Val Loss: 0.302676\n",
      "Epoch: 55/100... Step: 5632... Loss: 0.019029... Val Loss: 0.308608\n",
      "Epoch: 55/100... Step: 5633... Loss: 0.024241... Val Loss: 0.322028\n",
      "Epoch: 55/100... Step: 5634... Loss: 0.030965... Val Loss: 0.322643\n",
      "Epoch: 55/100... Step: 5635... Loss: 0.021823... Val Loss: 0.322596\n",
      "Epoch: 55/100... Step: 5636... Loss: 0.010788... Val Loss: 0.321767\n",
      "Epoch: 55/100... Step: 5637... Loss: 0.018446... Val Loss: 0.316057\n",
      "Epoch: 55/100... Step: 5638... Loss: 0.016454... Val Loss: 0.305485\n",
      "Epoch: 55/100... Step: 5639... Loss: 0.026508... Val Loss: 0.263831\n",
      "Epoch: 55/100... Step: 5640... Loss: 0.017497... Val Loss: 0.233506\n",
      "Epoch: 55/100... Step: 5641... Loss: 0.016926... Val Loss: 0.243212\n",
      "Epoch: 55/100... Step: 5642... Loss: 0.017221... Val Loss: 0.216285\n",
      "Epoch: 55/100... Step: 5643... Loss: 0.016061... Val Loss: 0.176021\n",
      "Epoch: 55/100... Step: 5644... Loss: 0.020918... Val Loss: 0.139695\n",
      "Epoch: 55/100... Step: 5645... Loss: 0.016927... Val Loss: 0.131969\n",
      "Epoch: 55/100... Step: 5646... Loss: 0.034088... Val Loss: 0.130741\n",
      "Epoch: 55/100... Step: 5647... Loss: 0.015426... Val Loss: 0.126806\n",
      "Epoch: 55/100... Step: 5648... Loss: 0.009946... Val Loss: 0.116756\n",
      "Epoch: 55/100... Step: 5649... Loss: 0.022775... Val Loss: 0.110869\n",
      "Epoch: 55/100... Step: 5650... Loss: 0.022051... Val Loss: 0.112007\n",
      "Epoch: 55/100... Step: 5651... Loss: 0.022730... Val Loss: 0.111777\n",
      "Epoch: 55/100... Step: 5652... Loss: 0.018653... Val Loss: 0.111273\n",
      "Epoch: 55/100... Step: 5653... Loss: 0.021962... Val Loss: 0.120476\n",
      "Epoch: 55/100... Step: 5654... Loss: 0.025043... Val Loss: 0.123099\n",
      "Epoch: 55/100... Step: 5655... Loss: 0.017935... Val Loss: 0.123046\n",
      "Epoch: 55/100... Step: 5656... Loss: 0.017840... Val Loss: 0.103074\n",
      "Epoch: 55/100... Step: 5657... Loss: 0.022663... Val Loss: 0.100741\n",
      "Epoch: 55/100... Step: 5658... Loss: 0.019280... Val Loss: 0.099528\n",
      "Epoch: 55/100... Step: 5659... Loss: 0.022245... Val Loss: 0.106277\n",
      "Epoch: 55/100... Step: 5660... Loss: 0.017087... Val Loss: 0.097227\n",
      "Epoch: 55/100... Step: 5661... Loss: 0.014814... Val Loss: 0.093371\n",
      "Epoch: 55/100... Step: 5662... Loss: 0.015357... Val Loss: 0.093145\n",
      "Epoch: 55/100... Step: 5663... Loss: 0.017285... Val Loss: 0.086717\n",
      "Epoch: 55/100... Step: 5664... Loss: 0.015337... Val Loss: 0.070369\n",
      "Epoch: 55/100... Step: 5665... Loss: 0.019056... Val Loss: 0.055877\n",
      "Epoch: 55/100... Step: 5666... Loss: 0.014291... Val Loss: 0.049943\n",
      "Epoch: 55/100... Step: 5667... Loss: 0.011592... Val Loss: 0.035561\n",
      "Epoch: 55/100... Step: 5668... Loss: 0.016122... Val Loss: 0.026932\n",
      "Epoch: 55/100... Step: 5669... Loss: 0.017912... Val Loss: 0.023301\n",
      "Epoch: 55/100... Step: 5670... Loss: 0.008814... Val Loss: 0.021906\n",
      "Epoch: 55/100... Step: 5671... Loss: 0.015383... Val Loss: 0.033419\n",
      "Epoch: 55/100... Step: 5672... Loss: 0.011962... Val Loss: 0.053492\n",
      "Epoch: 55/100... Step: 5673... Loss: 0.015792... Val Loss: 0.074215\n",
      "Epoch: 55/100... Step: 5674... Loss: 0.013530... Val Loss: 0.090183\n",
      "Epoch: 55/100... Step: 5675... Loss: 0.015108... Val Loss: 0.100672\n",
      "Epoch: 55/100... Step: 5676... Loss: 0.015285... Val Loss: 0.099714\n",
      "Epoch: 55/100... Step: 5677... Loss: 0.026641... Val Loss: 0.095633\n",
      "Epoch: 55/100... Step: 5678... Loss: 0.023041... Val Loss: 0.089847\n",
      "Epoch: 55/100... Step: 5679... Loss: 0.026748... Val Loss: 0.072792\n",
      "Epoch: 55/100... Step: 5680... Loss: 0.018000... Val Loss: 0.058472\n",
      "Epoch: 55/100... Step: 5681... Loss: 0.015672... Val Loss: 0.047926\n",
      "Epoch: 55/100... Step: 5682... Loss: 0.025627... Val Loss: 0.032831\n",
      "Epoch: 55/100... Step: 5683... Loss: 0.017851... Val Loss: 0.022382\n",
      "Epoch: 55/100... Step: 5684... Loss: 0.018621... Val Loss: 0.020847\n",
      "Epoch: 55/100... Step: 5685... Loss: 0.012438... Val Loss: 0.022501\n",
      "Epoch: 55/100... Step: 5686... Loss: 0.020247... Val Loss: 0.018829\n",
      "Epoch: 55/100... Step: 5687... Loss: 0.019686... Val Loss: 0.009018\n",
      "Epoch: 55/100... Step: 5688... Loss: 0.013857... Val Loss: 0.019998\n",
      "Epoch: 55/100... Step: 5689... Loss: 0.015492... Val Loss: 0.023771\n",
      "Epoch: 55/100... Step: 5690... Loss: 0.012949... Val Loss: 0.026082\n",
      "Epoch: 55/100... Step: 5691... Loss: 0.019785... Val Loss: 0.024719\n",
      "Epoch: 55/100... Step: 5692... Loss: 0.015358... Val Loss: 0.023895\n",
      "Epoch: 55/100... Step: 5693... Loss: 0.024942... Val Loss: 0.028712\n",
      "Epoch: 55/100... Step: 5694... Loss: 0.028078... Val Loss: 0.041624\n",
      "Epoch: 55/100... Step: 5695... Loss: 0.025761... Val Loss: 0.061175\n",
      "Epoch: 55/100... Step: 5696... Loss: 0.012660... Val Loss: 0.082341\n",
      "Epoch: 55/100... Step: 5697... Loss: 0.026694... Val Loss: 0.107243\n",
      "Epoch: 55/100... Step: 5698... Loss: 0.015509... Val Loss: 0.114931\n",
      "Epoch: 55/100... Step: 5699... Loss: 0.014824... Val Loss: 0.128165\n",
      "Epoch: 55/100... Step: 5700... Loss: 0.019154... Val Loss: 0.106504\n",
      "Epoch: 55/100... Step: 5701... Loss: 0.030199... Val Loss: 0.082704\n",
      "Epoch: 55/100... Step: 5702... Loss: 0.022462... Val Loss: 0.067198\n",
      "Epoch: 55/100... Step: 5703... Loss: 0.026570... Val Loss: 0.051990\n",
      "Epoch: 55/100... Step: 5704... Loss: 0.015049... Val Loss: 0.041677\n",
      "Epoch: 55/100... Step: 5705... Loss: 0.021154... Val Loss: 0.024955\n",
      "Epoch: 55/100... Step: 5706... Loss: 0.021280... Val Loss: 0.011091\n",
      "Epoch: 55/100... Step: 5707... Loss: 0.013160... Val Loss: 0.018444\n",
      "Epoch: 55/100... Step: 5708... Loss: 0.018410... Val Loss: 0.035142\n",
      "Epoch: 55/100... Step: 5709... Loss: 0.013233... Val Loss: 0.038560\n",
      "Epoch: 55/100... Step: 5710... Loss: 0.018985... Val Loss: 0.035682\n",
      "Epoch: 55/100... Step: 5711... Loss: 0.026475... Val Loss: 0.025008\n",
      "Epoch: 55/100... Step: 5712... Loss: 0.017545... Val Loss: 0.017038\n",
      "Epoch: 55/100... Step: 5713... Loss: 0.013022... Val Loss: 0.011936\n",
      "Epoch: 55/100... Step: 5714... Loss: 0.032405... Val Loss: 0.006562\n",
      "Epoch: 55/100... Step: 5715... Loss: 0.016912... Val Loss: 0.007381\n",
      "Epoch: 55/100... Step: 5716... Loss: 0.018660... Val Loss: 0.014101\n",
      "Epoch: 55/100... Step: 5717... Loss: 0.007730... Val Loss: 0.021964\n",
      "Epoch: 55/100... Step: 5718... Loss: 0.015300... Val Loss: 0.028955\n",
      "Epoch: 55/100... Step: 5719... Loss: 0.015762... Val Loss: 0.027708\n",
      "Epoch: 55/100... Step: 5720... Loss: 0.013831... Val Loss: 0.033987\n",
      "Epoch: 56/100... Step: 5721... Loss: 0.018080... Val Loss: 0.014870\n",
      "Epoch: 56/100... Step: 5722... Loss: 0.016353... Val Loss: 0.092222\n",
      "Epoch: 56/100... Step: 5723... Loss: 0.015255... Val Loss: 0.167303\n",
      "Epoch: 56/100... Step: 5724... Loss: 0.025892... Val Loss: 0.178360\n",
      "Epoch: 56/100... Step: 5725... Loss: 0.020151... Val Loss: 0.170773\n",
      "Epoch: 56/100... Step: 5726... Loss: 0.017727... Val Loss: 0.165283\n",
      "Epoch: 56/100... Step: 5727... Loss: 0.016232... Val Loss: 0.161013\n",
      "Epoch: 56/100... Step: 5728... Loss: 0.012315... Val Loss: 0.160384\n",
      "Epoch: 56/100... Step: 5729... Loss: 0.022032... Val Loss: 0.151123\n",
      "Epoch: 56/100... Step: 5730... Loss: 0.033150... Val Loss: 0.146571\n",
      "Epoch: 56/100... Step: 5731... Loss: 0.015618... Val Loss: 0.120990\n",
      "Epoch: 56/100... Step: 5732... Loss: 0.013572... Val Loss: 0.112831\n",
      "Epoch: 56/100... Step: 5733... Loss: 0.014504... Val Loss: 0.101663\n",
      "Epoch: 56/100... Step: 5734... Loss: 0.007964... Val Loss: 0.078484\n",
      "Epoch: 56/100... Step: 5735... Loss: 0.018135... Val Loss: 0.071178\n",
      "Epoch: 56/100... Step: 5736... Loss: 0.014402... Val Loss: 0.072274\n",
      "Epoch: 56/100... Step: 5737... Loss: 0.016206... Val Loss: 0.076868\n",
      "Epoch: 56/100... Step: 5738... Loss: 0.012650... Val Loss: 0.083150\n",
      "Epoch: 56/100... Step: 5739... Loss: 0.016215... Val Loss: 0.076614\n",
      "Epoch: 56/100... Step: 5740... Loss: 0.014182... Val Loss: 0.065330\n",
      "Epoch: 56/100... Step: 5741... Loss: 0.015868... Val Loss: 0.049220\n",
      "Epoch: 56/100... Step: 5742... Loss: 0.010263... Val Loss: 0.037086\n",
      "Epoch: 56/100... Step: 5743... Loss: 0.017305... Val Loss: 0.022534\n",
      "Epoch: 56/100... Step: 5744... Loss: 0.019150... Val Loss: 0.014848\n",
      "Epoch: 56/100... Step: 5745... Loss: 0.017986... Val Loss: 0.010840\n",
      "Epoch: 56/100... Step: 5746... Loss: 0.015925... Val Loss: 0.016021\n",
      "Epoch: 56/100... Step: 5747... Loss: 0.023202... Val Loss: 0.025292\n",
      "Epoch: 56/100... Step: 5748... Loss: 0.014226... Val Loss: 0.029201\n",
      "Epoch: 56/100... Step: 5749... Loss: 0.019224... Val Loss: 0.012915\n",
      "Epoch: 56/100... Step: 5750... Loss: 0.021830... Val Loss: 0.012999\n",
      "Epoch: 56/100... Step: 5751... Loss: 0.018292... Val Loss: 0.011386\n",
      "Epoch: 56/100... Step: 5752... Loss: 0.025751... Val Loss: 0.010297\n",
      "Epoch: 56/100... Step: 5753... Loss: 0.019044... Val Loss: 0.013812\n",
      "Epoch: 56/100... Step: 5754... Loss: 0.009063... Val Loss: 0.023348\n",
      "Epoch: 56/100... Step: 5755... Loss: 0.014399... Val Loss: 0.023767\n",
      "Epoch: 56/100... Step: 5756... Loss: 0.021577... Val Loss: 0.024569\n",
      "Epoch: 56/100... Step: 5757... Loss: 0.024465... Val Loss: 0.022362\n",
      "Epoch: 56/100... Step: 5758... Loss: 0.018552... Val Loss: 0.026121\n",
      "Epoch: 56/100... Step: 5759... Loss: 0.010725... Val Loss: 0.032354\n",
      "Epoch: 56/100... Step: 5760... Loss: 0.012876... Val Loss: 0.019069\n",
      "Epoch: 56/100... Step: 5761... Loss: 0.019111... Val Loss: 0.018015\n",
      "Epoch: 56/100... Step: 5762... Loss: 0.031347... Val Loss: 0.023488\n",
      "Epoch: 56/100... Step: 5763... Loss: 0.025698... Val Loss: 0.030620\n",
      "Epoch: 56/100... Step: 5764... Loss: 0.023419... Val Loss: 0.034062\n",
      "Epoch: 56/100... Step: 5765... Loss: 0.018151... Val Loss: 0.039721\n",
      "Epoch: 56/100... Step: 5766... Loss: 0.012534... Val Loss: 0.047940\n",
      "Epoch: 56/100... Step: 5767... Loss: 0.028701... Val Loss: 0.057606\n",
      "Epoch: 56/100... Step: 5768... Loss: 0.026937... Val Loss: 0.059224\n",
      "Epoch: 56/100... Step: 5769... Loss: 0.026695... Val Loss: 0.051306\n",
      "Epoch: 56/100... Step: 5770... Loss: 0.034208... Val Loss: 0.039154\n",
      "Epoch: 56/100... Step: 5771... Loss: 0.011989... Val Loss: 0.014270\n",
      "Epoch: 56/100... Step: 5772... Loss: 0.013159... Val Loss: 0.010150\n",
      "Epoch: 56/100... Step: 5773... Loss: 0.012075... Val Loss: 0.023620\n",
      "Epoch: 56/100... Step: 5774... Loss: 0.020024... Val Loss: 0.031742\n",
      "Epoch: 56/100... Step: 5775... Loss: 0.026916... Val Loss: 0.034988\n",
      "Epoch: 56/100... Step: 5776... Loss: 0.023732... Val Loss: 0.036061\n",
      "Epoch: 56/100... Step: 5777... Loss: 0.021008... Val Loss: 0.031388\n",
      "Epoch: 56/100... Step: 5778... Loss: 0.029119... Val Loss: 0.023999\n",
      "Epoch: 56/100... Step: 5779... Loss: 0.014788... Val Loss: 0.020807\n",
      "Epoch: 56/100... Step: 5780... Loss: 0.014515... Val Loss: 0.021866\n",
      "Epoch: 56/100... Step: 5781... Loss: 0.022936... Val Loss: 0.020882\n",
      "Epoch: 56/100... Step: 5782... Loss: 0.021321... Val Loss: 0.022726\n",
      "Epoch: 56/100... Step: 5783... Loss: 0.028737... Val Loss: 0.030418\n",
      "Epoch: 56/100... Step: 5784... Loss: 0.020910... Val Loss: 0.047193\n",
      "Epoch: 56/100... Step: 5785... Loss: 0.015492... Val Loss: 0.056451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Step: 5786... Loss: 0.018786... Val Loss: 0.061389\n",
      "Epoch: 56/100... Step: 5787... Loss: 0.019752... Val Loss: 0.051462\n",
      "Epoch: 56/100... Step: 5788... Loss: 0.024742... Val Loss: 0.037066\n",
      "Epoch: 56/100... Step: 5789... Loss: 0.016992... Val Loss: 0.027383\n",
      "Epoch: 56/100... Step: 5790... Loss: 0.019574... Val Loss: 0.015578\n",
      "Epoch: 56/100... Step: 5791... Loss: 0.016490... Val Loss: 0.010154\n",
      "Epoch: 56/100... Step: 5792... Loss: 0.013814... Val Loss: 0.007859\n",
      "Epoch: 56/100... Step: 5793... Loss: 0.019767... Val Loss: 0.008121\n",
      "Epoch: 56/100... Step: 5794... Loss: 0.016955... Val Loss: 0.008202\n",
      "Epoch: 56/100... Step: 5795... Loss: 0.016679... Val Loss: 0.013046\n",
      "Epoch: 56/100... Step: 5796... Loss: 0.017327... Val Loss: 0.027465\n",
      "Epoch: 56/100... Step: 5797... Loss: 0.015606... Val Loss: 0.044063\n",
      "Epoch: 56/100... Step: 5798... Loss: 0.009326... Val Loss: 0.053741\n",
      "Epoch: 56/100... Step: 5799... Loss: 0.014347... Val Loss: 0.066258\n",
      "Epoch: 56/100... Step: 5800... Loss: 0.010431... Val Loss: 0.069456\n",
      "Epoch: 56/100... Step: 5801... Loss: 0.029228... Val Loss: 0.061293\n",
      "Epoch: 56/100... Step: 5802... Loss: 0.018453... Val Loss: 0.071517\n",
      "Epoch: 56/100... Step: 5803... Loss: 0.017223... Val Loss: 0.082713\n",
      "Epoch: 56/100... Step: 5804... Loss: 0.014480... Val Loss: 0.082926\n",
      "Epoch: 56/100... Step: 5805... Loss: 0.025028... Val Loss: 0.072079\n",
      "Epoch: 56/100... Step: 5806... Loss: 0.012380... Val Loss: 0.053989\n",
      "Epoch: 56/100... Step: 5807... Loss: 0.019593... Val Loss: 0.045947\n",
      "Epoch: 56/100... Step: 5808... Loss: 0.017723... Val Loss: 0.031984\n",
      "Epoch: 56/100... Step: 5809... Loss: 0.020339... Val Loss: 0.025718\n",
      "Epoch: 56/100... Step: 5810... Loss: 0.018218... Val Loss: 0.015176\n",
      "Epoch: 56/100... Step: 5811... Loss: 0.019584... Val Loss: 0.015495\n",
      "Epoch: 56/100... Step: 5812... Loss: 0.024929... Val Loss: 0.020865\n",
      "Epoch: 56/100... Step: 5813... Loss: 0.017635... Val Loss: 0.028120\n",
      "Epoch: 56/100... Step: 5814... Loss: 0.019109... Val Loss: 0.026239\n",
      "Epoch: 56/100... Step: 5815... Loss: 0.013538... Val Loss: 0.017184\n",
      "Epoch: 56/100... Step: 5816... Loss: 0.026690... Val Loss: 0.013675\n",
      "Epoch: 56/100... Step: 5817... Loss: 0.017461... Val Loss: 0.015581\n",
      "Epoch: 56/100... Step: 5818... Loss: 0.012689... Val Loss: 0.013701\n",
      "Epoch: 56/100... Step: 5819... Loss: 0.016676... Val Loss: 0.014057\n",
      "Epoch: 56/100... Step: 5820... Loss: 0.008888... Val Loss: 0.013236\n",
      "Epoch: 56/100... Step: 5821... Loss: 0.017560... Val Loss: 0.012763\n",
      "Epoch: 56/100... Step: 5822... Loss: 0.021636... Val Loss: 0.011727\n",
      "Epoch: 56/100... Step: 5823... Loss: 0.021913... Val Loss: 0.010422\n",
      "Epoch: 56/100... Step: 5824... Loss: 0.019048... Val Loss: 0.012280\n",
      "Epoch: 57/100... Step: 5825... Loss: 0.012469... Val Loss: 0.067603\n",
      "Epoch: 57/100... Step: 5826... Loss: 0.015860... Val Loss: 0.010564\n",
      "Epoch: 57/100... Step: 5827... Loss: 0.015459... Val Loss: 0.094290\n",
      "Epoch: 57/100... Step: 5828... Loss: 0.011701... Val Loss: 0.162180\n",
      "Epoch: 57/100... Step: 5829... Loss: 0.015256... Val Loss: 0.200057\n",
      "Epoch: 57/100... Step: 5830... Loss: 0.027574... Val Loss: 0.216967\n",
      "Epoch: 57/100... Step: 5831... Loss: 0.024606... Val Loss: 0.223119\n",
      "Epoch: 57/100... Step: 5832... Loss: 0.015195... Val Loss: 0.228097\n",
      "Epoch: 57/100... Step: 5833... Loss: 0.014396... Val Loss: 0.207604\n",
      "Epoch: 57/100... Step: 5834... Loss: 0.016823... Val Loss: 0.216407\n",
      "Epoch: 57/100... Step: 5835... Loss: 0.017380... Val Loss: 0.243948\n",
      "Epoch: 57/100... Step: 5836... Loss: 0.011393... Val Loss: 0.257981\n",
      "Epoch: 57/100... Step: 5837... Loss: 0.017878... Val Loss: 0.263916\n",
      "Epoch: 57/100... Step: 5838... Loss: 0.012528... Val Loss: 0.263373\n",
      "Epoch: 57/100... Step: 5839... Loss: 0.015773... Val Loss: 0.261639\n",
      "Epoch: 57/100... Step: 5840... Loss: 0.023880... Val Loss: 0.259349\n",
      "Epoch: 57/100... Step: 5841... Loss: 0.011440... Val Loss: 0.261318\n",
      "Epoch: 57/100... Step: 5842... Loss: 0.021631... Val Loss: 0.273579\n",
      "Epoch: 57/100... Step: 5843... Loss: 0.013280... Val Loss: 0.268885\n",
      "Epoch: 57/100... Step: 5844... Loss: 0.021093... Val Loss: 0.259696\n",
      "Epoch: 57/100... Step: 5845... Loss: 0.023111... Val Loss: 0.259130\n",
      "Epoch: 57/100... Step: 5846... Loss: 0.018585... Val Loss: 0.254481\n",
      "Epoch: 57/100... Step: 5847... Loss: 0.019622... Val Loss: 0.217117\n",
      "Epoch: 57/100... Step: 5848... Loss: 0.010543... Val Loss: 0.167694\n",
      "Epoch: 57/100... Step: 5849... Loss: 0.013029... Val Loss: 0.149156\n",
      "Epoch: 57/100... Step: 5850... Loss: 0.018821... Val Loss: 0.193251\n",
      "Epoch: 57/100... Step: 5851... Loss: 0.016350... Val Loss: 0.190323\n",
      "Epoch: 57/100... Step: 5852... Loss: 0.018016... Val Loss: 0.184214\n",
      "Epoch: 57/100... Step: 5853... Loss: 0.020534... Val Loss: 0.176893\n",
      "Epoch: 57/100... Step: 5854... Loss: 0.012591... Val Loss: 0.176798\n",
      "Epoch: 57/100... Step: 5855... Loss: 0.017579... Val Loss: 0.174330\n",
      "Epoch: 57/100... Step: 5856... Loss: 0.018184... Val Loss: 0.176763\n",
      "Epoch: 57/100... Step: 5857... Loss: 0.023930... Val Loss: 0.173450\n",
      "Epoch: 57/100... Step: 5858... Loss: 0.028916... Val Loss: 0.161397\n",
      "Epoch: 57/100... Step: 5859... Loss: 0.027865... Val Loss: 0.149626\n",
      "Epoch: 57/100... Step: 5860... Loss: 0.015952... Val Loss: 0.127602\n",
      "Epoch: 57/100... Step: 5861... Loss: 0.018399... Val Loss: 0.108501\n",
      "Epoch: 57/100... Step: 5862... Loss: 0.016604... Val Loss: 0.090521\n",
      "Epoch: 57/100... Step: 5863... Loss: 0.018528... Val Loss: 0.078178\n",
      "Epoch: 57/100... Step: 5864... Loss: 0.013977... Val Loss: 0.060489\n",
      "Epoch: 57/100... Step: 5865... Loss: 0.021315... Val Loss: 0.052740\n",
      "Epoch: 57/100... Step: 5866... Loss: 0.026711... Val Loss: 0.035666\n",
      "Epoch: 57/100... Step: 5867... Loss: 0.011205... Val Loss: 0.026383\n",
      "Epoch: 57/100... Step: 5868... Loss: 0.022055... Val Loss: 0.025309\n",
      "Epoch: 57/100... Step: 5869... Loss: 0.020656... Val Loss: 0.034271\n",
      "Epoch: 57/100... Step: 5870... Loss: 0.020780... Val Loss: 0.036126\n",
      "Epoch: 57/100... Step: 5871... Loss: 0.010566... Val Loss: 0.041228\n",
      "Epoch: 57/100... Step: 5872... Loss: 0.027377... Val Loss: 0.044035\n",
      "Epoch: 57/100... Step: 5873... Loss: 0.026401... Val Loss: 0.037001\n",
      "Epoch: 57/100... Step: 5874... Loss: 0.015870... Val Loss: 0.027549\n",
      "Epoch: 57/100... Step: 5875... Loss: 0.018482... Val Loss: 0.027101\n",
      "Epoch: 57/100... Step: 5876... Loss: 0.010992... Val Loss: 0.025935\n",
      "Epoch: 57/100... Step: 5877... Loss: 0.019475... Val Loss: 0.033670\n",
      "Epoch: 57/100... Step: 5878... Loss: 0.018866... Val Loss: 0.033835\n",
      "Epoch: 57/100... Step: 5879... Loss: 0.020454... Val Loss: 0.032303\n",
      "Epoch: 57/100... Step: 5880... Loss: 0.012293... Val Loss: 0.048339\n",
      "Epoch: 57/100... Step: 5881... Loss: 0.019669... Val Loss: 0.061718\n",
      "Epoch: 57/100... Step: 5882... Loss: 0.016691... Val Loss: 0.070276\n",
      "Epoch: 57/100... Step: 5883... Loss: 0.015041... Val Loss: 0.068900\n",
      "Epoch: 57/100... Step: 5884... Loss: 0.018788... Val Loss: 0.066573\n",
      "Epoch: 57/100... Step: 5885... Loss: 0.020477... Val Loss: 0.042488\n",
      "Epoch: 57/100... Step: 5886... Loss: 0.016475... Val Loss: 0.027302\n",
      "Epoch: 57/100... Step: 5887... Loss: 0.018329... Val Loss: 0.034062\n",
      "Epoch: 57/100... Step: 5888... Loss: 0.014500... Val Loss: 0.036362\n",
      "Epoch: 57/100... Step: 5889... Loss: 0.013411... Val Loss: 0.058649\n",
      "Epoch: 57/100... Step: 5890... Loss: 0.017135... Val Loss: 0.069093\n",
      "Epoch: 57/100... Step: 5891... Loss: 0.020269... Val Loss: 0.051876\n",
      "Epoch: 57/100... Step: 5892... Loss: 0.020641... Val Loss: 0.047706\n",
      "Epoch: 57/100... Step: 5893... Loss: 0.011444... Val Loss: 0.043110\n",
      "Epoch: 57/100... Step: 5894... Loss: 0.015411... Val Loss: 0.037423\n",
      "Epoch: 57/100... Step: 5895... Loss: 0.019501... Val Loss: 0.037267\n",
      "Epoch: 57/100... Step: 5896... Loss: 0.021171... Val Loss: 0.036042\n",
      "Epoch: 57/100... Step: 5897... Loss: 0.016088... Val Loss: 0.037196\n",
      "Epoch: 57/100... Step: 5898... Loss: 0.013775... Val Loss: 0.034412\n",
      "Epoch: 57/100... Step: 5899... Loss: 0.016647... Val Loss: 0.032596\n",
      "Epoch: 57/100... Step: 5900... Loss: 0.015794... Val Loss: 0.038361\n",
      "Epoch: 57/100... Step: 5901... Loss: 0.011992... Val Loss: 0.038850\n",
      "Epoch: 57/100... Step: 5902... Loss: 0.016713... Val Loss: 0.033062\n",
      "Epoch: 57/100... Step: 5903... Loss: 0.017352... Val Loss: 0.018182\n",
      "Epoch: 57/100... Step: 5904... Loss: 0.024939... Val Loss: 0.009026\n",
      "Epoch: 57/100... Step: 5905... Loss: 0.017124... Val Loss: 0.015959\n",
      "Epoch: 57/100... Step: 5906... Loss: 0.010122... Val Loss: 0.032747\n",
      "Epoch: 57/100... Step: 5907... Loss: 0.023054... Val Loss: 0.053192\n",
      "Epoch: 57/100... Step: 5908... Loss: 0.015062... Val Loss: 0.057331\n",
      "Epoch: 57/100... Step: 5909... Loss: 0.018803... Val Loss: 0.055117\n",
      "Epoch: 57/100... Step: 5910... Loss: 0.025913... Val Loss: 0.069340\n",
      "Epoch: 57/100... Step: 5911... Loss: 0.017160... Val Loss: 0.076506\n",
      "Epoch: 57/100... Step: 5912... Loss: 0.016898... Val Loss: 0.082684\n",
      "Epoch: 57/100... Step: 5913... Loss: 0.009979... Val Loss: 0.076773\n",
      "Epoch: 57/100... Step: 5914... Loss: 0.020103... Val Loss: 0.065945\n",
      "Epoch: 57/100... Step: 5915... Loss: 0.014153... Val Loss: 0.054721\n",
      "Epoch: 57/100... Step: 5916... Loss: 0.018125... Val Loss: 0.042314\n",
      "Epoch: 57/100... Step: 5917... Loss: 0.023383... Val Loss: 0.022057\n",
      "Epoch: 57/100... Step: 5918... Loss: 0.023077... Val Loss: 0.015217\n",
      "Epoch: 57/100... Step: 5919... Loss: 0.018172... Val Loss: 0.015375\n",
      "Epoch: 57/100... Step: 5920... Loss: 0.016755... Val Loss: 0.014042\n",
      "Epoch: 57/100... Step: 5921... Loss: 0.014634... Val Loss: 0.012457\n",
      "Epoch: 57/100... Step: 5922... Loss: 0.020041... Val Loss: 0.013922\n",
      "Epoch: 57/100... Step: 5923... Loss: 0.020464... Val Loss: 0.015629\n",
      "Epoch: 57/100... Step: 5924... Loss: 0.018673... Val Loss: 0.018767\n",
      "Epoch: 57/100... Step: 5925... Loss: 0.017744... Val Loss: 0.023616\n",
      "Epoch: 57/100... Step: 5926... Loss: 0.024400... Val Loss: 0.024643\n",
      "Epoch: 57/100... Step: 5927... Loss: 0.020838... Val Loss: 0.022636\n",
      "Epoch: 57/100... Step: 5928... Loss: 0.016064... Val Loss: 0.021034\n",
      "Epoch: 58/100... Step: 5929... Loss: 0.009886... Val Loss: 0.020113\n",
      "Epoch: 58/100... Step: 5930... Loss: 0.013439... Val Loss: 0.036473\n",
      "Epoch: 58/100... Step: 5931... Loss: 0.016343... Val Loss: 0.114442\n",
      "Epoch: 58/100... Step: 5932... Loss: 0.007133... Val Loss: 0.172035\n",
      "Epoch: 58/100... Step: 5933... Loss: 0.015222... Val Loss: 0.209366\n",
      "Epoch: 58/100... Step: 5934... Loss: 0.018483... Val Loss: 0.229868\n",
      "Epoch: 58/100... Step: 5935... Loss: 0.015549... Val Loss: 0.234791\n",
      "Epoch: 58/100... Step: 5936... Loss: 0.008089... Val Loss: 0.245546\n",
      "Epoch: 58/100... Step: 5937... Loss: 0.025108... Val Loss: 0.264503\n",
      "Epoch: 58/100... Step: 5938... Loss: 0.018839... Val Loss: 0.284913\n",
      "Epoch: 58/100... Step: 5939... Loss: 0.021564... Val Loss: 0.282017\n",
      "Epoch: 58/100... Step: 5940... Loss: 0.012917... Val Loss: 0.281458\n",
      "Epoch: 58/100... Step: 5941... Loss: 0.018430... Val Loss: 0.282380\n",
      "Epoch: 58/100... Step: 5942... Loss: 0.017908... Val Loss: 0.278263\n",
      "Epoch: 58/100... Step: 5943... Loss: 0.027030... Val Loss: 0.276419\n",
      "Epoch: 58/100... Step: 5944... Loss: 0.017893... Val Loss: 0.269370\n",
      "Epoch: 58/100... Step: 5945... Loss: 0.014015... Val Loss: 0.260881\n",
      "Epoch: 58/100... Step: 5946... Loss: 0.020562... Val Loss: 0.251090\n",
      "Epoch: 58/100... Step: 5947... Loss: 0.022599... Val Loss: 0.235361\n",
      "Epoch: 58/100... Step: 5948... Loss: 0.020277... Val Loss: 0.218347\n",
      "Epoch: 58/100... Step: 5949... Loss: 0.034820... Val Loss: 0.194574\n",
      "Epoch: 58/100... Step: 5950... Loss: 0.023385... Val Loss: 0.167143\n",
      "Epoch: 58/100... Step: 5951... Loss: 0.020285... Val Loss: 0.145706\n",
      "Epoch: 58/100... Step: 5952... Loss: 0.016476... Val Loss: 0.122907\n",
      "Epoch: 58/100... Step: 5953... Loss: 0.010307... Val Loss: 0.095553\n",
      "Epoch: 58/100... Step: 5954... Loss: 0.021829... Val Loss: 0.077781\n",
      "Epoch: 58/100... Step: 5955... Loss: 0.016886... Val Loss: 0.070825\n",
      "Epoch: 58/100... Step: 5956... Loss: 0.029195... Val Loss: 0.072462\n",
      "Epoch: 58/100... Step: 5957... Loss: 0.020062... Val Loss: 0.081666\n",
      "Epoch: 58/100... Step: 5958... Loss: 0.015243... Val Loss: 0.088539\n",
      "Epoch: 58/100... Step: 5959... Loss: 0.022441... Val Loss: 0.092358\n",
      "Epoch: 58/100... Step: 5960... Loss: 0.016978... Val Loss: 0.098167\n",
      "Epoch: 58/100... Step: 5961... Loss: 0.016638... Val Loss: 0.109466\n",
      "Epoch: 58/100... Step: 5962... Loss: 0.023937... Val Loss: 0.114546\n",
      "Epoch: 58/100... Step: 5963... Loss: 0.017545... Val Loss: 0.115040\n",
      "Epoch: 58/100... Step: 5964... Loss: 0.017500... Val Loss: 0.108094\n",
      "Epoch: 58/100... Step: 5965... Loss: 0.018697... Val Loss: 0.105392\n",
      "Epoch: 58/100... Step: 5966... Loss: 0.019156... Val Loss: 0.109258\n",
      "Epoch: 58/100... Step: 5967... Loss: 0.014620... Val Loss: 0.109361\n",
      "Epoch: 58/100... Step: 5968... Loss: 0.016922... Val Loss: 0.109359\n",
      "Epoch: 58/100... Step: 5969... Loss: 0.013918... Val Loss: 0.109530\n",
      "Epoch: 58/100... Step: 5970... Loss: 0.019332... Val Loss: 0.109085\n",
      "Epoch: 58/100... Step: 5971... Loss: 0.011181... Val Loss: 0.112873\n",
      "Epoch: 58/100... Step: 5972... Loss: 0.017979... Val Loss: 0.115446\n",
      "Epoch: 58/100... Step: 5973... Loss: 0.014388... Val Loss: 0.112276\n",
      "Epoch: 58/100... Step: 5974... Loss: 0.008759... Val Loss: 0.105305\n",
      "Epoch: 58/100... Step: 5975... Loss: 0.013280... Val Loss: 0.102924\n",
      "Epoch: 58/100... Step: 5976... Loss: 0.019180... Val Loss: 0.096906\n",
      "Epoch: 58/100... Step: 5977... Loss: 0.026284... Val Loss: 0.092215\n",
      "Epoch: 58/100... Step: 5978... Loss: 0.016960... Val Loss: 0.090433\n",
      "Epoch: 58/100... Step: 5979... Loss: 0.023065... Val Loss: 0.088141\n",
      "Epoch: 58/100... Step: 5980... Loss: 0.016504... Val Loss: 0.087294\n",
      "Epoch: 58/100... Step: 5981... Loss: 0.013626... Val Loss: 0.088348\n",
      "Epoch: 58/100... Step: 5982... Loss: 0.024037... Val Loss: 0.079383\n",
      "Epoch: 58/100... Step: 5983... Loss: 0.024229... Val Loss: 0.073217\n",
      "Epoch: 58/100... Step: 5984... Loss: 0.017241... Val Loss: 0.072425\n",
      "Epoch: 58/100... Step: 5985... Loss: 0.012107... Val Loss: 0.068295\n",
      "Epoch: 58/100... Step: 5986... Loss: 0.016141... Val Loss: 0.065182\n",
      "Epoch: 58/100... Step: 5987... Loss: 0.023122... Val Loss: 0.060652\n",
      "Epoch: 58/100... Step: 5988... Loss: 0.023138... Val Loss: 0.051446\n",
      "Epoch: 58/100... Step: 5989... Loss: 0.019291... Val Loss: 0.041726\n",
      "Epoch: 58/100... Step: 5990... Loss: 0.016656... Val Loss: 0.034863\n",
      "Epoch: 58/100... Step: 5991... Loss: 0.020373... Val Loss: 0.025694\n",
      "Epoch: 58/100... Step: 5992... Loss: 0.018149... Val Loss: 0.019078\n",
      "Epoch: 58/100... Step: 5993... Loss: 0.016918... Val Loss: 0.014661\n",
      "Epoch: 58/100... Step: 5994... Loss: 0.018856... Val Loss: 0.014907\n",
      "Epoch: 58/100... Step: 5995... Loss: 0.018766... Val Loss: 0.018126\n",
      "Epoch: 58/100... Step: 5996... Loss: 0.012639... Val Loss: 0.017055\n",
      "Epoch: 58/100... Step: 5997... Loss: 0.008281... Val Loss: 0.017700\n",
      "Epoch: 58/100... Step: 5998... Loss: 0.016396... Val Loss: 0.017415\n",
      "Epoch: 58/100... Step: 5999... Loss: 0.015932... Val Loss: 0.017256\n",
      "Epoch: 58/100... Step: 6000... Loss: 0.022356... Val Loss: 0.015929\n",
      "Epoch: 58/100... Step: 6001... Loss: 0.012647... Val Loss: 0.013577\n",
      "Epoch: 58/100... Step: 6002... Loss: 0.020628... Val Loss: 0.015017\n",
      "Epoch: 58/100... Step: 6003... Loss: 0.027887... Val Loss: 0.018668\n",
      "Epoch: 58/100... Step: 6004... Loss: 0.022539... Val Loss: 0.020715\n",
      "Epoch: 58/100... Step: 6005... Loss: 0.016847... Val Loss: 0.025079\n",
      "Epoch: 58/100... Step: 6006... Loss: 0.017915... Val Loss: 0.031562\n",
      "Epoch: 58/100... Step: 6007... Loss: 0.019218... Val Loss: 0.038344\n",
      "Epoch: 58/100... Step: 6008... Loss: 0.024453... Val Loss: 0.036301\n",
      "Epoch: 58/100... Step: 6009... Loss: 0.023614... Val Loss: 0.034919\n",
      "Epoch: 58/100... Step: 6010... Loss: 0.018515... Val Loss: 0.039942\n",
      "Epoch: 58/100... Step: 6011... Loss: 0.023980... Val Loss: 0.043402\n",
      "Epoch: 58/100... Step: 6012... Loss: 0.018375... Val Loss: 0.048042\n",
      "Epoch: 58/100... Step: 6013... Loss: 0.012729... Val Loss: 0.049681\n",
      "Epoch: 58/100... Step: 6014... Loss: 0.018843... Val Loss: 0.047698\n",
      "Epoch: 58/100... Step: 6015... Loss: 0.009164... Val Loss: 0.041704\n",
      "Epoch: 58/100... Step: 6016... Loss: 0.014272... Val Loss: 0.035267\n",
      "Epoch: 58/100... Step: 6017... Loss: 0.014189... Val Loss: 0.033870\n",
      "Epoch: 58/100... Step: 6018... Loss: 0.022921... Val Loss: 0.034918\n",
      "Epoch: 58/100... Step: 6019... Loss: 0.035637... Val Loss: 0.032380\n",
      "Epoch: 58/100... Step: 6020... Loss: 0.016302... Val Loss: 0.025806\n",
      "Epoch: 58/100... Step: 6021... Loss: 0.019624... Val Loss: 0.013945\n",
      "Epoch: 58/100... Step: 6022... Loss: 0.013501... Val Loss: 0.010857\n",
      "Epoch: 58/100... Step: 6023... Loss: 0.022904... Val Loss: 0.011252\n",
      "Epoch: 58/100... Step: 6024... Loss: 0.016787... Val Loss: 0.026165\n",
      "Epoch: 58/100... Step: 6025... Loss: 0.019947... Val Loss: 0.041000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Step: 6026... Loss: 0.008276... Val Loss: 0.055266\n",
      "Epoch: 58/100... Step: 6027... Loss: 0.019211... Val Loss: 0.066130\n",
      "Epoch: 58/100... Step: 6028... Loss: 0.019913... Val Loss: 0.067849\n",
      "Epoch: 58/100... Step: 6029... Loss: 0.012926... Val Loss: 0.070000\n",
      "Epoch: 58/100... Step: 6030... Loss: 0.017910... Val Loss: 0.067347\n",
      "Epoch: 58/100... Step: 6031... Loss: 0.023128... Val Loss: 0.063912\n",
      "Epoch: 58/100... Step: 6032... Loss: 0.023410... Val Loss: 0.055702\n",
      "Epoch: 59/100... Step: 6033... Loss: 0.013306... Val Loss: 0.087707\n",
      "Epoch: 59/100... Step: 6034... Loss: 0.018510... Val Loss: 0.008690\n",
      "Epoch: 59/100... Step: 6035... Loss: 0.018131... Val Loss: 0.124158\n",
      "Epoch: 59/100... Step: 6036... Loss: 0.015223... Val Loss: 0.206861\n",
      "Epoch: 59/100... Step: 6037... Loss: 0.016344... Val Loss: 0.260656\n",
      "Epoch: 59/100... Step: 6038... Loss: 0.012836... Val Loss: 0.292287\n",
      "Epoch: 59/100... Step: 6039... Loss: 0.011353... Val Loss: 0.312908\n",
      "Epoch: 59/100... Step: 6040... Loss: 0.012046... Val Loss: 0.321252\n",
      "Epoch: 59/100... Step: 6041... Loss: 0.014845... Val Loss: 0.327323\n",
      "Epoch: 59/100... Step: 6042... Loss: 0.014704... Val Loss: 0.329580\n",
      "Epoch: 59/100... Step: 6043... Loss: 0.011830... Val Loss: 0.327734\n",
      "Epoch: 59/100... Step: 6044... Loss: 0.012703... Val Loss: 0.313172\n",
      "Epoch: 59/100... Step: 6045... Loss: 0.013289... Val Loss: 0.307996\n",
      "Epoch: 59/100... Step: 6046... Loss: 0.011130... Val Loss: 0.312141\n",
      "Epoch: 59/100... Step: 6047... Loss: 0.009219... Val Loss: 0.315371\n",
      "Epoch: 59/100... Step: 6048... Loss: 0.013229... Val Loss: 0.313743\n",
      "Epoch: 59/100... Step: 6049... Loss: 0.009019... Val Loss: 0.310411\n",
      "Epoch: 59/100... Step: 6050... Loss: 0.010266... Val Loss: 0.306455\n",
      "Epoch: 59/100... Step: 6051... Loss: 0.017678... Val Loss: 0.301202\n",
      "Epoch: 59/100... Step: 6052... Loss: 0.015960... Val Loss: 0.292155\n",
      "Epoch: 59/100... Step: 6053... Loss: 0.006628... Val Loss: 0.282406\n",
      "Epoch: 59/100... Step: 6054... Loss: 0.015119... Val Loss: 0.271454\n",
      "Epoch: 59/100... Step: 6055... Loss: 0.017144... Val Loss: 0.261010\n",
      "Epoch: 59/100... Step: 6056... Loss: 0.016442... Val Loss: 0.246127\n",
      "Epoch: 59/100... Step: 6057... Loss: 0.019773... Val Loss: 0.234561\n",
      "Epoch: 59/100... Step: 6058... Loss: 0.012227... Val Loss: 0.227204\n",
      "Epoch: 59/100... Step: 6059... Loss: 0.014714... Val Loss: 0.222596\n",
      "Epoch: 59/100... Step: 6060... Loss: 0.023239... Val Loss: 0.211022\n",
      "Epoch: 59/100... Step: 6061... Loss: 0.017990... Val Loss: 0.199133\n",
      "Epoch: 59/100... Step: 6062... Loss: 0.019791... Val Loss: 0.181501\n",
      "Epoch: 59/100... Step: 6063... Loss: 0.016219... Val Loss: 0.165139\n",
      "Epoch: 59/100... Step: 6064... Loss: 0.017328... Val Loss: 0.145972\n",
      "Epoch: 59/100... Step: 6065... Loss: 0.016531... Val Loss: 0.131023\n",
      "Epoch: 59/100... Step: 6066... Loss: 0.017386... Val Loss: 0.124859\n",
      "Epoch: 59/100... Step: 6067... Loss: 0.016404... Val Loss: 0.118357\n",
      "Epoch: 59/100... Step: 6068... Loss: 0.017734... Val Loss: 0.103353\n",
      "Epoch: 59/100... Step: 6069... Loss: 0.011843... Val Loss: 0.086512\n",
      "Epoch: 59/100... Step: 6070... Loss: 0.012670... Val Loss: 0.069206\n",
      "Epoch: 59/100... Step: 6071... Loss: 0.013356... Val Loss: 0.058157\n",
      "Epoch: 59/100... Step: 6072... Loss: 0.014755... Val Loss: 0.038376\n",
      "Epoch: 59/100... Step: 6073... Loss: 0.015422... Val Loss: 0.018999\n",
      "Epoch: 59/100... Step: 6074... Loss: 0.011311... Val Loss: 0.009237\n",
      "Epoch: 59/100... Step: 6075... Loss: 0.017938... Val Loss: 0.013939\n",
      "Epoch: 59/100... Step: 6076... Loss: 0.012660... Val Loss: 0.032585\n",
      "Epoch: 59/100... Step: 6077... Loss: 0.013791... Val Loss: 0.045599\n",
      "Epoch: 59/100... Step: 6078... Loss: 0.021179... Val Loss: 0.053553\n",
      "Epoch: 59/100... Step: 6079... Loss: 0.010344... Val Loss: 0.058502\n",
      "Epoch: 59/100... Step: 6080... Loss: 0.016826... Val Loss: 0.062501\n",
      "Epoch: 59/100... Step: 6081... Loss: 0.023768... Val Loss: 0.064297\n",
      "Epoch: 59/100... Step: 6082... Loss: 0.017029... Val Loss: 0.070310\n",
      "Epoch: 59/100... Step: 6083... Loss: 0.015797... Val Loss: 0.075448\n",
      "Epoch: 59/100... Step: 6084... Loss: 0.021524... Val Loss: 0.084671\n",
      "Epoch: 59/100... Step: 6085... Loss: 0.009771... Val Loss: 0.098135\n",
      "Epoch: 59/100... Step: 6086... Loss: 0.017799... Val Loss: 0.113657\n",
      "Epoch: 59/100... Step: 6087... Loss: 0.014896... Val Loss: 0.120278\n",
      "Epoch: 59/100... Step: 6088... Loss: 0.010464... Val Loss: 0.116674\n",
      "Epoch: 59/100... Step: 6089... Loss: 0.011693... Val Loss: 0.108395\n",
      "Epoch: 59/100... Step: 6090... Loss: 0.013144... Val Loss: 0.102151\n",
      "Epoch: 59/100... Step: 6091... Loss: 0.015396... Val Loss: 0.088184\n",
      "Epoch: 59/100... Step: 6092... Loss: 0.019288... Val Loss: 0.067708\n",
      "Epoch: 59/100... Step: 6093... Loss: 0.019474... Val Loss: 0.042750\n",
      "Epoch: 59/100... Step: 6094... Loss: 0.022535... Val Loss: 0.018847\n",
      "Epoch: 59/100... Step: 6095... Loss: 0.020706... Val Loss: 0.021023\n",
      "Epoch: 59/100... Step: 6096... Loss: 0.018435... Val Loss: 0.034996\n",
      "Epoch: 59/100... Step: 6097... Loss: 0.018752... Val Loss: 0.054969\n",
      "Epoch: 59/100... Step: 6098... Loss: 0.017742... Val Loss: 0.073625\n",
      "Epoch: 59/100... Step: 6099... Loss: 0.019362... Val Loss: 0.076318\n",
      "Epoch: 59/100... Step: 6100... Loss: 0.017122... Val Loss: 0.083767\n",
      "Epoch: 59/100... Step: 6101... Loss: 0.008929... Val Loss: 0.081802\n",
      "Epoch: 59/100... Step: 6102... Loss: 0.013642... Val Loss: 0.086228\n",
      "Epoch: 59/100... Step: 6103... Loss: 0.013950... Val Loss: 0.086435\n",
      "Epoch: 59/100... Step: 6104... Loss: 0.017352... Val Loss: 0.089560\n",
      "Epoch: 59/100... Step: 6105... Loss: 0.017749... Val Loss: 0.093200\n",
      "Epoch: 59/100... Step: 6106... Loss: 0.016270... Val Loss: 0.088044\n",
      "Epoch: 59/100... Step: 6107... Loss: 0.018625... Val Loss: 0.082888\n",
      "Epoch: 59/100... Step: 6108... Loss: 0.026086... Val Loss: 0.072308\n",
      "Epoch: 59/100... Step: 6109... Loss: 0.013601... Val Loss: 0.061805\n",
      "Epoch: 59/100... Step: 6110... Loss: 0.019934... Val Loss: 0.055442\n",
      "Epoch: 59/100... Step: 6111... Loss: 0.015256... Val Loss: 0.049821\n",
      "Epoch: 59/100... Step: 6112... Loss: 0.016745... Val Loss: 0.046865\n",
      "Epoch: 59/100... Step: 6113... Loss: 0.019297... Val Loss: 0.042923\n",
      "Epoch: 59/100... Step: 6114... Loss: 0.015899... Val Loss: 0.040987\n",
      "Epoch: 59/100... Step: 6115... Loss: 0.018519... Val Loss: 0.037083\n",
      "Epoch: 59/100... Step: 6116... Loss: 0.016066... Val Loss: 0.039088\n",
      "Epoch: 59/100... Step: 6117... Loss: 0.011460... Val Loss: 0.045515\n",
      "Epoch: 59/100... Step: 6118... Loss: 0.015675... Val Loss: 0.052103\n",
      "Epoch: 59/100... Step: 6119... Loss: 0.015892... Val Loss: 0.048832\n",
      "Epoch: 59/100... Step: 6120... Loss: 0.023891... Val Loss: 0.047941\n",
      "Epoch: 59/100... Step: 6121... Loss: 0.014191... Val Loss: 0.049780\n",
      "Epoch: 59/100... Step: 6122... Loss: 0.017661... Val Loss: 0.048202\n",
      "Epoch: 59/100... Step: 6123... Loss: 0.030264... Val Loss: 0.039573\n",
      "Epoch: 59/100... Step: 6124... Loss: 0.012788... Val Loss: 0.031031\n",
      "Epoch: 59/100... Step: 6125... Loss: 0.015099... Val Loss: 0.029781\n",
      "Epoch: 59/100... Step: 6126... Loss: 0.015462... Val Loss: 0.024569\n",
      "Epoch: 59/100... Step: 6127... Loss: 0.018051... Val Loss: 0.021005\n",
      "Epoch: 59/100... Step: 6128... Loss: 0.013985... Val Loss: 0.014765\n",
      "Epoch: 59/100... Step: 6129... Loss: 0.017638... Val Loss: 0.014528\n",
      "Epoch: 59/100... Step: 6130... Loss: 0.014876... Val Loss: 0.014103\n",
      "Epoch: 59/100... Step: 6131... Loss: 0.017220... Val Loss: 0.015181\n",
      "Epoch: 59/100... Step: 6132... Loss: 0.019074... Val Loss: 0.014958\n",
      "Epoch: 59/100... Step: 6133... Loss: 0.022959... Val Loss: 0.013507\n",
      "Epoch: 59/100... Step: 6134... Loss: 0.012310... Val Loss: 0.013475\n",
      "Epoch: 59/100... Step: 6135... Loss: 0.016832... Val Loss: 0.019482\n",
      "Epoch: 59/100... Step: 6136... Loss: 0.015771... Val Loss: 0.028818\n",
      "Epoch: 60/100... Step: 6137... Loss: 0.012670... Val Loss: 0.045921\n",
      "Epoch: 60/100... Step: 6138... Loss: 0.017326... Val Loss: 0.125147\n",
      "Epoch: 60/100... Step: 6139... Loss: 0.015259... Val Loss: 0.210785\n",
      "Epoch: 60/100... Step: 6140... Loss: 0.009520... Val Loss: 0.263091\n",
      "Epoch: 60/100... Step: 6141... Loss: 0.014169... Val Loss: 0.303286\n",
      "Epoch: 60/100... Step: 6142... Loss: 0.012938... Val Loss: 0.328973\n",
      "Epoch: 60/100... Step: 6143... Loss: 0.018112... Val Loss: 0.344328\n",
      "Epoch: 60/100... Step: 6144... Loss: 0.008464... Val Loss: 0.339853\n",
      "Epoch: 60/100... Step: 6145... Loss: 0.015231... Val Loss: 0.343397\n",
      "Epoch: 60/100... Step: 6146... Loss: 0.017218... Val Loss: 0.334403\n",
      "Epoch: 60/100... Step: 6147... Loss: 0.017222... Val Loss: 0.315249\n",
      "Epoch: 60/100... Step: 6148... Loss: 0.013209... Val Loss: 0.307626\n",
      "Epoch: 60/100... Step: 6149... Loss: 0.018315... Val Loss: 0.303259\n",
      "Epoch: 60/100... Step: 6150... Loss: 0.018854... Val Loss: 0.297538\n",
      "Epoch: 60/100... Step: 6151... Loss: 0.016311... Val Loss: 0.291421\n",
      "Epoch: 60/100... Step: 6152... Loss: 0.010020... Val Loss: 0.286190\n",
      "Epoch: 60/100... Step: 6153... Loss: 0.021026... Val Loss: 0.281407\n",
      "Epoch: 60/100... Step: 6154... Loss: 0.022572... Val Loss: 0.273533\n",
      "Epoch: 60/100... Step: 6155... Loss: 0.015300... Val Loss: 0.263316\n",
      "Epoch: 60/100... Step: 6156... Loss: 0.012781... Val Loss: 0.247433\n",
      "Epoch: 60/100... Step: 6157... Loss: 0.011402... Val Loss: 0.229354\n",
      "Epoch: 60/100... Step: 6158... Loss: 0.019317... Val Loss: 0.206390\n",
      "Epoch: 60/100... Step: 6159... Loss: 0.028762... Val Loss: 0.188823\n",
      "Epoch: 60/100... Step: 6160... Loss: 0.014920... Val Loss: 0.174224\n",
      "Epoch: 60/100... Step: 6161... Loss: 0.017217... Val Loss: 0.161299\n",
      "Epoch: 60/100... Step: 6162... Loss: 0.021154... Val Loss: 0.152579\n",
      "Epoch: 60/100... Step: 6163... Loss: 0.012384... Val Loss: 0.151416\n",
      "Epoch: 60/100... Step: 6164... Loss: 0.016592... Val Loss: 0.149537\n",
      "Epoch: 60/100... Step: 6165... Loss: 0.012868... Val Loss: 0.146357\n",
      "Epoch: 60/100... Step: 6166... Loss: 0.013707... Val Loss: 0.142021\n",
      "Epoch: 60/100... Step: 6167... Loss: 0.011620... Val Loss: 0.138989\n",
      "Epoch: 60/100... Step: 6168... Loss: 0.030418... Val Loss: 0.137647\n",
      "Epoch: 60/100... Step: 6169... Loss: 0.016921... Val Loss: 0.137831\n",
      "Epoch: 60/100... Step: 6170... Loss: 0.020613... Val Loss: 0.130716\n",
      "Epoch: 60/100... Step: 6171... Loss: 0.019745... Val Loss: 0.124325\n",
      "Epoch: 60/100... Step: 6172... Loss: 0.022007... Val Loss: 0.114812\n",
      "Epoch: 60/100... Step: 6173... Loss: 0.017058... Val Loss: 0.108567\n",
      "Epoch: 60/100... Step: 6174... Loss: 0.018600... Val Loss: 0.098863\n",
      "Epoch: 60/100... Step: 6175... Loss: 0.016177... Val Loss: 0.092247\n",
      "Epoch: 60/100... Step: 6176... Loss: 0.012083... Val Loss: 0.078557\n",
      "Epoch: 60/100... Step: 6177... Loss: 0.021513... Val Loss: 0.064155\n",
      "Epoch: 60/100... Step: 6178... Loss: 0.020993... Val Loss: 0.047908\n",
      "Epoch: 60/100... Step: 6179... Loss: 0.021500... Val Loss: 0.030663\n",
      "Epoch: 60/100... Step: 6180... Loss: 0.020202... Val Loss: 0.018840\n",
      "Epoch: 60/100... Step: 6181... Loss: 0.009364... Val Loss: 0.007064\n",
      "Epoch: 60/100... Step: 6182... Loss: 0.012971... Val Loss: 0.011587\n",
      "Epoch: 60/100... Step: 6183... Loss: 0.023223... Val Loss: 0.011717\n",
      "Epoch: 60/100... Step: 6184... Loss: 0.009701... Val Loss: 0.013147\n",
      "Epoch: 60/100... Step: 6185... Loss: 0.009987... Val Loss: 0.018265\n",
      "Epoch: 60/100... Step: 6186... Loss: 0.013732... Val Loss: 0.025485\n",
      "Epoch: 60/100... Step: 6187... Loss: 0.016477... Val Loss: 0.028058\n",
      "Epoch: 60/100... Step: 6188... Loss: 0.016538... Val Loss: 0.032599\n",
      "Epoch: 60/100... Step: 6189... Loss: 0.019523... Val Loss: 0.035134\n",
      "Epoch: 60/100... Step: 6190... Loss: 0.018549... Val Loss: 0.037573\n",
      "Epoch: 60/100... Step: 6191... Loss: 0.011046... Val Loss: 0.036631\n",
      "Epoch: 60/100... Step: 6192... Loss: 0.013598... Val Loss: 0.036273\n",
      "Epoch: 60/100... Step: 6193... Loss: 0.019759... Val Loss: 0.033040\n",
      "Epoch: 60/100... Step: 6194... Loss: 0.016817... Val Loss: 0.031361\n",
      "Epoch: 60/100... Step: 6195... Loss: 0.030035... Val Loss: 0.022659\n",
      "Epoch: 60/100... Step: 6196... Loss: 0.022398... Val Loss: 0.018350\n",
      "Epoch: 60/100... Step: 6197... Loss: 0.019128... Val Loss: 0.018083\n",
      "Epoch: 60/100... Step: 6198... Loss: 0.016067... Val Loss: 0.027502\n",
      "Epoch: 60/100... Step: 6199... Loss: 0.018390... Val Loss: 0.027964\n",
      "Epoch: 60/100... Step: 6200... Loss: 0.012541... Val Loss: 0.024401\n",
      "Epoch: 60/100... Step: 6201... Loss: 0.019196... Val Loss: 0.014694\n",
      "Epoch: 60/100... Step: 6202... Loss: 0.011707... Val Loss: 0.014131\n",
      "Epoch: 60/100... Step: 6203... Loss: 0.016295... Val Loss: 0.016099\n",
      "Epoch: 60/100... Step: 6204... Loss: 0.010387... Val Loss: 0.012661\n",
      "Epoch: 60/100... Step: 6205... Loss: 0.016211... Val Loss: 0.011103\n",
      "Epoch: 60/100... Step: 6206... Loss: 0.016632... Val Loss: 0.016257\n",
      "Epoch: 60/100... Step: 6207... Loss: 0.013772... Val Loss: 0.018663\n",
      "Epoch: 60/100... Step: 6208... Loss: 0.011825... Val Loss: 0.024665\n",
      "Epoch: 60/100... Step: 6209... Loss: 0.021797... Val Loss: 0.031076\n",
      "Epoch: 60/100... Step: 6210... Loss: 0.015082... Val Loss: 0.034335\n",
      "Epoch: 60/100... Step: 6211... Loss: 0.011675... Val Loss: 0.033516\n",
      "Epoch: 60/100... Step: 6212... Loss: 0.014473... Val Loss: 0.030136\n",
      "Epoch: 60/100... Step: 6213... Loss: 0.012571... Val Loss: 0.027598\n",
      "Epoch: 60/100... Step: 6214... Loss: 0.010339... Val Loss: 0.026980\n",
      "Epoch: 60/100... Step: 6215... Loss: 0.015102... Val Loss: 0.033659\n",
      "Epoch: 60/100... Step: 6216... Loss: 0.016205... Val Loss: 0.060780\n",
      "Epoch: 60/100... Step: 6217... Loss: 0.014751... Val Loss: 0.055820\n",
      "Epoch: 60/100... Step: 6218... Loss: 0.012333... Val Loss: 0.040579\n",
      "Epoch: 60/100... Step: 6219... Loss: 0.021429... Val Loss: 0.029512\n",
      "Epoch: 60/100... Step: 6220... Loss: 0.013281... Val Loss: 0.024155\n",
      "Epoch: 60/100... Step: 6221... Loss: 0.012124... Val Loss: 0.019674\n",
      "Epoch: 60/100... Step: 6222... Loss: 0.018113... Val Loss: 0.016735\n",
      "Epoch: 60/100... Step: 6223... Loss: 0.017803... Val Loss: 0.020754\n",
      "Epoch: 60/100... Step: 6224... Loss: 0.013615... Val Loss: 0.029696\n",
      "Epoch: 60/100... Step: 6225... Loss: 0.010830... Val Loss: 0.027593\n",
      "Epoch: 60/100... Step: 6226... Loss: 0.016951... Val Loss: 0.026920\n",
      "Epoch: 60/100... Step: 6227... Loss: 0.018498... Val Loss: 0.029805\n",
      "Epoch: 60/100... Step: 6228... Loss: 0.015826... Val Loss: 0.040124\n",
      "Epoch: 60/100... Step: 6229... Loss: 0.015356... Val Loss: 0.051811\n",
      "Epoch: 60/100... Step: 6230... Loss: 0.015669... Val Loss: 0.056066\n",
      "Epoch: 60/100... Step: 6231... Loss: 0.012173... Val Loss: 0.053577\n",
      "Epoch: 60/100... Step: 6232... Loss: 0.017667... Val Loss: 0.050328\n",
      "Epoch: 60/100... Step: 6233... Loss: 0.015639... Val Loss: 0.045592\n",
      "Epoch: 60/100... Step: 6234... Loss: 0.015612... Val Loss: 0.034938\n",
      "Epoch: 60/100... Step: 6235... Loss: 0.017996... Val Loss: 0.021810\n",
      "Epoch: 60/100... Step: 6236... Loss: 0.024022... Val Loss: 0.016209\n",
      "Epoch: 60/100... Step: 6237... Loss: 0.014893... Val Loss: 0.013895\n",
      "Epoch: 60/100... Step: 6238... Loss: 0.021380... Val Loss: 0.013506\n",
      "Epoch: 60/100... Step: 6239... Loss: 0.013855... Val Loss: 0.011889\n",
      "Epoch: 60/100... Step: 6240... Loss: 0.019968... Val Loss: 0.012575\n",
      "Epoch: 61/100... Step: 6241... Loss: 0.016443... Val Loss: 0.010100\n",
      "Epoch: 61/100... Step: 6242... Loss: 0.016207... Val Loss: 0.081300\n",
      "Epoch: 61/100... Step: 6243... Loss: 0.016962... Val Loss: 0.183924\n",
      "Epoch: 61/100... Step: 6244... Loss: 0.011913... Val Loss: 0.257178\n",
      "Epoch: 61/100... Step: 6245... Loss: 0.017053... Val Loss: 0.303422\n",
      "Epoch: 61/100... Step: 6246... Loss: 0.015094... Val Loss: 0.316094\n",
      "Epoch: 61/100... Step: 6247... Loss: 0.008945... Val Loss: 0.341047\n",
      "Epoch: 61/100... Step: 6248... Loss: 0.026320... Val Loss: 0.360028\n",
      "Epoch: 61/100... Step: 6249... Loss: 0.022589... Val Loss: 0.373638\n",
      "Epoch: 61/100... Step: 6250... Loss: 0.017081... Val Loss: 0.370050\n",
      "Epoch: 61/100... Step: 6251... Loss: 0.010672... Val Loss: 0.383121\n",
      "Epoch: 61/100... Step: 6252... Loss: 0.014107... Val Loss: 0.380587\n",
      "Epoch: 61/100... Step: 6253... Loss: 0.021363... Val Loss: 0.364433\n",
      "Epoch: 61/100... Step: 6254... Loss: 0.017068... Val Loss: 0.338140\n",
      "Epoch: 61/100... Step: 6255... Loss: 0.019432... Val Loss: 0.323156\n",
      "Epoch: 61/100... Step: 6256... Loss: 0.020352... Val Loss: 0.311819\n",
      "Epoch: 61/100... Step: 6257... Loss: 0.021544... Val Loss: 0.316892\n",
      "Epoch: 61/100... Step: 6258... Loss: 0.019723... Val Loss: 0.329043\n",
      "Epoch: 61/100... Step: 6259... Loss: 0.016278... Val Loss: 0.324910\n",
      "Epoch: 61/100... Step: 6260... Loss: 0.012593... Val Loss: 0.309689\n",
      "Epoch: 61/100... Step: 6261... Loss: 0.017036... Val Loss: 0.294322\n",
      "Epoch: 61/100... Step: 6262... Loss: 0.016697... Val Loss: 0.277368\n",
      "Epoch: 61/100... Step: 6263... Loss: 0.010586... Val Loss: 0.261535\n",
      "Epoch: 61/100... Step: 6264... Loss: 0.016702... Val Loss: 0.247068\n",
      "Epoch: 61/100... Step: 6265... Loss: 0.009340... Val Loss: 0.231227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100... Step: 6266... Loss: 0.012809... Val Loss: 0.213790\n",
      "Epoch: 61/100... Step: 6267... Loss: 0.008912... Val Loss: 0.199537\n",
      "Epoch: 61/100... Step: 6268... Loss: 0.011759... Val Loss: 0.185554\n",
      "Epoch: 61/100... Step: 6269... Loss: 0.012330... Val Loss: 0.167931\n",
      "Epoch: 61/100... Step: 6270... Loss: 0.018738... Val Loss: 0.151718\n",
      "Epoch: 61/100... Step: 6271... Loss: 0.011228... Val Loss: 0.135600\n",
      "Epoch: 61/100... Step: 6272... Loss: 0.012993... Val Loss: 0.117944\n",
      "Epoch: 61/100... Step: 6273... Loss: 0.010670... Val Loss: 0.106151\n",
      "Epoch: 61/100... Step: 6274... Loss: 0.014626... Val Loss: 0.094276\n",
      "Epoch: 61/100... Step: 6275... Loss: 0.009869... Val Loss: 0.089189\n",
      "Epoch: 61/100... Step: 6276... Loss: 0.015028... Val Loss: 0.086511\n",
      "Epoch: 61/100... Step: 6277... Loss: 0.017919... Val Loss: 0.083453\n",
      "Epoch: 61/100... Step: 6278... Loss: 0.015918... Val Loss: 0.079082\n",
      "Epoch: 61/100... Step: 6279... Loss: 0.016458... Val Loss: 0.073807\n",
      "Epoch: 61/100... Step: 6280... Loss: 0.025064... Val Loss: 0.065707\n",
      "Epoch: 61/100... Step: 6281... Loss: 0.026654... Val Loss: 0.053785\n",
      "Epoch: 61/100... Step: 6282... Loss: 0.020297... Val Loss: 0.039504\n",
      "Epoch: 61/100... Step: 6283... Loss: 0.017224... Val Loss: 0.028655\n",
      "Epoch: 61/100... Step: 6284... Loss: 0.014759... Val Loss: 0.015477\n",
      "Epoch: 61/100... Step: 6285... Loss: 0.018932... Val Loss: 0.009425\n",
      "Epoch: 61/100... Step: 6286... Loss: 0.013934... Val Loss: 0.010210\n",
      "Epoch: 61/100... Step: 6287... Loss: 0.010814... Val Loss: 0.012908\n",
      "Epoch: 61/100... Step: 6288... Loss: 0.010055... Val Loss: 0.012206\n",
      "Epoch: 61/100... Step: 6289... Loss: 0.021333... Val Loss: 0.010492\n",
      "Epoch: 61/100... Step: 6290... Loss: 0.012078... Val Loss: 0.010711\n",
      "Epoch: 61/100... Step: 6291... Loss: 0.013767... Val Loss: 0.013230\n",
      "Epoch: 61/100... Step: 6292... Loss: 0.016830... Val Loss: 0.020918\n",
      "Epoch: 61/100... Step: 6293... Loss: 0.021218... Val Loss: 0.032180\n",
      "Epoch: 61/100... Step: 6294... Loss: 0.019045... Val Loss: 0.043768\n",
      "Epoch: 61/100... Step: 6295... Loss: 0.026233... Val Loss: 0.049733\n",
      "Epoch: 61/100... Step: 6296... Loss: 0.016539... Val Loss: 0.049125\n",
      "Epoch: 61/100... Step: 6297... Loss: 0.012879... Val Loss: 0.050215\n",
      "Epoch: 61/100... Step: 6298... Loss: 0.019299... Val Loss: 0.055978\n",
      "Epoch: 61/100... Step: 6299... Loss: 0.011912... Val Loss: 0.064525\n",
      "Epoch: 61/100... Step: 6300... Loss: 0.017828... Val Loss: 0.071191\n",
      "Epoch: 61/100... Step: 6301... Loss: 0.012310... Val Loss: 0.073433\n",
      "Epoch: 61/100... Step: 6302... Loss: 0.010182... Val Loss: 0.068264\n",
      "Epoch: 61/100... Step: 6303... Loss: 0.012961... Val Loss: 0.059854\n",
      "Epoch: 61/100... Step: 6304... Loss: 0.013725... Val Loss: 0.048327\n",
      "Epoch: 61/100... Step: 6305... Loss: 0.009792... Val Loss: 0.036394\n",
      "Epoch: 61/100... Step: 6306... Loss: 0.011965... Val Loss: 0.018462\n",
      "Epoch: 61/100... Step: 6307... Loss: 0.016157... Val Loss: 0.013150\n",
      "Epoch: 61/100... Step: 6308... Loss: 0.012946... Val Loss: 0.014024\n",
      "Epoch: 61/100... Step: 6309... Loss: 0.020355... Val Loss: 0.015744\n",
      "Epoch: 61/100... Step: 6310... Loss: 0.017537... Val Loss: 0.014562\n",
      "Epoch: 61/100... Step: 6311... Loss: 0.013636... Val Loss: 0.011426\n",
      "Epoch: 61/100... Step: 6312... Loss: 0.009241... Val Loss: 0.012357\n",
      "Epoch: 61/100... Step: 6313... Loss: 0.011590... Val Loss: 0.012766\n",
      "Epoch: 61/100... Step: 6314... Loss: 0.012122... Val Loss: 0.009851\n",
      "Epoch: 61/100... Step: 6315... Loss: 0.013636... Val Loss: 0.008727\n",
      "Epoch: 61/100... Step: 6316... Loss: 0.019519... Val Loss: 0.008188\n",
      "Epoch: 61/100... Step: 6317... Loss: 0.013378... Val Loss: 0.012733\n",
      "Epoch: 61/100... Step: 6318... Loss: 0.014206... Val Loss: 0.014659\n",
      "Epoch: 61/100... Step: 6319... Loss: 0.015922... Val Loss: 0.018154\n",
      "Epoch: 61/100... Step: 6320... Loss: 0.010016... Val Loss: 0.020672\n",
      "Epoch: 61/100... Step: 6321... Loss: 0.015337... Val Loss: 0.019509\n",
      "Epoch: 61/100... Step: 6322... Loss: 0.017055... Val Loss: 0.016186\n",
      "Epoch: 61/100... Step: 6323... Loss: 0.019669... Val Loss: 0.011340\n",
      "Epoch: 61/100... Step: 6324... Loss: 0.013923... Val Loss: 0.007763\n",
      "Epoch: 61/100... Step: 6325... Loss: 0.021514... Val Loss: 0.014564\n",
      "Epoch: 61/100... Step: 6326... Loss: 0.015421... Val Loss: 0.029907\n",
      "Epoch: 61/100... Step: 6327... Loss: 0.014530... Val Loss: 0.032180\n",
      "Epoch: 61/100... Step: 6328... Loss: 0.015507... Val Loss: 0.030770\n",
      "Epoch: 61/100... Step: 6329... Loss: 0.010834... Val Loss: 0.027378\n",
      "Epoch: 61/100... Step: 6330... Loss: 0.018060... Val Loss: 0.024390\n",
      "Epoch: 61/100... Step: 6331... Loss: 0.011562... Val Loss: 0.012026\n",
      "Epoch: 61/100... Step: 6332... Loss: 0.015961... Val Loss: 0.040514\n",
      "Epoch: 61/100... Step: 6333... Loss: 0.012503... Val Loss: 0.055440\n",
      "Epoch: 61/100... Step: 6334... Loss: 0.012847... Val Loss: 0.064419\n",
      "Epoch: 61/100... Step: 6335... Loss: 0.019618... Val Loss: 0.072094\n",
      "Epoch: 61/100... Step: 6336... Loss: 0.013350... Val Loss: 0.081952\n",
      "Epoch: 61/100... Step: 6337... Loss: 0.010498... Val Loss: 0.094479\n",
      "Epoch: 61/100... Step: 6338... Loss: 0.022507... Val Loss: 0.100313\n",
      "Epoch: 61/100... Step: 6339... Loss: 0.011730... Val Loss: 0.101421\n",
      "Epoch: 61/100... Step: 6340... Loss: 0.025427... Val Loss: 0.093919\n",
      "Epoch: 61/100... Step: 6341... Loss: 0.021257... Val Loss: 0.078058\n",
      "Epoch: 61/100... Step: 6342... Loss: 0.021076... Val Loss: 0.064385\n",
      "Epoch: 61/100... Step: 6343... Loss: 0.016839... Val Loss: 0.052887\n",
      "Epoch: 61/100... Step: 6344... Loss: 0.008610... Val Loss: 0.038563\n",
      "Epoch: 62/100... Step: 6345... Loss: 0.013852... Val Loss: 0.062838\n",
      "Epoch: 62/100... Step: 6346... Loss: 0.018086... Val Loss: 0.015874\n",
      "Epoch: 62/100... Step: 6347... Loss: 0.015635... Val Loss: 0.074758\n",
      "Epoch: 62/100... Step: 6348... Loss: 0.015313... Val Loss: 0.153142\n",
      "Epoch: 62/100... Step: 6349... Loss: 0.013493... Val Loss: 0.210871\n",
      "Epoch: 62/100... Step: 6350... Loss: 0.012443... Val Loss: 0.237041\n",
      "Epoch: 62/100... Step: 6351... Loss: 0.009865... Val Loss: 0.245701\n",
      "Epoch: 62/100... Step: 6352... Loss: 0.014865... Val Loss: 0.263196\n",
      "Epoch: 62/100... Step: 6353... Loss: 0.013376... Val Loss: 0.277950\n",
      "Epoch: 62/100... Step: 6354... Loss: 0.012384... Val Loss: 0.292330\n",
      "Epoch: 62/100... Step: 6355... Loss: 0.017428... Val Loss: 0.308088\n",
      "Epoch: 62/100... Step: 6356... Loss: 0.011518... Val Loss: 0.324545\n",
      "Epoch: 62/100... Step: 6357... Loss: 0.020618... Val Loss: 0.336178\n",
      "Epoch: 62/100... Step: 6358... Loss: 0.016279... Val Loss: 0.346805\n",
      "Epoch: 62/100... Step: 6359... Loss: 0.023193... Val Loss: 0.352426\n",
      "Epoch: 62/100... Step: 6360... Loss: 0.015517... Val Loss: 0.352098\n",
      "Epoch: 62/100... Step: 6361... Loss: 0.015856... Val Loss: 0.349467\n",
      "Epoch: 62/100... Step: 6362... Loss: 0.014116... Val Loss: 0.343509\n",
      "Epoch: 62/100... Step: 6363... Loss: 0.022243... Val Loss: 0.331525\n",
      "Epoch: 62/100... Step: 6364... Loss: 0.014997... Val Loss: 0.306053\n",
      "Epoch: 62/100... Step: 6365... Loss: 0.012910... Val Loss: 0.273560\n",
      "Epoch: 62/100... Step: 6366... Loss: 0.017030... Val Loss: 0.255582\n",
      "Epoch: 62/100... Step: 6367... Loss: 0.017058... Val Loss: 0.234960\n",
      "Epoch: 62/100... Step: 6368... Loss: 0.015721... Val Loss: 0.213758\n",
      "Epoch: 62/100... Step: 6369... Loss: 0.016471... Val Loss: 0.194605\n",
      "Epoch: 62/100... Step: 6370... Loss: 0.014507... Val Loss: 0.172277\n",
      "Epoch: 62/100... Step: 6371... Loss: 0.011790... Val Loss: 0.158522\n",
      "Epoch: 62/100... Step: 6372... Loss: 0.014408... Val Loss: 0.144813\n",
      "Epoch: 62/100... Step: 6373... Loss: 0.013731... Val Loss: 0.132249\n",
      "Epoch: 62/100... Step: 6374... Loss: 0.014388... Val Loss: 0.124102\n",
      "Epoch: 62/100... Step: 6375... Loss: 0.019467... Val Loss: 0.127376\n",
      "Epoch: 62/100... Step: 6376... Loss: 0.014987... Val Loss: 0.118009\n",
      "Epoch: 62/100... Step: 6377... Loss: 0.016276... Val Loss: 0.106544\n",
      "Epoch: 62/100... Step: 6378... Loss: 0.019357... Val Loss: 0.093166\n",
      "Epoch: 62/100... Step: 6379... Loss: 0.014564... Val Loss: 0.086543\n",
      "Epoch: 62/100... Step: 6380... Loss: 0.011692... Val Loss: 0.079058\n",
      "Epoch: 62/100... Step: 6381... Loss: 0.013900... Val Loss: 0.071420\n",
      "Epoch: 62/100... Step: 6382... Loss: 0.010442... Val Loss: 0.063818\n",
      "Epoch: 62/100... Step: 6383... Loss: 0.023561... Val Loss: 0.064207\n",
      "Epoch: 62/100... Step: 6384... Loss: 0.014245... Val Loss: 0.060124\n",
      "Epoch: 62/100... Step: 6385... Loss: 0.018264... Val Loss: 0.057032\n",
      "Epoch: 62/100... Step: 6386... Loss: 0.014006... Val Loss: 0.054707\n",
      "Epoch: 62/100... Step: 6387... Loss: 0.020364... Val Loss: 0.046385\n",
      "Epoch: 62/100... Step: 6388... Loss: 0.016430... Val Loss: 0.043783\n",
      "Epoch: 62/100... Step: 6389... Loss: 0.022884... Val Loss: 0.043194\n",
      "Epoch: 62/100... Step: 6390... Loss: 0.017572... Val Loss: 0.041384\n",
      "Epoch: 62/100... Step: 6391... Loss: 0.013069... Val Loss: 0.038696\n",
      "Epoch: 62/100... Step: 6392... Loss: 0.023077... Val Loss: 0.034595\n",
      "Epoch: 62/100... Step: 6393... Loss: 0.018474... Val Loss: 0.037834\n",
      "Epoch: 62/100... Step: 6394... Loss: 0.014756... Val Loss: 0.042536\n",
      "Epoch: 62/100... Step: 6395... Loss: 0.013969... Val Loss: 0.050485\n",
      "Epoch: 62/100... Step: 6396... Loss: 0.010554... Val Loss: 0.055502\n",
      "Epoch: 62/100... Step: 6397... Loss: 0.020630... Val Loss: 0.059666\n",
      "Epoch: 62/100... Step: 6398... Loss: 0.018702... Val Loss: 0.062984\n",
      "Epoch: 62/100... Step: 6399... Loss: 0.011658... Val Loss: 0.064374\n",
      "Epoch: 62/100... Step: 6400... Loss: 0.011398... Val Loss: 0.062772\n",
      "Epoch: 62/100... Step: 6401... Loss: 0.015619... Val Loss: 0.059926\n",
      "Epoch: 62/100... Step: 6402... Loss: 0.019008... Val Loss: 0.049227\n",
      "Epoch: 62/100... Step: 6403... Loss: 0.011707... Val Loss: 0.037271\n",
      "Epoch: 62/100... Step: 6404... Loss: 0.015474... Val Loss: 0.031113\n",
      "Epoch: 62/100... Step: 6405... Loss: 0.015826... Val Loss: 0.025323\n",
      "Epoch: 62/100... Step: 6406... Loss: 0.017284... Val Loss: 0.021924\n",
      "Epoch: 62/100... Step: 6407... Loss: 0.014308... Val Loss: 0.019749\n",
      "Epoch: 62/100... Step: 6408... Loss: 0.012408... Val Loss: 0.018720\n",
      "Epoch: 62/100... Step: 6409... Loss: 0.013674... Val Loss: 0.026038\n",
      "Epoch: 62/100... Step: 6410... Loss: 0.015022... Val Loss: 0.031659\n",
      "Epoch: 62/100... Step: 6411... Loss: 0.022594... Val Loss: 0.034180\n",
      "Epoch: 62/100... Step: 6412... Loss: 0.021246... Val Loss: 0.036629\n",
      "Epoch: 62/100... Step: 6413... Loss: 0.020228... Val Loss: 0.034656\n",
      "Epoch: 62/100... Step: 6414... Loss: 0.013994... Val Loss: 0.032397\n",
      "Epoch: 62/100... Step: 6415... Loss: 0.011955... Val Loss: 0.030953\n",
      "Epoch: 62/100... Step: 6416... Loss: 0.017762... Val Loss: 0.029865\n",
      "Epoch: 62/100... Step: 6417... Loss: 0.024107... Val Loss: 0.020808\n",
      "Epoch: 62/100... Step: 6418... Loss: 0.015926... Val Loss: 0.012622\n",
      "Epoch: 62/100... Step: 6419... Loss: 0.018030... Val Loss: 0.010452\n",
      "Epoch: 62/100... Step: 6420... Loss: 0.011432... Val Loss: 0.018227\n",
      "Epoch: 62/100... Step: 6421... Loss: 0.010810... Val Loss: 0.032097\n",
      "Epoch: 62/100... Step: 6422... Loss: 0.012583... Val Loss: 0.042309\n",
      "Epoch: 62/100... Step: 6423... Loss: 0.016731... Val Loss: 0.049920\n",
      "Epoch: 62/100... Step: 6424... Loss: 0.019865... Val Loss: 0.058060\n",
      "Epoch: 62/100... Step: 6425... Loss: 0.015818... Val Loss: 0.065013\n",
      "Epoch: 62/100... Step: 6426... Loss: 0.011244... Val Loss: 0.072324\n",
      "Epoch: 62/100... Step: 6427... Loss: 0.012262... Val Loss: 0.080883\n",
      "Epoch: 62/100... Step: 6428... Loss: 0.014759... Val Loss: 0.089929\n",
      "Epoch: 62/100... Step: 6429... Loss: 0.014113... Val Loss: 0.095197\n",
      "Epoch: 62/100... Step: 6430... Loss: 0.011601... Val Loss: 0.098285\n",
      "Epoch: 62/100... Step: 6431... Loss: 0.016267... Val Loss: 0.096809\n",
      "Epoch: 62/100... Step: 6432... Loss: 0.016783... Val Loss: 0.089127\n",
      "Epoch: 62/100... Step: 6433... Loss: 0.015407... Val Loss: 0.082830\n",
      "Epoch: 62/100... Step: 6434... Loss: 0.013095... Val Loss: 0.076344\n",
      "Epoch: 62/100... Step: 6435... Loss: 0.032056... Val Loss: 0.068909\n",
      "Epoch: 62/100... Step: 6436... Loss: 0.019068... Val Loss: 0.067432\n",
      "Epoch: 62/100... Step: 6437... Loss: 0.017233... Val Loss: 0.068123\n",
      "Epoch: 62/100... Step: 6438... Loss: 0.015952... Val Loss: 0.068638\n",
      "Epoch: 62/100... Step: 6439... Loss: 0.015315... Val Loss: 0.072863\n",
      "Epoch: 62/100... Step: 6440... Loss: 0.018800... Val Loss: 0.079162\n",
      "Epoch: 62/100... Step: 6441... Loss: 0.013655... Val Loss: 0.085425\n",
      "Epoch: 62/100... Step: 6442... Loss: 0.015015... Val Loss: 0.088024\n",
      "Epoch: 62/100... Step: 6443... Loss: 0.019918... Val Loss: 0.087835\n",
      "Epoch: 62/100... Step: 6444... Loss: 0.012709... Val Loss: 0.083934\n",
      "Epoch: 62/100... Step: 6445... Loss: 0.015727... Val Loss: 0.072004\n",
      "Epoch: 62/100... Step: 6446... Loss: 0.016352... Val Loss: 0.059096\n",
      "Epoch: 62/100... Step: 6447... Loss: 0.010592... Val Loss: 0.052383\n",
      "Epoch: 62/100... Step: 6448... Loss: 0.010045... Val Loss: 0.040844\n",
      "Epoch: 63/100... Step: 6449... Loss: 0.016226... Val Loss: 0.047795\n",
      "Epoch: 63/100... Step: 6450... Loss: 0.017537... Val Loss: 0.005064\n",
      "Epoch: 63/100... Step: 6451... Loss: 0.011579... Val Loss: 0.005368\n",
      "Epoch: 63/100... Step: 6452... Loss: 0.013033... Val Loss: 0.030698\n",
      "Epoch: 63/100... Step: 6453... Loss: 0.020913... Val Loss: 0.057755\n",
      "Epoch: 63/100... Step: 6454... Loss: 0.012655... Val Loss: 0.074334\n",
      "Epoch: 63/100... Step: 6455... Loss: 0.018067... Val Loss: 0.091062\n",
      "Epoch: 63/100... Step: 6456... Loss: 0.023711... Val Loss: 0.098198\n",
      "Epoch: 63/100... Step: 6457... Loss: 0.013953... Val Loss: 0.092354\n",
      "Epoch: 63/100... Step: 6458... Loss: 0.016513... Val Loss: 0.084647\n",
      "Epoch: 63/100... Step: 6459... Loss: 0.011525... Val Loss: 0.087762\n",
      "Epoch: 63/100... Step: 6460... Loss: 0.017563... Val Loss: 0.112445\n",
      "Epoch: 63/100... Step: 6461... Loss: 0.013336... Val Loss: 0.112432\n",
      "Epoch: 63/100... Step: 6462... Loss: 0.016163... Val Loss: 0.100528\n",
      "Epoch: 63/100... Step: 6463... Loss: 0.014077... Val Loss: 0.095010\n",
      "Epoch: 63/100... Step: 6464... Loss: 0.014595... Val Loss: 0.096842\n",
      "Epoch: 63/100... Step: 6465... Loss: 0.008965... Val Loss: 0.097764\n",
      "Epoch: 63/100... Step: 6466... Loss: 0.009926... Val Loss: 0.100944\n",
      "Epoch: 63/100... Step: 6467... Loss: 0.014816... Val Loss: 0.107757\n",
      "Epoch: 63/100... Step: 6468... Loss: 0.014451... Val Loss: 0.110199\n",
      "Epoch: 63/100... Step: 6469... Loss: 0.018597... Val Loss: 0.107789\n",
      "Epoch: 63/100... Step: 6470... Loss: 0.022356... Val Loss: 0.103500\n",
      "Epoch: 63/100... Step: 6471... Loss: 0.012208... Val Loss: 0.096477\n",
      "Epoch: 63/100... Step: 6472... Loss: 0.017123... Val Loss: 0.085463\n",
      "Epoch: 63/100... Step: 6473... Loss: 0.014733... Val Loss: 0.074862\n",
      "Epoch: 63/100... Step: 6474... Loss: 0.015713... Val Loss: 0.068478\n",
      "Epoch: 63/100... Step: 6475... Loss: 0.013625... Val Loss: 0.064755\n",
      "Epoch: 63/100... Step: 6476... Loss: 0.015196... Val Loss: 0.058097\n",
      "Epoch: 63/100... Step: 6477... Loss: 0.013916... Val Loss: 0.057520\n",
      "Epoch: 63/100... Step: 6478... Loss: 0.016666... Val Loss: 0.060473\n",
      "Epoch: 63/100... Step: 6479... Loss: 0.019824... Val Loss: 0.064010\n",
      "Epoch: 63/100... Step: 6480... Loss: 0.015851... Val Loss: 0.063695\n",
      "Epoch: 63/100... Step: 6481... Loss: 0.014459... Val Loss: 0.061527\n",
      "Epoch: 63/100... Step: 6482... Loss: 0.013334... Val Loss: 0.056984\n",
      "Epoch: 63/100... Step: 6483... Loss: 0.009367... Val Loss: 0.048618\n",
      "Epoch: 63/100... Step: 6484... Loss: 0.014378... Val Loss: 0.039834\n",
      "Epoch: 63/100... Step: 6485... Loss: 0.013590... Val Loss: 0.034266\n",
      "Epoch: 63/100... Step: 6486... Loss: 0.016518... Val Loss: 0.027052\n",
      "Epoch: 63/100... Step: 6487... Loss: 0.014812... Val Loss: 0.024750\n",
      "Epoch: 63/100... Step: 6488... Loss: 0.013531... Val Loss: 0.010310\n",
      "Epoch: 63/100... Step: 6489... Loss: 0.020572... Val Loss: 0.011837\n",
      "Epoch: 63/100... Step: 6490... Loss: 0.022217... Val Loss: 0.013085\n",
      "Epoch: 63/100... Step: 6491... Loss: 0.020502... Val Loss: 0.015419\n",
      "Epoch: 63/100... Step: 6492... Loss: 0.015179... Val Loss: 0.019054\n",
      "Epoch: 63/100... Step: 6493... Loss: 0.017078... Val Loss: 0.023025\n",
      "Epoch: 63/100... Step: 6494... Loss: 0.014180... Val Loss: 0.019080\n",
      "Epoch: 63/100... Step: 6495... Loss: 0.009747... Val Loss: 0.015065\n",
      "Epoch: 63/100... Step: 6496... Loss: 0.018925... Val Loss: 0.010533\n",
      "Epoch: 63/100... Step: 6497... Loss: 0.015632... Val Loss: 0.011398\n",
      "Epoch: 63/100... Step: 6498... Loss: 0.009241... Val Loss: 0.011934\n",
      "Epoch: 63/100... Step: 6499... Loss: 0.013305... Val Loss: 0.012080\n",
      "Epoch: 63/100... Step: 6500... Loss: 0.022899... Val Loss: 0.013400\n",
      "Epoch: 63/100... Step: 6501... Loss: 0.013939... Val Loss: 0.016666\n",
      "Epoch: 63/100... Step: 6502... Loss: 0.011931... Val Loss: 0.022967\n",
      "Epoch: 63/100... Step: 6503... Loss: 0.021411... Val Loss: 0.021687\n",
      "Epoch: 63/100... Step: 6504... Loss: 0.015504... Val Loss: 0.024123\n",
      "Epoch: 63/100... Step: 6505... Loss: 0.020714... Val Loss: 0.024596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Step: 6506... Loss: 0.016306... Val Loss: 0.021182\n",
      "Epoch: 63/100... Step: 6507... Loss: 0.011401... Val Loss: 0.016391\n",
      "Epoch: 63/100... Step: 6508... Loss: 0.019647... Val Loss: 0.010236\n",
      "Epoch: 63/100... Step: 6509... Loss: 0.018308... Val Loss: 0.011769\n",
      "Epoch: 63/100... Step: 6510... Loss: 0.012931... Val Loss: 0.012823\n",
      "Epoch: 63/100... Step: 6511... Loss: 0.013867... Val Loss: 0.013684\n",
      "Epoch: 63/100... Step: 6512... Loss: 0.021837... Val Loss: 0.014002\n",
      "Epoch: 63/100... Step: 6513... Loss: 0.015683... Val Loss: 0.011564\n",
      "Epoch: 63/100... Step: 6514... Loss: 0.012699... Val Loss: 0.009888\n",
      "Epoch: 63/100... Step: 6515... Loss: 0.016260... Val Loss: 0.013753\n",
      "Epoch: 63/100... Step: 6516... Loss: 0.012606... Val Loss: 0.021939\n",
      "Epoch: 63/100... Step: 6517... Loss: 0.016817... Val Loss: 0.030753\n",
      "Epoch: 63/100... Step: 6518... Loss: 0.018482... Val Loss: 0.037297\n",
      "Epoch: 63/100... Step: 6519... Loss: 0.017370... Val Loss: 0.041480\n",
      "Epoch: 63/100... Step: 6520... Loss: 0.016037... Val Loss: 0.045810\n",
      "Epoch: 63/100... Step: 6521... Loss: 0.017904... Val Loss: 0.050057\n",
      "Epoch: 63/100... Step: 6522... Loss: 0.016010... Val Loss: 0.055051\n",
      "Epoch: 63/100... Step: 6523... Loss: 0.018837... Val Loss: 0.053826\n",
      "Epoch: 63/100... Step: 6524... Loss: 0.011714... Val Loss: 0.049991\n",
      "Epoch: 63/100... Step: 6525... Loss: 0.017602... Val Loss: 0.052789\n",
      "Epoch: 63/100... Step: 6526... Loss: 0.017568... Val Loss: 0.059463\n",
      "Epoch: 63/100... Step: 6527... Loss: 0.008710... Val Loss: 0.064749\n",
      "Epoch: 63/100... Step: 6528... Loss: 0.016504... Val Loss: 0.066654\n",
      "Epoch: 63/100... Step: 6529... Loss: 0.012337... Val Loss: 0.065893\n",
      "Epoch: 63/100... Step: 6530... Loss: 0.012287... Val Loss: 0.056129\n",
      "Epoch: 63/100... Step: 6531... Loss: 0.012869... Val Loss: 0.069457\n",
      "Epoch: 63/100... Step: 6532... Loss: 0.016462... Val Loss: 0.038638\n",
      "Epoch: 63/100... Step: 6533... Loss: 0.014795... Val Loss: 0.016389\n",
      "Epoch: 63/100... Step: 6534... Loss: 0.016040... Val Loss: 0.013566\n",
      "Epoch: 63/100... Step: 6535... Loss: 0.013110... Val Loss: 0.014851\n",
      "Epoch: 63/100... Step: 6536... Loss: 0.013788... Val Loss: 0.012474\n",
      "Epoch: 63/100... Step: 6537... Loss: 0.018173... Val Loss: 0.013318\n",
      "Epoch: 63/100... Step: 6538... Loss: 0.013619... Val Loss: 0.012803\n",
      "Epoch: 63/100... Step: 6539... Loss: 0.022491... Val Loss: 0.015555\n",
      "Epoch: 63/100... Step: 6540... Loss: 0.014995... Val Loss: 0.016461\n",
      "Epoch: 63/100... Step: 6541... Loss: 0.021598... Val Loss: 0.016298\n",
      "Epoch: 63/100... Step: 6542... Loss: 0.016686... Val Loss: 0.016217\n",
      "Epoch: 63/100... Step: 6543... Loss: 0.016298... Val Loss: 0.017802\n",
      "Epoch: 63/100... Step: 6544... Loss: 0.022878... Val Loss: 0.019995\n",
      "Epoch: 63/100... Step: 6545... Loss: 0.009696... Val Loss: 0.019924\n",
      "Epoch: 63/100... Step: 6546... Loss: 0.014964... Val Loss: 0.021918\n",
      "Epoch: 63/100... Step: 6547... Loss: 0.010264... Val Loss: 0.023547\n",
      "Epoch: 63/100... Step: 6548... Loss: 0.018024... Val Loss: 0.028291\n",
      "Epoch: 63/100... Step: 6549... Loss: 0.013486... Val Loss: 0.029444\n",
      "Epoch: 63/100... Step: 6550... Loss: 0.008716... Val Loss: 0.018989\n",
      "Epoch: 63/100... Step: 6551... Loss: 0.014282... Val Loss: 0.016692\n",
      "Epoch: 63/100... Step: 6552... Loss: 0.010253... Val Loss: 0.021726\n",
      "Epoch: 64/100... Step: 6553... Loss: 0.015943... Val Loss: 0.028025\n",
      "Epoch: 64/100... Step: 6554... Loss: 0.012109... Val Loss: 0.054875\n",
      "Epoch: 64/100... Step: 6555... Loss: 0.009632... Val Loss: 0.055496\n",
      "Epoch: 64/100... Step: 6556... Loss: 0.015808... Val Loss: 0.055900\n",
      "Epoch: 64/100... Step: 6557... Loss: 0.009984... Val Loss: 0.059780\n",
      "Epoch: 64/100... Step: 6558... Loss: 0.008481... Val Loss: 0.055214\n",
      "Epoch: 64/100... Step: 6559... Loss: 0.015093... Val Loss: 0.055737\n",
      "Epoch: 64/100... Step: 6560... Loss: 0.013994... Val Loss: 0.057046\n",
      "Epoch: 64/100... Step: 6561... Loss: 0.013787... Val Loss: 0.067799\n",
      "Epoch: 64/100... Step: 6562... Loss: 0.007469... Val Loss: 0.068639\n",
      "Epoch: 64/100... Step: 6563... Loss: 0.011770... Val Loss: 0.074060\n",
      "Epoch: 64/100... Step: 6564... Loss: 0.014804... Val Loss: 0.080190\n",
      "Epoch: 64/100... Step: 6565... Loss: 0.011760... Val Loss: 0.083523\n",
      "Epoch: 64/100... Step: 6566... Loss: 0.007452... Val Loss: 0.085551\n",
      "Epoch: 64/100... Step: 6567... Loss: 0.010912... Val Loss: 0.083359\n",
      "Epoch: 64/100... Step: 6568... Loss: 0.011885... Val Loss: 0.080504\n",
      "Epoch: 64/100... Step: 6569... Loss: 0.025486... Val Loss: 0.077557\n",
      "Epoch: 64/100... Step: 6570... Loss: 0.012210... Val Loss: 0.074967\n",
      "Epoch: 64/100... Step: 6571... Loss: 0.014690... Val Loss: 0.080053\n",
      "Epoch: 64/100... Step: 6572... Loss: 0.013057... Val Loss: 0.079476\n",
      "Epoch: 64/100... Step: 6573... Loss: 0.020884... Val Loss: 0.070262\n",
      "Epoch: 64/100... Step: 6574... Loss: 0.014506... Val Loss: 0.061123\n",
      "Epoch: 64/100... Step: 6575... Loss: 0.012768... Val Loss: 0.052668\n",
      "Epoch: 64/100... Step: 6576... Loss: 0.016395... Val Loss: 0.074462\n",
      "Epoch: 64/100... Step: 6577... Loss: 0.014926... Val Loss: 0.074277\n",
      "Epoch: 64/100... Step: 6578... Loss: 0.019276... Val Loss: 0.071211\n",
      "Epoch: 64/100... Step: 6579... Loss: 0.015970... Val Loss: 0.061751\n",
      "Epoch: 64/100... Step: 6580... Loss: 0.014092... Val Loss: 0.049086\n",
      "Epoch: 64/100... Step: 6581... Loss: 0.013444... Val Loss: 0.034122\n",
      "Epoch: 64/100... Step: 6582... Loss: 0.018035... Val Loss: 0.019017\n",
      "Epoch: 64/100... Step: 6583... Loss: 0.023210... Val Loss: 0.005528\n",
      "Epoch: 64/100... Step: 6584... Loss: 0.018009... Val Loss: 0.010116\n",
      "Epoch: 64/100... Step: 6585... Loss: 0.016081... Val Loss: 0.014914\n",
      "Epoch: 64/100... Step: 6586... Loss: 0.019441... Val Loss: 0.015904\n",
      "Epoch: 64/100... Step: 6587... Loss: 0.018254... Val Loss: 0.013238\n",
      "Epoch: 64/100... Step: 6588... Loss: 0.010913... Val Loss: 0.013869\n",
      "Epoch: 64/100... Step: 6589... Loss: 0.016103... Val Loss: 0.017876\n",
      "Epoch: 64/100... Step: 6590... Loss: 0.011494... Val Loss: 0.027503\n",
      "Epoch: 64/100... Step: 6591... Loss: 0.020925... Val Loss: 0.033303\n",
      "Epoch: 64/100... Step: 6592... Loss: 0.016951... Val Loss: 0.035933\n",
      "Epoch: 64/100... Step: 6593... Loss: 0.015196... Val Loss: 0.041084\n",
      "Epoch: 64/100... Step: 6594... Loss: 0.022974... Val Loss: 0.027055\n",
      "Epoch: 64/100... Step: 6595... Loss: 0.013166... Val Loss: 0.027918\n",
      "Epoch: 64/100... Step: 6596... Loss: 0.015785... Val Loss: 0.021599\n",
      "Epoch: 64/100... Step: 6597... Loss: 0.011797... Val Loss: 0.009937\n",
      "Epoch: 64/100... Step: 6598... Loss: 0.013904... Val Loss: 0.005657\n",
      "Epoch: 64/100... Step: 6599... Loss: 0.012143... Val Loss: 0.010201\n",
      "Epoch: 64/100... Step: 6600... Loss: 0.009604... Val Loss: 0.019442\n",
      "Epoch: 64/100... Step: 6601... Loss: 0.012624... Val Loss: 0.029402\n",
      "Epoch: 64/100... Step: 6602... Loss: 0.009512... Val Loss: 0.035822\n",
      "Epoch: 64/100... Step: 6603... Loss: 0.020810... Val Loss: 0.041588\n",
      "Epoch: 64/100... Step: 6604... Loss: 0.023908... Val Loss: 0.047846\n",
      "Epoch: 64/100... Step: 6605... Loss: 0.012840... Val Loss: 0.047918\n",
      "Epoch: 64/100... Step: 6606... Loss: 0.014480... Val Loss: 0.042458\n",
      "Epoch: 64/100... Step: 6607... Loss: 0.016303... Val Loss: 0.033532\n",
      "Epoch: 64/100... Step: 6608... Loss: 0.011140... Val Loss: 0.021239\n",
      "Epoch: 64/100... Step: 6609... Loss: 0.013947... Val Loss: 0.014777\n",
      "Epoch: 64/100... Step: 6610... Loss: 0.017811... Val Loss: 0.012036\n",
      "Epoch: 64/100... Step: 6611... Loss: 0.013935... Val Loss: 0.018343\n",
      "Epoch: 64/100... Step: 6612... Loss: 0.013449... Val Loss: 0.023948\n",
      "Epoch: 64/100... Step: 6613... Loss: 0.018419... Val Loss: 0.029754\n",
      "Epoch: 64/100... Step: 6614... Loss: 0.009731... Val Loss: 0.035509\n",
      "Epoch: 64/100... Step: 6615... Loss: 0.018247... Val Loss: 0.040326\n",
      "Epoch: 64/100... Step: 6616... Loss: 0.015856... Val Loss: 0.043976\n",
      "Epoch: 64/100... Step: 6617... Loss: 0.012286... Val Loss: 0.045714\n",
      "Epoch: 64/100... Step: 6618... Loss: 0.017805... Val Loss: 0.048272\n",
      "Epoch: 64/100... Step: 6619... Loss: 0.016385... Val Loss: 0.053140\n",
      "Epoch: 64/100... Step: 6620... Loss: 0.018344... Val Loss: 0.051141\n",
      "Epoch: 64/100... Step: 6621... Loss: 0.016878... Val Loss: 0.048294\n",
      "Epoch: 64/100... Step: 6622... Loss: 0.011806... Val Loss: 0.043829\n",
      "Epoch: 64/100... Step: 6623... Loss: 0.022345... Val Loss: 0.042515\n",
      "Epoch: 64/100... Step: 6624... Loss: 0.013231... Val Loss: 0.042172\n",
      "Epoch: 64/100... Step: 6625... Loss: 0.011804... Val Loss: 0.038915\n",
      "Epoch: 64/100... Step: 6626... Loss: 0.013388... Val Loss: 0.036943\n",
      "Epoch: 64/100... Step: 6627... Loss: 0.015219... Val Loss: 0.035894\n",
      "Epoch: 64/100... Step: 6628... Loss: 0.015657... Val Loss: 0.034513\n",
      "Epoch: 64/100... Step: 6629... Loss: 0.013083... Val Loss: 0.031009\n",
      "Epoch: 64/100... Step: 6630... Loss: 0.010202... Val Loss: 0.029545\n",
      "Epoch: 64/100... Step: 6631... Loss: 0.016426... Val Loss: 0.031851\n",
      "Epoch: 64/100... Step: 6632... Loss: 0.015473... Val Loss: 0.037309\n",
      "Epoch: 64/100... Step: 6633... Loss: 0.016069... Val Loss: 0.042296\n",
      "Epoch: 64/100... Step: 6634... Loss: 0.022800... Val Loss: 0.043962\n",
      "Epoch: 64/100... Step: 6635... Loss: 0.015959... Val Loss: 0.039374\n",
      "Epoch: 64/100... Step: 6636... Loss: 0.013941... Val Loss: 0.034757\n",
      "Epoch: 64/100... Step: 6637... Loss: 0.009509... Val Loss: 0.034683\n",
      "Epoch: 64/100... Step: 6638... Loss: 0.011712... Val Loss: 0.038687\n",
      "Epoch: 64/100... Step: 6639... Loss: 0.019857... Val Loss: 0.042423\n",
      "Epoch: 64/100... Step: 6640... Loss: 0.016195... Val Loss: 0.042547\n",
      "Epoch: 64/100... Step: 6641... Loss: 0.016278... Val Loss: 0.034241\n",
      "Epoch: 64/100... Step: 6642... Loss: 0.013267... Val Loss: 0.026542\n",
      "Epoch: 64/100... Step: 6643... Loss: 0.014064... Val Loss: 0.024660\n",
      "Epoch: 64/100... Step: 6644... Loss: 0.017055... Val Loss: 0.027571\n",
      "Epoch: 64/100... Step: 6645... Loss: 0.013491... Val Loss: 0.030782\n",
      "Epoch: 64/100... Step: 6646... Loss: 0.013660... Val Loss: 0.031939\n",
      "Epoch: 64/100... Step: 6647... Loss: 0.012502... Val Loss: 0.033688\n",
      "Epoch: 64/100... Step: 6648... Loss: 0.006664... Val Loss: 0.033770\n",
      "Epoch: 64/100... Step: 6649... Loss: 0.018579... Val Loss: 0.030602\n",
      "Epoch: 64/100... Step: 6650... Loss: 0.013072... Val Loss: 0.022483\n",
      "Epoch: 64/100... Step: 6651... Loss: 0.013792... Val Loss: 0.013284\n",
      "Epoch: 64/100... Step: 6652... Loss: 0.016431... Val Loss: 0.012155\n",
      "Epoch: 64/100... Step: 6653... Loss: 0.019006... Val Loss: 0.016056\n",
      "Epoch: 64/100... Step: 6654... Loss: 0.017182... Val Loss: 0.023232\n",
      "Epoch: 64/100... Step: 6655... Loss: 0.012062... Val Loss: 0.028365\n",
      "Epoch: 64/100... Step: 6656... Loss: 0.013976... Val Loss: 0.027777\n",
      "Epoch: 65/100... Step: 6657... Loss: 0.009699... Val Loss: 0.019540\n",
      "Epoch: 65/100... Step: 6658... Loss: 0.013715... Val Loss: 0.009625\n",
      "Epoch: 65/100... Step: 6659... Loss: 0.014538... Val Loss: 0.026414\n",
      "Epoch: 65/100... Step: 6660... Loss: 0.013649... Val Loss: 0.059272\n",
      "Epoch: 65/100... Step: 6661... Loss: 0.014283... Val Loss: 0.089983\n",
      "Epoch: 65/100... Step: 6662... Loss: 0.010461... Val Loss: 0.110595\n",
      "Epoch: 65/100... Step: 6663... Loss: 0.009996... Val Loss: 0.134784\n",
      "Epoch: 65/100... Step: 6664... Loss: 0.012162... Val Loss: 0.158856\n",
      "Epoch: 65/100... Step: 6665... Loss: 0.016336... Val Loss: 0.166537\n",
      "Epoch: 65/100... Step: 6666... Loss: 0.010948... Val Loss: 0.175965\n",
      "Epoch: 65/100... Step: 6667... Loss: 0.017885... Val Loss: 0.178819\n",
      "Epoch: 65/100... Step: 6668... Loss: 0.006753... Val Loss: 0.174859\n",
      "Epoch: 65/100... Step: 6669... Loss: 0.015853... Val Loss: 0.172903\n",
      "Epoch: 65/100... Step: 6670... Loss: 0.017046... Val Loss: 0.171892\n",
      "Epoch: 65/100... Step: 6671... Loss: 0.010070... Val Loss: 0.171320\n",
      "Epoch: 65/100... Step: 6672... Loss: 0.012794... Val Loss: 0.166559\n",
      "Epoch: 65/100... Step: 6673... Loss: 0.018785... Val Loss: 0.159500\n",
      "Epoch: 65/100... Step: 6674... Loss: 0.019239... Val Loss: 0.148925\n",
      "Epoch: 65/100... Step: 6675... Loss: 0.014622... Val Loss: 0.139994\n",
      "Epoch: 65/100... Step: 6676... Loss: 0.014825... Val Loss: 0.133092\n",
      "Epoch: 65/100... Step: 6677... Loss: 0.013949... Val Loss: 0.125265\n",
      "Epoch: 65/100... Step: 6678... Loss: 0.017707... Val Loss: 0.117134\n",
      "Epoch: 65/100... Step: 6679... Loss: 0.015052... Val Loss: 0.110339\n",
      "Epoch: 65/100... Step: 6680... Loss: 0.018022... Val Loss: 0.104197\n",
      "Epoch: 65/100... Step: 6681... Loss: 0.014351... Val Loss: 0.098239\n",
      "Epoch: 65/100... Step: 6682... Loss: 0.007177... Val Loss: 0.090386\n",
      "Epoch: 65/100... Step: 6683... Loss: 0.010923... Val Loss: 0.081735\n",
      "Epoch: 65/100... Step: 6684... Loss: 0.015218... Val Loss: 0.077021\n",
      "Epoch: 65/100... Step: 6685... Loss: 0.015700... Val Loss: 0.071178\n",
      "Epoch: 65/100... Step: 6686... Loss: 0.012524... Val Loss: 0.065938\n",
      "Epoch: 65/100... Step: 6687... Loss: 0.012542... Val Loss: 0.062514\n",
      "Epoch: 65/100... Step: 6688... Loss: 0.016042... Val Loss: 0.059281\n",
      "Epoch: 65/100... Step: 6689... Loss: 0.012282... Val Loss: 0.057479\n",
      "Epoch: 65/100... Step: 6690... Loss: 0.011867... Val Loss: 0.061160\n",
      "Epoch: 65/100... Step: 6691... Loss: 0.011097... Val Loss: 0.063050\n",
      "Epoch: 65/100... Step: 6692... Loss: 0.009440... Val Loss: 0.065988\n",
      "Epoch: 65/100... Step: 6693... Loss: 0.014077... Val Loss: 0.070209\n",
      "Epoch: 65/100... Step: 6694... Loss: 0.010786... Val Loss: 0.075336\n",
      "Epoch: 65/100... Step: 6695... Loss: 0.013345... Val Loss: 0.078142\n",
      "Epoch: 65/100... Step: 6696... Loss: 0.012208... Val Loss: 0.079031\n",
      "Epoch: 65/100... Step: 6697... Loss: 0.017764... Val Loss: 0.079349\n",
      "Epoch: 65/100... Step: 6698... Loss: 0.015229... Val Loss: 0.078566\n",
      "Epoch: 65/100... Step: 6699... Loss: 0.017418... Val Loss: 0.077159\n",
      "Epoch: 65/100... Step: 6700... Loss: 0.020252... Val Loss: 0.069578\n",
      "Epoch: 65/100... Step: 6701... Loss: 0.017310... Val Loss: 0.059757\n",
      "Epoch: 65/100... Step: 6702... Loss: 0.014675... Val Loss: 0.053522\n",
      "Epoch: 65/100... Step: 6703... Loss: 0.013085... Val Loss: 0.046288\n",
      "Epoch: 65/100... Step: 6704... Loss: 0.015434... Val Loss: 0.038169\n",
      "Epoch: 65/100... Step: 6705... Loss: 0.013604... Val Loss: 0.029045\n",
      "Epoch: 65/100... Step: 6706... Loss: 0.016568... Val Loss: 0.021344\n",
      "Epoch: 65/100... Step: 6707... Loss: 0.016013... Val Loss: 0.012824\n",
      "Epoch: 65/100... Step: 6708... Loss: 0.016366... Val Loss: 0.005895\n",
      "Epoch: 65/100... Step: 6709... Loss: 0.014072... Val Loss: 0.010361\n",
      "Epoch: 65/100... Step: 6710... Loss: 0.012471... Val Loss: 0.018904\n",
      "Epoch: 65/100... Step: 6711... Loss: 0.008386... Val Loss: 0.029026\n",
      "Epoch: 65/100... Step: 6712... Loss: 0.012150... Val Loss: 0.040884\n",
      "Epoch: 65/100... Step: 6713... Loss: 0.013951... Val Loss: 0.049025\n",
      "Epoch: 65/100... Step: 6714... Loss: 0.013555... Val Loss: 0.058142\n",
      "Epoch: 65/100... Step: 6715... Loss: 0.010439... Val Loss: 0.062698\n",
      "Epoch: 65/100... Step: 6716... Loss: 0.009595... Val Loss: 0.060021\n",
      "Epoch: 65/100... Step: 6717... Loss: 0.014446... Val Loss: 0.053853\n",
      "Epoch: 65/100... Step: 6718... Loss: 0.013093... Val Loss: 0.043226\n",
      "Epoch: 65/100... Step: 6719... Loss: 0.012546... Val Loss: 0.035702\n",
      "Epoch: 65/100... Step: 6720... Loss: 0.012704... Val Loss: 0.028643\n",
      "Epoch: 65/100... Step: 6721... Loss: 0.009418... Val Loss: 0.018283\n",
      "Epoch: 65/100... Step: 6722... Loss: 0.007993... Val Loss: 0.011857\n",
      "Epoch: 65/100... Step: 6723... Loss: 0.018589... Val Loss: 0.011587\n",
      "Epoch: 65/100... Step: 6724... Loss: 0.017248... Val Loss: 0.010494\n",
      "Epoch: 65/100... Step: 6725... Loss: 0.013158... Val Loss: 0.008224\n",
      "Epoch: 65/100... Step: 6726... Loss: 0.012070... Val Loss: 0.006063\n",
      "Epoch: 65/100... Step: 6727... Loss: 0.008595... Val Loss: 0.008268\n",
      "Epoch: 65/100... Step: 6728... Loss: 0.009787... Val Loss: 0.009141\n",
      "Epoch: 65/100... Step: 6729... Loss: 0.010385... Val Loss: 0.009893\n",
      "Epoch: 65/100... Step: 6730... Loss: 0.006948... Val Loss: 0.013625\n",
      "Epoch: 65/100... Step: 6731... Loss: 0.014913... Val Loss: 0.013274\n",
      "Epoch: 65/100... Step: 6732... Loss: 0.009611... Val Loss: 0.014198\n",
      "Epoch: 65/100... Step: 6733... Loss: 0.020955... Val Loss: 0.011646\n",
      "Epoch: 65/100... Step: 6734... Loss: 0.011762... Val Loss: 0.011610\n",
      "Epoch: 65/100... Step: 6735... Loss: 0.021036... Val Loss: 0.011499\n",
      "Epoch: 65/100... Step: 6736... Loss: 0.018821... Val Loss: 0.010680\n",
      "Epoch: 65/100... Step: 6737... Loss: 0.012823... Val Loss: 0.010147\n",
      "Epoch: 65/100... Step: 6738... Loss: 0.011148... Val Loss: 0.009971\n",
      "Epoch: 65/100... Step: 6739... Loss: 0.013896... Val Loss: 0.011065\n",
      "Epoch: 65/100... Step: 6740... Loss: 0.008799... Val Loss: 0.012124\n",
      "Epoch: 65/100... Step: 6741... Loss: 0.010437... Val Loss: 0.010986\n",
      "Epoch: 65/100... Step: 6742... Loss: 0.011141... Val Loss: 0.008491\n",
      "Epoch: 65/100... Step: 6743... Loss: 0.015714... Val Loss: 0.008326\n",
      "Epoch: 65/100... Step: 6744... Loss: 0.010040... Val Loss: 0.008455\n",
      "Epoch: 65/100... Step: 6745... Loss: 0.013603... Val Loss: 0.009055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Step: 6746... Loss: 0.011938... Val Loss: 0.009467\n",
      "Epoch: 65/100... Step: 6747... Loss: 0.014718... Val Loss: 0.008735\n",
      "Epoch: 65/100... Step: 6748... Loss: 0.014672... Val Loss: 0.011926\n",
      "Epoch: 65/100... Step: 6749... Loss: 0.013637... Val Loss: 0.017450\n",
      "Epoch: 65/100... Step: 6750... Loss: 0.015241... Val Loss: 0.019736\n",
      "Epoch: 65/100... Step: 6751... Loss: 0.020189... Val Loss: 0.018914\n",
      "Epoch: 65/100... Step: 6752... Loss: 0.026429... Val Loss: 0.016187\n",
      "Epoch: 65/100... Step: 6753... Loss: 0.012516... Val Loss: 0.011292\n",
      "Epoch: 65/100... Step: 6754... Loss: 0.017517... Val Loss: 0.008308\n",
      "Epoch: 65/100... Step: 6755... Loss: 0.015506... Val Loss: 0.008039\n",
      "Epoch: 65/100... Step: 6756... Loss: 0.012164... Val Loss: 0.011857\n",
      "Epoch: 65/100... Step: 6757... Loss: 0.014506... Val Loss: 0.015641\n",
      "Epoch: 65/100... Step: 6758... Loss: 0.018452... Val Loss: 0.017253\n",
      "Epoch: 65/100... Step: 6759... Loss: 0.020558... Val Loss: 0.017623\n",
      "Epoch: 65/100... Step: 6760... Loss: 0.018013... Val Loss: 0.017186\n",
      "Epoch: 66/100... Step: 6761... Loss: 0.015275... Val Loss: 0.062694\n",
      "Epoch: 66/100... Step: 6762... Loss: 0.015739... Val Loss: 0.041656\n",
      "Epoch: 66/100... Step: 6763... Loss: 0.012561... Val Loss: 0.013353\n",
      "Epoch: 66/100... Step: 6764... Loss: 0.014333... Val Loss: 0.069888\n",
      "Epoch: 66/100... Step: 6765... Loss: 0.007947... Val Loss: 0.116847\n",
      "Epoch: 66/100... Step: 6766... Loss: 0.011271... Val Loss: 0.157422\n",
      "Epoch: 66/100... Step: 6767... Loss: 0.013477... Val Loss: 0.178623\n",
      "Epoch: 66/100... Step: 6768... Loss: 0.015883... Val Loss: 0.199669\n",
      "Epoch: 66/100... Step: 6769... Loss: 0.016366... Val Loss: 0.218887\n",
      "Epoch: 66/100... Step: 6770... Loss: 0.021829... Val Loss: 0.235334\n",
      "Epoch: 66/100... Step: 6771... Loss: 0.014171... Val Loss: 0.247310\n",
      "Epoch: 66/100... Step: 6772... Loss: 0.020085... Val Loss: 0.255484\n",
      "Epoch: 66/100... Step: 6773... Loss: 0.020158... Val Loss: 0.261655\n",
      "Epoch: 66/100... Step: 6774... Loss: 0.011752... Val Loss: 0.262923\n",
      "Epoch: 66/100... Step: 6775... Loss: 0.016611... Val Loss: 0.262707\n",
      "Epoch: 66/100... Step: 6776... Loss: 0.012729... Val Loss: 0.262610\n",
      "Epoch: 66/100... Step: 6777... Loss: 0.008881... Val Loss: 0.254677\n",
      "Epoch: 66/100... Step: 6778... Loss: 0.015296... Val Loss: 0.248732\n",
      "Epoch: 66/100... Step: 6779... Loss: 0.011635... Val Loss: 0.237956\n",
      "Epoch: 66/100... Step: 6780... Loss: 0.018665... Val Loss: 0.227255\n",
      "Epoch: 66/100... Step: 6781... Loss: 0.012205... Val Loss: 0.206014\n",
      "Epoch: 66/100... Step: 6782... Loss: 0.013986... Val Loss: 0.173056\n",
      "Epoch: 66/100... Step: 6783... Loss: 0.010691... Val Loss: 0.157146\n",
      "Epoch: 66/100... Step: 6784... Loss: 0.009787... Val Loss: 0.144347\n",
      "Epoch: 66/100... Step: 6785... Loss: 0.016939... Val Loss: 0.136306\n",
      "Epoch: 66/100... Step: 6786... Loss: 0.009950... Val Loss: 0.134631\n",
      "Epoch: 66/100... Step: 6787... Loss: 0.012764... Val Loss: 0.137249\n",
      "Epoch: 66/100... Step: 6788... Loss: 0.015643... Val Loss: 0.139353\n",
      "Epoch: 66/100... Step: 6789... Loss: 0.009863... Val Loss: 0.140282\n",
      "Epoch: 66/100... Step: 6790... Loss: 0.014733... Val Loss: 0.139529\n",
      "Epoch: 66/100... Step: 6791... Loss: 0.015614... Val Loss: 0.134624\n",
      "Epoch: 66/100... Step: 6792... Loss: 0.017569... Val Loss: 0.129662\n",
      "Epoch: 66/100... Step: 6793... Loss: 0.019102... Val Loss: 0.126578\n",
      "Epoch: 66/100... Step: 6794... Loss: 0.011475... Val Loss: 0.123612\n",
      "Epoch: 66/100... Step: 6795... Loss: 0.012965... Val Loss: 0.123425\n",
      "Epoch: 66/100... Step: 6796... Loss: 0.014924... Val Loss: 0.123343\n",
      "Epoch: 66/100... Step: 6797... Loss: 0.010106... Val Loss: 0.126611\n",
      "Epoch: 66/100... Step: 6798... Loss: 0.014131... Val Loss: 0.126595\n",
      "Epoch: 66/100... Step: 6799... Loss: 0.009212... Val Loss: 0.120906\n",
      "Epoch: 66/100... Step: 6800... Loss: 0.014740... Val Loss: 0.115200\n",
      "Epoch: 66/100... Step: 6801... Loss: 0.015921... Val Loss: 0.112029\n",
      "Epoch: 66/100... Step: 6802... Loss: 0.019113... Val Loss: 0.105173\n",
      "Epoch: 66/100... Step: 6803... Loss: 0.013832... Val Loss: 0.099342\n",
      "Epoch: 66/100... Step: 6804... Loss: 0.014915... Val Loss: 0.093471\n",
      "Epoch: 66/100... Step: 6805... Loss: 0.016226... Val Loss: 0.087001\n",
      "Epoch: 66/100... Step: 6806... Loss: 0.021663... Val Loss: 0.083260\n",
      "Epoch: 66/100... Step: 6807... Loss: 0.012702... Val Loss: 0.075940\n",
      "Epoch: 66/100... Step: 6808... Loss: 0.015004... Val Loss: 0.065813\n",
      "Epoch: 66/100... Step: 6809... Loss: 0.007790... Val Loss: 0.054333\n",
      "Epoch: 66/100... Step: 6810... Loss: 0.018696... Val Loss: 0.046556\n",
      "Epoch: 66/100... Step: 6811... Loss: 0.012869... Val Loss: 0.040082\n",
      "Epoch: 66/100... Step: 6812... Loss: 0.009989... Val Loss: 0.031198\n",
      "Epoch: 66/100... Step: 6813... Loss: 0.014309... Val Loss: 0.026649\n",
      "Epoch: 66/100... Step: 6814... Loss: 0.011337... Val Loss: 0.022569\n",
      "Epoch: 66/100... Step: 6815... Loss: 0.010646... Val Loss: 0.018784\n",
      "Epoch: 66/100... Step: 6816... Loss: 0.017743... Val Loss: 0.014193\n",
      "Epoch: 66/100... Step: 6817... Loss: 0.012079... Val Loss: 0.009263\n",
      "Epoch: 66/100... Step: 6818... Loss: 0.013332... Val Loss: 0.007002\n",
      "Epoch: 66/100... Step: 6819... Loss: 0.011253... Val Loss: 0.007446\n",
      "Epoch: 66/100... Step: 6820... Loss: 0.011262... Val Loss: 0.008283\n",
      "Epoch: 66/100... Step: 6821... Loss: 0.011841... Val Loss: 0.009313\n",
      "Epoch: 66/100... Step: 6822... Loss: 0.013821... Val Loss: 0.009659\n",
      "Epoch: 66/100... Step: 6823... Loss: 0.012428... Val Loss: 0.009277\n",
      "Epoch: 66/100... Step: 6824... Loss: 0.022499... Val Loss: 0.009578\n",
      "Epoch: 66/100... Step: 6825... Loss: 0.015672... Val Loss: 0.008805\n",
      "Epoch: 66/100... Step: 6826... Loss: 0.009861... Val Loss: 0.006704\n",
      "Epoch: 66/100... Step: 6827... Loss: 0.006944... Val Loss: 0.013913\n",
      "Epoch: 66/100... Step: 6828... Loss: 0.012545... Val Loss: 0.013814\n",
      "Epoch: 66/100... Step: 6829... Loss: 0.014353... Val Loss: 0.018243\n",
      "Epoch: 66/100... Step: 6830... Loss: 0.009374... Val Loss: 0.017690\n",
      "Epoch: 66/100... Step: 6831... Loss: 0.014330... Val Loss: 0.010882\n",
      "Epoch: 66/100... Step: 6832... Loss: 0.021026... Val Loss: 0.008004\n",
      "Epoch: 66/100... Step: 6833... Loss: 0.015538... Val Loss: 0.014693\n",
      "Epoch: 66/100... Step: 6834... Loss: 0.016004... Val Loss: 0.018822\n",
      "Epoch: 66/100... Step: 6835... Loss: 0.013088... Val Loss: 0.022874\n",
      "Epoch: 66/100... Step: 6836... Loss: 0.011862... Val Loss: 0.027764\n",
      "Epoch: 66/100... Step: 6837... Loss: 0.009491... Val Loss: 0.032998\n",
      "Epoch: 66/100... Step: 6838... Loss: 0.012370... Val Loss: 0.036730\n",
      "Epoch: 66/100... Step: 6839... Loss: 0.010954... Val Loss: 0.038152\n",
      "Epoch: 66/100... Step: 6840... Loss: 0.015812... Val Loss: 0.039682\n",
      "Epoch: 66/100... Step: 6841... Loss: 0.008723... Val Loss: 0.041597\n",
      "Epoch: 66/100... Step: 6842... Loss: 0.008941... Val Loss: 0.041880\n",
      "Epoch: 66/100... Step: 6843... Loss: 0.008719... Val Loss: 0.039249\n",
      "Epoch: 66/100... Step: 6844... Loss: 0.014415... Val Loss: 0.037578\n",
      "Epoch: 66/100... Step: 6845... Loss: 0.014765... Val Loss: 0.031252\n",
      "Epoch: 66/100... Step: 6846... Loss: 0.009541... Val Loss: 0.026762\n",
      "Epoch: 66/100... Step: 6847... Loss: 0.009816... Val Loss: 0.027084\n",
      "Epoch: 66/100... Step: 6848... Loss: 0.016345... Val Loss: 0.026778\n",
      "Epoch: 66/100... Step: 6849... Loss: 0.010544... Val Loss: 0.028307\n",
      "Epoch: 66/100... Step: 6850... Loss: 0.009174... Val Loss: 0.027030\n",
      "Epoch: 66/100... Step: 6851... Loss: 0.007831... Val Loss: 0.029026\n",
      "Epoch: 66/100... Step: 6852... Loss: 0.012993... Val Loss: 0.031959\n",
      "Epoch: 66/100... Step: 6853... Loss: 0.006944... Val Loss: 0.029843\n",
      "Epoch: 66/100... Step: 6854... Loss: 0.018413... Val Loss: 0.026444\n",
      "Epoch: 66/100... Step: 6855... Loss: 0.010864... Val Loss: 0.021655\n",
      "Epoch: 66/100... Step: 6856... Loss: 0.017453... Val Loss: 0.015016\n",
      "Epoch: 66/100... Step: 6857... Loss: 0.017797... Val Loss: 0.011544\n",
      "Epoch: 66/100... Step: 6858... Loss: 0.012399... Val Loss: 0.012993\n",
      "Epoch: 66/100... Step: 6859... Loss: 0.008441... Val Loss: 0.013478\n",
      "Epoch: 66/100... Step: 6860... Loss: 0.015544... Val Loss: 0.013795\n",
      "Epoch: 66/100... Step: 6861... Loss: 0.012674... Val Loss: 0.013156\n",
      "Epoch: 66/100... Step: 6862... Loss: 0.011562... Val Loss: 0.012692\n",
      "Epoch: 66/100... Step: 6863... Loss: 0.011614... Val Loss: 0.014067\n",
      "Epoch: 66/100... Step: 6864... Loss: 0.016424... Val Loss: 0.019818\n",
      "Epoch: 67/100... Step: 6865... Loss: 0.010718... Val Loss: 0.023102\n",
      "Epoch: 67/100... Step: 6866... Loss: 0.019237... Val Loss: 0.019056\n",
      "Epoch: 67/100... Step: 6867... Loss: 0.012665... Val Loss: 0.097230\n",
      "Epoch: 67/100... Step: 6868... Loss: 0.015694... Val Loss: 0.169481\n",
      "Epoch: 67/100... Step: 6869... Loss: 0.014205... Val Loss: 0.219019\n",
      "Epoch: 67/100... Step: 6870... Loss: 0.013999... Val Loss: 0.258746\n",
      "Epoch: 67/100... Step: 6871... Loss: 0.010826... Val Loss: 0.264030\n",
      "Epoch: 67/100... Step: 6872... Loss: 0.008984... Val Loss: 0.285271\n",
      "Epoch: 67/100... Step: 6873... Loss: 0.014501... Val Loss: 0.292155\n",
      "Epoch: 67/100... Step: 6874... Loss: 0.009904... Val Loss: 0.301846\n",
      "Epoch: 67/100... Step: 6875... Loss: 0.010704... Val Loss: 0.316478\n",
      "Epoch: 67/100... Step: 6876... Loss: 0.013110... Val Loss: 0.329001\n",
      "Epoch: 67/100... Step: 6877... Loss: 0.014534... Val Loss: 0.341647\n",
      "Epoch: 67/100... Step: 6878... Loss: 0.014097... Val Loss: 0.356524\n",
      "Epoch: 67/100... Step: 6879... Loss: 0.012947... Val Loss: 0.360536\n",
      "Epoch: 67/100... Step: 6880... Loss: 0.015619... Val Loss: 0.360664\n",
      "Epoch: 67/100... Step: 6881... Loss: 0.009346... Val Loss: 0.362014\n",
      "Epoch: 67/100... Step: 6882... Loss: 0.014093... Val Loss: 0.359039\n",
      "Epoch: 67/100... Step: 6883... Loss: 0.016541... Val Loss: 0.352779\n",
      "Epoch: 67/100... Step: 6884... Loss: 0.010454... Val Loss: 0.350378\n",
      "Epoch: 67/100... Step: 6885... Loss: 0.010557... Val Loss: 0.349243\n",
      "Epoch: 67/100... Step: 6886... Loss: 0.014116... Val Loss: 0.347620\n",
      "Epoch: 67/100... Step: 6887... Loss: 0.012863... Val Loss: 0.345870\n",
      "Epoch: 67/100... Step: 6888... Loss: 0.015890... Val Loss: 0.341361\n",
      "Epoch: 67/100... Step: 6889... Loss: 0.020955... Val Loss: 0.335164\n",
      "Epoch: 67/100... Step: 6890... Loss: 0.020252... Val Loss: 0.327421\n",
      "Epoch: 67/100... Step: 6891... Loss: 0.020624... Val Loss: 0.315730\n",
      "Epoch: 67/100... Step: 6892... Loss: 0.013622... Val Loss: 0.303824\n",
      "Epoch: 67/100... Step: 6893... Loss: 0.016505... Val Loss: 0.288926\n",
      "Epoch: 67/100... Step: 6894... Loss: 0.010197... Val Loss: 0.282266\n",
      "Epoch: 67/100... Step: 6895... Loss: 0.010211... Val Loss: 0.271946\n",
      "Epoch: 67/100... Step: 6896... Loss: 0.013329... Val Loss: 0.259162\n",
      "Epoch: 67/100... Step: 6897... Loss: 0.010131... Val Loss: 0.246487\n",
      "Epoch: 67/100... Step: 6898... Loss: 0.016247... Val Loss: 0.236207\n",
      "Epoch: 67/100... Step: 6899... Loss: 0.008857... Val Loss: 0.225605\n",
      "Epoch: 67/100... Step: 6900... Loss: 0.012854... Val Loss: 0.213801\n",
      "Epoch: 67/100... Step: 6901... Loss: 0.011084... Val Loss: 0.203128\n",
      "Epoch: 67/100... Step: 6902... Loss: 0.011662... Val Loss: 0.189567\n",
      "Epoch: 67/100... Step: 6903... Loss: 0.010965... Val Loss: 0.175515\n",
      "Epoch: 67/100... Step: 6904... Loss: 0.009977... Val Loss: 0.163821\n",
      "Epoch: 67/100... Step: 6905... Loss: 0.010739... Val Loss: 0.146191\n",
      "Epoch: 67/100... Step: 6906... Loss: 0.009552... Val Loss: 0.124060\n",
      "Epoch: 67/100... Step: 6907... Loss: 0.015143... Val Loss: 0.112881\n",
      "Epoch: 67/100... Step: 6908... Loss: 0.017826... Val Loss: 0.100420\n",
      "Epoch: 67/100... Step: 6909... Loss: 0.014922... Val Loss: 0.087946\n",
      "Epoch: 67/100... Step: 6910... Loss: 0.023213... Val Loss: 0.074925\n",
      "Epoch: 67/100... Step: 6911... Loss: 0.013244... Val Loss: 0.059332\n",
      "Epoch: 67/100... Step: 6912... Loss: 0.010569... Val Loss: 0.042736\n",
      "Epoch: 67/100... Step: 6913... Loss: 0.009168... Val Loss: 0.024955\n",
      "Epoch: 67/100... Step: 6914... Loss: 0.013039... Val Loss: 0.010343\n",
      "Epoch: 67/100... Step: 6915... Loss: 0.011261... Val Loss: 0.007778\n",
      "Epoch: 67/100... Step: 6916... Loss: 0.009578... Val Loss: 0.020130\n",
      "Epoch: 67/100... Step: 6917... Loss: 0.008180... Val Loss: 0.029926\n",
      "Epoch: 67/100... Step: 6918... Loss: 0.015133... Val Loss: 0.037834\n",
      "Epoch: 67/100... Step: 6919... Loss: 0.013917... Val Loss: 0.043997\n",
      "Epoch: 67/100... Step: 6920... Loss: 0.011749... Val Loss: 0.045944\n",
      "Epoch: 67/100... Step: 6921... Loss: 0.010093... Val Loss: 0.044938\n",
      "Epoch: 67/100... Step: 6922... Loss: 0.015163... Val Loss: 0.040267\n",
      "Epoch: 67/100... Step: 6923... Loss: 0.014910... Val Loss: 0.035053\n",
      "Epoch: 67/100... Step: 6924... Loss: 0.013973... Val Loss: 0.029533\n",
      "Epoch: 67/100... Step: 6925... Loss: 0.011579... Val Loss: 0.025010\n",
      "Epoch: 67/100... Step: 6926... Loss: 0.007587... Val Loss: 0.021613\n",
      "Epoch: 67/100... Step: 6927... Loss: 0.017473... Val Loss: 0.018870\n",
      "Epoch: 67/100... Step: 6928... Loss: 0.009307... Val Loss: 0.013908\n",
      "Epoch: 67/100... Step: 6929... Loss: 0.014911... Val Loss: 0.011107\n",
      "Epoch: 67/100... Step: 6930... Loss: 0.010727... Val Loss: 0.008054\n",
      "Epoch: 67/100... Step: 6931... Loss: 0.008218... Val Loss: 0.007031\n",
      "Epoch: 67/100... Step: 6932... Loss: 0.014937... Val Loss: 0.005337\n",
      "Epoch: 67/100... Step: 6933... Loss: 0.010332... Val Loss: 0.004442\n",
      "Epoch: 67/100... Step: 6934... Loss: 0.013992... Val Loss: 0.003885\n",
      "Epoch: 67/100... Step: 6935... Loss: 0.014052... Val Loss: 0.004000\n",
      "Epoch: 67/100... Step: 6936... Loss: 0.017188... Val Loss: 0.005062\n",
      "Epoch: 67/100... Step: 6937... Loss: 0.015773... Val Loss: 0.004166\n",
      "Epoch: 67/100... Step: 6938... Loss: 0.012367... Val Loss: 0.005609\n",
      "Epoch: 67/100... Step: 6939... Loss: 0.011279... Val Loss: 0.005793\n",
      "Epoch: 67/100... Step: 6940... Loss: 0.014286... Val Loss: 0.005558\n",
      "Epoch: 67/100... Step: 6941... Loss: 0.012880... Val Loss: 0.006302\n",
      "Epoch: 67/100... Step: 6942... Loss: 0.010611... Val Loss: 0.007918\n",
      "Epoch: 67/100... Step: 6943... Loss: 0.021216... Val Loss: 0.011542\n",
      "Epoch: 67/100... Step: 6944... Loss: 0.008679... Val Loss: 0.015780\n",
      "Epoch: 67/100... Step: 6945... Loss: 0.009343... Val Loss: 0.015868\n",
      "Epoch: 67/100... Step: 6946... Loss: 0.015080... Val Loss: 0.013031\n",
      "Epoch: 67/100... Step: 6947... Loss: 0.008681... Val Loss: 0.011573\n",
      "Epoch: 67/100... Step: 6948... Loss: 0.016351... Val Loss: 0.009658\n",
      "Epoch: 67/100... Step: 6949... Loss: 0.014982... Val Loss: 0.007416\n",
      "Epoch: 67/100... Step: 6950... Loss: 0.014094... Val Loss: 0.005349\n",
      "Epoch: 67/100... Step: 6951... Loss: 0.011820... Val Loss: 0.007683\n",
      "Epoch: 67/100... Step: 6952... Loss: 0.012349... Val Loss: 0.010254\n",
      "Epoch: 67/100... Step: 6953... Loss: 0.011991... Val Loss: 0.011826\n",
      "Epoch: 67/100... Step: 6954... Loss: 0.015582... Val Loss: 0.011283\n",
      "Epoch: 67/100... Step: 6955... Loss: 0.013498... Val Loss: 0.009323\n",
      "Epoch: 67/100... Step: 6956... Loss: 0.013082... Val Loss: 0.008497\n",
      "Epoch: 67/100... Step: 6957... Loss: 0.011618... Val Loss: 0.013809\n",
      "Epoch: 67/100... Step: 6958... Loss: 0.009976... Val Loss: 0.022716\n",
      "Epoch: 67/100... Step: 6959... Loss: 0.017037... Val Loss: 0.032044\n",
      "Epoch: 67/100... Step: 6960... Loss: 0.007271... Val Loss: 0.037958\n",
      "Epoch: 67/100... Step: 6961... Loss: 0.015382... Val Loss: 0.045035\n",
      "Epoch: 67/100... Step: 6962... Loss: 0.011206... Val Loss: 0.050684\n",
      "Epoch: 67/100... Step: 6963... Loss: 0.012835... Val Loss: 0.053809\n",
      "Epoch: 67/100... Step: 6964... Loss: 0.016478... Val Loss: 0.058617\n",
      "Epoch: 67/100... Step: 6965... Loss: 0.014863... Val Loss: 0.062182\n",
      "Epoch: 67/100... Step: 6966... Loss: 0.016574... Val Loss: 0.065430\n",
      "Epoch: 67/100... Step: 6967... Loss: 0.010333... Val Loss: 0.067361\n",
      "Epoch: 67/100... Step: 6968... Loss: 0.019198... Val Loss: 0.067377\n",
      "Epoch: 68/100... Step: 6969... Loss: 0.009432... Val Loss: 0.015905\n",
      "Epoch: 68/100... Step: 6970... Loss: 0.015404... Val Loss: 0.061602\n",
      "Epoch: 68/100... Step: 6971... Loss: 0.012804... Val Loss: 0.137874\n",
      "Epoch: 68/100... Step: 6972... Loss: 0.014827... Val Loss: 0.197079\n",
      "Epoch: 68/100... Step: 6973... Loss: 0.011530... Val Loss: 0.247698\n",
      "Epoch: 68/100... Step: 6974... Loss: 0.015905... Val Loss: 0.282848\n",
      "Epoch: 68/100... Step: 6975... Loss: 0.011094... Val Loss: 0.309795\n",
      "Epoch: 68/100... Step: 6976... Loss: 0.009766... Val Loss: 0.329294\n",
      "Epoch: 68/100... Step: 6977... Loss: 0.011980... Val Loss: 0.344841\n",
      "Epoch: 68/100... Step: 6978... Loss: 0.010148... Val Loss: 0.354203\n",
      "Epoch: 68/100... Step: 6979... Loss: 0.006406... Val Loss: 0.360156\n",
      "Epoch: 68/100... Step: 6980... Loss: 0.013420... Val Loss: 0.359317\n",
      "Epoch: 68/100... Step: 6981... Loss: 0.016403... Val Loss: 0.354636\n",
      "Epoch: 68/100... Step: 6982... Loss: 0.013871... Val Loss: 0.336881\n",
      "Epoch: 68/100... Step: 6983... Loss: 0.010674... Val Loss: 0.324801\n",
      "Epoch: 68/100... Step: 6984... Loss: 0.010100... Val Loss: 0.315888\n",
      "Epoch: 68/100... Step: 6985... Loss: 0.012001... Val Loss: 0.307208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Step: 6986... Loss: 0.016129... Val Loss: 0.301626\n",
      "Epoch: 68/100... Step: 6987... Loss: 0.015894... Val Loss: 0.299430\n",
      "Epoch: 68/100... Step: 6988... Loss: 0.008121... Val Loss: 0.295790\n",
      "Epoch: 68/100... Step: 6989... Loss: 0.010055... Val Loss: 0.288995\n",
      "Epoch: 68/100... Step: 6990... Loss: 0.012255... Val Loss: 0.277295\n",
      "Epoch: 68/100... Step: 6991... Loss: 0.008944... Val Loss: 0.265252\n",
      "Epoch: 68/100... Step: 6992... Loss: 0.011385... Val Loss: 0.255434\n",
      "Epoch: 68/100... Step: 6993... Loss: 0.008910... Val Loss: 0.251693\n",
      "Epoch: 68/100... Step: 6994... Loss: 0.012880... Val Loss: 0.249079\n",
      "Epoch: 68/100... Step: 6995... Loss: 0.016295... Val Loss: 0.240232\n",
      "Epoch: 68/100... Step: 6996... Loss: 0.014372... Val Loss: 0.226704\n",
      "Epoch: 68/100... Step: 6997... Loss: 0.014993... Val Loss: 0.212451\n",
      "Epoch: 68/100... Step: 6998... Loss: 0.015342... Val Loss: 0.197683\n",
      "Epoch: 68/100... Step: 6999... Loss: 0.018825... Val Loss: 0.180919\n",
      "Epoch: 68/100... Step: 7000... Loss: 0.009441... Val Loss: 0.163922\n",
      "Epoch: 68/100... Step: 7001... Loss: 0.011754... Val Loss: 0.147797\n",
      "Epoch: 68/100... Step: 7002... Loss: 0.010484... Val Loss: 0.131239\n",
      "Epoch: 68/100... Step: 7003... Loss: 0.010524... Val Loss: 0.115870\n",
      "Epoch: 68/100... Step: 7004... Loss: 0.019808... Val Loss: 0.100348\n",
      "Epoch: 68/100... Step: 7005... Loss: 0.016538... Val Loss: 0.085881\n",
      "Epoch: 68/100... Step: 7006... Loss: 0.014304... Val Loss: 0.073821\n",
      "Epoch: 68/100... Step: 7007... Loss: 0.009213... Val Loss: 0.062002\n",
      "Epoch: 68/100... Step: 7008... Loss: 0.013086... Val Loss: 0.053536\n",
      "Epoch: 68/100... Step: 7009... Loss: 0.013411... Val Loss: 0.042965\n",
      "Epoch: 68/100... Step: 7010... Loss: 0.016705... Val Loss: 0.034551\n",
      "Epoch: 68/100... Step: 7011... Loss: 0.017173... Val Loss: 0.028708\n",
      "Epoch: 68/100... Step: 7012... Loss: 0.008638... Val Loss: 0.023368\n",
      "Epoch: 68/100... Step: 7013... Loss: 0.007655... Val Loss: 0.022810\n",
      "Epoch: 68/100... Step: 7014... Loss: 0.010929... Val Loss: 0.021124\n",
      "Epoch: 68/100... Step: 7015... Loss: 0.012660... Val Loss: 0.021715\n",
      "Epoch: 68/100... Step: 7016... Loss: 0.008570... Val Loss: 0.026749\n",
      "Epoch: 68/100... Step: 7017... Loss: 0.014504... Val Loss: 0.032506\n",
      "Epoch: 68/100... Step: 7018... Loss: 0.007803... Val Loss: 0.037275\n",
      "Epoch: 68/100... Step: 7019... Loss: 0.013695... Val Loss: 0.042249\n",
      "Epoch: 68/100... Step: 7020... Loss: 0.012048... Val Loss: 0.042692\n",
      "Epoch: 68/100... Step: 7021... Loss: 0.012199... Val Loss: 0.043479\n",
      "Epoch: 68/100... Step: 7022... Loss: 0.009750... Val Loss: 0.040976\n",
      "Epoch: 68/100... Step: 7023... Loss: 0.010924... Val Loss: 0.029974\n",
      "Epoch: 68/100... Step: 7024... Loss: 0.014437... Val Loss: 0.027877\n",
      "Epoch: 68/100... Step: 7025... Loss: 0.013815... Val Loss: 0.024505\n",
      "Epoch: 68/100... Step: 7026... Loss: 0.010155... Val Loss: 0.018671\n",
      "Epoch: 68/100... Step: 7027... Loss: 0.006972... Val Loss: 0.009078\n",
      "Epoch: 68/100... Step: 7028... Loss: 0.014270... Val Loss: 0.005677\n",
      "Epoch: 68/100... Step: 7029... Loss: 0.012779... Val Loss: 0.009579\n",
      "Epoch: 68/100... Step: 7030... Loss: 0.015578... Val Loss: 0.017851\n",
      "Epoch: 68/100... Step: 7031... Loss: 0.005590... Val Loss: 0.026837\n",
      "Epoch: 68/100... Step: 7032... Loss: 0.016935... Val Loss: 0.037782\n",
      "Epoch: 68/100... Step: 7033... Loss: 0.008510... Val Loss: 0.048784\n",
      "Epoch: 68/100... Step: 7034... Loss: 0.017968... Val Loss: 0.058881\n",
      "Epoch: 68/100... Step: 7035... Loss: 0.013651... Val Loss: 0.066222\n",
      "Epoch: 68/100... Step: 7036... Loss: 0.015682... Val Loss: 0.072717\n",
      "Epoch: 68/100... Step: 7037... Loss: 0.015981... Val Loss: 0.075791\n",
      "Epoch: 68/100... Step: 7038... Loss: 0.013175... Val Loss: 0.073318\n",
      "Epoch: 68/100... Step: 7039... Loss: 0.014009... Val Loss: 0.071769\n",
      "Epoch: 68/100... Step: 7040... Loss: 0.014248... Val Loss: 0.066781\n",
      "Epoch: 68/100... Step: 7041... Loss: 0.009437... Val Loss: 0.063436\n",
      "Epoch: 68/100... Step: 7042... Loss: 0.010647... Val Loss: 0.058198\n",
      "Epoch: 68/100... Step: 7043... Loss: 0.016669... Val Loss: 0.053333\n",
      "Epoch: 68/100... Step: 7044... Loss: 0.012179... Val Loss: 0.048052\n",
      "Epoch: 68/100... Step: 7045... Loss: 0.011572... Val Loss: 0.047881\n",
      "Epoch: 68/100... Step: 7046... Loss: 0.015020... Val Loss: 0.045703\n",
      "Epoch: 68/100... Step: 7047... Loss: 0.016043... Val Loss: 0.045282\n",
      "Epoch: 68/100... Step: 7048... Loss: 0.011557... Val Loss: 0.043695\n",
      "Epoch: 68/100... Step: 7049... Loss: 0.017469... Val Loss: 0.040688\n",
      "Epoch: 68/100... Step: 7050... Loss: 0.016229... Val Loss: 0.038293\n",
      "Epoch: 68/100... Step: 7051... Loss: 0.013445... Val Loss: 0.039373\n",
      "Epoch: 68/100... Step: 7052... Loss: 0.014263... Val Loss: 0.038889\n",
      "Epoch: 68/100... Step: 7053... Loss: 0.014982... Val Loss: 0.036953\n",
      "Epoch: 68/100... Step: 7054... Loss: 0.013716... Val Loss: 0.037085\n",
      "Epoch: 68/100... Step: 7055... Loss: 0.017419... Val Loss: 0.037003\n",
      "Epoch: 68/100... Step: 7056... Loss: 0.009570... Val Loss: 0.034495\n",
      "Epoch: 68/100... Step: 7057... Loss: 0.009337... Val Loss: 0.032080\n",
      "Epoch: 68/100... Step: 7058... Loss: 0.014060... Val Loss: 0.031904\n",
      "Epoch: 68/100... Step: 7059... Loss: 0.011974... Val Loss: 0.034933\n",
      "Epoch: 68/100... Step: 7060... Loss: 0.008297... Val Loss: 0.039006\n",
      "Epoch: 68/100... Step: 7061... Loss: 0.013976... Val Loss: 0.043164\n",
      "Epoch: 68/100... Step: 7062... Loss: 0.015316... Val Loss: 0.048792\n",
      "Epoch: 68/100... Step: 7063... Loss: 0.011572... Val Loss: 0.052412\n",
      "Epoch: 68/100... Step: 7064... Loss: 0.011764... Val Loss: 0.055338\n",
      "Epoch: 68/100... Step: 7065... Loss: 0.008302... Val Loss: 0.058286\n",
      "Epoch: 68/100... Step: 7066... Loss: 0.006215... Val Loss: 0.052507\n",
      "Epoch: 68/100... Step: 7067... Loss: 0.009000... Val Loss: 0.042848\n",
      "Epoch: 68/100... Step: 7068... Loss: 0.008190... Val Loss: 0.036314\n",
      "Epoch: 68/100... Step: 7069... Loss: 0.016559... Val Loss: 0.028922\n",
      "Epoch: 68/100... Step: 7070... Loss: 0.008844... Val Loss: 0.021151\n",
      "Epoch: 68/100... Step: 7071... Loss: 0.012249... Val Loss: 0.015150\n",
      "Epoch: 68/100... Step: 7072... Loss: 0.008079... Val Loss: 0.009695\n",
      "Epoch: 69/100... Step: 7073... Loss: 0.014899... Val Loss: 0.052318\n",
      "Epoch: 69/100... Step: 7074... Loss: 0.018647... Val Loss: 0.009167\n",
      "Epoch: 69/100... Step: 7075... Loss: 0.015419... Val Loss: 0.070313\n",
      "Epoch: 69/100... Step: 7076... Loss: 0.015931... Val Loss: 0.128347\n",
      "Epoch: 69/100... Step: 7077... Loss: 0.011183... Val Loss: 0.169939\n",
      "Epoch: 69/100... Step: 7078... Loss: 0.011702... Val Loss: 0.197047\n",
      "Epoch: 69/100... Step: 7079... Loss: 0.006427... Val Loss: 0.220115\n",
      "Epoch: 69/100... Step: 7080... Loss: 0.010640... Val Loss: 0.241127\n",
      "Epoch: 69/100... Step: 7081... Loss: 0.010778... Val Loss: 0.262067\n",
      "Epoch: 69/100... Step: 7082... Loss: 0.014142... Val Loss: 0.277765\n",
      "Epoch: 69/100... Step: 7083... Loss: 0.010206... Val Loss: 0.265674\n",
      "Epoch: 69/100... Step: 7084... Loss: 0.006406... Val Loss: 0.255771\n",
      "Epoch: 69/100... Step: 7085... Loss: 0.016235... Val Loss: 0.246384\n",
      "Epoch: 69/100... Step: 7086... Loss: 0.011908... Val Loss: 0.246540\n",
      "Epoch: 69/100... Step: 7087... Loss: 0.012608... Val Loss: 0.240243\n",
      "Epoch: 69/100... Step: 7088... Loss: 0.012332... Val Loss: 0.238241\n",
      "Epoch: 69/100... Step: 7089... Loss: 0.015219... Val Loss: 0.237143\n",
      "Epoch: 69/100... Step: 7090... Loss: 0.013183... Val Loss: 0.237032\n",
      "Epoch: 69/100... Step: 7091... Loss: 0.017423... Val Loss: 0.235229\n",
      "Epoch: 69/100... Step: 7092... Loss: 0.009674... Val Loss: 0.228811\n",
      "Epoch: 69/100... Step: 7093... Loss: 0.014836... Val Loss: 0.208656\n",
      "Epoch: 69/100... Step: 7094... Loss: 0.008257... Val Loss: 0.188396\n",
      "Epoch: 69/100... Step: 7095... Loss: 0.014735... Val Loss: 0.159701\n",
      "Epoch: 69/100... Step: 7096... Loss: 0.007278... Val Loss: 0.150790\n",
      "Epoch: 69/100... Step: 7097... Loss: 0.010823... Val Loss: 0.143500\n",
      "Epoch: 69/100... Step: 7098... Loss: 0.015931... Val Loss: 0.133964\n",
      "Epoch: 69/100... Step: 7099... Loss: 0.011623... Val Loss: 0.123540\n",
      "Epoch: 69/100... Step: 7100... Loss: 0.010213... Val Loss: 0.111136\n",
      "Epoch: 69/100... Step: 7101... Loss: 0.011000... Val Loss: 0.103135\n",
      "Epoch: 69/100... Step: 7102... Loss: 0.016245... Val Loss: 0.096011\n",
      "Epoch: 69/100... Step: 7103... Loss: 0.014043... Val Loss: 0.091741\n",
      "Epoch: 69/100... Step: 7104... Loss: 0.010794... Val Loss: 0.090712\n",
      "Epoch: 69/100... Step: 7105... Loss: 0.014345... Val Loss: 0.090354\n",
      "Epoch: 69/100... Step: 7106... Loss: 0.010935... Val Loss: 0.089667\n",
      "Epoch: 69/100... Step: 7107... Loss: 0.007520... Val Loss: 0.088520\n",
      "Epoch: 69/100... Step: 7108... Loss: 0.014279... Val Loss: 0.086290\n",
      "Epoch: 69/100... Step: 7109... Loss: 0.007264... Val Loss: 0.084846\n",
      "Epoch: 69/100... Step: 7110... Loss: 0.018126... Val Loss: 0.082057\n",
      "Epoch: 69/100... Step: 7111... Loss: 0.008385... Val Loss: 0.080520\n",
      "Epoch: 69/100... Step: 7112... Loss: 0.011326... Val Loss: 0.079117\n",
      "Epoch: 69/100... Step: 7113... Loss: 0.008931... Val Loss: 0.077105\n",
      "Epoch: 69/100... Step: 7114... Loss: 0.010567... Val Loss: 0.072890\n",
      "Epoch: 69/100... Step: 7115... Loss: 0.007877... Val Loss: 0.067775\n",
      "Epoch: 69/100... Step: 7116... Loss: 0.010685... Val Loss: 0.062156\n",
      "Epoch: 69/100... Step: 7117... Loss: 0.004494... Val Loss: 0.057898\n",
      "Epoch: 69/100... Step: 7118... Loss: 0.013103... Val Loss: 0.051497\n",
      "Epoch: 69/100... Step: 7119... Loss: 0.012955... Val Loss: 0.045824\n",
      "Epoch: 69/100... Step: 7120... Loss: 0.010051... Val Loss: 0.040862\n",
      "Epoch: 69/100... Step: 7121... Loss: 0.016399... Val Loss: 0.036037\n",
      "Epoch: 69/100... Step: 7122... Loss: 0.009481... Val Loss: 0.032491\n",
      "Epoch: 69/100... Step: 7123... Loss: 0.010793... Val Loss: 0.031088\n",
      "Epoch: 69/100... Step: 7124... Loss: 0.016118... Val Loss: 0.026084\n",
      "Epoch: 69/100... Step: 7125... Loss: 0.005478... Val Loss: 0.024715\n",
      "Epoch: 69/100... Step: 7126... Loss: 0.011858... Val Loss: 0.023549\n",
      "Epoch: 69/100... Step: 7127... Loss: 0.018557... Val Loss: 0.018702\n",
      "Epoch: 69/100... Step: 7128... Loss: 0.018004... Val Loss: 0.014342\n",
      "Epoch: 69/100... Step: 7129... Loss: 0.012332... Val Loss: 0.009283\n",
      "Epoch: 69/100... Step: 7130... Loss: 0.012037... Val Loss: 0.004112\n",
      "Epoch: 69/100... Step: 7131... Loss: 0.006894... Val Loss: 0.006862\n",
      "Epoch: 69/100... Step: 7132... Loss: 0.008547... Val Loss: 0.010236\n",
      "Epoch: 69/100... Step: 7133... Loss: 0.013188... Val Loss: 0.015321\n",
      "Epoch: 69/100... Step: 7134... Loss: 0.009184... Val Loss: 0.022155\n",
      "Epoch: 69/100... Step: 7135... Loss: 0.014732... Val Loss: 0.025733\n",
      "Epoch: 69/100... Step: 7136... Loss: 0.016379... Val Loss: 0.028293\n",
      "Epoch: 69/100... Step: 7137... Loss: 0.013687... Val Loss: 0.029932\n",
      "Epoch: 69/100... Step: 7138... Loss: 0.014279... Val Loss: 0.033017\n",
      "Epoch: 69/100... Step: 7139... Loss: 0.013323... Val Loss: 0.036326\n",
      "Epoch: 69/100... Step: 7140... Loss: 0.013034... Val Loss: 0.037723\n",
      "Epoch: 69/100... Step: 7141... Loss: 0.017564... Val Loss: 0.036255\n",
      "Epoch: 69/100... Step: 7142... Loss: 0.011606... Val Loss: 0.029681\n",
      "Epoch: 69/100... Step: 7143... Loss: 0.006506... Val Loss: 0.023042\n",
      "Epoch: 69/100... Step: 7144... Loss: 0.015851... Val Loss: 0.019214\n",
      "Epoch: 69/100... Step: 7145... Loss: 0.009163... Val Loss: 0.012069\n",
      "Epoch: 69/100... Step: 7146... Loss: 0.019130... Val Loss: 0.007456\n",
      "Epoch: 69/100... Step: 7147... Loss: 0.009627... Val Loss: 0.005211\n",
      "Epoch: 69/100... Step: 7148... Loss: 0.007544... Val Loss: 0.005996\n",
      "Epoch: 69/100... Step: 7149... Loss: 0.012886... Val Loss: 0.007950\n",
      "Epoch: 69/100... Step: 7150... Loss: 0.009503... Val Loss: 0.011668\n",
      "Epoch: 69/100... Step: 7151... Loss: 0.012565... Val Loss: 0.016113\n",
      "Epoch: 69/100... Step: 7152... Loss: 0.012158... Val Loss: 0.016498\n",
      "Epoch: 69/100... Step: 7153... Loss: 0.010103... Val Loss: 0.013218\n",
      "Epoch: 69/100... Step: 7154... Loss: 0.011664... Val Loss: 0.010452\n",
      "Epoch: 69/100... Step: 7155... Loss: 0.008997... Val Loss: 0.009383\n",
      "Epoch: 69/100... Step: 7156... Loss: 0.010036... Val Loss: 0.006743\n",
      "Epoch: 69/100... Step: 7157... Loss: 0.010876... Val Loss: 0.007502\n",
      "Epoch: 69/100... Step: 7158... Loss: 0.008583... Val Loss: 0.011079\n",
      "Epoch: 69/100... Step: 7159... Loss: 0.014871... Val Loss: 0.016051\n",
      "Epoch: 69/100... Step: 7160... Loss: 0.015184... Val Loss: 0.017615\n",
      "Epoch: 69/100... Step: 7161... Loss: 0.007239... Val Loss: 0.018368\n",
      "Epoch: 69/100... Step: 7162... Loss: 0.009495... Val Loss: 0.018360\n",
      "Epoch: 69/100... Step: 7163... Loss: 0.009989... Val Loss: 0.020039\n",
      "Epoch: 69/100... Step: 7164... Loss: 0.012273... Val Loss: 0.018347\n",
      "Epoch: 69/100... Step: 7165... Loss: 0.010865... Val Loss: 0.018471\n",
      "Epoch: 69/100... Step: 7166... Loss: 0.010359... Val Loss: 0.020158\n",
      "Epoch: 69/100... Step: 7167... Loss: 0.010321... Val Loss: 0.020674\n",
      "Epoch: 69/100... Step: 7168... Loss: 0.007601... Val Loss: 0.020110\n",
      "Epoch: 69/100... Step: 7169... Loss: 0.012587... Val Loss: 0.021596\n",
      "Epoch: 69/100... Step: 7170... Loss: 0.012052... Val Loss: 0.021515\n",
      "Epoch: 69/100... Step: 7171... Loss: 0.010668... Val Loss: 0.028265\n",
      "Epoch: 69/100... Step: 7172... Loss: 0.011799... Val Loss: 0.032478\n",
      "Epoch: 69/100... Step: 7173... Loss: 0.022329... Val Loss: 0.037859\n",
      "Epoch: 69/100... Step: 7174... Loss: 0.010394... Val Loss: 0.040281\n",
      "Epoch: 69/100... Step: 7175... Loss: 0.014838... Val Loss: 0.041431\n",
      "Epoch: 69/100... Step: 7176... Loss: 0.009040... Val Loss: 0.042144\n",
      "Epoch: 70/100... Step: 7177... Loss: 0.013798... Val Loss: 0.037875\n",
      "Epoch: 70/100... Step: 7178... Loss: 0.019218... Val Loss: 0.012890\n",
      "Epoch: 70/100... Step: 7179... Loss: 0.021720... Val Loss: 0.055987\n",
      "Epoch: 70/100... Step: 7180... Loss: 0.010206... Val Loss: 0.113445\n",
      "Epoch: 70/100... Step: 7181... Loss: 0.010722... Val Loss: 0.157410\n",
      "Epoch: 70/100... Step: 7182... Loss: 0.006880... Val Loss: 0.194602\n",
      "Epoch: 70/100... Step: 7183... Loss: 0.010518... Val Loss: 0.224381\n",
      "Epoch: 70/100... Step: 7184... Loss: 0.015668... Val Loss: 0.242096\n",
      "Epoch: 70/100... Step: 7185... Loss: 0.008831... Val Loss: 0.252760\n",
      "Epoch: 70/100... Step: 7186... Loss: 0.007197... Val Loss: 0.263607\n",
      "Epoch: 70/100... Step: 7187... Loss: 0.010689... Val Loss: 0.269158\n",
      "Epoch: 70/100... Step: 7188... Loss: 0.011364... Val Loss: 0.272793\n",
      "Epoch: 70/100... Step: 7189... Loss: 0.013222... Val Loss: 0.275616\n",
      "Epoch: 70/100... Step: 7190... Loss: 0.010691... Val Loss: 0.277312\n",
      "Epoch: 70/100... Step: 7191... Loss: 0.018556... Val Loss: 0.276365\n",
      "Epoch: 70/100... Step: 7192... Loss: 0.014094... Val Loss: 0.272269\n",
      "Epoch: 70/100... Step: 7193... Loss: 0.011955... Val Loss: 0.266069\n",
      "Epoch: 70/100... Step: 7194... Loss: 0.009093... Val Loss: 0.262752\n",
      "Epoch: 70/100... Step: 7195... Loss: 0.015722... Val Loss: 0.259255\n",
      "Epoch: 70/100... Step: 7196... Loss: 0.008639... Val Loss: 0.255275\n",
      "Epoch: 70/100... Step: 7197... Loss: 0.010579... Val Loss: 0.248336\n",
      "Epoch: 70/100... Step: 7198... Loss: 0.013033... Val Loss: 0.239596\n",
      "Epoch: 70/100... Step: 7199... Loss: 0.013010... Val Loss: 0.230037\n",
      "Epoch: 70/100... Step: 7200... Loss: 0.009931... Val Loss: 0.217736\n",
      "Epoch: 70/100... Step: 7201... Loss: 0.011636... Val Loss: 0.208729\n",
      "Epoch: 70/100... Step: 7202... Loss: 0.015881... Val Loss: 0.197176\n",
      "Epoch: 70/100... Step: 7203... Loss: 0.011964... Val Loss: 0.181240\n",
      "Epoch: 70/100... Step: 7204... Loss: 0.009479... Val Loss: 0.162697\n",
      "Epoch: 70/100... Step: 7205... Loss: 0.011408... Val Loss: 0.146070\n",
      "Epoch: 70/100... Step: 7206... Loss: 0.011682... Val Loss: 0.130539\n",
      "Epoch: 70/100... Step: 7207... Loss: 0.012097... Val Loss: 0.115791\n",
      "Epoch: 70/100... Step: 7208... Loss: 0.010419... Val Loss: 0.106587\n",
      "Epoch: 70/100... Step: 7209... Loss: 0.013202... Val Loss: 0.100279\n",
      "Epoch: 70/100... Step: 7210... Loss: 0.009613... Val Loss: 0.089376\n",
      "Epoch: 70/100... Step: 7211... Loss: 0.009414... Val Loss: 0.083385\n",
      "Epoch: 70/100... Step: 7212... Loss: 0.009394... Val Loss: 0.079250\n",
      "Epoch: 70/100... Step: 7213... Loss: 0.008663... Val Loss: 0.078216\n",
      "Epoch: 70/100... Step: 7214... Loss: 0.010861... Val Loss: 0.078729\n",
      "Epoch: 70/100... Step: 7215... Loss: 0.005943... Val Loss: 0.077097\n",
      "Epoch: 70/100... Step: 7216... Loss: 0.011093... Val Loss: 0.075633\n",
      "Epoch: 70/100... Step: 7217... Loss: 0.009712... Val Loss: 0.072653\n",
      "Epoch: 70/100... Step: 7218... Loss: 0.013453... Val Loss: 0.069586\n",
      "Epoch: 70/100... Step: 7219... Loss: 0.012988... Val Loss: 0.064913\n",
      "Epoch: 70/100... Step: 7220... Loss: 0.010906... Val Loss: 0.058688\n",
      "Epoch: 70/100... Step: 7221... Loss: 0.012998... Val Loss: 0.051764\n",
      "Epoch: 70/100... Step: 7222... Loss: 0.010698... Val Loss: 0.044101\n",
      "Epoch: 70/100... Step: 7223... Loss: 0.010024... Val Loss: 0.036677\n",
      "Epoch: 70/100... Step: 7224... Loss: 0.010457... Val Loss: 0.031549\n",
      "Epoch: 70/100... Step: 7225... Loss: 0.007828... Val Loss: 0.026258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Step: 7226... Loss: 0.005311... Val Loss: 0.023794\n",
      "Epoch: 70/100... Step: 7227... Loss: 0.009815... Val Loss: 0.022023\n",
      "Epoch: 70/100... Step: 7228... Loss: 0.006294... Val Loss: 0.018461\n",
      "Epoch: 70/100... Step: 7229... Loss: 0.008719... Val Loss: 0.015635\n",
      "Epoch: 70/100... Step: 7230... Loss: 0.008060... Val Loss: 0.015089\n",
      "Epoch: 70/100... Step: 7231... Loss: 0.016469... Val Loss: 0.015645\n",
      "Epoch: 70/100... Step: 7232... Loss: 0.011129... Val Loss: 0.013559\n",
      "Epoch: 70/100... Step: 7233... Loss: 0.011664... Val Loss: 0.010606\n",
      "Epoch: 70/100... Step: 7234... Loss: 0.009261... Val Loss: 0.008424\n",
      "Epoch: 70/100... Step: 7235... Loss: 0.013019... Val Loss: 0.008851\n",
      "Epoch: 70/100... Step: 7236... Loss: 0.013030... Val Loss: 0.008560\n",
      "Epoch: 70/100... Step: 7237... Loss: 0.011424... Val Loss: 0.007816\n",
      "Epoch: 70/100... Step: 7238... Loss: 0.011154... Val Loss: 0.006334\n",
      "Epoch: 70/100... Step: 7239... Loss: 0.011849... Val Loss: 0.006514\n",
      "Epoch: 70/100... Step: 7240... Loss: 0.009266... Val Loss: 0.009115\n",
      "Epoch: 70/100... Step: 7241... Loss: 0.010916... Val Loss: 0.013546\n",
      "Epoch: 70/100... Step: 7242... Loss: 0.008646... Val Loss: 0.018937\n",
      "Epoch: 70/100... Step: 7243... Loss: 0.015921... Val Loss: 0.022026\n",
      "Epoch: 70/100... Step: 7244... Loss: 0.009910... Val Loss: 0.022459\n",
      "Epoch: 70/100... Step: 7245... Loss: 0.008069... Val Loss: 0.023339\n",
      "Epoch: 70/100... Step: 7246... Loss: 0.006375... Val Loss: 0.022790\n",
      "Epoch: 70/100... Step: 7247... Loss: 0.012507... Val Loss: 0.027374\n",
      "Epoch: 70/100... Step: 7248... Loss: 0.014043... Val Loss: 0.033743\n",
      "Epoch: 70/100... Step: 7249... Loss: 0.008986... Val Loss: 0.038161\n",
      "Epoch: 70/100... Step: 7250... Loss: 0.011950... Val Loss: 0.041404\n",
      "Epoch: 70/100... Step: 7251... Loss: 0.007675... Val Loss: 0.042644\n",
      "Epoch: 70/100... Step: 7252... Loss: 0.013531... Val Loss: 0.043160\n",
      "Epoch: 70/100... Step: 7253... Loss: 0.009449... Val Loss: 0.042888\n",
      "Epoch: 70/100... Step: 7254... Loss: 0.006102... Val Loss: 0.043369\n",
      "Epoch: 70/100... Step: 7255... Loss: 0.011056... Val Loss: 0.041078\n",
      "Epoch: 70/100... Step: 7256... Loss: 0.011980... Val Loss: 0.039551\n",
      "Epoch: 70/100... Step: 7257... Loss: 0.012075... Val Loss: 0.038838\n",
      "Epoch: 70/100... Step: 7258... Loss: 0.009924... Val Loss: 0.039161\n",
      "Epoch: 70/100... Step: 7259... Loss: 0.014062... Val Loss: 0.038783\n",
      "Epoch: 70/100... Step: 7260... Loss: 0.010896... Val Loss: 0.040542\n",
      "Epoch: 70/100... Step: 7261... Loss: 0.012295... Val Loss: 0.039946\n",
      "Epoch: 70/100... Step: 7262... Loss: 0.009592... Val Loss: 0.037157\n",
      "Epoch: 70/100... Step: 7263... Loss: 0.012206... Val Loss: 0.033200\n",
      "Epoch: 70/100... Step: 7264... Loss: 0.015072... Val Loss: 0.026653\n",
      "Epoch: 70/100... Step: 7265... Loss: 0.016022... Val Loss: 0.020505\n",
      "Epoch: 70/100... Step: 7266... Loss: 0.007895... Val Loss: 0.013240\n",
      "Epoch: 70/100... Step: 7267... Loss: 0.015442... Val Loss: 0.009576\n",
      "Epoch: 70/100... Step: 7268... Loss: 0.012473... Val Loss: 0.007897\n",
      "Epoch: 70/100... Step: 7269... Loss: 0.009678... Val Loss: 0.007792\n",
      "Epoch: 70/100... Step: 7270... Loss: 0.009453... Val Loss: 0.007901\n",
      "Epoch: 70/100... Step: 7271... Loss: 0.015035... Val Loss: 0.007851\n",
      "Epoch: 70/100... Step: 7272... Loss: 0.014377... Val Loss: 0.008200\n",
      "Epoch: 70/100... Step: 7273... Loss: 0.009037... Val Loss: 0.008238\n",
      "Epoch: 70/100... Step: 7274... Loss: 0.009469... Val Loss: 0.007643\n",
      "Epoch: 70/100... Step: 7275... Loss: 0.015266... Val Loss: 0.007464\n",
      "Epoch: 70/100... Step: 7276... Loss: 0.009308... Val Loss: 0.007861\n",
      "Epoch: 70/100... Step: 7277... Loss: 0.011017... Val Loss: 0.008993\n",
      "Epoch: 70/100... Step: 7278... Loss: 0.011483... Val Loss: 0.009165\n",
      "Epoch: 70/100... Step: 7279... Loss: 0.011745... Val Loss: 0.008232\n",
      "Epoch: 70/100... Step: 7280... Loss: 0.008639... Val Loss: 0.008721\n",
      "Epoch: 71/100... Step: 7281... Loss: 0.019310... Val Loss: 0.026936\n",
      "Epoch: 71/100... Step: 7282... Loss: 0.016883... Val Loss: 0.020483\n",
      "Epoch: 71/100... Step: 7283... Loss: 0.014873... Val Loss: 0.025451\n",
      "Epoch: 71/100... Step: 7284... Loss: 0.008543... Val Loss: 0.065503\n",
      "Epoch: 71/100... Step: 7285... Loss: 0.017498... Val Loss: 0.101411\n",
      "Epoch: 71/100... Step: 7286... Loss: 0.015988... Val Loss: 0.130696\n",
      "Epoch: 71/100... Step: 7287... Loss: 0.016975... Val Loss: 0.154226\n",
      "Epoch: 71/100... Step: 7288... Loss: 0.011101... Val Loss: 0.172520\n",
      "Epoch: 71/100... Step: 7289... Loss: 0.005891... Val Loss: 0.187448\n",
      "Epoch: 71/100... Step: 7290... Loss: 0.007341... Val Loss: 0.200171\n",
      "Epoch: 71/100... Step: 7291... Loss: 0.009344... Val Loss: 0.210057\n",
      "Epoch: 71/100... Step: 7292... Loss: 0.011129... Val Loss: 0.217777\n",
      "Epoch: 71/100... Step: 7293... Loss: 0.012790... Val Loss: 0.223220\n",
      "Epoch: 71/100... Step: 7294... Loss: 0.012988... Val Loss: 0.226456\n",
      "Epoch: 71/100... Step: 7295... Loss: 0.014507... Val Loss: 0.226540\n",
      "Epoch: 71/100... Step: 7296... Loss: 0.016777... Val Loss: 0.218332\n",
      "Epoch: 71/100... Step: 7297... Loss: 0.010464... Val Loss: 0.198869\n",
      "Epoch: 71/100... Step: 7298... Loss: 0.011151... Val Loss: 0.187709\n",
      "Epoch: 71/100... Step: 7299... Loss: 0.020369... Val Loss: 0.176478\n",
      "Epoch: 71/100... Step: 7300... Loss: 0.010856... Val Loss: 0.167850\n",
      "Epoch: 71/100... Step: 7301... Loss: 0.007275... Val Loss: 0.161383\n",
      "Epoch: 71/100... Step: 7302... Loss: 0.015952... Val Loss: 0.159531\n",
      "Epoch: 71/100... Step: 7303... Loss: 0.010404... Val Loss: 0.157756\n",
      "Epoch: 71/100... Step: 7304... Loss: 0.010321... Val Loss: 0.156077\n",
      "Epoch: 71/100... Step: 7305... Loss: 0.010946... Val Loss: 0.151245\n",
      "Epoch: 71/100... Step: 7306... Loss: 0.009069... Val Loss: 0.144198\n",
      "Epoch: 71/100... Step: 7307... Loss: 0.006872... Val Loss: 0.136990\n",
      "Epoch: 71/100... Step: 7308... Loss: 0.009494... Val Loss: 0.129500\n",
      "Epoch: 71/100... Step: 7309... Loss: 0.009333... Val Loss: 0.122155\n",
      "Epoch: 71/100... Step: 7310... Loss: 0.015268... Val Loss: 0.115972\n",
      "Epoch: 71/100... Step: 7311... Loss: 0.014095... Val Loss: 0.108730\n",
      "Epoch: 71/100... Step: 7312... Loss: 0.012215... Val Loss: 0.100013\n",
      "Epoch: 71/100... Step: 7313... Loss: 0.009689... Val Loss: 0.090734\n",
      "Epoch: 71/100... Step: 7314... Loss: 0.009973... Val Loss: 0.083114\n",
      "Epoch: 71/100... Step: 7315... Loss: 0.005105... Val Loss: 0.076505\n",
      "Epoch: 71/100... Step: 7316... Loss: 0.007081... Val Loss: 0.070738\n",
      "Epoch: 71/100... Step: 7317... Loss: 0.012472... Val Loss: 0.064105\n",
      "Epoch: 71/100... Step: 7318... Loss: 0.013485... Val Loss: 0.060553\n",
      "Epoch: 71/100... Step: 7319... Loss: 0.009114... Val Loss: 0.058096\n",
      "Epoch: 71/100... Step: 7320... Loss: 0.010991... Val Loss: 0.057060\n",
      "Epoch: 71/100... Step: 7321... Loss: 0.019299... Val Loss: 0.057049\n",
      "Epoch: 71/100... Step: 7322... Loss: 0.012743... Val Loss: 0.056316\n",
      "Epoch: 71/100... Step: 7323... Loss: 0.009342... Val Loss: 0.055203\n",
      "Epoch: 71/100... Step: 7324... Loss: 0.009446... Val Loss: 0.053347\n",
      "Epoch: 71/100... Step: 7325... Loss: 0.015824... Val Loss: 0.049322\n",
      "Epoch: 71/100... Step: 7326... Loss: 0.013646... Val Loss: 0.047745\n",
      "Epoch: 71/100... Step: 7327... Loss: 0.011082... Val Loss: 0.045748\n",
      "Epoch: 71/100... Step: 7328... Loss: 0.013211... Val Loss: 0.042966\n",
      "Epoch: 71/100... Step: 7329... Loss: 0.010448... Val Loss: 0.039566\n",
      "Epoch: 71/100... Step: 7330... Loss: 0.012893... Val Loss: 0.036662\n",
      "Epoch: 71/100... Step: 7331... Loss: 0.011664... Val Loss: 0.033707\n",
      "Epoch: 71/100... Step: 7332... Loss: 0.007362... Val Loss: 0.027681\n",
      "Epoch: 71/100... Step: 7333... Loss: 0.010126... Val Loss: 0.020915\n",
      "Epoch: 71/100... Step: 7334... Loss: 0.012452... Val Loss: 0.015900\n",
      "Epoch: 71/100... Step: 7335... Loss: 0.012714... Val Loss: 0.013433\n",
      "Epoch: 71/100... Step: 7336... Loss: 0.011358... Val Loss: 0.010786\n",
      "Epoch: 71/100... Step: 7337... Loss: 0.009939... Val Loss: 0.008338\n",
      "Epoch: 71/100... Step: 7338... Loss: 0.012779... Val Loss: 0.009779\n",
      "Epoch: 71/100... Step: 7339... Loss: 0.008681... Val Loss: 0.010777\n",
      "Epoch: 71/100... Step: 7340... Loss: 0.014245... Val Loss: 0.011671\n",
      "Epoch: 71/100... Step: 7341... Loss: 0.008241... Val Loss: 0.013122\n",
      "Epoch: 71/100... Step: 7342... Loss: 0.008625... Val Loss: 0.014839\n",
      "Epoch: 71/100... Step: 7343... Loss: 0.007023... Val Loss: 0.018403\n",
      "Epoch: 71/100... Step: 7344... Loss: 0.011527... Val Loss: 0.021026\n",
      "Epoch: 71/100... Step: 7345... Loss: 0.016625... Val Loss: 0.020243\n",
      "Epoch: 71/100... Step: 7346... Loss: 0.014046... Val Loss: 0.018918\n",
      "Epoch: 71/100... Step: 7347... Loss: 0.009245... Val Loss: 0.014544\n",
      "Epoch: 71/100... Step: 7348... Loss: 0.014924... Val Loss: 0.011158\n",
      "Epoch: 71/100... Step: 7349... Loss: 0.014702... Val Loss: 0.010526\n",
      "Epoch: 71/100... Step: 7350... Loss: 0.009189... Val Loss: 0.014770\n",
      "Epoch: 71/100... Step: 7351... Loss: 0.006108... Val Loss: 0.019848\n",
      "Epoch: 71/100... Step: 7352... Loss: 0.012198... Val Loss: 0.023503\n",
      "Epoch: 71/100... Step: 7353... Loss: 0.013080... Val Loss: 0.026309\n",
      "Epoch: 71/100... Step: 7354... Loss: 0.013783... Val Loss: 0.027244\n",
      "Epoch: 71/100... Step: 7355... Loss: 0.016480... Val Loss: 0.028714\n",
      "Epoch: 71/100... Step: 7356... Loss: 0.012885... Val Loss: 0.027283\n",
      "Epoch: 71/100... Step: 7357... Loss: 0.010928... Val Loss: 0.024097\n",
      "Epoch: 71/100... Step: 7358... Loss: 0.010773... Val Loss: 0.020076\n",
      "Epoch: 71/100... Step: 7359... Loss: 0.011317... Val Loss: 0.018270\n",
      "Epoch: 71/100... Step: 7360... Loss: 0.016275... Val Loss: 0.018065\n",
      "Epoch: 71/100... Step: 7361... Loss: 0.012501... Val Loss: 0.016782\n",
      "Epoch: 71/100... Step: 7362... Loss: 0.011595... Val Loss: 0.016045\n",
      "Epoch: 71/100... Step: 7363... Loss: 0.010088... Val Loss: 0.015611\n",
      "Epoch: 71/100... Step: 7364... Loss: 0.007898... Val Loss: 0.015989\n",
      "Epoch: 71/100... Step: 7365... Loss: 0.011822... Val Loss: 0.016153\n",
      "Epoch: 71/100... Step: 7366... Loss: 0.014232... Val Loss: 0.015565\n",
      "Epoch: 71/100... Step: 7367... Loss: 0.008792... Val Loss: 0.014136\n",
      "Epoch: 71/100... Step: 7368... Loss: 0.009491... Val Loss: 0.013471\n",
      "Epoch: 71/100... Step: 7369... Loss: 0.004230... Val Loss: 0.015876\n",
      "Epoch: 71/100... Step: 7370... Loss: 0.014721... Val Loss: 0.017569\n",
      "Epoch: 71/100... Step: 7371... Loss: 0.015592... Val Loss: 0.018753\n",
      "Epoch: 71/100... Step: 7372... Loss: 0.014386... Val Loss: 0.019379\n",
      "Epoch: 71/100... Step: 7373... Loss: 0.012790... Val Loss: 0.019164\n",
      "Epoch: 71/100... Step: 7374... Loss: 0.016341... Val Loss: 0.019757\n",
      "Epoch: 71/100... Step: 7375... Loss: 0.013215... Val Loss: 0.020871\n",
      "Epoch: 71/100... Step: 7376... Loss: 0.007521... Val Loss: 0.024088\n",
      "Epoch: 71/100... Step: 7377... Loss: 0.013416... Val Loss: 0.024054\n",
      "Epoch: 71/100... Step: 7378... Loss: 0.011872... Val Loss: 0.022868\n",
      "Epoch: 71/100... Step: 7379... Loss: 0.011887... Val Loss: 0.023550\n",
      "Epoch: 71/100... Step: 7380... Loss: 0.008612... Val Loss: 0.024479\n",
      "Epoch: 71/100... Step: 7381... Loss: 0.012323... Val Loss: 0.025399\n",
      "Epoch: 71/100... Step: 7382... Loss: 0.011042... Val Loss: 0.023051\n",
      "Epoch: 71/100... Step: 7383... Loss: 0.007823... Val Loss: 0.022917\n",
      "Epoch: 71/100... Step: 7384... Loss: 0.010614... Val Loss: 0.022433\n",
      "Epoch: 72/100... Step: 7385... Loss: 0.011276... Val Loss: 0.044068\n",
      "Epoch: 72/100... Step: 7386... Loss: 0.012669... Val Loss: 0.012781\n",
      "Epoch: 72/100... Step: 7387... Loss: 0.009433... Val Loss: 0.029510\n",
      "Epoch: 72/100... Step: 7388... Loss: 0.009012... Val Loss: 0.076028\n",
      "Epoch: 72/100... Step: 7389... Loss: 0.008701... Val Loss: 0.116213\n",
      "Epoch: 72/100... Step: 7390... Loss: 0.007836... Val Loss: 0.147220\n",
      "Epoch: 72/100... Step: 7391... Loss: 0.012194... Val Loss: 0.172795\n",
      "Epoch: 72/100... Step: 7392... Loss: 0.005552... Val Loss: 0.190107\n",
      "Epoch: 72/100... Step: 7393... Loss: 0.006071... Val Loss: 0.203244\n",
      "Epoch: 72/100... Step: 7394... Loss: 0.009880... Val Loss: 0.213992\n",
      "Epoch: 72/100... Step: 7395... Loss: 0.013717... Val Loss: 0.218810\n",
      "Epoch: 72/100... Step: 7396... Loss: 0.013452... Val Loss: 0.222091\n",
      "Epoch: 72/100... Step: 7397... Loss: 0.013776... Val Loss: 0.222904\n",
      "Epoch: 72/100... Step: 7398... Loss: 0.004753... Val Loss: 0.226358\n",
      "Epoch: 72/100... Step: 7399... Loss: 0.015726... Val Loss: 0.230582\n",
      "Epoch: 72/100... Step: 7400... Loss: 0.013795... Val Loss: 0.233855\n",
      "Epoch: 72/100... Step: 7401... Loss: 0.006498... Val Loss: 0.234368\n",
      "Epoch: 72/100... Step: 7402... Loss: 0.009358... Val Loss: 0.233568\n",
      "Epoch: 72/100... Step: 7403... Loss: 0.004946... Val Loss: 0.230655\n",
      "Epoch: 72/100... Step: 7404... Loss: 0.007742... Val Loss: 0.226087\n",
      "Epoch: 72/100... Step: 7405... Loss: 0.008827... Val Loss: 0.221528\n",
      "Epoch: 72/100... Step: 7406... Loss: 0.016984... Val Loss: 0.214377\n",
      "Epoch: 72/100... Step: 7407... Loss: 0.008519... Val Loss: 0.214224\n",
      "Epoch: 72/100... Step: 7408... Loss: 0.010196... Val Loss: 0.212365\n",
      "Epoch: 72/100... Step: 7409... Loss: 0.012072... Val Loss: 0.209538\n",
      "Epoch: 72/100... Step: 7410... Loss: 0.012411... Val Loss: 0.203407\n",
      "Epoch: 72/100... Step: 7411... Loss: 0.011999... Val Loss: 0.195280\n",
      "Epoch: 72/100... Step: 7412... Loss: 0.007431... Val Loss: 0.187865\n",
      "Epoch: 72/100... Step: 7413... Loss: 0.005896... Val Loss: 0.180377\n",
      "Epoch: 72/100... Step: 7414... Loss: 0.012960... Val Loss: 0.158494\n",
      "Epoch: 72/100... Step: 7415... Loss: 0.009832... Val Loss: 0.129237\n",
      "Epoch: 72/100... Step: 7416... Loss: 0.010356... Val Loss: 0.112850\n",
      "Epoch: 72/100... Step: 7417... Loss: 0.009895... Val Loss: 0.105099\n",
      "Epoch: 72/100... Step: 7418... Loss: 0.009417... Val Loss: 0.101662\n",
      "Epoch: 72/100... Step: 7419... Loss: 0.008276... Val Loss: 0.101070\n",
      "Epoch: 72/100... Step: 7420... Loss: 0.009089... Val Loss: 0.100892\n",
      "Epoch: 72/100... Step: 7421... Loss: 0.010018... Val Loss: 0.098123\n",
      "Epoch: 72/100... Step: 7422... Loss: 0.006872... Val Loss: 0.095181\n",
      "Epoch: 72/100... Step: 7423... Loss: 0.007510... Val Loss: 0.091721\n",
      "Epoch: 72/100... Step: 7424... Loss: 0.011819... Val Loss: 0.089228\n",
      "Epoch: 72/100... Step: 7425... Loss: 0.013421... Val Loss: 0.087310\n",
      "Epoch: 72/100... Step: 7426... Loss: 0.008885... Val Loss: 0.085477\n",
      "Epoch: 72/100... Step: 7427... Loss: 0.006806... Val Loss: 0.081578\n",
      "Epoch: 72/100... Step: 7428... Loss: 0.005426... Val Loss: 0.077037\n",
      "Epoch: 72/100... Step: 7429... Loss: 0.009035... Val Loss: 0.072512\n",
      "Epoch: 72/100... Step: 7430... Loss: 0.008602... Val Loss: 0.064956\n",
      "Epoch: 72/100... Step: 7431... Loss: 0.009684... Val Loss: 0.056585\n",
      "Epoch: 72/100... Step: 7432... Loss: 0.006948... Val Loss: 0.047975\n",
      "Epoch: 72/100... Step: 7433... Loss: 0.011487... Val Loss: 0.039729\n",
      "Epoch: 72/100... Step: 7434... Loss: 0.010004... Val Loss: 0.031194\n",
      "Epoch: 72/100... Step: 7435... Loss: 0.012530... Val Loss: 0.022460\n",
      "Epoch: 72/100... Step: 7436... Loss: 0.010491... Val Loss: 0.014820\n",
      "Epoch: 72/100... Step: 7437... Loss: 0.011757... Val Loss: 0.010389\n",
      "Epoch: 72/100... Step: 7438... Loss: 0.013299... Val Loss: 0.006860\n",
      "Epoch: 72/100... Step: 7439... Loss: 0.009902... Val Loss: 0.004387\n",
      "Epoch: 72/100... Step: 7440... Loss: 0.007519... Val Loss: 0.002980\n",
      "Epoch: 72/100... Step: 7441... Loss: 0.013056... Val Loss: 0.004714\n",
      "Epoch: 72/100... Step: 7442... Loss: 0.010403... Val Loss: 0.006847\n",
      "Epoch: 72/100... Step: 7443... Loss: 0.005537... Val Loss: 0.008394\n",
      "Epoch: 72/100... Step: 7444... Loss: 0.008347... Val Loss: 0.008912\n",
      "Epoch: 72/100... Step: 7445... Loss: 0.012261... Val Loss: 0.010542\n",
      "Epoch: 72/100... Step: 7446... Loss: 0.008674... Val Loss: 0.011379\n",
      "Epoch: 72/100... Step: 7447... Loss: 0.011082... Val Loss: 0.012291\n",
      "Epoch: 72/100... Step: 7448... Loss: 0.010890... Val Loss: 0.013479\n",
      "Epoch: 72/100... Step: 7449... Loss: 0.009688... Val Loss: 0.012216\n",
      "Epoch: 72/100... Step: 7450... Loss: 0.009917... Val Loss: 0.010568\n",
      "Epoch: 72/100... Step: 7451... Loss: 0.007058... Val Loss: 0.010219\n",
      "Epoch: 72/100... Step: 7452... Loss: 0.008357... Val Loss: 0.008889\n",
      "Epoch: 72/100... Step: 7453... Loss: 0.011075... Val Loss: 0.008113\n",
      "Epoch: 72/100... Step: 7454... Loss: 0.009585... Val Loss: 0.006809\n",
      "Epoch: 72/100... Step: 7455... Loss: 0.010645... Val Loss: 0.006484\n",
      "Epoch: 72/100... Step: 7456... Loss: 0.013942... Val Loss: 0.008415\n",
      "Epoch: 72/100... Step: 7457... Loss: 0.006713... Val Loss: 0.010457\n",
      "Epoch: 72/100... Step: 7458... Loss: 0.006389... Val Loss: 0.010168\n",
      "Epoch: 72/100... Step: 7459... Loss: 0.011601... Val Loss: 0.010171\n",
      "Epoch: 72/100... Step: 7460... Loss: 0.011715... Val Loss: 0.010485\n",
      "Epoch: 72/100... Step: 7461... Loss: 0.008030... Val Loss: 0.010437\n",
      "Epoch: 72/100... Step: 7462... Loss: 0.009528... Val Loss: 0.011358\n",
      "Epoch: 72/100... Step: 7463... Loss: 0.012071... Val Loss: 0.012032\n",
      "Epoch: 72/100... Step: 7464... Loss: 0.009918... Val Loss: 0.014246\n",
      "Epoch: 72/100... Step: 7465... Loss: 0.012625... Val Loss: 0.014483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Step: 7466... Loss: 0.006746... Val Loss: 0.015361\n",
      "Epoch: 72/100... Step: 7467... Loss: 0.012167... Val Loss: 0.014197\n",
      "Epoch: 72/100... Step: 7468... Loss: 0.012175... Val Loss: 0.013144\n",
      "Epoch: 72/100... Step: 7469... Loss: 0.006648... Val Loss: 0.010957\n",
      "Epoch: 72/100... Step: 7470... Loss: 0.008406... Val Loss: 0.009659\n",
      "Epoch: 72/100... Step: 7471... Loss: 0.006288... Val Loss: 0.008931\n",
      "Epoch: 72/100... Step: 7472... Loss: 0.006411... Val Loss: 0.009051\n",
      "Epoch: 72/100... Step: 7473... Loss: 0.006746... Val Loss: 0.009980\n",
      "Epoch: 72/100... Step: 7474... Loss: 0.013747... Val Loss: 0.010563\n",
      "Epoch: 72/100... Step: 7475... Loss: 0.010254... Val Loss: 0.011114\n",
      "Epoch: 72/100... Step: 7476... Loss: 0.011139... Val Loss: 0.011290\n",
      "Epoch: 72/100... Step: 7477... Loss: 0.014311... Val Loss: 0.011717\n",
      "Epoch: 72/100... Step: 7478... Loss: 0.012766... Val Loss: 0.011728\n",
      "Epoch: 72/100... Step: 7479... Loss: 0.012504... Val Loss: 0.013588\n",
      "Epoch: 72/100... Step: 7480... Loss: 0.010185... Val Loss: 0.016692\n",
      "Epoch: 72/100... Step: 7481... Loss: 0.008298... Val Loss: 0.019924\n",
      "Epoch: 72/100... Step: 7482... Loss: 0.012500... Val Loss: 0.023917\n",
      "Epoch: 72/100... Step: 7483... Loss: 0.014847... Val Loss: 0.025538\n",
      "Epoch: 72/100... Step: 7484... Loss: 0.007603... Val Loss: 0.026304\n",
      "Epoch: 72/100... Step: 7485... Loss: 0.016121... Val Loss: 0.026253\n",
      "Epoch: 72/100... Step: 7486... Loss: 0.008069... Val Loss: 0.025515\n",
      "Epoch: 72/100... Step: 7487... Loss: 0.012583... Val Loss: 0.022744\n",
      "Epoch: 72/100... Step: 7488... Loss: 0.015098... Val Loss: 0.020274\n",
      "Epoch: 73/100... Step: 7489... Loss: 0.009240... Val Loss: 0.020683\n",
      "Epoch: 73/100... Step: 7490... Loss: 0.009305... Val Loss: 0.003732\n",
      "Epoch: 73/100... Step: 7491... Loss: 0.009545... Val Loss: 0.019546\n",
      "Epoch: 73/100... Step: 7492... Loss: 0.009611... Val Loss: 0.042999\n",
      "Epoch: 73/100... Step: 7493... Loss: 0.012299... Val Loss: 0.067049\n",
      "Epoch: 73/100... Step: 7494... Loss: 0.008252... Val Loss: 0.091609\n",
      "Epoch: 73/100... Step: 7495... Loss: 0.005511... Val Loss: 0.109455\n",
      "Epoch: 73/100... Step: 7496... Loss: 0.006508... Val Loss: 0.125717\n",
      "Epoch: 73/100... Step: 7497... Loss: 0.011953... Val Loss: 0.137340\n",
      "Epoch: 73/100... Step: 7498... Loss: 0.008050... Val Loss: 0.146362\n",
      "Epoch: 73/100... Step: 7499... Loss: 0.011646... Val Loss: 0.153732\n",
      "Epoch: 73/100... Step: 7500... Loss: 0.007309... Val Loss: 0.159849\n",
      "Epoch: 73/100... Step: 7501... Loss: 0.007904... Val Loss: 0.165088\n",
      "Epoch: 73/100... Step: 7502... Loss: 0.007958... Val Loss: 0.167538\n",
      "Epoch: 73/100... Step: 7503... Loss: 0.007609... Val Loss: 0.169395\n",
      "Epoch: 73/100... Step: 7504... Loss: 0.012166... Val Loss: 0.170527\n",
      "Epoch: 73/100... Step: 7505... Loss: 0.009236... Val Loss: 0.169965\n",
      "Epoch: 73/100... Step: 7506... Loss: 0.007958... Val Loss: 0.167653\n",
      "Epoch: 73/100... Step: 7507... Loss: 0.006681... Val Loss: 0.168325\n",
      "Epoch: 73/100... Step: 7508... Loss: 0.011703... Val Loss: 0.163590\n",
      "Epoch: 73/100... Step: 7509... Loss: 0.009861... Val Loss: 0.155849\n",
      "Epoch: 73/100... Step: 7510... Loss: 0.011653... Val Loss: 0.149571\n",
      "Epoch: 73/100... Step: 7511... Loss: 0.009490... Val Loss: 0.143236\n",
      "Epoch: 73/100... Step: 7512... Loss: 0.011246... Val Loss: 0.139150\n",
      "Epoch: 73/100... Step: 7513... Loss: 0.010165... Val Loss: 0.136502\n",
      "Epoch: 73/100... Step: 7514... Loss: 0.016098... Val Loss: 0.134403\n",
      "Epoch: 73/100... Step: 7515... Loss: 0.015025... Val Loss: 0.131382\n",
      "Epoch: 73/100... Step: 7516... Loss: 0.012248... Val Loss: 0.129212\n",
      "Epoch: 73/100... Step: 7517... Loss: 0.013425... Val Loss: 0.125305\n",
      "Epoch: 73/100... Step: 7518... Loss: 0.011538... Val Loss: 0.120433\n",
      "Epoch: 73/100... Step: 7519... Loss: 0.010165... Val Loss: 0.115477\n",
      "Epoch: 73/100... Step: 7520... Loss: 0.006300... Val Loss: 0.110046\n",
      "Epoch: 73/100... Step: 7521... Loss: 0.015546... Val Loss: 0.104490\n",
      "Epoch: 73/100... Step: 7522... Loss: 0.015856... Val Loss: 0.097936\n",
      "Epoch: 73/100... Step: 7523... Loss: 0.013256... Val Loss: 0.092485\n",
      "Epoch: 73/100... Step: 7524... Loss: 0.012369... Val Loss: 0.085503\n",
      "Epoch: 73/100... Step: 7525... Loss: 0.012264... Val Loss: 0.077214\n",
      "Epoch: 73/100... Step: 7526... Loss: 0.015113... Val Loss: 0.070685\n",
      "Epoch: 73/100... Step: 7527... Loss: 0.009472... Val Loss: 0.061610\n",
      "Epoch: 73/100... Step: 7528... Loss: 0.007376... Val Loss: 0.052388\n",
      "Epoch: 73/100... Step: 7529... Loss: 0.008464... Val Loss: 0.045978\n",
      "Epoch: 73/100... Step: 7530... Loss: 0.013031... Val Loss: 0.040404\n",
      "Epoch: 73/100... Step: 7531... Loss: 0.011293... Val Loss: 0.033419\n",
      "Epoch: 73/100... Step: 7532... Loss: 0.009421... Val Loss: 0.025913\n",
      "Epoch: 73/100... Step: 7533... Loss: 0.007522... Val Loss: 0.019165\n",
      "Epoch: 73/100... Step: 7534... Loss: 0.013573... Val Loss: 0.015935\n",
      "Epoch: 73/100... Step: 7535... Loss: 0.006857... Val Loss: 0.015573\n",
      "Epoch: 73/100... Step: 7536... Loss: 0.010719... Val Loss: 0.015861\n",
      "Epoch: 73/100... Step: 7537... Loss: 0.008991... Val Loss: 0.016524\n",
      "Epoch: 73/100... Step: 7538... Loss: 0.012223... Val Loss: 0.016332\n",
      "Epoch: 73/100... Step: 7539... Loss: 0.008068... Val Loss: 0.017146\n",
      "Epoch: 73/100... Step: 7540... Loss: 0.006331... Val Loss: 0.015576\n",
      "Epoch: 73/100... Step: 7541... Loss: 0.010652... Val Loss: 0.016286\n",
      "Epoch: 73/100... Step: 7542... Loss: 0.010618... Val Loss: 0.016706\n",
      "Epoch: 73/100... Step: 7543... Loss: 0.008953... Val Loss: 0.014769\n",
      "Epoch: 73/100... Step: 7544... Loss: 0.010681... Val Loss: 0.014235\n",
      "Epoch: 73/100... Step: 7545... Loss: 0.010452... Val Loss: 0.014248\n",
      "Epoch: 73/100... Step: 7546... Loss: 0.010231... Val Loss: 0.012149\n",
      "Epoch: 73/100... Step: 7547... Loss: 0.010658... Val Loss: 0.010338\n",
      "Epoch: 73/100... Step: 7548... Loss: 0.011363... Val Loss: 0.009262\n",
      "Epoch: 73/100... Step: 7549... Loss: 0.010048... Val Loss: 0.006204\n",
      "Epoch: 73/100... Step: 7550... Loss: 0.008699... Val Loss: 0.003982\n",
      "Epoch: 73/100... Step: 7551... Loss: 0.009730... Val Loss: 0.005244\n",
      "Epoch: 73/100... Step: 7552... Loss: 0.008724... Val Loss: 0.007603\n",
      "Epoch: 73/100... Step: 7553... Loss: 0.011030... Val Loss: 0.009565\n",
      "Epoch: 73/100... Step: 7554... Loss: 0.009208... Val Loss: 0.011209\n",
      "Epoch: 73/100... Step: 7555... Loss: 0.012831... Val Loss: 0.011354\n",
      "Epoch: 73/100... Step: 7556... Loss: 0.016027... Val Loss: 0.009846\n",
      "Epoch: 73/100... Step: 7557... Loss: 0.008073... Val Loss: 0.008602\n",
      "Epoch: 73/100... Step: 7558... Loss: 0.012348... Val Loss: 0.007767\n",
      "Epoch: 73/100... Step: 7559... Loss: 0.011344... Val Loss: 0.007512\n",
      "Epoch: 73/100... Step: 7560... Loss: 0.008092... Val Loss: 0.009841\n",
      "Epoch: 73/100... Step: 7561... Loss: 0.008498... Val Loss: 0.012007\n",
      "Epoch: 73/100... Step: 7562... Loss: 0.011534... Val Loss: 0.013340\n",
      "Epoch: 73/100... Step: 7563... Loss: 0.010470... Val Loss: 0.013435\n",
      "Epoch: 73/100... Step: 7564... Loss: 0.013288... Val Loss: 0.012976\n",
      "Epoch: 73/100... Step: 7565... Loss: 0.006704... Val Loss: 0.011550\n",
      "Epoch: 73/100... Step: 7566... Loss: 0.008985... Val Loss: 0.011334\n",
      "Epoch: 73/100... Step: 7567... Loss: 0.005503... Val Loss: 0.011434\n",
      "Epoch: 73/100... Step: 7568... Loss: 0.007029... Val Loss: 0.011874\n",
      "Epoch: 73/100... Step: 7569... Loss: 0.010127... Val Loss: 0.012075\n",
      "Epoch: 73/100... Step: 7570... Loss: 0.006060... Val Loss: 0.012270\n",
      "Epoch: 73/100... Step: 7571... Loss: 0.008398... Val Loss: 0.011257\n",
      "Epoch: 73/100... Step: 7572... Loss: 0.008373... Val Loss: 0.010274\n",
      "Epoch: 73/100... Step: 7573... Loss: 0.010283... Val Loss: 0.008729\n",
      "Epoch: 73/100... Step: 7574... Loss: 0.005765... Val Loss: 0.008344\n",
      "Epoch: 73/100... Step: 7575... Loss: 0.011093... Val Loss: 0.006529\n",
      "Epoch: 73/100... Step: 7576... Loss: 0.011973... Val Loss: 0.005410\n",
      "Epoch: 73/100... Step: 7577... Loss: 0.008765... Val Loss: 0.007646\n",
      "Epoch: 73/100... Step: 7578... Loss: 0.010193... Val Loss: 0.010311\n",
      "Epoch: 73/100... Step: 7579... Loss: 0.008985... Val Loss: 0.014783\n",
      "Epoch: 73/100... Step: 7580... Loss: 0.010529... Val Loss: 0.018522\n",
      "Epoch: 73/100... Step: 7581... Loss: 0.012621... Val Loss: 0.020567\n",
      "Epoch: 73/100... Step: 7582... Loss: 0.010445... Val Loss: 0.022742\n",
      "Epoch: 73/100... Step: 7583... Loss: 0.007583... Val Loss: 0.024984\n",
      "Epoch: 73/100... Step: 7584... Loss: 0.012228... Val Loss: 0.026254\n",
      "Epoch: 73/100... Step: 7585... Loss: 0.010037... Val Loss: 0.024927\n",
      "Epoch: 73/100... Step: 7586... Loss: 0.007009... Val Loss: 0.026070\n",
      "Epoch: 73/100... Step: 7587... Loss: 0.010620... Val Loss: 0.024130\n",
      "Epoch: 73/100... Step: 7588... Loss: 0.005945... Val Loss: 0.023709\n",
      "Epoch: 73/100... Step: 7589... Loss: 0.004600... Val Loss: 0.023737\n",
      "Epoch: 73/100... Step: 7590... Loss: 0.009494... Val Loss: 0.020878\n",
      "Epoch: 73/100... Step: 7591... Loss: 0.009130... Val Loss: 0.020938\n",
      "Epoch: 73/100... Step: 7592... Loss: 0.009589... Val Loss: 0.020909\n",
      "Epoch: 74/100... Step: 7593... Loss: 0.007518... Val Loss: 0.021941\n",
      "Epoch: 74/100... Step: 7594... Loss: 0.010897... Val Loss: 0.018662\n",
      "Epoch: 74/100... Step: 7595... Loss: 0.007703... Val Loss: 0.007649\n",
      "Epoch: 74/100... Step: 7596... Loss: 0.009644... Val Loss: 0.005507\n",
      "Epoch: 74/100... Step: 7597... Loss: 0.011417... Val Loss: 0.015479\n",
      "Epoch: 74/100... Step: 7598... Loss: 0.013677... Val Loss: 0.026479\n",
      "Epoch: 74/100... Step: 7599... Loss: 0.009496... Val Loss: 0.037204\n",
      "Epoch: 74/100... Step: 7600... Loss: 0.006028... Val Loss: 0.046305\n",
      "Epoch: 74/100... Step: 7601... Loss: 0.010940... Val Loss: 0.053257\n",
      "Epoch: 74/100... Step: 7602... Loss: 0.007265... Val Loss: 0.058755\n",
      "Epoch: 74/100... Step: 7603... Loss: 0.008937... Val Loss: 0.063168\n",
      "Epoch: 74/100... Step: 7604... Loss: 0.008172... Val Loss: 0.066679\n",
      "Epoch: 74/100... Step: 7605... Loss: 0.007090... Val Loss: 0.069682\n",
      "Epoch: 74/100... Step: 7606... Loss: 0.013748... Val Loss: 0.071481\n",
      "Epoch: 74/100... Step: 7607... Loss: 0.014483... Val Loss: 0.073160\n",
      "Epoch: 74/100... Step: 7608... Loss: 0.007604... Val Loss: 0.074836\n",
      "Epoch: 74/100... Step: 7609... Loss: 0.010348... Val Loss: 0.074428\n",
      "Epoch: 74/100... Step: 7610... Loss: 0.009530... Val Loss: 0.074691\n",
      "Epoch: 74/100... Step: 7611... Loss: 0.011961... Val Loss: 0.074898\n",
      "Epoch: 74/100... Step: 7612... Loss: 0.008239... Val Loss: 0.073883\n",
      "Epoch: 74/100... Step: 7613... Loss: 0.009318... Val Loss: 0.072655\n",
      "Epoch: 74/100... Step: 7614... Loss: 0.011635... Val Loss: 0.072995\n",
      "Epoch: 74/100... Step: 7615... Loss: 0.007885... Val Loss: 0.074093\n",
      "Epoch: 74/100... Step: 7616... Loss: 0.009238... Val Loss: 0.074757\n",
      "Epoch: 74/100... Step: 7617... Loss: 0.010327... Val Loss: 0.075816\n",
      "Epoch: 74/100... Step: 7618... Loss: 0.012148... Val Loss: 0.076204\n",
      "Epoch: 74/100... Step: 7619... Loss: 0.012865... Val Loss: 0.076515\n",
      "Epoch: 74/100... Step: 7620... Loss: 0.008904... Val Loss: 0.076393\n",
      "Epoch: 74/100... Step: 7621... Loss: 0.007655... Val Loss: 0.074669\n",
      "Epoch: 74/100... Step: 7622... Loss: 0.012282... Val Loss: 0.072362\n",
      "Epoch: 74/100... Step: 7623... Loss: 0.010774... Val Loss: 0.070919\n",
      "Epoch: 74/100... Step: 7624... Loss: 0.005559... Val Loss: 0.068536\n",
      "Epoch: 74/100... Step: 7625... Loss: 0.006968... Val Loss: 0.064912\n",
      "Epoch: 74/100... Step: 7626... Loss: 0.007254... Val Loss: 0.062909\n",
      "Epoch: 74/100... Step: 7627... Loss: 0.010629... Val Loss: 0.060710\n",
      "Epoch: 74/100... Step: 7628... Loss: 0.009117... Val Loss: 0.059166\n",
      "Epoch: 74/100... Step: 7629... Loss: 0.009771... Val Loss: 0.056880\n",
      "Epoch: 74/100... Step: 7630... Loss: 0.008489... Val Loss: 0.054464\n",
      "Epoch: 74/100... Step: 7631... Loss: 0.007413... Val Loss: 0.052307\n",
      "Epoch: 74/100... Step: 7632... Loss: 0.011342... Val Loss: 0.050664\n",
      "Epoch: 74/100... Step: 7633... Loss: 0.006065... Val Loss: 0.048766\n",
      "Epoch: 74/100... Step: 7634... Loss: 0.008512... Val Loss: 0.047566\n",
      "Epoch: 74/100... Step: 7635... Loss: 0.011610... Val Loss: 0.046804\n",
      "Epoch: 74/100... Step: 7636... Loss: 0.011772... Val Loss: 0.046404\n",
      "Epoch: 74/100... Step: 7637... Loss: 0.011265... Val Loss: 0.045986\n",
      "Epoch: 74/100... Step: 7638... Loss: 0.008955... Val Loss: 0.045948\n",
      "Epoch: 74/100... Step: 7639... Loss: 0.005678... Val Loss: 0.044342\n",
      "Epoch: 74/100... Step: 7640... Loss: 0.007663... Val Loss: 0.043881\n",
      "Epoch: 74/100... Step: 7641... Loss: 0.008112... Val Loss: 0.043340\n",
      "Epoch: 74/100... Step: 7642... Loss: 0.012060... Val Loss: 0.040764\n",
      "Epoch: 74/100... Step: 7643... Loss: 0.008898... Val Loss: 0.038603\n",
      "Epoch: 74/100... Step: 7644... Loss: 0.006777... Val Loss: 0.035429\n",
      "Epoch: 74/100... Step: 7645... Loss: 0.008872... Val Loss: 0.031788\n",
      "Epoch: 74/100... Step: 7646... Loss: 0.014587... Val Loss: 0.028013\n",
      "Epoch: 74/100... Step: 7647... Loss: 0.012756... Val Loss: 0.024277\n",
      "Epoch: 74/100... Step: 7648... Loss: 0.017154... Val Loss: 0.020552\n",
      "Epoch: 74/100... Step: 7649... Loss: 0.009049... Val Loss: 0.016425\n",
      "Epoch: 74/100... Step: 7650... Loss: 0.010733... Val Loss: 0.014022\n",
      "Epoch: 74/100... Step: 7651... Loss: 0.012329... Val Loss: 0.012929\n",
      "Epoch: 74/100... Step: 7652... Loss: 0.010947... Val Loss: 0.011276\n",
      "Epoch: 74/100... Step: 7653... Loss: 0.008964... Val Loss: 0.009956\n",
      "Epoch: 74/100... Step: 7654... Loss: 0.009788... Val Loss: 0.010360\n",
      "Epoch: 74/100... Step: 7655... Loss: 0.009736... Val Loss: 0.010045\n",
      "Epoch: 74/100... Step: 7656... Loss: 0.008791... Val Loss: 0.011352\n",
      "Epoch: 74/100... Step: 7657... Loss: 0.008278... Val Loss: 0.012464\n",
      "Epoch: 74/100... Step: 7658... Loss: 0.010447... Val Loss: 0.014104\n",
      "Epoch: 74/100... Step: 7659... Loss: 0.006401... Val Loss: 0.014779\n",
      "Epoch: 74/100... Step: 7660... Loss: 0.008707... Val Loss: 0.015710\n",
      "Epoch: 74/100... Step: 7661... Loss: 0.007130... Val Loss: 0.016966\n",
      "Epoch: 74/100... Step: 7662... Loss: 0.011475... Val Loss: 0.017167\n",
      "Epoch: 74/100... Step: 7663... Loss: 0.007917... Val Loss: 0.017978\n",
      "Epoch: 74/100... Step: 7664... Loss: 0.008700... Val Loss: 0.018816\n",
      "Epoch: 74/100... Step: 7665... Loss: 0.010207... Val Loss: 0.019467\n",
      "Epoch: 74/100... Step: 7666... Loss: 0.007313... Val Loss: 0.019236\n",
      "Epoch: 74/100... Step: 7667... Loss: 0.004771... Val Loss: 0.019438\n",
      "Epoch: 74/100... Step: 7668... Loss: 0.007594... Val Loss: 0.019373\n",
      "Epoch: 74/100... Step: 7669... Loss: 0.007298... Val Loss: 0.020993\n",
      "Epoch: 74/100... Step: 7670... Loss: 0.004842... Val Loss: 0.020863\n",
      "Epoch: 74/100... Step: 7671... Loss: 0.008860... Val Loss: 0.020161\n",
      "Epoch: 74/100... Step: 7672... Loss: 0.009604... Val Loss: 0.020619\n",
      "Epoch: 74/100... Step: 7673... Loss: 0.015380... Val Loss: 0.019252\n",
      "Epoch: 74/100... Step: 7674... Loss: 0.008255... Val Loss: 0.020372\n",
      "Epoch: 74/100... Step: 7675... Loss: 0.007434... Val Loss: 0.020904\n",
      "Epoch: 74/100... Step: 7676... Loss: 0.006112... Val Loss: 0.023721\n",
      "Epoch: 74/100... Step: 7677... Loss: 0.006575... Val Loss: 0.026799\n",
      "Epoch: 74/100... Step: 7678... Loss: 0.009460... Val Loss: 0.028489\n",
      "Epoch: 74/100... Step: 7679... Loss: 0.012272... Val Loss: 0.029619\n",
      "Epoch: 74/100... Step: 7680... Loss: 0.007642... Val Loss: 0.030306\n",
      "Epoch: 74/100... Step: 7681... Loss: 0.010544... Val Loss: 0.030206\n",
      "Epoch: 74/100... Step: 7682... Loss: 0.007979... Val Loss: 0.027867\n",
      "Epoch: 74/100... Step: 7683... Loss: 0.008907... Val Loss: 0.024209\n",
      "Epoch: 74/100... Step: 7684... Loss: 0.006007... Val Loss: 0.021815\n",
      "Epoch: 74/100... Step: 7685... Loss: 0.004684... Val Loss: 0.021256\n",
      "Epoch: 74/100... Step: 7686... Loss: 0.011314... Val Loss: 0.021498\n",
      "Epoch: 74/100... Step: 7687... Loss: 0.008839... Val Loss: 0.021162\n",
      "Epoch: 74/100... Step: 7688... Loss: 0.013034... Val Loss: 0.020442\n",
      "Epoch: 74/100... Step: 7689... Loss: 0.007380... Val Loss: 0.019954\n",
      "Epoch: 74/100... Step: 7690... Loss: 0.008255... Val Loss: 0.019317\n",
      "Epoch: 74/100... Step: 7691... Loss: 0.008066... Val Loss: 0.020183\n",
      "Epoch: 74/100... Step: 7692... Loss: 0.008231... Val Loss: 0.020211\n",
      "Epoch: 74/100... Step: 7693... Loss: 0.003636... Val Loss: 0.020913\n",
      "Epoch: 74/100... Step: 7694... Loss: 0.008877... Val Loss: 0.021639\n",
      "Epoch: 74/100... Step: 7695... Loss: 0.006578... Val Loss: 0.021952\n",
      "Epoch: 74/100... Step: 7696... Loss: 0.005297... Val Loss: 0.021877\n",
      "Epoch: 75/100... Step: 7697... Loss: 0.020530... Val Loss: 0.024540\n",
      "Epoch: 75/100... Step: 7698... Loss: 0.011459... Val Loss: 0.018369\n",
      "Epoch: 75/100... Step: 7699... Loss: 0.005462... Val Loss: 0.007873\n",
      "Epoch: 75/100... Step: 7700... Loss: 0.007981... Val Loss: 0.008490\n",
      "Epoch: 75/100... Step: 7701... Loss: 0.008374... Val Loss: 0.019721\n",
      "Epoch: 75/100... Step: 7702... Loss: 0.009973... Val Loss: 0.030165\n",
      "Epoch: 75/100... Step: 7703... Loss: 0.008316... Val Loss: 0.039667\n",
      "Epoch: 75/100... Step: 7704... Loss: 0.003634... Val Loss: 0.047232\n",
      "Epoch: 75/100... Step: 7705... Loss: 0.009440... Val Loss: 0.053016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Step: 7706... Loss: 0.006639... Val Loss: 0.057908\n",
      "Epoch: 75/100... Step: 7707... Loss: 0.008756... Val Loss: 0.062089\n",
      "Epoch: 75/100... Step: 7708... Loss: 0.013413... Val Loss: 0.066864\n",
      "Epoch: 75/100... Step: 7709... Loss: 0.011755... Val Loss: 0.070451\n",
      "Epoch: 75/100... Step: 7710... Loss: 0.009474... Val Loss: 0.072273\n",
      "Epoch: 75/100... Step: 7711... Loss: 0.007159... Val Loss: 0.073963\n",
      "Epoch: 75/100... Step: 7712... Loss: 0.005966... Val Loss: 0.074475\n",
      "Epoch: 75/100... Step: 7713... Loss: 0.005512... Val Loss: 0.074879\n",
      "Epoch: 75/100... Step: 7714... Loss: 0.005947... Val Loss: 0.074706\n",
      "Epoch: 75/100... Step: 7715... Loss: 0.008058... Val Loss: 0.074664\n",
      "Epoch: 75/100... Step: 7716... Loss: 0.008458... Val Loss: 0.074600\n",
      "Epoch: 75/100... Step: 7717... Loss: 0.013086... Val Loss: 0.073694\n",
      "Epoch: 75/100... Step: 7718... Loss: 0.005599... Val Loss: 0.073052\n",
      "Epoch: 75/100... Step: 7719... Loss: 0.006043... Val Loss: 0.071001\n",
      "Epoch: 75/100... Step: 7720... Loss: 0.009342... Val Loss: 0.068397\n",
      "Epoch: 75/100... Step: 7721... Loss: 0.009548... Val Loss: 0.066252\n",
      "Epoch: 75/100... Step: 7722... Loss: 0.009935... Val Loss: 0.064430\n",
      "Epoch: 75/100... Step: 7723... Loss: 0.007929... Val Loss: 0.063028\n",
      "Epoch: 75/100... Step: 7724... Loss: 0.011513... Val Loss: 0.060854\n",
      "Epoch: 75/100... Step: 7725... Loss: 0.009896... Val Loss: 0.058742\n",
      "Epoch: 75/100... Step: 7726... Loss: 0.007497... Val Loss: 0.055588\n",
      "Epoch: 75/100... Step: 7727... Loss: 0.005054... Val Loss: 0.051764\n",
      "Epoch: 75/100... Step: 7728... Loss: 0.008770... Val Loss: 0.048344\n",
      "Epoch: 75/100... Step: 7729... Loss: 0.010512... Val Loss: 0.045037\n",
      "Epoch: 75/100... Step: 7730... Loss: 0.006617... Val Loss: 0.042116\n",
      "Epoch: 75/100... Step: 7731... Loss: 0.010606... Val Loss: 0.040518\n",
      "Epoch: 75/100... Step: 7732... Loss: 0.007294... Val Loss: 0.040874\n",
      "Epoch: 75/100... Step: 7733... Loss: 0.009101... Val Loss: 0.041065\n",
      "Epoch: 75/100... Step: 7734... Loss: 0.007184... Val Loss: 0.038391\n",
      "Epoch: 75/100... Step: 7735... Loss: 0.006540... Val Loss: 0.032637\n",
      "Epoch: 75/100... Step: 7736... Loss: 0.010268... Val Loss: 0.026745\n",
      "Epoch: 75/100... Step: 7737... Loss: 0.006821... Val Loss: 0.024008\n",
      "Epoch: 75/100... Step: 7738... Loss: 0.007904... Val Loss: 0.022474\n",
      "Epoch: 75/100... Step: 7739... Loss: 0.010093... Val Loss: 0.022217\n",
      "Epoch: 75/100... Step: 7740... Loss: 0.009946... Val Loss: 0.021955\n",
      "Epoch: 75/100... Step: 7741... Loss: 0.007341... Val Loss: 0.021997\n",
      "Epoch: 75/100... Step: 7742... Loss: 0.010745... Val Loss: 0.021720\n",
      "Epoch: 75/100... Step: 7743... Loss: 0.005425... Val Loss: 0.020680\n",
      "Epoch: 75/100... Step: 7744... Loss: 0.009614... Val Loss: 0.021184\n",
      "Epoch: 75/100... Step: 7745... Loss: 0.005478... Val Loss: 0.019676\n",
      "Epoch: 75/100... Step: 7746... Loss: 0.006727... Val Loss: 0.017096\n",
      "Epoch: 75/100... Step: 7747... Loss: 0.006631... Val Loss: 0.015536\n",
      "Epoch: 75/100... Step: 7748... Loss: 0.008352... Val Loss: 0.013948\n",
      "Epoch: 75/100... Step: 7749... Loss: 0.010593... Val Loss: 0.013165\n",
      "Epoch: 75/100... Step: 7750... Loss: 0.007599... Val Loss: 0.012657\n",
      "Epoch: 75/100... Step: 7751... Loss: 0.008287... Val Loss: 0.012460\n",
      "Epoch: 75/100... Step: 7752... Loss: 0.006430... Val Loss: 0.012506\n",
      "Epoch: 75/100... Step: 7753... Loss: 0.007604... Val Loss: 0.013018\n",
      "Epoch: 75/100... Step: 7754... Loss: 0.009571... Val Loss: 0.013803\n",
      "Epoch: 75/100... Step: 7755... Loss: 0.009224... Val Loss: 0.014219\n",
      "Epoch: 75/100... Step: 7756... Loss: 0.006779... Val Loss: 0.014331\n",
      "Epoch: 75/100... Step: 7757... Loss: 0.010590... Val Loss: 0.014340\n",
      "Epoch: 75/100... Step: 7758... Loss: 0.010364... Val Loss: 0.014769\n",
      "Epoch: 75/100... Step: 7759... Loss: 0.007631... Val Loss: 0.015905\n",
      "Epoch: 75/100... Step: 7760... Loss: 0.008869... Val Loss: 0.017181\n",
      "Epoch: 75/100... Step: 7761... Loss: 0.010318... Val Loss: 0.018217\n",
      "Epoch: 75/100... Step: 7762... Loss: 0.008372... Val Loss: 0.019206\n",
      "Epoch: 75/100... Step: 7763... Loss: 0.005553... Val Loss: 0.020096\n",
      "Epoch: 75/100... Step: 7764... Loss: 0.005339... Val Loss: 0.020695\n",
      "Epoch: 75/100... Step: 7765... Loss: 0.006286... Val Loss: 0.020523\n",
      "Epoch: 75/100... Step: 7766... Loss: 0.006364... Val Loss: 0.020947\n",
      "Epoch: 75/100... Step: 7767... Loss: 0.005161... Val Loss: 0.019887\n",
      "Epoch: 75/100... Step: 7768... Loss: 0.007458... Val Loss: 0.019463\n",
      "Epoch: 75/100... Step: 7769... Loss: 0.008710... Val Loss: 0.018517\n",
      "Epoch: 75/100... Step: 7770... Loss: 0.009606... Val Loss: 0.017366\n",
      "Epoch: 75/100... Step: 7771... Loss: 0.006611... Val Loss: 0.017489\n",
      "Epoch: 75/100... Step: 7772... Loss: 0.007101... Val Loss: 0.017237\n",
      "Epoch: 75/100... Step: 7773... Loss: 0.007782... Val Loss: 0.016815\n",
      "Epoch: 75/100... Step: 7774... Loss: 0.010840... Val Loss: 0.016277\n",
      "Epoch: 75/100... Step: 7775... Loss: 0.008570... Val Loss: 0.015421\n",
      "Epoch: 75/100... Step: 7776... Loss: 0.006045... Val Loss: 0.014277\n",
      "Epoch: 75/100... Step: 7777... Loss: 0.005383... Val Loss: 0.013888\n",
      "Epoch: 75/100... Step: 7778... Loss: 0.008256... Val Loss: 0.014778\n",
      "Epoch: 75/100... Step: 7779... Loss: 0.009052... Val Loss: 0.015203\n",
      "Epoch: 75/100... Step: 7780... Loss: 0.006832... Val Loss: 0.015719\n",
      "Epoch: 75/100... Step: 7781... Loss: 0.009593... Val Loss: 0.015497\n",
      "Epoch: 75/100... Step: 7782... Loss: 0.007156... Val Loss: 0.015262\n",
      "Epoch: 75/100... Step: 7783... Loss: 0.009504... Val Loss: 0.015684\n",
      "Epoch: 75/100... Step: 7784... Loss: 0.006291... Val Loss: 0.016101\n",
      "Epoch: 75/100... Step: 7785... Loss: 0.010614... Val Loss: 0.016397\n",
      "Epoch: 75/100... Step: 7786... Loss: 0.009831... Val Loss: 0.017441\n",
      "Epoch: 75/100... Step: 7787... Loss: 0.007841... Val Loss: 0.018342\n",
      "Epoch: 75/100... Step: 7788... Loss: 0.009146... Val Loss: 0.018720\n",
      "Epoch: 75/100... Step: 7789... Loss: 0.005810... Val Loss: 0.018490\n",
      "Epoch: 75/100... Step: 7790... Loss: 0.005716... Val Loss: 0.018216\n",
      "Epoch: 75/100... Step: 7791... Loss: 0.007465... Val Loss: 0.017742\n",
      "Epoch: 75/100... Step: 7792... Loss: 0.007958... Val Loss: 0.017409\n",
      "Epoch: 75/100... Step: 7793... Loss: 0.008661... Val Loss: 0.018823\n",
      "Epoch: 75/100... Step: 7794... Loss: 0.004292... Val Loss: 0.020447\n",
      "Epoch: 75/100... Step: 7795... Loss: 0.006440... Val Loss: 0.022444\n",
      "Epoch: 75/100... Step: 7796... Loss: 0.007166... Val Loss: 0.023731\n",
      "Epoch: 75/100... Step: 7797... Loss: 0.011531... Val Loss: 0.024287\n",
      "Epoch: 75/100... Step: 7798... Loss: 0.004613... Val Loss: 0.025958\n",
      "Epoch: 75/100... Step: 7799... Loss: 0.006864... Val Loss: 0.026599\n",
      "Epoch: 75/100... Step: 7800... Loss: 0.008061... Val Loss: 0.026098\n",
      "Epoch: 76/100... Step: 7801... Loss: 0.012731... Val Loss: 0.011358\n",
      "Epoch: 76/100... Step: 7802... Loss: 0.009263... Val Loss: 0.006167\n",
      "Epoch: 76/100... Step: 7803... Loss: 0.004703... Val Loss: 0.004326\n",
      "Epoch: 76/100... Step: 7804... Loss: 0.007749... Val Loss: 0.003692\n",
      "Epoch: 76/100... Step: 7805... Loss: 0.009264... Val Loss: 0.003447\n",
      "Epoch: 76/100... Step: 7806... Loss: 0.012951... Val Loss: 0.002999\n",
      "Epoch: 76/100... Step: 7807... Loss: 0.007801... Val Loss: 0.002432\n",
      "Validation loss decreased (0.002503 --> 0.002432).  Saving model ...\n",
      "Epoch: 76/100... Step: 7808... Loss: 0.007445... Val Loss: 0.002792\n",
      "Epoch: 76/100... Step: 7809... Loss: 0.007553... Val Loss: 0.003899\n",
      "Epoch: 76/100... Step: 7810... Loss: 0.006466... Val Loss: 0.005301\n",
      "Epoch: 76/100... Step: 7811... Loss: 0.005153... Val Loss: 0.005808\n",
      "Epoch: 76/100... Step: 7812... Loss: 0.007174... Val Loss: 0.005810\n",
      "Epoch: 76/100... Step: 7813... Loss: 0.009001... Val Loss: 0.005430\n",
      "Epoch: 76/100... Step: 7814... Loss: 0.006860... Val Loss: 0.005550\n",
      "Epoch: 76/100... Step: 7815... Loss: 0.005991... Val Loss: 0.006018\n",
      "Epoch: 76/100... Step: 7816... Loss: 0.006237... Val Loss: 0.006652\n",
      "Epoch: 76/100... Step: 7817... Loss: 0.006738... Val Loss: 0.007283\n",
      "Epoch: 76/100... Step: 7818... Loss: 0.007091... Val Loss: 0.007495\n",
      "Epoch: 76/100... Step: 7819... Loss: 0.007388... Val Loss: 0.007327\n",
      "Epoch: 76/100... Step: 7820... Loss: 0.009427... Val Loss: 0.007255\n",
      "Epoch: 76/100... Step: 7821... Loss: 0.005661... Val Loss: 0.007166\n",
      "Epoch: 76/100... Step: 7822... Loss: 0.009817... Val Loss: 0.007655\n",
      "Epoch: 76/100... Step: 7823... Loss: 0.005407... Val Loss: 0.008566\n",
      "Epoch: 76/100... Step: 7824... Loss: 0.007107... Val Loss: 0.010134\n",
      "Epoch: 76/100... Step: 7825... Loss: 0.005731... Val Loss: 0.011831\n",
      "Epoch: 76/100... Step: 7826... Loss: 0.008444... Val Loss: 0.013925\n",
      "Epoch: 76/100... Step: 7827... Loss: 0.005285... Val Loss: 0.017059\n",
      "Epoch: 76/100... Step: 7828... Loss: 0.007844... Val Loss: 0.018680\n",
      "Epoch: 76/100... Step: 7829... Loss: 0.007267... Val Loss: 0.020310\n",
      "Epoch: 76/100... Step: 7830... Loss: 0.006717... Val Loss: 0.020342\n",
      "Epoch: 76/100... Step: 7831... Loss: 0.011776... Val Loss: 0.018947\n",
      "Epoch: 76/100... Step: 7832... Loss: 0.008298... Val Loss: 0.017453\n",
      "Epoch: 76/100... Step: 7833... Loss: 0.005090... Val Loss: 0.015206\n",
      "Epoch: 76/100... Step: 7834... Loss: 0.005065... Val Loss: 0.013445\n",
      "Epoch: 76/100... Step: 7835... Loss: 0.008447... Val Loss: 0.012863\n",
      "Epoch: 76/100... Step: 7836... Loss: 0.005446... Val Loss: 0.013099\n",
      "Epoch: 76/100... Step: 7837... Loss: 0.008954... Val Loss: 0.013435\n",
      "Epoch: 76/100... Step: 7838... Loss: 0.007451... Val Loss: 0.013857\n",
      "Epoch: 76/100... Step: 7839... Loss: 0.008098... Val Loss: 0.013886\n",
      "Epoch: 76/100... Step: 7840... Loss: 0.011729... Val Loss: 0.013999\n",
      "Epoch: 76/100... Step: 7841... Loss: 0.009680... Val Loss: 0.014139\n",
      "Epoch: 76/100... Step: 7842... Loss: 0.007553... Val Loss: 0.014156\n",
      "Epoch: 76/100... Step: 7843... Loss: 0.006690... Val Loss: 0.015206\n",
      "Epoch: 76/100... Step: 7844... Loss: 0.008604... Val Loss: 0.016264\n",
      "Epoch: 76/100... Step: 7845... Loss: 0.005800... Val Loss: 0.016751\n",
      "Epoch: 76/100... Step: 7846... Loss: 0.008437... Val Loss: 0.017958\n",
      "Epoch: 76/100... Step: 7847... Loss: 0.005461... Val Loss: 0.017726\n",
      "Epoch: 76/100... Step: 7848... Loss: 0.007244... Val Loss: 0.016684\n",
      "Epoch: 76/100... Step: 7849... Loss: 0.007070... Val Loss: 0.014000\n",
      "Epoch: 76/100... Step: 7850... Loss: 0.006644... Val Loss: 0.012401\n",
      "Epoch: 76/100... Step: 7851... Loss: 0.006977... Val Loss: 0.011566\n",
      "Epoch: 76/100... Step: 7852... Loss: 0.004957... Val Loss: 0.010786\n",
      "Epoch: 76/100... Step: 7853... Loss: 0.007264... Val Loss: 0.011124\n",
      "Epoch: 76/100... Step: 7854... Loss: 0.007505... Val Loss: 0.009865\n",
      "Epoch: 76/100... Step: 7855... Loss: 0.011421... Val Loss: 0.008733\n",
      "Epoch: 76/100... Step: 7856... Loss: 0.007151... Val Loss: 0.007028\n",
      "Epoch: 76/100... Step: 7857... Loss: 0.010618... Val Loss: 0.005415\n",
      "Epoch: 76/100... Step: 7858... Loss: 0.008229... Val Loss: 0.005117\n",
      "Epoch: 76/100... Step: 7859... Loss: 0.003731... Val Loss: 0.004831\n",
      "Epoch: 76/100... Step: 7860... Loss: 0.009480... Val Loss: 0.003991\n",
      "Epoch: 76/100... Step: 7861... Loss: 0.005986... Val Loss: 0.003359\n",
      "Epoch: 76/100... Step: 7862... Loss: 0.009002... Val Loss: 0.003364\n",
      "Epoch: 76/100... Step: 7863... Loss: 0.007769... Val Loss: 0.004400\n",
      "Epoch: 76/100... Step: 7864... Loss: 0.008287... Val Loss: 0.005504\n",
      "Epoch: 76/100... Step: 7865... Loss: 0.008780... Val Loss: 0.006513\n",
      "Epoch: 76/100... Step: 7866... Loss: 0.007862... Val Loss: 0.006899\n",
      "Epoch: 76/100... Step: 7867... Loss: 0.008809... Val Loss: 0.006428\n",
      "Epoch: 76/100... Step: 7868... Loss: 0.009719... Val Loss: 0.005511\n",
      "Epoch: 76/100... Step: 7869... Loss: 0.006444... Val Loss: 0.004824\n",
      "Epoch: 76/100... Step: 7870... Loss: 0.007477... Val Loss: 0.005960\n",
      "Epoch: 76/100... Step: 7871... Loss: 0.006377... Val Loss: 0.006679\n",
      "Epoch: 76/100... Step: 7872... Loss: 0.009526... Val Loss: 0.006313\n",
      "Epoch: 76/100... Step: 7873... Loss: 0.007614... Val Loss: 0.005608\n",
      "Epoch: 76/100... Step: 7874... Loss: 0.004925... Val Loss: 0.003997\n",
      "Epoch: 76/100... Step: 7875... Loss: 0.009392... Val Loss: 0.003460\n",
      "Epoch: 76/100... Step: 7876... Loss: 0.008689... Val Loss: 0.003451\n",
      "Epoch: 76/100... Step: 7877... Loss: 0.007746... Val Loss: 0.003321\n",
      "Epoch: 76/100... Step: 7878... Loss: 0.005757... Val Loss: 0.003341\n",
      "Epoch: 76/100... Step: 7879... Loss: 0.007234... Val Loss: 0.003370\n",
      "Epoch: 76/100... Step: 7880... Loss: 0.007276... Val Loss: 0.003548\n",
      "Epoch: 76/100... Step: 7881... Loss: 0.006774... Val Loss: 0.004808\n",
      "Epoch: 76/100... Step: 7882... Loss: 0.007261... Val Loss: 0.006888\n",
      "Epoch: 76/100... Step: 7883... Loss: 0.009795... Val Loss: 0.009541\n",
      "Epoch: 76/100... Step: 7884... Loss: 0.010594... Val Loss: 0.011761\n",
      "Epoch: 76/100... Step: 7885... Loss: 0.006624... Val Loss: 0.013102\n",
      "Epoch: 76/100... Step: 7886... Loss: 0.007174... Val Loss: 0.014775\n",
      "Epoch: 76/100... Step: 7887... Loss: 0.006528... Val Loss: 0.017839\n",
      "Epoch: 76/100... Step: 7888... Loss: 0.006203... Val Loss: 0.020369\n",
      "Epoch: 76/100... Step: 7889... Loss: 0.005138... Val Loss: 0.023068\n",
      "Epoch: 76/100... Step: 7890... Loss: 0.006263... Val Loss: 0.024140\n",
      "Epoch: 76/100... Step: 7891... Loss: 0.009355... Val Loss: 0.023622\n",
      "Epoch: 76/100... Step: 7892... Loss: 0.004668... Val Loss: 0.023610\n",
      "Epoch: 76/100... Step: 7893... Loss: 0.007584... Val Loss: 0.024310\n",
      "Epoch: 76/100... Step: 7894... Loss: 0.008949... Val Loss: 0.025359\n",
      "Epoch: 76/100... Step: 7895... Loss: 0.008149... Val Loss: 0.026690\n",
      "Epoch: 76/100... Step: 7896... Loss: 0.006421... Val Loss: 0.027875\n",
      "Epoch: 76/100... Step: 7897... Loss: 0.006860... Val Loss: 0.028812\n",
      "Epoch: 76/100... Step: 7898... Loss: 0.005720... Val Loss: 0.028310\n",
      "Epoch: 76/100... Step: 7899... Loss: 0.007066... Val Loss: 0.026883\n",
      "Epoch: 76/100... Step: 7900... Loss: 0.007172... Val Loss: 0.026059\n",
      "Epoch: 76/100... Step: 7901... Loss: 0.008447... Val Loss: 0.024192\n",
      "Epoch: 76/100... Step: 7902... Loss: 0.010254... Val Loss: 0.023308\n",
      "Epoch: 76/100... Step: 7903... Loss: 0.007125... Val Loss: 0.022743\n",
      "Epoch: 76/100... Step: 7904... Loss: 0.002667... Val Loss: 0.022510\n",
      "Epoch: 77/100... Step: 7905... Loss: 0.011750... Val Loss: 0.007498\n",
      "Epoch: 77/100... Step: 7906... Loss: 0.006653... Val Loss: 0.008135\n",
      "Epoch: 77/100... Step: 7907... Loss: 0.005681... Val Loss: 0.010284\n",
      "Epoch: 77/100... Step: 7908... Loss: 0.007841... Val Loss: 0.010720\n",
      "Epoch: 77/100... Step: 7909... Loss: 0.005550... Val Loss: 0.010231\n",
      "Epoch: 77/100... Step: 7910... Loss: 0.008353... Val Loss: 0.008632\n",
      "Epoch: 77/100... Step: 7911... Loss: 0.009359... Val Loss: 0.007059\n",
      "Epoch: 77/100... Step: 7912... Loss: 0.005659... Val Loss: 0.006525\n",
      "Epoch: 77/100... Step: 7913... Loss: 0.010344... Val Loss: 0.006027\n",
      "Epoch: 77/100... Step: 7914... Loss: 0.009266... Val Loss: 0.006706\n",
      "Epoch: 77/100... Step: 7915... Loss: 0.005274... Val Loss: 0.008363\n",
      "Epoch: 77/100... Step: 7916... Loss: 0.005798... Val Loss: 0.009681\n",
      "Epoch: 77/100... Step: 7917... Loss: 0.004788... Val Loss: 0.010424\n",
      "Epoch: 77/100... Step: 7918... Loss: 0.007295... Val Loss: 0.010739\n",
      "Epoch: 77/100... Step: 7919... Loss: 0.004770... Val Loss: 0.010945\n",
      "Epoch: 77/100... Step: 7920... Loss: 0.007974... Val Loss: 0.011469\n",
      "Epoch: 77/100... Step: 7921... Loss: 0.007599... Val Loss: 0.011652\n",
      "Epoch: 77/100... Step: 7922... Loss: 0.008240... Val Loss: 0.011199\n",
      "Epoch: 77/100... Step: 7923... Loss: 0.007667... Val Loss: 0.011055\n",
      "Epoch: 77/100... Step: 7924... Loss: 0.007967... Val Loss: 0.010584\n",
      "Epoch: 77/100... Step: 7925... Loss: 0.008813... Val Loss: 0.010387\n",
      "Epoch: 77/100... Step: 7926... Loss: 0.005067... Val Loss: 0.011735\n",
      "Epoch: 77/100... Step: 7927... Loss: 0.008917... Val Loss: 0.013405\n",
      "Epoch: 77/100... Step: 7928... Loss: 0.008303... Val Loss: 0.014290\n",
      "Epoch: 77/100... Step: 7929... Loss: 0.006809... Val Loss: 0.014942\n",
      "Epoch: 77/100... Step: 7930... Loss: 0.007984... Val Loss: 0.015248\n",
      "Epoch: 77/100... Step: 7931... Loss: 0.009737... Val Loss: 0.015970\n",
      "Epoch: 77/100... Step: 7932... Loss: 0.004379... Val Loss: 0.016452\n",
      "Epoch: 77/100... Step: 7933... Loss: 0.003849... Val Loss: 0.015833\n",
      "Epoch: 77/100... Step: 7934... Loss: 0.008822... Val Loss: 0.015030\n",
      "Epoch: 77/100... Step: 7935... Loss: 0.008565... Val Loss: 0.013322\n",
      "Epoch: 77/100... Step: 7936... Loss: 0.008326... Val Loss: 0.011158\n",
      "Epoch: 77/100... Step: 7937... Loss: 0.007355... Val Loss: 0.008824\n",
      "Epoch: 77/100... Step: 7938... Loss: 0.007591... Val Loss: 0.005855\n",
      "Epoch: 77/100... Step: 7939... Loss: 0.005445... Val Loss: 0.004423\n",
      "Epoch: 77/100... Step: 7940... Loss: 0.007308... Val Loss: 0.003120\n",
      "Epoch: 77/100... Step: 7941... Loss: 0.007132... Val Loss: 0.002750\n",
      "Epoch: 77/100... Step: 7942... Loss: 0.005857... Val Loss: 0.002281\n",
      "Validation loss decreased (0.002432 --> 0.002281).  Saving model ...\n",
      "Epoch: 77/100... Step: 7943... Loss: 0.008276... Val Loss: 0.002093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.002281 --> 0.002093).  Saving model ...\n",
      "Epoch: 77/100... Step: 7944... Loss: 0.007705... Val Loss: 0.002830\n",
      "Epoch: 77/100... Step: 7945... Loss: 0.007553... Val Loss: 0.003605\n",
      "Epoch: 77/100... Step: 7946... Loss: 0.007255... Val Loss: 0.003430\n",
      "Epoch: 77/100... Step: 7947... Loss: 0.006729... Val Loss: 0.004317\n",
      "Epoch: 77/100... Step: 7948... Loss: 0.006396... Val Loss: 0.004335\n",
      "Epoch: 77/100... Step: 7949... Loss: 0.008498... Val Loss: 0.005123\n",
      "Epoch: 77/100... Step: 7950... Loss: 0.009148... Val Loss: 0.005093\n",
      "Epoch: 77/100... Step: 7951... Loss: 0.007836... Val Loss: 0.004313\n",
      "Epoch: 77/100... Step: 7952... Loss: 0.007386... Val Loss: 0.003262\n",
      "Epoch: 77/100... Step: 7953... Loss: 0.008703... Val Loss: 0.002525\n",
      "Epoch: 77/100... Step: 7954... Loss: 0.008278... Val Loss: 0.002594\n",
      "Epoch: 77/100... Step: 7955... Loss: 0.006413... Val Loss: 0.002930\n",
      "Epoch: 77/100... Step: 7956... Loss: 0.007571... Val Loss: 0.003450\n",
      "Epoch: 77/100... Step: 7957... Loss: 0.006990... Val Loss: 0.003809\n",
      "Epoch: 77/100... Step: 7958... Loss: 0.008726... Val Loss: 0.004666\n",
      "Epoch: 77/100... Step: 7959... Loss: 0.006691... Val Loss: 0.005474\n",
      "Epoch: 77/100... Step: 7960... Loss: 0.005738... Val Loss: 0.005915\n",
      "Epoch: 77/100... Step: 7961... Loss: 0.006423... Val Loss: 0.005946\n",
      "Epoch: 77/100... Step: 7962... Loss: 0.007676... Val Loss: 0.005948\n",
      "Epoch: 77/100... Step: 7963... Loss: 0.005866... Val Loss: 0.005179\n",
      "Epoch: 77/100... Step: 7964... Loss: 0.006867... Val Loss: 0.003979\n",
      "Epoch: 77/100... Step: 7965... Loss: 0.010587... Val Loss: 0.004505\n",
      "Epoch: 77/100... Step: 7966... Loss: 0.007118... Val Loss: 0.004781\n",
      "Epoch: 77/100... Step: 7967... Loss: 0.007133... Val Loss: 0.005086\n",
      "Epoch: 77/100... Step: 7968... Loss: 0.004641... Val Loss: 0.005682\n",
      "Epoch: 77/100... Step: 7969... Loss: 0.007480... Val Loss: 0.006179\n",
      "Epoch: 77/100... Step: 7970... Loss: 0.005710... Val Loss: 0.006084\n",
      "Epoch: 77/100... Step: 7971... Loss: 0.009696... Val Loss: 0.005290\n",
      "Epoch: 77/100... Step: 7972... Loss: 0.009743... Val Loss: 0.004137\n",
      "Epoch: 77/100... Step: 7973... Loss: 0.009645... Val Loss: 0.003347\n",
      "Epoch: 77/100... Step: 7974... Loss: 0.007607... Val Loss: 0.004517\n",
      "Epoch: 77/100... Step: 7975... Loss: 0.008347... Val Loss: 0.006301\n",
      "Epoch: 77/100... Step: 7976... Loss: 0.003522... Val Loss: 0.007888\n",
      "Epoch: 77/100... Step: 7977... Loss: 0.006297... Val Loss: 0.009600\n",
      "Epoch: 77/100... Step: 7978... Loss: 0.006596... Val Loss: 0.009934\n",
      "Epoch: 77/100... Step: 7979... Loss: 0.010138... Val Loss: 0.009512\n",
      "Epoch: 77/100... Step: 7980... Loss: 0.009568... Val Loss: 0.008108\n",
      "Epoch: 77/100... Step: 7981... Loss: 0.007354... Val Loss: 0.007643\n",
      "Epoch: 77/100... Step: 7982... Loss: 0.008750... Val Loss: 0.006462\n",
      "Epoch: 77/100... Step: 7983... Loss: 0.011354... Val Loss: 0.004017\n",
      "Epoch: 77/100... Step: 7984... Loss: 0.006324... Val Loss: 0.002630\n",
      "Epoch: 77/100... Step: 7985... Loss: 0.005262... Val Loss: 0.003354\n",
      "Epoch: 77/100... Step: 7986... Loss: 0.007475... Val Loss: 0.005129\n",
      "Epoch: 77/100... Step: 7987... Loss: 0.007741... Val Loss: 0.006844\n",
      "Epoch: 77/100... Step: 7988... Loss: 0.008439... Val Loss: 0.008448\n",
      "Epoch: 77/100... Step: 7989... Loss: 0.006118... Val Loss: 0.010239\n",
      "Epoch: 77/100... Step: 7990... Loss: 0.005620... Val Loss: 0.011406\n",
      "Epoch: 77/100... Step: 7991... Loss: 0.008435... Val Loss: 0.010806\n",
      "Epoch: 77/100... Step: 7992... Loss: 0.005256... Val Loss: 0.010288\n",
      "Epoch: 77/100... Step: 7993... Loss: 0.007249... Val Loss: 0.009253\n",
      "Epoch: 77/100... Step: 7994... Loss: 0.008195... Val Loss: 0.008315\n",
      "Epoch: 77/100... Step: 7995... Loss: 0.005333... Val Loss: 0.006910\n",
      "Epoch: 77/100... Step: 7996... Loss: 0.007208... Val Loss: 0.005403\n",
      "Epoch: 77/100... Step: 7997... Loss: 0.006609... Val Loss: 0.005218\n",
      "Epoch: 77/100... Step: 7998... Loss: 0.005449... Val Loss: 0.005841\n",
      "Epoch: 77/100... Step: 7999... Loss: 0.007262... Val Loss: 0.006711\n",
      "Epoch: 77/100... Step: 8000... Loss: 0.006863... Val Loss: 0.006724\n",
      "Epoch: 77/100... Step: 8001... Loss: 0.007640... Val Loss: 0.006818\n",
      "Epoch: 77/100... Step: 8002... Loss: 0.006197... Val Loss: 0.006810\n",
      "Epoch: 77/100... Step: 8003... Loss: 0.007543... Val Loss: 0.006756\n",
      "Epoch: 77/100... Step: 8004... Loss: 0.008813... Val Loss: 0.006730\n",
      "Epoch: 77/100... Step: 8005... Loss: 0.008009... Val Loss: 0.006891\n",
      "Epoch: 77/100... Step: 8006... Loss: 0.005759... Val Loss: 0.007051\n",
      "Epoch: 77/100... Step: 8007... Loss: 0.003024... Val Loss: 0.007573\n",
      "Epoch: 77/100... Step: 8008... Loss: 0.004785... Val Loss: 0.007654\n",
      "Epoch: 78/100... Step: 8009... Loss: 0.007774... Val Loss: 0.008056\n",
      "Epoch: 78/100... Step: 8010... Loss: 0.007969... Val Loss: 0.011472\n",
      "Epoch: 78/100... Step: 8011... Loss: 0.008044... Val Loss: 0.019487\n",
      "Epoch: 78/100... Step: 8012... Loss: 0.005514... Val Loss: 0.026647\n",
      "Epoch: 78/100... Step: 8013... Loss: 0.005383... Val Loss: 0.033204\n",
      "Epoch: 78/100... Step: 8014... Loss: 0.006247... Val Loss: 0.038978\n",
      "Epoch: 78/100... Step: 8015... Loss: 0.006238... Val Loss: 0.043809\n",
      "Epoch: 78/100... Step: 8016... Loss: 0.006158... Val Loss: 0.047939\n",
      "Epoch: 78/100... Step: 8017... Loss: 0.006576... Val Loss: 0.051438\n",
      "Epoch: 78/100... Step: 8018... Loss: 0.005207... Val Loss: 0.054299\n",
      "Epoch: 78/100... Step: 8019... Loss: 0.006460... Val Loss: 0.056662\n",
      "Epoch: 78/100... Step: 8020... Loss: 0.006863... Val Loss: 0.058046\n",
      "Epoch: 78/100... Step: 8021... Loss: 0.005740... Val Loss: 0.059004\n",
      "Epoch: 78/100... Step: 8022... Loss: 0.005302... Val Loss: 0.059147\n",
      "Epoch: 78/100... Step: 8023... Loss: 0.007579... Val Loss: 0.059165\n",
      "Epoch: 78/100... Step: 8024... Loss: 0.006283... Val Loss: 0.059347\n",
      "Epoch: 78/100... Step: 8025... Loss: 0.012323... Val Loss: 0.058553\n",
      "Epoch: 78/100... Step: 8026... Loss: 0.007554... Val Loss: 0.057421\n",
      "Epoch: 78/100... Step: 8027... Loss: 0.007740... Val Loss: 0.055780\n",
      "Epoch: 78/100... Step: 8028... Loss: 0.009950... Val Loss: 0.053635\n",
      "Epoch: 78/100... Step: 8029... Loss: 0.008664... Val Loss: 0.050434\n",
      "Epoch: 78/100... Step: 8030... Loss: 0.005025... Val Loss: 0.047288\n",
      "Epoch: 78/100... Step: 8031... Loss: 0.008053... Val Loss: 0.044490\n",
      "Epoch: 78/100... Step: 8032... Loss: 0.009811... Val Loss: 0.041592\n",
      "Epoch: 78/100... Step: 8033... Loss: 0.006122... Val Loss: 0.039132\n",
      "Epoch: 78/100... Step: 8034... Loss: 0.008722... Val Loss: 0.036394\n",
      "Epoch: 78/100... Step: 8035... Loss: 0.009375... Val Loss: 0.033999\n",
      "Epoch: 78/100... Step: 8036... Loss: 0.008311... Val Loss: 0.032294\n",
      "Epoch: 78/100... Step: 8037... Loss: 0.005849... Val Loss: 0.030866\n",
      "Epoch: 78/100... Step: 8038... Loss: 0.003428... Val Loss: 0.029656\n",
      "Epoch: 78/100... Step: 8039... Loss: 0.006720... Val Loss: 0.028382\n",
      "Epoch: 78/100... Step: 8040... Loss: 0.006262... Val Loss: 0.027829\n",
      "Epoch: 78/100... Step: 8041... Loss: 0.005414... Val Loss: 0.027028\n",
      "Epoch: 78/100... Step: 8042... Loss: 0.004679... Val Loss: 0.026637\n",
      "Epoch: 78/100... Step: 8043... Loss: 0.010119... Val Loss: 0.026371\n",
      "Epoch: 78/100... Step: 8044... Loss: 0.009510... Val Loss: 0.025421\n",
      "Epoch: 78/100... Step: 8045... Loss: 0.009770... Val Loss: 0.023817\n",
      "Epoch: 78/100... Step: 8046... Loss: 0.011686... Val Loss: 0.021946\n",
      "Epoch: 78/100... Step: 8047... Loss: 0.008102... Val Loss: 0.021021\n",
      "Epoch: 78/100... Step: 8048... Loss: 0.007672... Val Loss: 0.019658\n",
      "Epoch: 78/100... Step: 8049... Loss: 0.009614... Val Loss: 0.018638\n",
      "Epoch: 78/100... Step: 8050... Loss: 0.007627... Val Loss: 0.017438\n",
      "Epoch: 78/100... Step: 8051... Loss: 0.006529... Val Loss: 0.016049\n",
      "Epoch: 78/100... Step: 8052... Loss: 0.003632... Val Loss: 0.014972\n",
      "Epoch: 78/100... Step: 8053... Loss: 0.007812... Val Loss: 0.013828\n",
      "Epoch: 78/100... Step: 8054... Loss: 0.006730... Val Loss: 0.012824\n",
      "Epoch: 78/100... Step: 8055... Loss: 0.008722... Val Loss: 0.012430\n",
      "Epoch: 78/100... Step: 8056... Loss: 0.009327... Val Loss: 0.012107\n",
      "Epoch: 78/100... Step: 8057... Loss: 0.006636... Val Loss: 0.011940\n",
      "Epoch: 78/100... Step: 8058... Loss: 0.008859... Val Loss: 0.012183\n",
      "Epoch: 78/100... Step: 8059... Loss: 0.008636... Val Loss: 0.013065\n",
      "Epoch: 78/100... Step: 8060... Loss: 0.006873... Val Loss: 0.014716\n",
      "Epoch: 78/100... Step: 8061... Loss: 0.006203... Val Loss: 0.015462\n",
      "Epoch: 78/100... Step: 8062... Loss: 0.003984... Val Loss: 0.016457\n",
      "Epoch: 78/100... Step: 8063... Loss: 0.009151... Val Loss: 0.016865\n",
      "Epoch: 78/100... Step: 8064... Loss: 0.007045... Val Loss: 0.016308\n",
      "Epoch: 78/100... Step: 8065... Loss: 0.004307... Val Loss: 0.016161\n",
      "Epoch: 78/100... Step: 8066... Loss: 0.007793... Val Loss: 0.015283\n",
      "Epoch: 78/100... Step: 8067... Loss: 0.006266... Val Loss: 0.014636\n",
      "Epoch: 78/100... Step: 8068... Loss: 0.007118... Val Loss: 0.013196\n",
      "Epoch: 78/100... Step: 8069... Loss: 0.006901... Val Loss: 0.011401\n",
      "Epoch: 78/100... Step: 8070... Loss: 0.006802... Val Loss: 0.010742\n",
      "Epoch: 78/100... Step: 8071... Loss: 0.004531... Val Loss: 0.011125\n",
      "Epoch: 78/100... Step: 8072... Loss: 0.005483... Val Loss: 0.011120\n",
      "Epoch: 78/100... Step: 8073... Loss: 0.008395... Val Loss: 0.010780\n",
      "Epoch: 78/100... Step: 8074... Loss: 0.005465... Val Loss: 0.010274\n",
      "Epoch: 78/100... Step: 8075... Loss: 0.013120... Val Loss: 0.008703\n",
      "Epoch: 78/100... Step: 8076... Loss: 0.004792... Val Loss: 0.007180\n",
      "Epoch: 78/100... Step: 8077... Loss: 0.005533... Val Loss: 0.006340\n",
      "Epoch: 78/100... Step: 8078... Loss: 0.008813... Val Loss: 0.006399\n",
      "Epoch: 78/100... Step: 8079... Loss: 0.005578... Val Loss: 0.006913\n",
      "Epoch: 78/100... Step: 8080... Loss: 0.007140... Val Loss: 0.006486\n",
      "Epoch: 78/100... Step: 8081... Loss: 0.003674... Val Loss: 0.006677\n",
      "Epoch: 78/100... Step: 8082... Loss: 0.003575... Val Loss: 0.006038\n",
      "Epoch: 78/100... Step: 8083... Loss: 0.005508... Val Loss: 0.004780\n",
      "Epoch: 78/100... Step: 8084... Loss: 0.004896... Val Loss: 0.004158\n",
      "Epoch: 78/100... Step: 8085... Loss: 0.009195... Val Loss: 0.003577\n",
      "Epoch: 78/100... Step: 8086... Loss: 0.006224... Val Loss: 0.003173\n",
      "Epoch: 78/100... Step: 8087... Loss: 0.005780... Val Loss: 0.003710\n",
      "Epoch: 78/100... Step: 8088... Loss: 0.005980... Val Loss: 0.004909\n",
      "Epoch: 78/100... Step: 8089... Loss: 0.007921... Val Loss: 0.006756\n",
      "Epoch: 78/100... Step: 8090... Loss: 0.004853... Val Loss: 0.007898\n",
      "Epoch: 78/100... Step: 8091... Loss: 0.007793... Val Loss: 0.008670\n",
      "Epoch: 78/100... Step: 8092... Loss: 0.005850... Val Loss: 0.008994\n",
      "Epoch: 78/100... Step: 8093... Loss: 0.005211... Val Loss: 0.008708\n",
      "Epoch: 78/100... Step: 8094... Loss: 0.005207... Val Loss: 0.008554\n",
      "Epoch: 78/100... Step: 8095... Loss: 0.008256... Val Loss: 0.008089\n",
      "Epoch: 78/100... Step: 8096... Loss: 0.004946... Val Loss: 0.007762\n",
      "Epoch: 78/100... Step: 8097... Loss: 0.004935... Val Loss: 0.007424\n",
      "Epoch: 78/100... Step: 8098... Loss: 0.006861... Val Loss: 0.007201\n",
      "Epoch: 78/100... Step: 8099... Loss: 0.006177... Val Loss: 0.006077\n",
      "Epoch: 78/100... Step: 8100... Loss: 0.004062... Val Loss: 0.005531\n",
      "Epoch: 78/100... Step: 8101... Loss: 0.004606... Val Loss: 0.005456\n",
      "Epoch: 78/100... Step: 8102... Loss: 0.007175... Val Loss: 0.004918\n",
      "Epoch: 78/100... Step: 8103... Loss: 0.007731... Val Loss: 0.004801\n",
      "Epoch: 78/100... Step: 8104... Loss: 0.008413... Val Loss: 0.004542\n",
      "Epoch: 78/100... Step: 8105... Loss: 0.006556... Val Loss: 0.004494\n",
      "Epoch: 78/100... Step: 8106... Loss: 0.005782... Val Loss: 0.003971\n",
      "Epoch: 78/100... Step: 8107... Loss: 0.005753... Val Loss: 0.003957\n",
      "Epoch: 78/100... Step: 8108... Loss: 0.007063... Val Loss: 0.003873\n",
      "Epoch: 78/100... Step: 8109... Loss: 0.004304... Val Loss: 0.004250\n",
      "Epoch: 78/100... Step: 8110... Loss: 0.003768... Val Loss: 0.004247\n",
      "Epoch: 78/100... Step: 8111... Loss: 0.004971... Val Loss: 0.005002\n",
      "Epoch: 78/100... Step: 8112... Loss: 0.004551... Val Loss: 0.005316\n",
      "Epoch: 79/100... Step: 8113... Loss: 0.006629... Val Loss: 0.012070\n",
      "Epoch: 79/100... Step: 8114... Loss: 0.004223... Val Loss: 0.013109\n",
      "Epoch: 79/100... Step: 8115... Loss: 0.004912... Val Loss: 0.007127\n",
      "Epoch: 79/100... Step: 8116... Loss: 0.006003... Val Loss: 0.002888\n",
      "Epoch: 79/100... Step: 8117... Loss: 0.008984... Val Loss: 0.009111\n",
      "Epoch: 79/100... Step: 8118... Loss: 0.007048... Val Loss: 0.016871\n",
      "Epoch: 79/100... Step: 8119... Loss: 0.004227... Val Loss: 0.024169\n",
      "Epoch: 79/100... Step: 8120... Loss: 0.004969... Val Loss: 0.031233\n",
      "Epoch: 79/100... Step: 8121... Loss: 0.003195... Val Loss: 0.037529\n",
      "Epoch: 79/100... Step: 8122... Loss: 0.005812... Val Loss: 0.043383\n",
      "Epoch: 79/100... Step: 8123... Loss: 0.007944... Val Loss: 0.047808\n",
      "Epoch: 79/100... Step: 8124... Loss: 0.005476... Val Loss: 0.051686\n",
      "Epoch: 79/100... Step: 8125... Loss: 0.006518... Val Loss: 0.053773\n",
      "Epoch: 79/100... Step: 8126... Loss: 0.004797... Val Loss: 0.054776\n",
      "Epoch: 79/100... Step: 8127... Loss: 0.009017... Val Loss: 0.050866\n",
      "Epoch: 79/100... Step: 8128... Loss: 0.007706... Val Loss: 0.047536\n",
      "Epoch: 79/100... Step: 8129... Loss: 0.010464... Val Loss: 0.045482\n",
      "Epoch: 79/100... Step: 8130... Loss: 0.006191... Val Loss: 0.044791\n",
      "Epoch: 79/100... Step: 8131... Loss: 0.006607... Val Loss: 0.043603\n",
      "Epoch: 79/100... Step: 8132... Loss: 0.009982... Val Loss: 0.042118\n",
      "Epoch: 79/100... Step: 8133... Loss: 0.008096... Val Loss: 0.042323\n",
      "Epoch: 79/100... Step: 8134... Loss: 0.004182... Val Loss: 0.043782\n",
      "Epoch: 79/100... Step: 8135... Loss: 0.003637... Val Loss: 0.044280\n",
      "Epoch: 79/100... Step: 8136... Loss: 0.004983... Val Loss: 0.043341\n",
      "Epoch: 79/100... Step: 8137... Loss: 0.006106... Val Loss: 0.041700\n",
      "Epoch: 79/100... Step: 8138... Loss: 0.010232... Val Loss: 0.039113\n",
      "Epoch: 79/100... Step: 8139... Loss: 0.008007... Val Loss: 0.037229\n",
      "Epoch: 79/100... Step: 8140... Loss: 0.007499... Val Loss: 0.034356\n",
      "Epoch: 79/100... Step: 8141... Loss: 0.007323... Val Loss: 0.032246\n",
      "Epoch: 79/100... Step: 8142... Loss: 0.005801... Val Loss: 0.030015\n",
      "Epoch: 79/100... Step: 8143... Loss: 0.008731... Val Loss: 0.028853\n",
      "Epoch: 79/100... Step: 8144... Loss: 0.004397... Val Loss: 0.027434\n",
      "Epoch: 79/100... Step: 8145... Loss: 0.006546... Val Loss: 0.026197\n",
      "Epoch: 79/100... Step: 8146... Loss: 0.006943... Val Loss: 0.024703\n",
      "Epoch: 79/100... Step: 8147... Loss: 0.007217... Val Loss: 0.022746\n",
      "Epoch: 79/100... Step: 8148... Loss: 0.005116... Val Loss: 0.020368\n",
      "Epoch: 79/100... Step: 8149... Loss: 0.003408... Val Loss: 0.018646\n",
      "Epoch: 79/100... Step: 8150... Loss: 0.006137... Val Loss: 0.017018\n",
      "Epoch: 79/100... Step: 8151... Loss: 0.005294... Val Loss: 0.016012\n",
      "Epoch: 79/100... Step: 8152... Loss: 0.007443... Val Loss: 0.015156\n",
      "Epoch: 79/100... Step: 8153... Loss: 0.009599... Val Loss: 0.015557\n",
      "Epoch: 79/100... Step: 8154... Loss: 0.006548... Val Loss: 0.016227\n",
      "Epoch: 79/100... Step: 8155... Loss: 0.005793... Val Loss: 0.017112\n",
      "Epoch: 79/100... Step: 8156... Loss: 0.006928... Val Loss: 0.017813\n",
      "Epoch: 79/100... Step: 8157... Loss: 0.008775... Val Loss: 0.018561\n",
      "Epoch: 79/100... Step: 8158... Loss: 0.005731... Val Loss: 0.019683\n",
      "Epoch: 79/100... Step: 8159... Loss: 0.008999... Val Loss: 0.019358\n",
      "Epoch: 79/100... Step: 8160... Loss: 0.006993... Val Loss: 0.018836\n",
      "Epoch: 79/100... Step: 8161... Loss: 0.006581... Val Loss: 0.018281\n",
      "Epoch: 79/100... Step: 8162... Loss: 0.006533... Val Loss: 0.017633\n",
      "Epoch: 79/100... Step: 8163... Loss: 0.005618... Val Loss: 0.016857\n",
      "Epoch: 79/100... Step: 8164... Loss: 0.007589... Val Loss: 0.015592\n",
      "Epoch: 79/100... Step: 8165... Loss: 0.004589... Val Loss: 0.014505\n",
      "Epoch: 79/100... Step: 8166... Loss: 0.006921... Val Loss: 0.013363\n",
      "Epoch: 79/100... Step: 8167... Loss: 0.008447... Val Loss: 0.012198\n",
      "Epoch: 79/100... Step: 8168... Loss: 0.006169... Val Loss: 0.012697\n",
      "Epoch: 79/100... Step: 8169... Loss: 0.005342... Val Loss: 0.012917\n",
      "Epoch: 79/100... Step: 8170... Loss: 0.005798... Val Loss: 0.012707\n",
      "Epoch: 79/100... Step: 8171... Loss: 0.005246... Val Loss: 0.011791\n",
      "Epoch: 79/100... Step: 8172... Loss: 0.004789... Val Loss: 0.010645\n",
      "Epoch: 79/100... Step: 8173... Loss: 0.003169... Val Loss: 0.009762\n",
      "Epoch: 79/100... Step: 8174... Loss: 0.006665... Val Loss: 0.009488\n",
      "Epoch: 79/100... Step: 8175... Loss: 0.006677... Val Loss: 0.009666\n",
      "Epoch: 79/100... Step: 8176... Loss: 0.007659... Val Loss: 0.009590\n",
      "Epoch: 79/100... Step: 8177... Loss: 0.003137... Val Loss: 0.009125\n",
      "Epoch: 79/100... Step: 8178... Loss: 0.005567... Val Loss: 0.008188\n",
      "Epoch: 79/100... Step: 8179... Loss: 0.006997... Val Loss: 0.006379\n",
      "Epoch: 79/100... Step: 8180... Loss: 0.006259... Val Loss: 0.004865\n",
      "Epoch: 79/100... Step: 8181... Loss: 0.005976... Val Loss: 0.003450\n",
      "Epoch: 79/100... Step: 8182... Loss: 0.003709... Val Loss: 0.002745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Step: 8183... Loss: 0.005065... Val Loss: 0.002556\n",
      "Epoch: 79/100... Step: 8184... Loss: 0.004854... Val Loss: 0.003192\n",
      "Epoch: 79/100... Step: 8185... Loss: 0.004273... Val Loss: 0.004328\n",
      "Epoch: 79/100... Step: 8186... Loss: 0.006546... Val Loss: 0.005411\n",
      "Epoch: 79/100... Step: 8187... Loss: 0.006818... Val Loss: 0.005819\n",
      "Epoch: 79/100... Step: 8188... Loss: 0.005126... Val Loss: 0.005578\n",
      "Epoch: 79/100... Step: 8189... Loss: 0.008295... Val Loss: 0.004217\n",
      "Epoch: 79/100... Step: 8190... Loss: 0.003635... Val Loss: 0.002878\n",
      "Epoch: 79/100... Step: 8191... Loss: 0.006901... Val Loss: 0.002039\n",
      "Validation loss decreased (0.002093 --> 0.002039).  Saving model ...\n",
      "Epoch: 79/100... Step: 8192... Loss: 0.004925... Val Loss: 0.002248\n",
      "Epoch: 79/100... Step: 8193... Loss: 0.004180... Val Loss: 0.003244\n",
      "Epoch: 79/100... Step: 8194... Loss: 0.004850... Val Loss: 0.004045\n",
      "Epoch: 79/100... Step: 8195... Loss: 0.006500... Val Loss: 0.004826\n",
      "Epoch: 79/100... Step: 8196... Loss: 0.004940... Val Loss: 0.004789\n",
      "Epoch: 79/100... Step: 8197... Loss: 0.006970... Val Loss: 0.004369\n",
      "Epoch: 79/100... Step: 8198... Loss: 0.006195... Val Loss: 0.003330\n",
      "Epoch: 79/100... Step: 8199... Loss: 0.004503... Val Loss: 0.002357\n",
      "Epoch: 79/100... Step: 8200... Loss: 0.006599... Val Loss: 0.001755\n",
      "Validation loss decreased (0.002039 --> 0.001755).  Saving model ...\n",
      "Epoch: 79/100... Step: 8201... Loss: 0.005920... Val Loss: 0.002320\n",
      "Epoch: 79/100... Step: 8202... Loss: 0.009991... Val Loss: 0.002529\n",
      "Epoch: 79/100... Step: 8203... Loss: 0.004920... Val Loss: 0.003060\n",
      "Epoch: 79/100... Step: 8204... Loss: 0.005505... Val Loss: 0.003210\n",
      "Epoch: 79/100... Step: 8205... Loss: 0.006640... Val Loss: 0.003013\n",
      "Epoch: 79/100... Step: 8206... Loss: 0.003682... Val Loss: 0.003404\n",
      "Epoch: 79/100... Step: 8207... Loss: 0.007892... Val Loss: 0.003216\n",
      "Epoch: 79/100... Step: 8208... Loss: 0.005221... Val Loss: 0.002869\n",
      "Epoch: 79/100... Step: 8209... Loss: 0.005351... Val Loss: 0.002538\n",
      "Epoch: 79/100... Step: 8210... Loss: 0.005986... Val Loss: 0.002552\n",
      "Epoch: 79/100... Step: 8211... Loss: 0.003958... Val Loss: 0.002876\n",
      "Epoch: 79/100... Step: 8212... Loss: 0.004499... Val Loss: 0.002723\n",
      "Epoch: 79/100... Step: 8213... Loss: 0.005669... Val Loss: 0.002473\n",
      "Epoch: 79/100... Step: 8214... Loss: 0.003937... Val Loss: 0.002680\n",
      "Epoch: 79/100... Step: 8215... Loss: 0.005262... Val Loss: 0.002444\n",
      "Epoch: 79/100... Step: 8216... Loss: 0.004947... Val Loss: 0.002634\n",
      "Epoch: 80/100... Step: 8217... Loss: 0.004112... Val Loss: 0.017794\n",
      "Epoch: 80/100... Step: 8218... Loss: 0.007023... Val Loss: 0.015302\n",
      "Epoch: 80/100... Step: 8219... Loss: 0.005202... Val Loss: 0.009729\n",
      "Epoch: 80/100... Step: 8220... Loss: 0.007209... Val Loss: 0.005528\n",
      "Epoch: 80/100... Step: 8221... Loss: 0.005246... Val Loss: 0.003187\n",
      "Epoch: 80/100... Step: 8222... Loss: 0.005670... Val Loss: 0.002717\n",
      "Epoch: 80/100... Step: 8223... Loss: 0.005471... Val Loss: 0.004047\n",
      "Epoch: 80/100... Step: 8224... Loss: 0.006501... Val Loss: 0.006072\n",
      "Epoch: 80/100... Step: 8225... Loss: 0.006645... Val Loss: 0.008479\n",
      "Epoch: 80/100... Step: 8226... Loss: 0.006092... Val Loss: 0.010193\n",
      "Epoch: 80/100... Step: 8227... Loss: 0.007215... Val Loss: 0.011498\n",
      "Epoch: 80/100... Step: 8228... Loss: 0.007158... Val Loss: 0.011914\n",
      "Epoch: 80/100... Step: 8229... Loss: 0.005130... Val Loss: 0.012196\n",
      "Epoch: 80/100... Step: 8230... Loss: 0.006604... Val Loss: 0.012135\n",
      "Epoch: 80/100... Step: 8231... Loss: 0.006757... Val Loss: 0.011407\n",
      "Epoch: 80/100... Step: 8232... Loss: 0.006126... Val Loss: 0.010704\n",
      "Epoch: 80/100... Step: 8233... Loss: 0.005163... Val Loss: 0.009854\n",
      "Epoch: 80/100... Step: 8234... Loss: 0.005911... Val Loss: 0.008884\n",
      "Epoch: 80/100... Step: 8235... Loss: 0.006608... Val Loss: 0.007985\n",
      "Epoch: 80/100... Step: 8236... Loss: 0.006305... Val Loss: 0.007534\n",
      "Epoch: 80/100... Step: 8237... Loss: 0.005856... Val Loss: 0.007193\n",
      "Epoch: 80/100... Step: 8238... Loss: 0.005577... Val Loss: 0.006547\n",
      "Epoch: 80/100... Step: 8239... Loss: 0.006048... Val Loss: 0.005934\n",
      "Epoch: 80/100... Step: 8240... Loss: 0.005095... Val Loss: 0.005564\n",
      "Epoch: 80/100... Step: 8241... Loss: 0.004255... Val Loss: 0.005091\n",
      "Epoch: 80/100... Step: 8242... Loss: 0.005029... Val Loss: 0.004465\n",
      "Epoch: 80/100... Step: 8243... Loss: 0.006888... Val Loss: 0.003816\n",
      "Epoch: 80/100... Step: 8244... Loss: 0.007391... Val Loss: 0.003535\n",
      "Epoch: 80/100... Step: 8245... Loss: 0.006585... Val Loss: 0.003241\n",
      "Epoch: 80/100... Step: 8246... Loss: 0.004748... Val Loss: 0.003300\n",
      "Epoch: 80/100... Step: 8247... Loss: 0.006749... Val Loss: 0.003736\n",
      "Epoch: 80/100... Step: 8248... Loss: 0.003234... Val Loss: 0.004021\n",
      "Epoch: 80/100... Step: 8249... Loss: 0.003878... Val Loss: 0.004449\n",
      "Epoch: 80/100... Step: 8250... Loss: 0.007165... Val Loss: 0.004140\n",
      "Epoch: 80/100... Step: 8251... Loss: 0.005188... Val Loss: 0.003973\n",
      "Epoch: 80/100... Step: 8252... Loss: 0.006398... Val Loss: 0.004828\n",
      "Epoch: 80/100... Step: 8253... Loss: 0.007762... Val Loss: 0.005546\n",
      "Epoch: 80/100... Step: 8254... Loss: 0.004046... Val Loss: 0.005855\n",
      "Epoch: 80/100... Step: 8255... Loss: 0.007099... Val Loss: 0.006013\n",
      "Epoch: 80/100... Step: 8256... Loss: 0.008025... Val Loss: 0.006341\n",
      "Epoch: 80/100... Step: 8257... Loss: 0.006159... Val Loss: 0.006743\n",
      "Epoch: 80/100... Step: 8258... Loss: 0.004351... Val Loss: 0.006554\n",
      "Epoch: 80/100... Step: 8259... Loss: 0.003288... Val Loss: 0.006069\n",
      "Epoch: 80/100... Step: 8260... Loss: 0.007783... Val Loss: 0.005277\n",
      "Epoch: 80/100... Step: 8261... Loss: 0.004519... Val Loss: 0.005309\n",
      "Epoch: 80/100... Step: 8262... Loss: 0.003952... Val Loss: 0.006288\n",
      "Epoch: 80/100... Step: 8263... Loss: 0.003760... Val Loss: 0.006360\n",
      "Epoch: 80/100... Step: 8264... Loss: 0.005562... Val Loss: 0.006054\n",
      "Epoch: 80/100... Step: 8265... Loss: 0.005374... Val Loss: 0.005104\n",
      "Epoch: 80/100... Step: 8266... Loss: 0.003460... Val Loss: 0.003698\n",
      "Epoch: 80/100... Step: 8267... Loss: 0.004511... Val Loss: 0.003525\n",
      "Epoch: 80/100... Step: 8268... Loss: 0.004750... Val Loss: 0.004067\n",
      "Epoch: 80/100... Step: 8269... Loss: 0.007156... Val Loss: 0.004821\n",
      "Epoch: 80/100... Step: 8270... Loss: 0.005246... Val Loss: 0.005618\n",
      "Epoch: 80/100... Step: 8271... Loss: 0.004108... Val Loss: 0.006289\n",
      "Epoch: 80/100... Step: 8272... Loss: 0.006449... Val Loss: 0.007124\n",
      "Epoch: 80/100... Step: 8273... Loss: 0.005340... Val Loss: 0.007611\n",
      "Epoch: 80/100... Step: 8274... Loss: 0.004784... Val Loss: 0.008234\n",
      "Epoch: 80/100... Step: 8275... Loss: 0.003576... Val Loss: 0.008750\n",
      "Epoch: 80/100... Step: 8276... Loss: 0.005960... Val Loss: 0.009390\n",
      "Epoch: 80/100... Step: 8277... Loss: 0.006872... Val Loss: 0.009164\n",
      "Epoch: 80/100... Step: 8278... Loss: 0.004649... Val Loss: 0.009357\n",
      "Epoch: 80/100... Step: 8279... Loss: 0.005085... Val Loss: 0.009642\n",
      "Epoch: 80/100... Step: 8280... Loss: 0.003913... Val Loss: 0.010116\n",
      "Epoch: 80/100... Step: 8281... Loss: 0.005489... Val Loss: 0.011264\n",
      "Epoch: 80/100... Step: 8282... Loss: 0.005571... Val Loss: 0.012711\n",
      "Epoch: 80/100... Step: 8283... Loss: 0.006066... Val Loss: 0.013564\n",
      "Epoch: 80/100... Step: 8284... Loss: 0.006505... Val Loss: 0.013181\n",
      "Epoch: 80/100... Step: 8285... Loss: 0.009685... Val Loss: 0.012292\n",
      "Epoch: 80/100... Step: 8286... Loss: 0.008343... Val Loss: 0.010799\n",
      "Epoch: 80/100... Step: 8287... Loss: 0.006456... Val Loss: 0.008215\n",
      "Epoch: 80/100... Step: 8288... Loss: 0.005941... Val Loss: 0.007151\n",
      "Epoch: 80/100... Step: 8289... Loss: 0.004604... Val Loss: 0.006613\n",
      "Epoch: 80/100... Step: 8290... Loss: 0.005064... Val Loss: 0.005839\n",
      "Epoch: 80/100... Step: 8291... Loss: 0.005775... Val Loss: 0.006124\n",
      "Epoch: 80/100... Step: 8292... Loss: 0.007280... Val Loss: 0.006235\n",
      "Epoch: 80/100... Step: 8293... Loss: 0.005269... Val Loss: 0.006265\n",
      "Epoch: 80/100... Step: 8294... Loss: 0.005188... Val Loss: 0.006340\n",
      "Epoch: 80/100... Step: 8295... Loss: 0.006876... Val Loss: 0.006238\n",
      "Epoch: 80/100... Step: 8296... Loss: 0.004996... Val Loss: 0.006053\n",
      "Epoch: 80/100... Step: 8297... Loss: 0.006346... Val Loss: 0.005951\n",
      "Epoch: 80/100... Step: 8298... Loss: 0.005891... Val Loss: 0.006174\n",
      "Epoch: 80/100... Step: 8299... Loss: 0.005307... Val Loss: 0.006061\n",
      "Epoch: 80/100... Step: 8300... Loss: 0.004100... Val Loss: 0.006556\n",
      "Epoch: 80/100... Step: 8301... Loss: 0.007659... Val Loss: 0.006307\n",
      "Epoch: 80/100... Step: 8302... Loss: 0.005190... Val Loss: 0.006398\n",
      "Epoch: 80/100... Step: 8303... Loss: 0.003925... Val Loss: 0.006652\n",
      "Epoch: 80/100... Step: 8304... Loss: 0.003060... Val Loss: 0.006971\n",
      "Epoch: 80/100... Step: 8305... Loss: 0.005521... Val Loss: 0.006421\n",
      "Epoch: 80/100... Step: 8306... Loss: 0.003784... Val Loss: 0.006093\n",
      "Epoch: 80/100... Step: 8307... Loss: 0.005659... Val Loss: 0.006526\n",
      "Epoch: 80/100... Step: 8308... Loss: 0.003389... Val Loss: 0.005956\n",
      "Epoch: 80/100... Step: 8309... Loss: 0.004597... Val Loss: 0.005911\n",
      "Epoch: 80/100... Step: 8310... Loss: 0.005070... Val Loss: 0.005847\n",
      "Epoch: 80/100... Step: 8311... Loss: 0.005689... Val Loss: 0.005400\n",
      "Epoch: 80/100... Step: 8312... Loss: 0.007411... Val Loss: 0.004719\n",
      "Epoch: 80/100... Step: 8313... Loss: 0.004490... Val Loss: 0.004676\n",
      "Epoch: 80/100... Step: 8314... Loss: 0.003940... Val Loss: 0.004743\n",
      "Epoch: 80/100... Step: 8315... Loss: 0.006142... Val Loss: 0.004332\n",
      "Epoch: 80/100... Step: 8316... Loss: 0.005038... Val Loss: 0.003691\n",
      "Epoch: 80/100... Step: 8317... Loss: 0.003984... Val Loss: 0.003456\n",
      "Epoch: 80/100... Step: 8318... Loss: 0.005203... Val Loss: 0.003991\n",
      "Epoch: 80/100... Step: 8319... Loss: 0.004146... Val Loss: 0.004019\n",
      "Epoch: 80/100... Step: 8320... Loss: 0.002886... Val Loss: 0.004213\n",
      "Epoch: 81/100... Step: 8321... Loss: 0.003078... Val Loss: 0.002875\n",
      "Epoch: 81/100... Step: 8322... Loss: 0.005372... Val Loss: 0.005787\n",
      "Epoch: 81/100... Step: 8323... Loss: 0.006960... Val Loss: 0.009858\n",
      "Epoch: 81/100... Step: 8324... Loss: 0.005333... Val Loss: 0.013822\n",
      "Epoch: 81/100... Step: 8325... Loss: 0.006360... Val Loss: 0.016966\n",
      "Epoch: 81/100... Step: 8326... Loss: 0.007885... Val Loss: 0.019773\n",
      "Epoch: 81/100... Step: 8327... Loss: 0.006029... Val Loss: 0.021872\n",
      "Epoch: 81/100... Step: 8328... Loss: 0.006412... Val Loss: 0.023566\n",
      "Epoch: 81/100... Step: 8329... Loss: 0.005050... Val Loss: 0.024738\n",
      "Epoch: 81/100... Step: 8330... Loss: 0.005407... Val Loss: 0.025441\n",
      "Epoch: 81/100... Step: 8331... Loss: 0.005969... Val Loss: 0.025733\n",
      "Epoch: 81/100... Step: 8332... Loss: 0.004540... Val Loss: 0.025714\n",
      "Epoch: 81/100... Step: 8333... Loss: 0.003598... Val Loss: 0.025741\n",
      "Epoch: 81/100... Step: 8334... Loss: 0.007879... Val Loss: 0.025900\n",
      "Epoch: 81/100... Step: 8335... Loss: 0.005175... Val Loss: 0.025589\n",
      "Epoch: 81/100... Step: 8336... Loss: 0.005510... Val Loss: 0.025127\n",
      "Epoch: 81/100... Step: 8337... Loss: 0.005662... Val Loss: 0.024868\n",
      "Epoch: 81/100... Step: 8338... Loss: 0.006038... Val Loss: 0.024389\n",
      "Epoch: 81/100... Step: 8339... Loss: 0.005555... Val Loss: 0.023800\n",
      "Epoch: 81/100... Step: 8340... Loss: 0.004410... Val Loss: 0.023169\n",
      "Epoch: 81/100... Step: 8341... Loss: 0.006522... Val Loss: 0.022919\n",
      "Epoch: 81/100... Step: 8342... Loss: 0.005311... Val Loss: 0.021659\n",
      "Epoch: 81/100... Step: 8343... Loss: 0.005492... Val Loss: 0.020881\n",
      "Epoch: 81/100... Step: 8344... Loss: 0.006161... Val Loss: 0.019930\n",
      "Epoch: 81/100... Step: 8345... Loss: 0.004567... Val Loss: 0.019087\n",
      "Epoch: 81/100... Step: 8346... Loss: 0.004293... Val Loss: 0.018390\n",
      "Epoch: 81/100... Step: 8347... Loss: 0.004992... Val Loss: 0.017409\n",
      "Epoch: 81/100... Step: 8348... Loss: 0.005865... Val Loss: 0.016269\n",
      "Epoch: 81/100... Step: 8349... Loss: 0.005959... Val Loss: 0.015331\n",
      "Epoch: 81/100... Step: 8350... Loss: 0.006966... Val Loss: 0.014250\n",
      "Epoch: 81/100... Step: 8351... Loss: 0.006400... Val Loss: 0.013304\n",
      "Epoch: 81/100... Step: 8352... Loss: 0.004660... Val Loss: 0.012292\n",
      "Epoch: 81/100... Step: 8353... Loss: 0.006213... Val Loss: 0.011706\n",
      "Epoch: 81/100... Step: 8354... Loss: 0.005396... Val Loss: 0.011911\n",
      "Epoch: 81/100... Step: 8355... Loss: 0.002688... Val Loss: 0.012123\n",
      "Epoch: 81/100... Step: 8356... Loss: 0.004046... Val Loss: 0.012086\n",
      "Epoch: 81/100... Step: 8357... Loss: 0.005504... Val Loss: 0.012223\n",
      "Epoch: 81/100... Step: 8358... Loss: 0.004932... Val Loss: 0.011957\n",
      "Epoch: 81/100... Step: 8359... Loss: 0.004196... Val Loss: 0.011689\n",
      "Epoch: 81/100... Step: 8360... Loss: 0.006287... Val Loss: 0.011490\n",
      "Epoch: 81/100... Step: 8361... Loss: 0.005516... Val Loss: 0.010707\n",
      "Epoch: 81/100... Step: 8362... Loss: 0.004476... Val Loss: 0.010212\n",
      "Epoch: 81/100... Step: 8363... Loss: 0.004454... Val Loss: 0.009698\n",
      "Epoch: 81/100... Step: 8364... Loss: 0.006178... Val Loss: 0.008562\n",
      "Epoch: 81/100... Step: 8365... Loss: 0.007370... Val Loss: 0.007502\n",
      "Epoch: 81/100... Step: 8366... Loss: 0.006335... Val Loss: 0.006728\n",
      "Epoch: 81/100... Step: 8367... Loss: 0.002972... Val Loss: 0.006561\n",
      "Epoch: 81/100... Step: 8368... Loss: 0.005361... Val Loss: 0.006654\n",
      "Epoch: 81/100... Step: 8369... Loss: 0.006185... Val Loss: 0.006790\n",
      "Epoch: 81/100... Step: 8370... Loss: 0.005883... Val Loss: 0.006790\n",
      "Epoch: 81/100... Step: 8371... Loss: 0.007843... Val Loss: 0.006567\n",
      "Epoch: 81/100... Step: 8372... Loss: 0.003739... Val Loss: 0.006043\n",
      "Epoch: 81/100... Step: 8373... Loss: 0.005427... Val Loss: 0.005813\n",
      "Epoch: 81/100... Step: 8374... Loss: 0.005589... Val Loss: 0.005830\n",
      "Epoch: 81/100... Step: 8375... Loss: 0.004951... Val Loss: 0.006632\n",
      "Epoch: 81/100... Step: 8376... Loss: 0.003324... Val Loss: 0.007327\n",
      "Epoch: 81/100... Step: 8377... Loss: 0.005430... Val Loss: 0.008153\n",
      "Epoch: 81/100... Step: 8378... Loss: 0.006651... Val Loss: 0.008471\n",
      "Epoch: 81/100... Step: 8379... Loss: 0.002741... Val Loss: 0.008919\n",
      "Epoch: 81/100... Step: 8380... Loss: 0.005051... Val Loss: 0.009136\n",
      "Epoch: 81/100... Step: 8381... Loss: 0.005708... Val Loss: 0.008789\n",
      "Epoch: 81/100... Step: 8382... Loss: 0.006544... Val Loss: 0.007847\n",
      "Epoch: 81/100... Step: 8383... Loss: 0.005713... Val Loss: 0.007340\n",
      "Epoch: 81/100... Step: 8384... Loss: 0.003938... Val Loss: 0.006894\n",
      "Epoch: 81/100... Step: 8385... Loss: 0.003365... Val Loss: 0.006232\n",
      "Epoch: 81/100... Step: 8386... Loss: 0.005155... Val Loss: 0.005945\n",
      "Epoch: 81/100... Step: 8387... Loss: 0.004457... Val Loss: 0.005977\n",
      "Epoch: 81/100... Step: 8388... Loss: 0.004806... Val Loss: 0.006411\n",
      "Epoch: 81/100... Step: 8389... Loss: 0.005783... Val Loss: 0.006106\n",
      "Epoch: 81/100... Step: 8390... Loss: 0.004598... Val Loss: 0.005662\n",
      "Epoch: 81/100... Step: 8391... Loss: 0.008445... Val Loss: 0.004873\n",
      "Epoch: 81/100... Step: 8392... Loss: 0.004841... Val Loss: 0.003721\n",
      "Epoch: 81/100... Step: 8393... Loss: 0.002310... Val Loss: 0.002989\n",
      "Epoch: 81/100... Step: 8394... Loss: 0.003601... Val Loss: 0.002420\n",
      "Epoch: 81/100... Step: 8395... Loss: 0.004785... Val Loss: 0.002143\n",
      "Epoch: 81/100... Step: 8396... Loss: 0.006531... Val Loss: 0.001941\n",
      "Epoch: 81/100... Step: 8397... Loss: 0.006062... Val Loss: 0.001929\n",
      "Epoch: 81/100... Step: 8398... Loss: 0.003546... Val Loss: 0.002360\n",
      "Epoch: 81/100... Step: 8399... Loss: 0.003596... Val Loss: 0.003039\n",
      "Epoch: 81/100... Step: 8400... Loss: 0.005080... Val Loss: 0.003905\n",
      "Epoch: 81/100... Step: 8401... Loss: 0.006939... Val Loss: 0.003684\n",
      "Epoch: 81/100... Step: 8402... Loss: 0.003244... Val Loss: 0.003600\n",
      "Epoch: 81/100... Step: 8403... Loss: 0.005108... Val Loss: 0.002635\n",
      "Epoch: 81/100... Step: 8404... Loss: 0.005678... Val Loss: 0.001793\n",
      "Epoch: 81/100... Step: 8405... Loss: 0.006595... Val Loss: 0.001705\n",
      "Validation loss decreased (0.001755 --> 0.001705).  Saving model ...\n",
      "Epoch: 81/100... Step: 8406... Loss: 0.004530... Val Loss: 0.001575\n",
      "Validation loss decreased (0.001705 --> 0.001575).  Saving model ...\n",
      "Epoch: 81/100... Step: 8407... Loss: 0.004226... Val Loss: 0.001541\n",
      "Validation loss decreased (0.001575 --> 0.001541).  Saving model ...\n",
      "Epoch: 81/100... Step: 8408... Loss: 0.006327... Val Loss: 0.001431\n",
      "Validation loss decreased (0.001541 --> 0.001431).  Saving model ...\n",
      "Epoch: 81/100... Step: 8409... Loss: 0.002569... Val Loss: 0.001382\n",
      "Validation loss decreased (0.001431 --> 0.001382).  Saving model ...\n",
      "Epoch: 81/100... Step: 8410... Loss: 0.005314... Val Loss: 0.001595\n",
      "Epoch: 81/100... Step: 8411... Loss: 0.003385... Val Loss: 0.001913\n",
      "Epoch: 81/100... Step: 8412... Loss: 0.004510... Val Loss: 0.002169\n",
      "Epoch: 81/100... Step: 8413... Loss: 0.003903... Val Loss: 0.002207\n",
      "Epoch: 81/100... Step: 8414... Loss: 0.005359... Val Loss: 0.002366\n",
      "Epoch: 81/100... Step: 8415... Loss: 0.007511... Val Loss: 0.002712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100... Step: 8416... Loss: 0.003932... Val Loss: 0.002694\n",
      "Epoch: 81/100... Step: 8417... Loss: 0.005127... Val Loss: 0.002602\n",
      "Epoch: 81/100... Step: 8418... Loss: 0.005664... Val Loss: 0.002298\n",
      "Epoch: 81/100... Step: 8419... Loss: 0.005332... Val Loss: 0.001776\n",
      "Epoch: 81/100... Step: 8420... Loss: 0.004569... Val Loss: 0.001576\n",
      "Epoch: 81/100... Step: 8421... Loss: 0.005993... Val Loss: 0.002536\n",
      "Epoch: 81/100... Step: 8422... Loss: 0.005196... Val Loss: 0.003270\n",
      "Epoch: 81/100... Step: 8423... Loss: 0.003044... Val Loss: 0.003976\n",
      "Epoch: 81/100... Step: 8424... Loss: 0.003407... Val Loss: 0.004444\n",
      "Epoch: 82/100... Step: 8425... Loss: 0.007707... Val Loss: 0.007583\n",
      "Epoch: 82/100... Step: 8426... Loss: 0.006970... Val Loss: 0.004513\n",
      "Epoch: 82/100... Step: 8427... Loss: 0.004394... Val Loss: 0.002887\n",
      "Epoch: 82/100... Step: 8428... Loss: 0.007785... Val Loss: 0.003598\n",
      "Epoch: 82/100... Step: 8429... Loss: 0.004801... Val Loss: 0.005864\n",
      "Epoch: 82/100... Step: 8430... Loss: 0.005582... Val Loss: 0.008479\n",
      "Epoch: 82/100... Step: 8431... Loss: 0.003749... Val Loss: 0.010361\n",
      "Epoch: 82/100... Step: 8432... Loss: 0.005539... Val Loss: 0.012098\n",
      "Epoch: 82/100... Step: 8433... Loss: 0.005138... Val Loss: 0.013735\n",
      "Epoch: 82/100... Step: 8434... Loss: 0.005470... Val Loss: 0.015630\n",
      "Epoch: 82/100... Step: 8435... Loss: 0.005458... Val Loss: 0.017834\n",
      "Epoch: 82/100... Step: 8436... Loss: 0.004036... Val Loss: 0.019566\n",
      "Epoch: 82/100... Step: 8437... Loss: 0.004469... Val Loss: 0.021246\n",
      "Epoch: 82/100... Step: 8438... Loss: 0.003786... Val Loss: 0.023264\n",
      "Epoch: 82/100... Step: 8439... Loss: 0.005352... Val Loss: 0.024536\n",
      "Epoch: 82/100... Step: 8440... Loss: 0.004686... Val Loss: 0.025437\n",
      "Epoch: 82/100... Step: 8441... Loss: 0.004277... Val Loss: 0.025628\n",
      "Epoch: 82/100... Step: 8442... Loss: 0.005827... Val Loss: 0.025348\n",
      "Epoch: 82/100... Step: 8443... Loss: 0.005515... Val Loss: 0.025351\n",
      "Epoch: 82/100... Step: 8444... Loss: 0.005560... Val Loss: 0.025093\n",
      "Epoch: 82/100... Step: 8445... Loss: 0.006846... Val Loss: 0.025188\n",
      "Epoch: 82/100... Step: 8446... Loss: 0.006305... Val Loss: 0.025022\n",
      "Epoch: 82/100... Step: 8447... Loss: 0.006915... Val Loss: 0.025224\n",
      "Epoch: 82/100... Step: 8448... Loss: 0.005997... Val Loss: 0.025014\n",
      "Epoch: 82/100... Step: 8449... Loss: 0.004862... Val Loss: 0.024972\n",
      "Epoch: 82/100... Step: 8450... Loss: 0.009033... Val Loss: 0.023928\n",
      "Epoch: 82/100... Step: 8451... Loss: 0.003670... Val Loss: 0.023547\n",
      "Epoch: 82/100... Step: 8452... Loss: 0.006322... Val Loss: 0.023362\n",
      "Epoch: 82/100... Step: 8453... Loss: 0.005230... Val Loss: 0.023288\n",
      "Epoch: 82/100... Step: 8454... Loss: 0.005717... Val Loss: 0.023070\n",
      "Epoch: 82/100... Step: 8455... Loss: 0.003923... Val Loss: 0.022529\n",
      "Epoch: 82/100... Step: 8456... Loss: 0.005073... Val Loss: 0.022284\n",
      "Epoch: 82/100... Step: 8457... Loss: 0.005972... Val Loss: 0.021840\n",
      "Epoch: 82/100... Step: 8458... Loss: 0.005101... Val Loss: 0.021617\n",
      "Epoch: 82/100... Step: 8459... Loss: 0.004354... Val Loss: 0.020926\n",
      "Epoch: 82/100... Step: 8460... Loss: 0.005131... Val Loss: 0.020174\n",
      "Epoch: 82/100... Step: 8461... Loss: 0.004091... Val Loss: 0.019610\n",
      "Epoch: 82/100... Step: 8462... Loss: 0.004163... Val Loss: 0.019051\n",
      "Epoch: 82/100... Step: 8463... Loss: 0.003898... Val Loss: 0.017989\n",
      "Epoch: 82/100... Step: 8464... Loss: 0.005364... Val Loss: 0.017449\n",
      "Epoch: 82/100... Step: 8465... Loss: 0.004473... Val Loss: 0.016438\n",
      "Epoch: 82/100... Step: 8466... Loss: 0.005615... Val Loss: 0.015500\n",
      "Epoch: 82/100... Step: 8467... Loss: 0.007008... Val Loss: 0.014770\n",
      "Epoch: 82/100... Step: 8468... Loss: 0.004966... Val Loss: 0.013869\n",
      "Epoch: 82/100... Step: 8469... Loss: 0.007423... Val Loss: 0.013186\n",
      "Epoch: 82/100... Step: 8470... Loss: 0.006629... Val Loss: 0.012510\n",
      "Epoch: 82/100... Step: 8471... Loss: 0.004428... Val Loss: 0.012205\n",
      "Epoch: 82/100... Step: 8472... Loss: 0.004505... Val Loss: 0.011788\n",
      "Epoch: 82/100... Step: 8473... Loss: 0.005662... Val Loss: 0.010970\n",
      "Epoch: 82/100... Step: 8474... Loss: 0.005024... Val Loss: 0.010362\n",
      "Epoch: 82/100... Step: 8475... Loss: 0.003042... Val Loss: 0.009767\n",
      "Epoch: 82/100... Step: 8476... Loss: 0.003208... Val Loss: 0.009459\n",
      "Epoch: 82/100... Step: 8477... Loss: 0.004611... Val Loss: 0.009687\n",
      "Epoch: 82/100... Step: 8478... Loss: 0.005551... Val Loss: 0.009275\n",
      "Epoch: 82/100... Step: 8479... Loss: 0.005317... Val Loss: 0.008970\n",
      "Epoch: 82/100... Step: 8480... Loss: 0.005636... Val Loss: 0.008941\n",
      "Epoch: 82/100... Step: 8481... Loss: 0.005999... Val Loss: 0.008090\n",
      "Epoch: 82/100... Step: 8482... Loss: 0.005302... Val Loss: 0.007975\n",
      "Epoch: 82/100... Step: 8483... Loss: 0.006040... Val Loss: 0.008247\n",
      "Epoch: 82/100... Step: 8484... Loss: 0.002583... Val Loss: 0.008286\n",
      "Epoch: 82/100... Step: 8485... Loss: 0.003917... Val Loss: 0.008460\n",
      "Epoch: 82/100... Step: 8486... Loss: 0.004377... Val Loss: 0.008285\n",
      "Epoch: 82/100... Step: 8487... Loss: 0.003645... Val Loss: 0.007945\n",
      "Epoch: 82/100... Step: 8488... Loss: 0.005277... Val Loss: 0.007592\n",
      "Epoch: 82/100... Step: 8489... Loss: 0.004980... Val Loss: 0.007266\n",
      "Epoch: 82/100... Step: 8490... Loss: 0.007836... Val Loss: 0.006791\n",
      "Epoch: 82/100... Step: 8491... Loss: 0.005802... Val Loss: 0.005857\n",
      "Epoch: 82/100... Step: 8492... Loss: 0.005965... Val Loss: 0.004827\n",
      "Epoch: 82/100... Step: 8493... Loss: 0.004386... Val Loss: 0.004131\n",
      "Epoch: 82/100... Step: 8494... Loss: 0.005839... Val Loss: 0.003898\n",
      "Epoch: 82/100... Step: 8495... Loss: 0.005721... Val Loss: 0.003303\n",
      "Epoch: 82/100... Step: 8496... Loss: 0.005885... Val Loss: 0.003084\n",
      "Epoch: 82/100... Step: 8497... Loss: 0.008377... Val Loss: 0.003138\n",
      "Epoch: 82/100... Step: 8498... Loss: 0.004226... Val Loss: 0.003229\n",
      "Epoch: 82/100... Step: 8499... Loss: 0.003619... Val Loss: 0.002834\n",
      "Epoch: 82/100... Step: 8500... Loss: 0.004175... Val Loss: 0.002363\n",
      "Epoch: 82/100... Step: 8501... Loss: 0.005444... Val Loss: 0.001814\n",
      "Epoch: 82/100... Step: 8502... Loss: 0.004391... Val Loss: 0.001825\n",
      "Epoch: 82/100... Step: 8503... Loss: 0.003488... Val Loss: 0.002196\n",
      "Epoch: 82/100... Step: 8504... Loss: 0.004761... Val Loss: 0.002349\n",
      "Epoch: 82/100... Step: 8505... Loss: 0.003341... Val Loss: 0.002165\n",
      "Epoch: 82/100... Step: 8506... Loss: 0.005208... Val Loss: 0.001894\n",
      "Epoch: 82/100... Step: 8507... Loss: 0.002624... Val Loss: 0.001862\n",
      "Epoch: 82/100... Step: 8508... Loss: 0.004599... Val Loss: 0.001740\n",
      "Epoch: 82/100... Step: 8509... Loss: 0.006291... Val Loss: 0.001534\n",
      "Epoch: 82/100... Step: 8510... Loss: 0.001897... Val Loss: 0.001498\n",
      "Epoch: 82/100... Step: 8511... Loss: 0.004698... Val Loss: 0.002318\n",
      "Epoch: 82/100... Step: 8512... Loss: 0.003839... Val Loss: 0.002778\n",
      "Epoch: 82/100... Step: 8513... Loss: 0.003249... Val Loss: 0.002769\n",
      "Epoch: 82/100... Step: 8514... Loss: 0.005023... Val Loss: 0.002734\n",
      "Epoch: 82/100... Step: 8515... Loss: 0.005070... Val Loss: 0.003129\n",
      "Epoch: 82/100... Step: 8516... Loss: 0.002937... Val Loss: 0.003283\n",
      "Epoch: 82/100... Step: 8517... Loss: 0.004468... Val Loss: 0.003534\n",
      "Epoch: 82/100... Step: 8518... Loss: 0.002677... Val Loss: 0.003846\n",
      "Epoch: 82/100... Step: 8519... Loss: 0.005705... Val Loss: 0.004222\n",
      "Epoch: 82/100... Step: 8520... Loss: 0.003545... Val Loss: 0.004106\n",
      "Epoch: 82/100... Step: 8521... Loss: 0.003048... Val Loss: 0.003621\n",
      "Epoch: 82/100... Step: 8522... Loss: 0.006438... Val Loss: 0.003227\n",
      "Epoch: 82/100... Step: 8523... Loss: 0.005691... Val Loss: 0.002832\n",
      "Epoch: 82/100... Step: 8524... Loss: 0.005634... Val Loss: 0.003061\n",
      "Epoch: 82/100... Step: 8525... Loss: 0.004172... Val Loss: 0.002698\n",
      "Epoch: 82/100... Step: 8526... Loss: 0.005163... Val Loss: 0.002333\n",
      "Epoch: 82/100... Step: 8527... Loss: 0.004081... Val Loss: 0.002232\n",
      "Epoch: 82/100... Step: 8528... Loss: 0.004320... Val Loss: 0.002614\n",
      "Epoch: 83/100... Step: 8529... Loss: 0.004449... Val Loss: 0.010426\n",
      "Epoch: 83/100... Step: 8530... Loss: 0.003728... Val Loss: 0.009343\n",
      "Epoch: 83/100... Step: 8531... Loss: 0.004697... Val Loss: 0.007049\n",
      "Epoch: 83/100... Step: 8532... Loss: 0.003564... Val Loss: 0.005306\n",
      "Epoch: 83/100... Step: 8533... Loss: 0.004032... Val Loss: 0.004365\n",
      "Epoch: 83/100... Step: 8534... Loss: 0.003726... Val Loss: 0.003566\n",
      "Epoch: 83/100... Step: 8535... Loss: 0.005082... Val Loss: 0.003107\n",
      "Epoch: 83/100... Step: 8536... Loss: 0.004043... Val Loss: 0.002878\n",
      "Epoch: 83/100... Step: 8537... Loss: 0.003703... Val Loss: 0.002546\n",
      "Epoch: 83/100... Step: 8538... Loss: 0.004484... Val Loss: 0.002588\n",
      "Epoch: 83/100... Step: 8539... Loss: 0.006714... Val Loss: 0.002486\n",
      "Epoch: 83/100... Step: 8540... Loss: 0.003536... Val Loss: 0.002457\n",
      "Epoch: 83/100... Step: 8541... Loss: 0.004870... Val Loss: 0.002372\n",
      "Epoch: 83/100... Step: 8542... Loss: 0.003311... Val Loss: 0.002547\n",
      "Epoch: 83/100... Step: 8543... Loss: 0.003273... Val Loss: 0.002950\n",
      "Epoch: 83/100... Step: 8544... Loss: 0.003739... Val Loss: 0.003840\n",
      "Epoch: 83/100... Step: 8545... Loss: 0.003562... Val Loss: 0.004619\n",
      "Epoch: 83/100... Step: 8546... Loss: 0.003708... Val Loss: 0.004967\n",
      "Epoch: 83/100... Step: 8547... Loss: 0.003557... Val Loss: 0.005380\n",
      "Epoch: 83/100... Step: 8548... Loss: 0.004598... Val Loss: 0.005340\n",
      "Epoch: 83/100... Step: 8549... Loss: 0.003503... Val Loss: 0.005312\n",
      "Epoch: 83/100... Step: 8550... Loss: 0.003120... Val Loss: 0.005088\n",
      "Epoch: 83/100... Step: 8551... Loss: 0.004926... Val Loss: 0.004816\n",
      "Epoch: 83/100... Step: 8552... Loss: 0.003493... Val Loss: 0.004595\n",
      "Epoch: 83/100... Step: 8553... Loss: 0.004188... Val Loss: 0.004127\n",
      "Epoch: 83/100... Step: 8554... Loss: 0.004639... Val Loss: 0.003804\n",
      "Epoch: 83/100... Step: 8555... Loss: 0.004620... Val Loss: 0.003363\n",
      "Epoch: 83/100... Step: 8556... Loss: 0.003804... Val Loss: 0.003150\n",
      "Epoch: 83/100... Step: 8557... Loss: 0.002272... Val Loss: 0.003033\n",
      "Epoch: 83/100... Step: 8558... Loss: 0.004253... Val Loss: 0.002897\n",
      "Epoch: 83/100... Step: 8559... Loss: 0.004446... Val Loss: 0.002629\n",
      "Epoch: 83/100... Step: 8560... Loss: 0.007245... Val Loss: 0.002543\n",
      "Epoch: 83/100... Step: 8561... Loss: 0.004363... Val Loss: 0.002318\n",
      "Epoch: 83/100... Step: 8562... Loss: 0.006642... Val Loss: 0.001957\n",
      "Epoch: 83/100... Step: 8563... Loss: 0.003992... Val Loss: 0.001862\n",
      "Epoch: 83/100... Step: 8564... Loss: 0.004977... Val Loss: 0.001756\n",
      "Epoch: 83/100... Step: 8565... Loss: 0.003307... Val Loss: 0.001616\n",
      "Epoch: 83/100... Step: 8566... Loss: 0.003743... Val Loss: 0.001584\n",
      "Epoch: 83/100... Step: 8567... Loss: 0.004729... Val Loss: 0.001717\n",
      "Epoch: 83/100... Step: 8568... Loss: 0.004276... Val Loss: 0.001696\n",
      "Epoch: 83/100... Step: 8569... Loss: 0.003566... Val Loss: 0.001718\n",
      "Epoch: 83/100... Step: 8570... Loss: 0.004263... Val Loss: 0.001725\n",
      "Epoch: 83/100... Step: 8571... Loss: 0.004711... Val Loss: 0.001870\n",
      "Epoch: 83/100... Step: 8572... Loss: 0.003934... Val Loss: 0.002074\n",
      "Epoch: 83/100... Step: 8573... Loss: 0.005492... Val Loss: 0.002189\n",
      "Epoch: 83/100... Step: 8574... Loss: 0.002777... Val Loss: 0.002112\n",
      "Epoch: 83/100... Step: 8575... Loss: 0.003011... Val Loss: 0.002046\n",
      "Epoch: 83/100... Step: 8576... Loss: 0.004580... Val Loss: 0.002106\n",
      "Epoch: 83/100... Step: 8577... Loss: 0.004145... Val Loss: 0.002232\n",
      "Epoch: 83/100... Step: 8578... Loss: 0.004022... Val Loss: 0.002661\n",
      "Epoch: 83/100... Step: 8579... Loss: 0.004492... Val Loss: 0.003308\n",
      "Epoch: 83/100... Step: 8580... Loss: 0.004815... Val Loss: 0.004042\n",
      "Epoch: 83/100... Step: 8581... Loss: 0.005416... Val Loss: 0.004932\n",
      "Epoch: 83/100... Step: 8582... Loss: 0.005526... Val Loss: 0.005246\n",
      "Epoch: 83/100... Step: 8583... Loss: 0.004565... Val Loss: 0.005280\n",
      "Epoch: 83/100... Step: 8584... Loss: 0.004730... Val Loss: 0.004839\n",
      "Epoch: 83/100... Step: 8585... Loss: 0.005153... Val Loss: 0.004317\n",
      "Epoch: 83/100... Step: 8586... Loss: 0.004798... Val Loss: 0.003956\n",
      "Epoch: 83/100... Step: 8587... Loss: 0.004716... Val Loss: 0.003693\n",
      "Epoch: 83/100... Step: 8588... Loss: 0.005122... Val Loss: 0.003610\n",
      "Epoch: 83/100... Step: 8589... Loss: 0.004604... Val Loss: 0.003035\n",
      "Epoch: 83/100... Step: 8590... Loss: 0.003671... Val Loss: 0.002440\n",
      "Epoch: 83/100... Step: 8591... Loss: 0.003990... Val Loss: 0.002221\n",
      "Epoch: 83/100... Step: 8592... Loss: 0.004876... Val Loss: 0.002482\n",
      "Epoch: 83/100... Step: 8593... Loss: 0.002203... Val Loss: 0.002617\n",
      "Epoch: 83/100... Step: 8594... Loss: 0.002874... Val Loss: 0.002622\n",
      "Epoch: 83/100... Step: 8595... Loss: 0.004004... Val Loss: 0.002829\n",
      "Epoch: 83/100... Step: 8596... Loss: 0.004339... Val Loss: 0.003146\n",
      "Epoch: 83/100... Step: 8597... Loss: 0.002687... Val Loss: 0.003310\n",
      "Epoch: 83/100... Step: 8598... Loss: 0.004500... Val Loss: 0.003072\n",
      "Epoch: 83/100... Step: 8599... Loss: 0.002849... Val Loss: 0.002833\n",
      "Epoch: 83/100... Step: 8600... Loss: 0.001879... Val Loss: 0.002778\n",
      "Epoch: 83/100... Step: 8601... Loss: 0.003514... Val Loss: 0.002863\n",
      "Epoch: 83/100... Step: 8602... Loss: 0.001831... Val Loss: 0.003190\n",
      "Epoch: 83/100... Step: 8603... Loss: 0.004003... Val Loss: 0.003123\n",
      "Epoch: 83/100... Step: 8604... Loss: 0.004512... Val Loss: 0.002732\n",
      "Epoch: 83/100... Step: 8605... Loss: 0.004795... Val Loss: 0.002347\n",
      "Epoch: 83/100... Step: 8606... Loss: 0.004239... Val Loss: 0.001852\n",
      "Epoch: 83/100... Step: 8607... Loss: 0.005733... Val Loss: 0.001737\n",
      "Epoch: 83/100... Step: 8608... Loss: 0.002798... Val Loss: 0.001999\n",
      "Epoch: 83/100... Step: 8609... Loss: 0.003688... Val Loss: 0.003099\n",
      "Epoch: 83/100... Step: 8610... Loss: 0.004608... Val Loss: 0.004646\n",
      "Epoch: 83/100... Step: 8611... Loss: 0.002827... Val Loss: 0.006219\n",
      "Epoch: 83/100... Step: 8612... Loss: 0.004769... Val Loss: 0.007228\n",
      "Epoch: 83/100... Step: 8613... Loss: 0.005036... Val Loss: 0.007630\n",
      "Epoch: 83/100... Step: 8614... Loss: 0.005951... Val Loss: 0.007774\n",
      "Epoch: 83/100... Step: 8615... Loss: 0.004032... Val Loss: 0.007689\n",
      "Epoch: 83/100... Step: 8616... Loss: 0.005531... Val Loss: 0.007012\n",
      "Epoch: 83/100... Step: 8617... Loss: 0.006109... Val Loss: 0.005746\n",
      "Epoch: 83/100... Step: 8618... Loss: 0.004875... Val Loss: 0.004664\n",
      "Epoch: 83/100... Step: 8619... Loss: 0.003687... Val Loss: 0.003888\n",
      "Epoch: 83/100... Step: 8620... Loss: 0.004076... Val Loss: 0.003579\n",
      "Epoch: 83/100... Step: 8621... Loss: 0.003200... Val Loss: 0.004046\n",
      "Epoch: 83/100... Step: 8622... Loss: 0.005058... Val Loss: 0.004042\n",
      "Epoch: 83/100... Step: 8623... Loss: 0.005824... Val Loss: 0.004036\n",
      "Epoch: 83/100... Step: 8624... Loss: 0.005187... Val Loss: 0.004237\n",
      "Epoch: 83/100... Step: 8625... Loss: 0.005636... Val Loss: 0.004147\n",
      "Epoch: 83/100... Step: 8626... Loss: 0.005322... Val Loss: 0.004074\n",
      "Epoch: 83/100... Step: 8627... Loss: 0.002644... Val Loss: 0.004250\n",
      "Epoch: 83/100... Step: 8628... Loss: 0.003593... Val Loss: 0.004366\n",
      "Epoch: 83/100... Step: 8629... Loss: 0.004290... Val Loss: 0.004573\n",
      "Epoch: 83/100... Step: 8630... Loss: 0.003777... Val Loss: 0.004705\n",
      "Epoch: 83/100... Step: 8631... Loss: 0.004489... Val Loss: 0.004652\n",
      "Epoch: 83/100... Step: 8632... Loss: 0.005195... Val Loss: 0.004623\n",
      "Epoch: 84/100... Step: 8633... Loss: 0.002464... Val Loss: 0.005692\n",
      "Epoch: 84/100... Step: 8634... Loss: 0.003687... Val Loss: 0.004917\n",
      "Epoch: 84/100... Step: 8635... Loss: 0.005984... Val Loss: 0.003567\n",
      "Epoch: 84/100... Step: 8636... Loss: 0.002399... Val Loss: 0.002376\n",
      "Epoch: 84/100... Step: 8637... Loss: 0.003445... Val Loss: 0.001368\n",
      "Validation loss decreased (0.001382 --> 0.001368).  Saving model ...\n",
      "Epoch: 84/100... Step: 8638... Loss: 0.004270... Val Loss: 0.000956\n",
      "Validation loss decreased (0.001368 --> 0.000956).  Saving model ...\n",
      "Epoch: 84/100... Step: 8639... Loss: 0.003905... Val Loss: 0.001106\n",
      "Epoch: 84/100... Step: 8640... Loss: 0.005473... Val Loss: 0.001818\n",
      "Epoch: 84/100... Step: 8641... Loss: 0.005539... Val Loss: 0.002602\n",
      "Epoch: 84/100... Step: 8642... Loss: 0.004828... Val Loss: 0.003236\n",
      "Epoch: 84/100... Step: 8643... Loss: 0.004904... Val Loss: 0.003675\n",
      "Epoch: 84/100... Step: 8644... Loss: 0.005974... Val Loss: 0.003719\n",
      "Epoch: 84/100... Step: 8645... Loss: 0.005564... Val Loss: 0.003417\n",
      "Epoch: 84/100... Step: 8646... Loss: 0.003789... Val Loss: 0.003407\n",
      "Epoch: 84/100... Step: 8647... Loss: 0.004415... Val Loss: 0.003876\n",
      "Epoch: 84/100... Step: 8648... Loss: 0.002633... Val Loss: 0.004238\n",
      "Epoch: 84/100... Step: 8649... Loss: 0.004660... Val Loss: 0.004129\n",
      "Epoch: 84/100... Step: 8650... Loss: 0.003840... Val Loss: 0.004154\n",
      "Epoch: 84/100... Step: 8651... Loss: 0.004580... Val Loss: 0.004149\n",
      "Epoch: 84/100... Step: 8652... Loss: 0.003375... Val Loss: 0.004172\n",
      "Epoch: 84/100... Step: 8653... Loss: 0.004025... Val Loss: 0.004121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Step: 8654... Loss: 0.003931... Val Loss: 0.004298\n",
      "Epoch: 84/100... Step: 8655... Loss: 0.004223... Val Loss: 0.004219\n",
      "Epoch: 84/100... Step: 8656... Loss: 0.005293... Val Loss: 0.004666\n",
      "Epoch: 84/100... Step: 8657... Loss: 0.002384... Val Loss: 0.004747\n",
      "Epoch: 84/100... Step: 8658... Loss: 0.002900... Val Loss: 0.004436\n",
      "Epoch: 84/100... Step: 8659... Loss: 0.005097... Val Loss: 0.004510\n",
      "Epoch: 84/100... Step: 8660... Loss: 0.004025... Val Loss: 0.004424\n",
      "Epoch: 84/100... Step: 8661... Loss: 0.003530... Val Loss: 0.004537\n",
      "Epoch: 84/100... Step: 8662... Loss: 0.004244... Val Loss: 0.004360\n",
      "Epoch: 84/100... Step: 8663... Loss: 0.003279... Val Loss: 0.004107\n",
      "Epoch: 84/100... Step: 8664... Loss: 0.003223... Val Loss: 0.003819\n",
      "Epoch: 84/100... Step: 8665... Loss: 0.004382... Val Loss: 0.003690\n",
      "Epoch: 84/100... Step: 8666... Loss: 0.005126... Val Loss: 0.003369\n",
      "Epoch: 84/100... Step: 8667... Loss: 0.001837... Val Loss: 0.003030\n",
      "Epoch: 84/100... Step: 8668... Loss: 0.003655... Val Loss: 0.002988\n",
      "Epoch: 84/100... Step: 8669... Loss: 0.002183... Val Loss: 0.003168\n",
      "Epoch: 84/100... Step: 8670... Loss: 0.004271... Val Loss: 0.003230\n",
      "Epoch: 84/100... Step: 8671... Loss: 0.004359... Val Loss: 0.003311\n",
      "Epoch: 84/100... Step: 8672... Loss: 0.006334... Val Loss: 0.003152\n",
      "Epoch: 84/100... Step: 8673... Loss: 0.004171... Val Loss: 0.002834\n",
      "Epoch: 84/100... Step: 8674... Loss: 0.004478... Val Loss: 0.002393\n",
      "Epoch: 84/100... Step: 8675... Loss: 0.003315... Val Loss: 0.002009\n",
      "Epoch: 84/100... Step: 8676... Loss: 0.004400... Val Loss: 0.001691\n",
      "Epoch: 84/100... Step: 8677... Loss: 0.005293... Val Loss: 0.001890\n",
      "Epoch: 84/100... Step: 8678... Loss: 0.004255... Val Loss: 0.002296\n",
      "Epoch: 84/100... Step: 8679... Loss: 0.004366... Val Loss: 0.002435\n",
      "Epoch: 84/100... Step: 8680... Loss: 0.005246... Val Loss: 0.002870\n",
      "Epoch: 84/100... Step: 8681... Loss: 0.006058... Val Loss: 0.003050\n",
      "Epoch: 84/100... Step: 8682... Loss: 0.005304... Val Loss: 0.003142\n",
      "Epoch: 84/100... Step: 8683... Loss: 0.003377... Val Loss: 0.003371\n",
      "Epoch: 84/100... Step: 8684... Loss: 0.003284... Val Loss: 0.003150\n",
      "Epoch: 84/100... Step: 8685... Loss: 0.003991... Val Loss: 0.002803\n",
      "Epoch: 84/100... Step: 8686... Loss: 0.002654... Val Loss: 0.002306\n",
      "Epoch: 84/100... Step: 8687... Loss: 0.004794... Val Loss: 0.002016\n",
      "Epoch: 84/100... Step: 8688... Loss: 0.005677... Val Loss: 0.002251\n",
      "Epoch: 84/100... Step: 8689... Loss: 0.004120... Val Loss: 0.002935\n",
      "Epoch: 84/100... Step: 8690... Loss: 0.003918... Val Loss: 0.003533\n",
      "Epoch: 84/100... Step: 8691... Loss: 0.003721... Val Loss: 0.004368\n",
      "Epoch: 84/100... Step: 8692... Loss: 0.003180... Val Loss: 0.005035\n",
      "Epoch: 84/100... Step: 8693... Loss: 0.004618... Val Loss: 0.005816\n",
      "Epoch: 84/100... Step: 8694... Loss: 0.003061... Val Loss: 0.006117\n",
      "Epoch: 84/100... Step: 8695... Loss: 0.003383... Val Loss: 0.006264\n",
      "Epoch: 84/100... Step: 8696... Loss: 0.005525... Val Loss: 0.006392\n",
      "Epoch: 84/100... Step: 8697... Loss: 0.003682... Val Loss: 0.005952\n",
      "Epoch: 84/100... Step: 8698... Loss: 0.003422... Val Loss: 0.005538\n",
      "Epoch: 84/100... Step: 8699... Loss: 0.003472... Val Loss: 0.004823\n",
      "Epoch: 84/100... Step: 8700... Loss: 0.003736... Val Loss: 0.004453\n",
      "Epoch: 84/100... Step: 8701... Loss: 0.004361... Val Loss: 0.004134\n",
      "Epoch: 84/100... Step: 8702... Loss: 0.004556... Val Loss: 0.003830\n",
      "Epoch: 84/100... Step: 8703... Loss: 0.003455... Val Loss: 0.003829\n",
      "Epoch: 84/100... Step: 8704... Loss: 0.004519... Val Loss: 0.003778\n",
      "Epoch: 84/100... Step: 8705... Loss: 0.003890... Val Loss: 0.003837\n",
      "Epoch: 84/100... Step: 8706... Loss: 0.002158... Val Loss: 0.004182\n",
      "Epoch: 84/100... Step: 8707... Loss: 0.003052... Val Loss: 0.004316\n",
      "Epoch: 84/100... Step: 8708... Loss: 0.005266... Val Loss: 0.004222\n",
      "Epoch: 84/100... Step: 8709... Loss: 0.003844... Val Loss: 0.003957\n",
      "Epoch: 84/100... Step: 8710... Loss: 0.003339... Val Loss: 0.003743\n",
      "Epoch: 84/100... Step: 8711... Loss: 0.003087... Val Loss: 0.003309\n",
      "Epoch: 84/100... Step: 8712... Loss: 0.005753... Val Loss: 0.003100\n",
      "Epoch: 84/100... Step: 8713... Loss: 0.002135... Val Loss: 0.003731\n",
      "Epoch: 84/100... Step: 8714... Loss: 0.002488... Val Loss: 0.004984\n",
      "Epoch: 84/100... Step: 8715... Loss: 0.003043... Val Loss: 0.005949\n",
      "Epoch: 84/100... Step: 8716... Loss: 0.003905... Val Loss: 0.006650\n",
      "Epoch: 84/100... Step: 8717... Loss: 0.002814... Val Loss: 0.007304\n",
      "Epoch: 84/100... Step: 8718... Loss: 0.004627... Val Loss: 0.007388\n",
      "Epoch: 84/100... Step: 8719... Loss: 0.004366... Val Loss: 0.007188\n",
      "Epoch: 84/100... Step: 8720... Loss: 0.006170... Val Loss: 0.006627\n",
      "Epoch: 84/100... Step: 8721... Loss: 0.005329... Val Loss: 0.005870\n",
      "Epoch: 84/100... Step: 8722... Loss: 0.004441... Val Loss: 0.004917\n",
      "Epoch: 84/100... Step: 8723... Loss: 0.002345... Val Loss: 0.003766\n",
      "Epoch: 84/100... Step: 8724... Loss: 0.004071... Val Loss: 0.002380\n",
      "Epoch: 84/100... Step: 8725... Loss: 0.002731... Val Loss: 0.001345\n",
      "Epoch: 84/100... Step: 8726... Loss: 0.005098... Val Loss: 0.002275\n",
      "Epoch: 84/100... Step: 8727... Loss: 0.003998... Val Loss: 0.003693\n",
      "Epoch: 84/100... Step: 8728... Loss: 0.003657... Val Loss: 0.004724\n",
      "Epoch: 84/100... Step: 8729... Loss: 0.003577... Val Loss: 0.005241\n",
      "Epoch: 84/100... Step: 8730... Loss: 0.004513... Val Loss: 0.005720\n",
      "Epoch: 84/100... Step: 8731... Loss: 0.003151... Val Loss: 0.005931\n",
      "Epoch: 84/100... Step: 8732... Loss: 0.003738... Val Loss: 0.005738\n",
      "Epoch: 84/100... Step: 8733... Loss: 0.006719... Val Loss: 0.005192\n",
      "Epoch: 84/100... Step: 8734... Loss: 0.003758... Val Loss: 0.004488\n",
      "Epoch: 84/100... Step: 8735... Loss: 0.001981... Val Loss: 0.003557\n",
      "Epoch: 84/100... Step: 8736... Loss: 0.005438... Val Loss: 0.002759\n",
      "Epoch: 85/100... Step: 8737... Loss: 0.004737... Val Loss: 0.008404\n",
      "Epoch: 85/100... Step: 8738... Loss: 0.004032... Val Loss: 0.008674\n",
      "Epoch: 85/100... Step: 8739... Loss: 0.004881... Val Loss: 0.007142\n",
      "Epoch: 85/100... Step: 8740... Loss: 0.004211... Val Loss: 0.005361\n",
      "Epoch: 85/100... Step: 8741... Loss: 0.003666... Val Loss: 0.003849\n",
      "Epoch: 85/100... Step: 8742... Loss: 0.003724... Val Loss: 0.002930\n",
      "Epoch: 85/100... Step: 8743... Loss: 0.002972... Val Loss: 0.002472\n",
      "Epoch: 85/100... Step: 8744... Loss: 0.003815... Val Loss: 0.002511\n",
      "Epoch: 85/100... Step: 8745... Loss: 0.004419... Val Loss: 0.002719\n",
      "Epoch: 85/100... Step: 8746... Loss: 0.004159... Val Loss: 0.003252\n",
      "Epoch: 85/100... Step: 8747... Loss: 0.004471... Val Loss: 0.004188\n",
      "Epoch: 85/100... Step: 8748... Loss: 0.003300... Val Loss: 0.005044\n",
      "Epoch: 85/100... Step: 8749... Loss: 0.002768... Val Loss: 0.005655\n",
      "Epoch: 85/100... Step: 8750... Loss: 0.002833... Val Loss: 0.005783\n",
      "Epoch: 85/100... Step: 8751... Loss: 0.003393... Val Loss: 0.006047\n",
      "Epoch: 85/100... Step: 8752... Loss: 0.001704... Val Loss: 0.006304\n",
      "Epoch: 85/100... Step: 8753... Loss: 0.003801... Val Loss: 0.006606\n",
      "Epoch: 85/100... Step: 8754... Loss: 0.004271... Val Loss: 0.006911\n",
      "Epoch: 85/100... Step: 8755... Loss: 0.004973... Val Loss: 0.006805\n",
      "Epoch: 85/100... Step: 8756... Loss: 0.005149... Val Loss: 0.006324\n",
      "Epoch: 85/100... Step: 8757... Loss: 0.003343... Val Loss: 0.005922\n",
      "Epoch: 85/100... Step: 8758... Loss: 0.003686... Val Loss: 0.005531\n",
      "Epoch: 85/100... Step: 8759... Loss: 0.004341... Val Loss: 0.005106\n",
      "Epoch: 85/100... Step: 8760... Loss: 0.003172... Val Loss: 0.004741\n",
      "Epoch: 85/100... Step: 8761... Loss: 0.003636... Val Loss: 0.004565\n",
      "Epoch: 85/100... Step: 8762... Loss: 0.004462... Val Loss: 0.004146\n",
      "Epoch: 85/100... Step: 8763... Loss: 0.004287... Val Loss: 0.003715\n",
      "Epoch: 85/100... Step: 8764... Loss: 0.003782... Val Loss: 0.003419\n",
      "Epoch: 85/100... Step: 8765... Loss: 0.002820... Val Loss: 0.003224\n",
      "Epoch: 85/100... Step: 8766... Loss: 0.004966... Val Loss: 0.003027\n",
      "Epoch: 85/100... Step: 8767... Loss: 0.004851... Val Loss: 0.002646\n",
      "Epoch: 85/100... Step: 8768... Loss: 0.003569... Val Loss: 0.002275\n",
      "Epoch: 85/100... Step: 8769... Loss: 0.003649... Val Loss: 0.001836\n",
      "Epoch: 85/100... Step: 8770... Loss: 0.004510... Val Loss: 0.002119\n",
      "Epoch: 85/100... Step: 8771... Loss: 0.003859... Val Loss: 0.002597\n",
      "Epoch: 85/100... Step: 8772... Loss: 0.005774... Val Loss: 0.003122\n",
      "Epoch: 85/100... Step: 8773... Loss: 0.002103... Val Loss: 0.003546\n",
      "Epoch: 85/100... Step: 8774... Loss: 0.004940... Val Loss: 0.003572\n",
      "Epoch: 85/100... Step: 8775... Loss: 0.003524... Val Loss: 0.003557\n",
      "Epoch: 85/100... Step: 8776... Loss: 0.003177... Val Loss: 0.003130\n",
      "Epoch: 85/100... Step: 8777... Loss: 0.003708... Val Loss: 0.002653\n",
      "Epoch: 85/100... Step: 8778... Loss: 0.003339... Val Loss: 0.002459\n",
      "Epoch: 85/100... Step: 8779... Loss: 0.004421... Val Loss: 0.002299\n",
      "Epoch: 85/100... Step: 8780... Loss: 0.003516... Val Loss: 0.002370\n",
      "Epoch: 85/100... Step: 8781... Loss: 0.004018... Val Loss: 0.002482\n",
      "Epoch: 85/100... Step: 8782... Loss: 0.004014... Val Loss: 0.002608\n",
      "Epoch: 85/100... Step: 8783... Loss: 0.003651... Val Loss: 0.002647\n",
      "Epoch: 85/100... Step: 8784... Loss: 0.003709... Val Loss: 0.002642\n",
      "Epoch: 85/100... Step: 8785... Loss: 0.004922... Val Loss: 0.002589\n",
      "Epoch: 85/100... Step: 8786... Loss: 0.003852... Val Loss: 0.002767\n",
      "Epoch: 85/100... Step: 8787... Loss: 0.003045... Val Loss: 0.003174\n",
      "Epoch: 85/100... Step: 8788... Loss: 0.005424... Val Loss: 0.003619\n",
      "Epoch: 85/100... Step: 8789... Loss: 0.004825... Val Loss: 0.003748\n",
      "Epoch: 85/100... Step: 8790... Loss: 0.003119... Val Loss: 0.003537\n",
      "Epoch: 85/100... Step: 8791... Loss: 0.004671... Val Loss: 0.003105\n",
      "Epoch: 85/100... Step: 8792... Loss: 0.004928... Val Loss: 0.002671\n",
      "Epoch: 85/100... Step: 8793... Loss: 0.002187... Val Loss: 0.002521\n",
      "Epoch: 85/100... Step: 8794... Loss: 0.004024... Val Loss: 0.002221\n",
      "Epoch: 85/100... Step: 8795... Loss: 0.003709... Val Loss: 0.002226\n",
      "Epoch: 85/100... Step: 8796... Loss: 0.003418... Val Loss: 0.002176\n",
      "Epoch: 85/100... Step: 8797... Loss: 0.003563... Val Loss: 0.002260\n",
      "Epoch: 85/100... Step: 8798... Loss: 0.003204... Val Loss: 0.002203\n",
      "Epoch: 85/100... Step: 8799... Loss: 0.005877... Val Loss: 0.002418\n",
      "Epoch: 85/100... Step: 8800... Loss: 0.004349... Val Loss: 0.002443\n",
      "Epoch: 85/100... Step: 8801... Loss: 0.003637... Val Loss: 0.002480\n",
      "Epoch: 85/100... Step: 8802... Loss: 0.003025... Val Loss: 0.002441\n",
      "Epoch: 85/100... Step: 8803... Loss: 0.002999... Val Loss: 0.002369\n",
      "Epoch: 85/100... Step: 8804... Loss: 0.004219... Val Loss: 0.002404\n",
      "Epoch: 85/100... Step: 8805... Loss: 0.002446... Val Loss: 0.002409\n",
      "Epoch: 85/100... Step: 8806... Loss: 0.003493... Val Loss: 0.002462\n",
      "Epoch: 85/100... Step: 8807... Loss: 0.002435... Val Loss: 0.002646\n",
      "Epoch: 85/100... Step: 8808... Loss: 0.004833... Val Loss: 0.002761\n",
      "Epoch: 85/100... Step: 8809... Loss: 0.003275... Val Loss: 0.002814\n",
      "Epoch: 85/100... Step: 8810... Loss: 0.002876... Val Loss: 0.002872\n",
      "Epoch: 85/100... Step: 8811... Loss: 0.002820... Val Loss: 0.002989\n",
      "Epoch: 85/100... Step: 8812... Loss: 0.005402... Val Loss: 0.002988\n",
      "Epoch: 85/100... Step: 8813... Loss: 0.003361... Val Loss: 0.002933\n",
      "Epoch: 85/100... Step: 8814... Loss: 0.001705... Val Loss: 0.002873\n",
      "Epoch: 85/100... Step: 8815... Loss: 0.001471... Val Loss: 0.003129\n",
      "Epoch: 85/100... Step: 8816... Loss: 0.003442... Val Loss: 0.003071\n",
      "Epoch: 85/100... Step: 8817... Loss: 0.002913... Val Loss: 0.003087\n",
      "Epoch: 85/100... Step: 8818... Loss: 0.002717... Val Loss: 0.003230\n",
      "Epoch: 85/100... Step: 8819... Loss: 0.004610... Val Loss: 0.003146\n",
      "Epoch: 85/100... Step: 8820... Loss: 0.005133... Val Loss: 0.003224\n",
      "Epoch: 85/100... Step: 8821... Loss: 0.003687... Val Loss: 0.003251\n",
      "Epoch: 85/100... Step: 8822... Loss: 0.003827... Val Loss: 0.003020\n",
      "Epoch: 85/100... Step: 8823... Loss: 0.004047... Val Loss: 0.002828\n",
      "Epoch: 85/100... Step: 8824... Loss: 0.003919... Val Loss: 0.002705\n",
      "Epoch: 85/100... Step: 8825... Loss: 0.005191... Val Loss: 0.002618\n",
      "Epoch: 85/100... Step: 8826... Loss: 0.003291... Val Loss: 0.002567\n",
      "Epoch: 85/100... Step: 8827... Loss: 0.003174... Val Loss: 0.002252\n",
      "Epoch: 85/100... Step: 8828... Loss: 0.003850... Val Loss: 0.002384\n",
      "Epoch: 85/100... Step: 8829... Loss: 0.002893... Val Loss: 0.002359\n",
      "Epoch: 85/100... Step: 8830... Loss: 0.005357... Val Loss: 0.002438\n",
      "Epoch: 85/100... Step: 8831... Loss: 0.001613... Val Loss: 0.002388\n",
      "Epoch: 85/100... Step: 8832... Loss: 0.005718... Val Loss: 0.002331\n",
      "Epoch: 85/100... Step: 8833... Loss: 0.005029... Val Loss: 0.002277\n",
      "Epoch: 85/100... Step: 8834... Loss: 0.004560... Val Loss: 0.001977\n",
      "Epoch: 85/100... Step: 8835... Loss: 0.001958... Val Loss: 0.001980\n",
      "Epoch: 85/100... Step: 8836... Loss: 0.003481... Val Loss: 0.001792\n",
      "Epoch: 85/100... Step: 8837... Loss: 0.003987... Val Loss: 0.001877\n",
      "Epoch: 85/100... Step: 8838... Loss: 0.003049... Val Loss: 0.002336\n",
      "Epoch: 85/100... Step: 8839... Loss: 0.003564... Val Loss: 0.002820\n",
      "Epoch: 85/100... Step: 8840... Loss: 0.002111... Val Loss: 0.003186\n",
      "Epoch: 86/100... Step: 8841... Loss: 0.002792... Val Loss: 0.005347\n",
      "Epoch: 86/100... Step: 8842... Loss: 0.003600... Val Loss: 0.004292\n",
      "Epoch: 86/100... Step: 8843... Loss: 0.003870... Val Loss: 0.003213\n",
      "Epoch: 86/100... Step: 8844... Loss: 0.004026... Val Loss: 0.002403\n",
      "Epoch: 86/100... Step: 8845... Loss: 0.003487... Val Loss: 0.001931\n",
      "Epoch: 86/100... Step: 8846... Loss: 0.004245... Val Loss: 0.002142\n",
      "Epoch: 86/100... Step: 8847... Loss: 0.004965... Val Loss: 0.002697\n",
      "Epoch: 86/100... Step: 8848... Loss: 0.003221... Val Loss: 0.003492\n",
      "Epoch: 86/100... Step: 8849... Loss: 0.002020... Val Loss: 0.004436\n",
      "Epoch: 86/100... Step: 8850... Loss: 0.002517... Val Loss: 0.005416\n",
      "Epoch: 86/100... Step: 8851... Loss: 0.003860... Val Loss: 0.006182\n",
      "Epoch: 86/100... Step: 8852... Loss: 0.003515... Val Loss: 0.006886\n",
      "Epoch: 86/100... Step: 8853... Loss: 0.003902... Val Loss: 0.007230\n",
      "Epoch: 86/100... Step: 8854... Loss: 0.003575... Val Loss: 0.007377\n",
      "Epoch: 86/100... Step: 8855... Loss: 0.004561... Val Loss: 0.007550\n",
      "Epoch: 86/100... Step: 8856... Loss: 0.003812... Val Loss: 0.007783\n",
      "Epoch: 86/100... Step: 8857... Loss: 0.004780... Val Loss: 0.007862\n",
      "Epoch: 86/100... Step: 8858... Loss: 0.002959... Val Loss: 0.007925\n",
      "Epoch: 86/100... Step: 8859... Loss: 0.003677... Val Loss: 0.007817\n",
      "Epoch: 86/100... Step: 8860... Loss: 0.003500... Val Loss: 0.007840\n",
      "Epoch: 86/100... Step: 8861... Loss: 0.002057... Val Loss: 0.007868\n",
      "Epoch: 86/100... Step: 8862... Loss: 0.003323... Val Loss: 0.008131\n",
      "Epoch: 86/100... Step: 8863... Loss: 0.003267... Val Loss: 0.008006\n",
      "Epoch: 86/100... Step: 8864... Loss: 0.004261... Val Loss: 0.007944\n",
      "Epoch: 86/100... Step: 8865... Loss: 0.003010... Val Loss: 0.007699\n",
      "Epoch: 86/100... Step: 8866... Loss: 0.002309... Val Loss: 0.007537\n",
      "Epoch: 86/100... Step: 8867... Loss: 0.004801... Val Loss: 0.007315\n",
      "Epoch: 86/100... Step: 8868... Loss: 0.003475... Val Loss: 0.007228\n",
      "Epoch: 86/100... Step: 8869... Loss: 0.003452... Val Loss: 0.007078\n",
      "Epoch: 86/100... Step: 8870... Loss: 0.003719... Val Loss: 0.007432\n",
      "Epoch: 86/100... Step: 8871... Loss: 0.004161... Val Loss: 0.007210\n",
      "Epoch: 86/100... Step: 8872... Loss: 0.003931... Val Loss: 0.007088\n",
      "Epoch: 86/100... Step: 8873... Loss: 0.004365... Val Loss: 0.006920\n",
      "Epoch: 86/100... Step: 8874... Loss: 0.004040... Val Loss: 0.006919\n",
      "Epoch: 86/100... Step: 8875... Loss: 0.002964... Val Loss: 0.006741\n",
      "Epoch: 86/100... Step: 8876... Loss: 0.002449... Val Loss: 0.006766\n",
      "Epoch: 86/100... Step: 8877... Loss: 0.002896... Val Loss: 0.006626\n",
      "Epoch: 86/100... Step: 8878... Loss: 0.005096... Val Loss: 0.006644\n",
      "Epoch: 86/100... Step: 8879... Loss: 0.001980... Val Loss: 0.006517\n",
      "Epoch: 86/100... Step: 8880... Loss: 0.003191... Val Loss: 0.006294\n",
      "Epoch: 86/100... Step: 8881... Loss: 0.002904... Val Loss: 0.006081\n",
      "Epoch: 86/100... Step: 8882... Loss: 0.003127... Val Loss: 0.005621\n",
      "Epoch: 86/100... Step: 8883... Loss: 0.003022... Val Loss: 0.005227\n",
      "Epoch: 86/100... Step: 8884... Loss: 0.002914... Val Loss: 0.005187\n",
      "Epoch: 86/100... Step: 8885... Loss: 0.002205... Val Loss: 0.004931\n",
      "Epoch: 86/100... Step: 8886... Loss: 0.003638... Val Loss: 0.004604\n",
      "Epoch: 86/100... Step: 8887... Loss: 0.003042... Val Loss: 0.004370\n",
      "Epoch: 86/100... Step: 8888... Loss: 0.002430... Val Loss: 0.004035\n",
      "Epoch: 86/100... Step: 8889... Loss: 0.003200... Val Loss: 0.003413\n",
      "Epoch: 86/100... Step: 8890... Loss: 0.003092... Val Loss: 0.002942\n",
      "Epoch: 86/100... Step: 8891... Loss: 0.003459... Val Loss: 0.002846\n",
      "Epoch: 86/100... Step: 8892... Loss: 0.003601... Val Loss: 0.002547\n",
      "Epoch: 86/100... Step: 8893... Loss: 0.003535... Val Loss: 0.002631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100... Step: 8894... Loss: 0.002020... Val Loss: 0.002943\n",
      "Epoch: 86/100... Step: 8895... Loss: 0.003564... Val Loss: 0.003347\n",
      "Epoch: 86/100... Step: 8896... Loss: 0.003958... Val Loss: 0.003803\n",
      "Epoch: 86/100... Step: 8897... Loss: 0.003458... Val Loss: 0.003870\n",
      "Epoch: 86/100... Step: 8898... Loss: 0.006145... Val Loss: 0.003730\n",
      "Epoch: 86/100... Step: 8899... Loss: 0.002623... Val Loss: 0.003683\n",
      "Epoch: 86/100... Step: 8900... Loss: 0.003725... Val Loss: 0.003654\n",
      "Epoch: 86/100... Step: 8901... Loss: 0.005230... Val Loss: 0.003268\n",
      "Epoch: 86/100... Step: 8902... Loss: 0.004589... Val Loss: 0.003113\n",
      "Epoch: 86/100... Step: 8903... Loss: 0.003351... Val Loss: 0.002917\n",
      "Epoch: 86/100... Step: 8904... Loss: 0.003817... Val Loss: 0.002654\n",
      "Epoch: 86/100... Step: 8905... Loss: 0.004228... Val Loss: 0.002691\n",
      "Epoch: 86/100... Step: 8906... Loss: 0.002479... Val Loss: 0.002669\n",
      "Epoch: 86/100... Step: 8907... Loss: 0.003482... Val Loss: 0.002704\n",
      "Epoch: 86/100... Step: 8908... Loss: 0.003298... Val Loss: 0.002696\n",
      "Epoch: 86/100... Step: 8909... Loss: 0.002566... Val Loss: 0.002720\n",
      "Epoch: 86/100... Step: 8910... Loss: 0.003309... Val Loss: 0.002834\n",
      "Epoch: 86/100... Step: 8911... Loss: 0.003161... Val Loss: 0.002751\n",
      "Epoch: 86/100... Step: 8912... Loss: 0.002551... Val Loss: 0.002653\n",
      "Epoch: 86/100... Step: 8913... Loss: 0.003395... Val Loss: 0.002669\n",
      "Epoch: 86/100... Step: 8914... Loss: 0.003022... Val Loss: 0.002686\n",
      "Epoch: 86/100... Step: 8915... Loss: 0.002382... Val Loss: 0.002735\n",
      "Epoch: 86/100... Step: 8916... Loss: 0.003528... Val Loss: 0.002812\n",
      "Epoch: 86/100... Step: 8917... Loss: 0.002817... Val Loss: 0.003028\n",
      "Epoch: 86/100... Step: 8918... Loss: 0.003163... Val Loss: 0.002764\n",
      "Epoch: 86/100... Step: 8919... Loss: 0.002269... Val Loss: 0.002753\n",
      "Epoch: 86/100... Step: 8920... Loss: 0.003133... Val Loss: 0.002882\n",
      "Epoch: 86/100... Step: 8921... Loss: 0.003541... Val Loss: 0.003172\n",
      "Epoch: 86/100... Step: 8922... Loss: 0.002757... Val Loss: 0.003459\n",
      "Epoch: 86/100... Step: 8923... Loss: 0.003768... Val Loss: 0.003610\n",
      "Epoch: 86/100... Step: 8924... Loss: 0.002721... Val Loss: 0.003570\n",
      "Epoch: 86/100... Step: 8925... Loss: 0.001577... Val Loss: 0.003479\n",
      "Epoch: 86/100... Step: 8926... Loss: 0.003902... Val Loss: 0.003253\n",
      "Epoch: 86/100... Step: 8927... Loss: 0.004929... Val Loss: 0.003246\n",
      "Epoch: 86/100... Step: 8928... Loss: 0.002224... Val Loss: 0.002877\n",
      "Epoch: 86/100... Step: 8929... Loss: 0.004053... Val Loss: 0.002806\n",
      "Epoch: 86/100... Step: 8930... Loss: 0.002672... Val Loss: 0.002806\n",
      "Epoch: 86/100... Step: 8931... Loss: 0.003180... Val Loss: 0.002889\n",
      "Epoch: 86/100... Step: 8932... Loss: 0.004080... Val Loss: 0.002557\n",
      "Epoch: 86/100... Step: 8933... Loss: 0.002217... Val Loss: 0.002197\n",
      "Epoch: 86/100... Step: 8934... Loss: 0.004354... Val Loss: 0.002501\n",
      "Epoch: 86/100... Step: 8935... Loss: 0.004239... Val Loss: 0.002661\n",
      "Epoch: 86/100... Step: 8936... Loss: 0.002594... Val Loss: 0.002766\n",
      "Epoch: 86/100... Step: 8937... Loss: 0.003908... Val Loss: 0.002640\n",
      "Epoch: 86/100... Step: 8938... Loss: 0.002214... Val Loss: 0.002275\n",
      "Epoch: 86/100... Step: 8939... Loss: 0.004633... Val Loss: 0.001976\n",
      "Epoch: 86/100... Step: 8940... Loss: 0.003347... Val Loss: 0.001536\n",
      "Epoch: 86/100... Step: 8941... Loss: 0.002859... Val Loss: 0.001359\n",
      "Epoch: 86/100... Step: 8942... Loss: 0.003879... Val Loss: 0.001025\n",
      "Epoch: 86/100... Step: 8943... Loss: 0.003271... Val Loss: 0.000957\n",
      "Epoch: 86/100... Step: 8944... Loss: 0.003154... Val Loss: 0.001402\n",
      "Epoch: 87/100... Step: 8945... Loss: 0.007636... Val Loss: 0.003212\n",
      "Epoch: 87/100... Step: 8946... Loss: 0.005235... Val Loss: 0.005598\n",
      "Epoch: 87/100... Step: 8947... Loss: 0.004824... Val Loss: 0.006205\n",
      "Epoch: 87/100... Step: 8948... Loss: 0.002980... Val Loss: 0.005922\n",
      "Epoch: 87/100... Step: 8949... Loss: 0.003287... Val Loss: 0.005165\n",
      "Epoch: 87/100... Step: 8950... Loss: 0.003790... Val Loss: 0.004231\n",
      "Epoch: 87/100... Step: 8951... Loss: 0.002290... Val Loss: 0.003072\n",
      "Epoch: 87/100... Step: 8952... Loss: 0.002614... Val Loss: 0.002089\n",
      "Epoch: 87/100... Step: 8953... Loss: 0.001907... Val Loss: 0.002008\n",
      "Epoch: 87/100... Step: 8954... Loss: 0.003819... Val Loss: 0.002541\n",
      "Epoch: 87/100... Step: 8955... Loss: 0.003414... Val Loss: 0.003383\n",
      "Epoch: 87/100... Step: 8956... Loss: 0.003109... Val Loss: 0.004311\n",
      "Epoch: 87/100... Step: 8957... Loss: 0.002893... Val Loss: 0.005057\n",
      "Epoch: 87/100... Step: 8958... Loss: 0.004267... Val Loss: 0.005840\n",
      "Epoch: 87/100... Step: 8959... Loss: 0.004093... Val Loss: 0.006564\n",
      "Epoch: 87/100... Step: 8960... Loss: 0.003054... Val Loss: 0.007290\n",
      "Epoch: 87/100... Step: 8961... Loss: 0.004436... Val Loss: 0.007774\n",
      "Epoch: 87/100... Step: 8962... Loss: 0.003551... Val Loss: 0.007972\n",
      "Epoch: 87/100... Step: 8963... Loss: 0.003123... Val Loss: 0.007989\n",
      "Epoch: 87/100... Step: 8964... Loss: 0.003602... Val Loss: 0.008069\n",
      "Epoch: 87/100... Step: 8965... Loss: 0.004193... Val Loss: 0.007965\n",
      "Epoch: 87/100... Step: 8966... Loss: 0.002733... Val Loss: 0.007784\n",
      "Epoch: 87/100... Step: 8967... Loss: 0.003787... Val Loss: 0.007688\n",
      "Epoch: 87/100... Step: 8968... Loss: 0.003981... Val Loss: 0.007725\n",
      "Epoch: 87/100... Step: 8969... Loss: 0.005007... Val Loss: 0.007539\n",
      "Epoch: 87/100... Step: 8970... Loss: 0.002790... Val Loss: 0.007351\n",
      "Epoch: 87/100... Step: 8971... Loss: 0.002783... Val Loss: 0.007297\n",
      "Epoch: 87/100... Step: 8972... Loss: 0.003316... Val Loss: 0.007310\n",
      "Epoch: 87/100... Step: 8973... Loss: 0.002960... Val Loss: 0.007339\n",
      "Epoch: 87/100... Step: 8974... Loss: 0.003215... Val Loss: 0.007301\n",
      "Epoch: 87/100... Step: 8975... Loss: 0.002490... Val Loss: 0.007386\n",
      "Epoch: 87/100... Step: 8976... Loss: 0.002464... Val Loss: 0.007358\n",
      "Epoch: 87/100... Step: 8977... Loss: 0.002651... Val Loss: 0.007182\n",
      "Epoch: 87/100... Step: 8978... Loss: 0.003228... Val Loss: 0.007084\n",
      "Epoch: 87/100... Step: 8979... Loss: 0.003410... Val Loss: 0.006746\n",
      "Epoch: 87/100... Step: 8980... Loss: 0.004302... Val Loss: 0.006260\n",
      "Epoch: 87/100... Step: 8981... Loss: 0.003182... Val Loss: 0.005581\n",
      "Epoch: 87/100... Step: 8982... Loss: 0.002940... Val Loss: 0.005207\n",
      "Epoch: 87/100... Step: 8983... Loss: 0.003245... Val Loss: 0.004841\n",
      "Epoch: 87/100... Step: 8984... Loss: 0.001598... Val Loss: 0.004337\n",
      "Epoch: 87/100... Step: 8985... Loss: 0.002074... Val Loss: 0.003967\n",
      "Epoch: 87/100... Step: 8986... Loss: 0.002728... Val Loss: 0.003660\n",
      "Epoch: 87/100... Step: 8987... Loss: 0.001655... Val Loss: 0.003580\n",
      "Epoch: 87/100... Step: 8988... Loss: 0.002741... Val Loss: 0.003468\n",
      "Epoch: 87/100... Step: 8989... Loss: 0.003687... Val Loss: 0.003316\n",
      "Epoch: 87/100... Step: 8990... Loss: 0.004529... Val Loss: 0.003308\n",
      "Epoch: 87/100... Step: 8991... Loss: 0.003142... Val Loss: 0.003272\n",
      "Epoch: 87/100... Step: 8992... Loss: 0.003214... Val Loss: 0.003219\n",
      "Epoch: 87/100... Step: 8993... Loss: 0.004314... Val Loss: 0.003071\n",
      "Epoch: 87/100... Step: 8994... Loss: 0.002033... Val Loss: 0.003025\n",
      "Epoch: 87/100... Step: 8995... Loss: 0.002627... Val Loss: 0.003105\n",
      "Epoch: 87/100... Step: 8996... Loss: 0.003752... Val Loss: 0.003200\n",
      "Epoch: 87/100... Step: 8997... Loss: 0.002056... Val Loss: 0.003105\n",
      "Epoch: 87/100... Step: 8998... Loss: 0.002988... Val Loss: 0.003254\n",
      "Epoch: 87/100... Step: 8999... Loss: 0.002648... Val Loss: 0.003506\n",
      "Epoch: 87/100... Step: 9000... Loss: 0.003854... Val Loss: 0.003431\n",
      "Epoch: 87/100... Step: 9001... Loss: 0.002354... Val Loss: 0.003451\n",
      "Epoch: 87/100... Step: 9002... Loss: 0.003207... Val Loss: 0.003306\n",
      "Epoch: 87/100... Step: 9003... Loss: 0.003289... Val Loss: 0.002838\n",
      "Epoch: 87/100... Step: 9004... Loss: 0.002985... Val Loss: 0.002266\n",
      "Epoch: 87/100... Step: 9005... Loss: 0.002838... Val Loss: 0.001817\n",
      "Epoch: 87/100... Step: 9006... Loss: 0.001895... Val Loss: 0.001607\n",
      "Epoch: 87/100... Step: 9007... Loss: 0.002248... Val Loss: 0.001746\n",
      "Epoch: 87/100... Step: 9008... Loss: 0.002640... Val Loss: 0.002260\n",
      "Epoch: 87/100... Step: 9009... Loss: 0.002132... Val Loss: 0.002615\n",
      "Epoch: 87/100... Step: 9010... Loss: 0.002251... Val Loss: 0.002835\n",
      "Epoch: 87/100... Step: 9011... Loss: 0.004030... Val Loss: 0.002849\n",
      "Epoch: 87/100... Step: 9012... Loss: 0.003031... Val Loss: 0.002820\n",
      "Epoch: 87/100... Step: 9013... Loss: 0.002473... Val Loss: 0.002571\n",
      "Epoch: 87/100... Step: 9014... Loss: 0.001145... Val Loss: 0.002439\n",
      "Epoch: 87/100... Step: 9015... Loss: 0.002018... Val Loss: 0.002403\n",
      "Epoch: 87/100... Step: 9016... Loss: 0.002630... Val Loss: 0.002358\n",
      "Epoch: 87/100... Step: 9017... Loss: 0.002732... Val Loss: 0.002362\n",
      "Epoch: 87/100... Step: 9018... Loss: 0.002258... Val Loss: 0.002247\n",
      "Epoch: 87/100... Step: 9019... Loss: 0.002223... Val Loss: 0.002099\n",
      "Epoch: 87/100... Step: 9020... Loss: 0.002487... Val Loss: 0.001772\n",
      "Epoch: 87/100... Step: 9021... Loss: 0.002573... Val Loss: 0.001492\n",
      "Epoch: 87/100... Step: 9022... Loss: 0.003478... Val Loss: 0.001375\n",
      "Epoch: 87/100... Step: 9023... Loss: 0.002123... Val Loss: 0.001548\n",
      "Epoch: 87/100... Step: 9024... Loss: 0.002093... Val Loss: 0.001841\n",
      "Epoch: 87/100... Step: 9025... Loss: 0.003546... Val Loss: 0.001992\n",
      "Epoch: 87/100... Step: 9026... Loss: 0.003313... Val Loss: 0.002229\n",
      "Epoch: 87/100... Step: 9027... Loss: 0.002812... Val Loss: 0.002312\n",
      "Epoch: 87/100... Step: 9028... Loss: 0.002674... Val Loss: 0.002123\n",
      "Epoch: 87/100... Step: 9029... Loss: 0.002647... Val Loss: 0.002027\n",
      "Epoch: 87/100... Step: 9030... Loss: 0.001351... Val Loss: 0.001993\n",
      "Epoch: 87/100... Step: 9031... Loss: 0.002762... Val Loss: 0.001775\n",
      "Epoch: 87/100... Step: 9032... Loss: 0.002690... Val Loss: 0.001674\n",
      "Epoch: 87/100... Step: 9033... Loss: 0.002968... Val Loss: 0.001654\n",
      "Epoch: 87/100... Step: 9034... Loss: 0.002666... Val Loss: 0.001591\n",
      "Epoch: 87/100... Step: 9035... Loss: 0.002717... Val Loss: 0.001617\n",
      "Epoch: 87/100... Step: 9036... Loss: 0.003311... Val Loss: 0.001784\n",
      "Epoch: 87/100... Step: 9037... Loss: 0.003730... Val Loss: 0.001849\n",
      "Epoch: 87/100... Step: 9038... Loss: 0.003300... Val Loss: 0.001758\n",
      "Epoch: 87/100... Step: 9039... Loss: 0.003268... Val Loss: 0.001513\n",
      "Epoch: 87/100... Step: 9040... Loss: 0.002536... Val Loss: 0.001364\n",
      "Epoch: 87/100... Step: 9041... Loss: 0.001419... Val Loss: 0.001241\n",
      "Epoch: 87/100... Step: 9042... Loss: 0.002330... Val Loss: 0.001025\n",
      "Epoch: 87/100... Step: 9043... Loss: 0.003101... Val Loss: 0.000949\n",
      "Validation loss decreased (0.000956 --> 0.000949).  Saving model ...\n",
      "Epoch: 87/100... Step: 9044... Loss: 0.002810... Val Loss: 0.001031\n",
      "Epoch: 87/100... Step: 9045... Loss: 0.002415... Val Loss: 0.001169\n",
      "Epoch: 87/100... Step: 9046... Loss: 0.003229... Val Loss: 0.001310\n",
      "Epoch: 87/100... Step: 9047... Loss: 0.002232... Val Loss: 0.001523\n",
      "Epoch: 87/100... Step: 9048... Loss: 0.002321... Val Loss: 0.001525\n",
      "Epoch: 88/100... Step: 9049... Loss: 0.003346... Val Loss: 0.006364\n",
      "Epoch: 88/100... Step: 9050... Loss: 0.003073... Val Loss: 0.005574\n",
      "Epoch: 88/100... Step: 9051... Loss: 0.003335... Val Loss: 0.003454\n",
      "Epoch: 88/100... Step: 9052... Loss: 0.004296... Val Loss: 0.001457\n",
      "Epoch: 88/100... Step: 9053... Loss: 0.003022... Val Loss: 0.001211\n",
      "Epoch: 88/100... Step: 9054... Loss: 0.002204... Val Loss: 0.002183\n",
      "Epoch: 88/100... Step: 9055... Loss: 0.002408... Val Loss: 0.003202\n",
      "Epoch: 88/100... Step: 9056... Loss: 0.003529... Val Loss: 0.004445\n",
      "Epoch: 88/100... Step: 9057... Loss: 0.002786... Val Loss: 0.005376\n",
      "Epoch: 88/100... Step: 9058... Loss: 0.002622... Val Loss: 0.006098\n",
      "Epoch: 88/100... Step: 9059... Loss: 0.003192... Val Loss: 0.006623\n",
      "Epoch: 88/100... Step: 9060... Loss: 0.002665... Val Loss: 0.007006\n",
      "Epoch: 88/100... Step: 9061... Loss: 0.002686... Val Loss: 0.007274\n",
      "Epoch: 88/100... Step: 9062... Loss: 0.001947... Val Loss: 0.007362\n",
      "Epoch: 88/100... Step: 9063... Loss: 0.002809... Val Loss: 0.007407\n",
      "Epoch: 88/100... Step: 9064... Loss: 0.003974... Val Loss: 0.007356\n",
      "Epoch: 88/100... Step: 9065... Loss: 0.002795... Val Loss: 0.007304\n",
      "Epoch: 88/100... Step: 9066... Loss: 0.003716... Val Loss: 0.007402\n",
      "Epoch: 88/100... Step: 9067... Loss: 0.003357... Val Loss: 0.007443\n",
      "Epoch: 88/100... Step: 9068... Loss: 0.003555... Val Loss: 0.007273\n",
      "Epoch: 88/100... Step: 9069... Loss: 0.003202... Val Loss: 0.007269\n",
      "Epoch: 88/100... Step: 9070... Loss: 0.003164... Val Loss: 0.007382\n",
      "Epoch: 88/100... Step: 9071... Loss: 0.002598... Val Loss: 0.007333\n",
      "Epoch: 88/100... Step: 9072... Loss: 0.002467... Val Loss: 0.007360\n",
      "Epoch: 88/100... Step: 9073... Loss: 0.002266... Val Loss: 0.007166\n",
      "Epoch: 88/100... Step: 9074... Loss: 0.001959... Val Loss: 0.007103\n",
      "Epoch: 88/100... Step: 9075... Loss: 0.001992... Val Loss: 0.006873\n",
      "Epoch: 88/100... Step: 9076... Loss: 0.003041... Val Loss: 0.006573\n",
      "Epoch: 88/100... Step: 9077... Loss: 0.002389... Val Loss: 0.006262\n",
      "Epoch: 88/100... Step: 9078... Loss: 0.002443... Val Loss: 0.005760\n",
      "Epoch: 88/100... Step: 9079... Loss: 0.001916... Val Loss: 0.005380\n",
      "Epoch: 88/100... Step: 9080... Loss: 0.001883... Val Loss: 0.005027\n",
      "Epoch: 88/100... Step: 9081... Loss: 0.003339... Val Loss: 0.004550\n",
      "Epoch: 88/100... Step: 9082... Loss: 0.002393... Val Loss: 0.004202\n",
      "Epoch: 88/100... Step: 9083... Loss: 0.003391... Val Loss: 0.003895\n",
      "Epoch: 88/100... Step: 9084... Loss: 0.003233... Val Loss: 0.003650\n",
      "Epoch: 88/100... Step: 9085... Loss: 0.003202... Val Loss: 0.003482\n",
      "Epoch: 88/100... Step: 9086... Loss: 0.002139... Val Loss: 0.003275\n",
      "Epoch: 88/100... Step: 9087... Loss: 0.002773... Val Loss: 0.003031\n",
      "Epoch: 88/100... Step: 9088... Loss: 0.001948... Val Loss: 0.002923\n",
      "Epoch: 88/100... Step: 9089... Loss: 0.001581... Val Loss: 0.002749\n",
      "Epoch: 88/100... Step: 9090... Loss: 0.001493... Val Loss: 0.002541\n",
      "Epoch: 88/100... Step: 9091... Loss: 0.003230... Val Loss: 0.002289\n",
      "Epoch: 88/100... Step: 9092... Loss: 0.002008... Val Loss: 0.002207\n",
      "Epoch: 88/100... Step: 9093... Loss: 0.003221... Val Loss: 0.001920\n",
      "Epoch: 88/100... Step: 9094... Loss: 0.003272... Val Loss: 0.001835\n",
      "Epoch: 88/100... Step: 9095... Loss: 0.003493... Val Loss: 0.001799\n",
      "Epoch: 88/100... Step: 9096... Loss: 0.003247... Val Loss: 0.001713\n",
      "Epoch: 88/100... Step: 9097... Loss: 0.002185... Val Loss: 0.001544\n",
      "Epoch: 88/100... Step: 9098... Loss: 0.002798... Val Loss: 0.001554\n",
      "Epoch: 88/100... Step: 9099... Loss: 0.002923... Val Loss: 0.001635\n",
      "Epoch: 88/100... Step: 9100... Loss: 0.001925... Val Loss: 0.001877\n",
      "Epoch: 88/100... Step: 9101... Loss: 0.002394... Val Loss: 0.002255\n",
      "Epoch: 88/100... Step: 9102... Loss: 0.002365... Val Loss: 0.002467\n",
      "Epoch: 88/100... Step: 9103... Loss: 0.003766... Val Loss: 0.002372\n",
      "Epoch: 88/100... Step: 9104... Loss: 0.003695... Val Loss: 0.002447\n",
      "Epoch: 88/100... Step: 9105... Loss: 0.002277... Val Loss: 0.002499\n",
      "Epoch: 88/100... Step: 9106... Loss: 0.002769... Val Loss: 0.002459\n",
      "Epoch: 88/100... Step: 9107... Loss: 0.002689... Val Loss: 0.002506\n",
      "Epoch: 88/100... Step: 9108... Loss: 0.002990... Val Loss: 0.002661\n",
      "Epoch: 88/100... Step: 9109... Loss: 0.002994... Val Loss: 0.002536\n",
      "Epoch: 88/100... Step: 9110... Loss: 0.002592... Val Loss: 0.002206\n",
      "Epoch: 88/100... Step: 9111... Loss: 0.002162... Val Loss: 0.002001\n",
      "Epoch: 88/100... Step: 9112... Loss: 0.001551... Val Loss: 0.002008\n",
      "Epoch: 88/100... Step: 9113... Loss: 0.003696... Val Loss: 0.002232\n",
      "Epoch: 88/100... Step: 9114... Loss: 0.003907... Val Loss: 0.002423\n",
      "Epoch: 88/100... Step: 9115... Loss: 0.001911... Val Loss: 0.002569\n",
      "Epoch: 88/100... Step: 9116... Loss: 0.002679... Val Loss: 0.002644\n",
      "Epoch: 88/100... Step: 9117... Loss: 0.001260... Val Loss: 0.002694\n",
      "Epoch: 88/100... Step: 9118... Loss: 0.002724... Val Loss: 0.002651\n",
      "Epoch: 88/100... Step: 9119... Loss: 0.002171... Val Loss: 0.002702\n",
      "Epoch: 88/100... Step: 9120... Loss: 0.002609... Val Loss: 0.002684\n",
      "Epoch: 88/100... Step: 9121... Loss: 0.003655... Val Loss: 0.002568\n",
      "Epoch: 88/100... Step: 9122... Loss: 0.003288... Val Loss: 0.002484\n",
      "Epoch: 88/100... Step: 9123... Loss: 0.003163... Val Loss: 0.002417\n",
      "Epoch: 88/100... Step: 9124... Loss: 0.003327... Val Loss: 0.002311\n",
      "Epoch: 88/100... Step: 9125... Loss: 0.002698... Val Loss: 0.002193\n",
      "Epoch: 88/100... Step: 9126... Loss: 0.001872... Val Loss: 0.002013\n",
      "Epoch: 88/100... Step: 9127... Loss: 0.002026... Val Loss: 0.001947\n",
      "Epoch: 88/100... Step: 9128... Loss: 0.001938... Val Loss: 0.001883\n",
      "Epoch: 88/100... Step: 9129... Loss: 0.003317... Val Loss: 0.001714\n",
      "Epoch: 88/100... Step: 9130... Loss: 0.001820... Val Loss: 0.001685\n",
      "Epoch: 88/100... Step: 9131... Loss: 0.001834... Val Loss: 0.001682\n",
      "Epoch: 88/100... Step: 9132... Loss: 0.002219... Val Loss: 0.001567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100... Step: 9133... Loss: 0.002866... Val Loss: 0.001529\n",
      "Epoch: 88/100... Step: 9134... Loss: 0.002651... Val Loss: 0.001422\n",
      "Epoch: 88/100... Step: 9135... Loss: 0.001925... Val Loss: 0.001260\n",
      "Epoch: 88/100... Step: 9136... Loss: 0.003780... Val Loss: 0.001289\n",
      "Epoch: 88/100... Step: 9137... Loss: 0.002415... Val Loss: 0.001227\n",
      "Epoch: 88/100... Step: 9138... Loss: 0.003032... Val Loss: 0.001079\n",
      "Epoch: 88/100... Step: 9139... Loss: 0.001818... Val Loss: 0.001056\n",
      "Epoch: 88/100... Step: 9140... Loss: 0.001887... Val Loss: 0.001014\n",
      "Epoch: 88/100... Step: 9141... Loss: 0.001300... Val Loss: 0.001107\n",
      "Epoch: 88/100... Step: 9142... Loss: 0.002651... Val Loss: 0.001217\n",
      "Epoch: 88/100... Step: 9143... Loss: 0.003048... Val Loss: 0.001340\n",
      "Epoch: 88/100... Step: 9144... Loss: 0.001838... Val Loss: 0.001489\n",
      "Epoch: 88/100... Step: 9145... Loss: 0.002428... Val Loss: 0.001558\n",
      "Epoch: 88/100... Step: 9146... Loss: 0.002677... Val Loss: 0.001502\n",
      "Epoch: 88/100... Step: 9147... Loss: 0.002269... Val Loss: 0.001525\n",
      "Epoch: 88/100... Step: 9148... Loss: 0.002690... Val Loss: 0.001486\n",
      "Epoch: 88/100... Step: 9149... Loss: 0.002774... Val Loss: 0.001409\n",
      "Epoch: 88/100... Step: 9150... Loss: 0.002584... Val Loss: 0.001347\n",
      "Epoch: 88/100... Step: 9151... Loss: 0.003393... Val Loss: 0.001274\n",
      "Epoch: 88/100... Step: 9152... Loss: 0.002335... Val Loss: 0.001231\n",
      "Epoch: 89/100... Step: 9153... Loss: 0.002247... Val Loss: 0.003288\n",
      "Epoch: 89/100... Step: 9154... Loss: 0.003035... Val Loss: 0.004438\n",
      "Epoch: 89/100... Step: 9155... Loss: 0.002533... Val Loss: 0.003707\n",
      "Epoch: 89/100... Step: 9156... Loss: 0.002513... Val Loss: 0.002460\n",
      "Epoch: 89/100... Step: 9157... Loss: 0.002418... Val Loss: 0.001207\n",
      "Epoch: 89/100... Step: 9158... Loss: 0.002825... Val Loss: 0.000807\n",
      "Validation loss decreased (0.000949 --> 0.000807).  Saving model ...\n",
      "Epoch: 89/100... Step: 9159... Loss: 0.002859... Val Loss: 0.001416\n",
      "Epoch: 89/100... Step: 9160... Loss: 0.002797... Val Loss: 0.002492\n",
      "Epoch: 89/100... Step: 9161... Loss: 0.002134... Val Loss: 0.003382\n",
      "Epoch: 89/100... Step: 9162... Loss: 0.002883... Val Loss: 0.004110\n",
      "Epoch: 89/100... Step: 9163... Loss: 0.001918... Val Loss: 0.004725\n",
      "Epoch: 89/100... Step: 9164... Loss: 0.003346... Val Loss: 0.005406\n",
      "Epoch: 89/100... Step: 9165... Loss: 0.002051... Val Loss: 0.005995\n",
      "Epoch: 89/100... Step: 9166... Loss: 0.001574... Val Loss: 0.006558\n",
      "Epoch: 89/100... Step: 9167... Loss: 0.001454... Val Loss: 0.007032\n",
      "Epoch: 89/100... Step: 9168... Loss: 0.002253... Val Loss: 0.007330\n",
      "Epoch: 89/100... Step: 9169... Loss: 0.002162... Val Loss: 0.007592\n",
      "Epoch: 89/100... Step: 9170... Loss: 0.003892... Val Loss: 0.007750\n",
      "Epoch: 89/100... Step: 9171... Loss: 0.001914... Val Loss: 0.007943\n",
      "Epoch: 89/100... Step: 9172... Loss: 0.001674... Val Loss: 0.007942\n",
      "Epoch: 89/100... Step: 9173... Loss: 0.002768... Val Loss: 0.008050\n",
      "Epoch: 89/100... Step: 9174... Loss: 0.001956... Val Loss: 0.008065\n",
      "Epoch: 89/100... Step: 9175... Loss: 0.002975... Val Loss: 0.008035\n",
      "Epoch: 89/100... Step: 9176... Loss: 0.003261... Val Loss: 0.007839\n",
      "Epoch: 89/100... Step: 9177... Loss: 0.002862... Val Loss: 0.007664\n",
      "Epoch: 89/100... Step: 9178... Loss: 0.002996... Val Loss: 0.007290\n",
      "Epoch: 89/100... Step: 9179... Loss: 0.001821... Val Loss: 0.006958\n",
      "Epoch: 89/100... Step: 9180... Loss: 0.002528... Val Loss: 0.006627\n",
      "Epoch: 89/100... Step: 9181... Loss: 0.001059... Val Loss: 0.006336\n",
      "Epoch: 89/100... Step: 9182... Loss: 0.001877... Val Loss: 0.006046\n",
      "Epoch: 89/100... Step: 9183... Loss: 0.002572... Val Loss: 0.005855\n",
      "Epoch: 89/100... Step: 9184... Loss: 0.001882... Val Loss: 0.005824\n",
      "Epoch: 89/100... Step: 9185... Loss: 0.002028... Val Loss: 0.005499\n",
      "Epoch: 89/100... Step: 9186... Loss: 0.002475... Val Loss: 0.005157\n",
      "Epoch: 89/100... Step: 9187... Loss: 0.002099... Val Loss: 0.004828\n",
      "Epoch: 89/100... Step: 9188... Loss: 0.002427... Val Loss: 0.004444\n",
      "Epoch: 89/100... Step: 9189... Loss: 0.001757... Val Loss: 0.004017\n",
      "Epoch: 89/100... Step: 9190... Loss: 0.001845... Val Loss: 0.003642\n",
      "Epoch: 89/100... Step: 9191... Loss: 0.002066... Val Loss: 0.003476\n",
      "Epoch: 89/100... Step: 9192... Loss: 0.002409... Val Loss: 0.003159\n",
      "Epoch: 89/100... Step: 9193... Loss: 0.003784... Val Loss: 0.002877\n",
      "Epoch: 89/100... Step: 9194... Loss: 0.003267... Val Loss: 0.002686\n",
      "Epoch: 89/100... Step: 9195... Loss: 0.002621... Val Loss: 0.002475\n",
      "Epoch: 89/100... Step: 9196... Loss: 0.002616... Val Loss: 0.002162\n",
      "Epoch: 89/100... Step: 9197... Loss: 0.002200... Val Loss: 0.002121\n",
      "Epoch: 89/100... Step: 9198... Loss: 0.002430... Val Loss: 0.002053\n",
      "Epoch: 89/100... Step: 9199... Loss: 0.003057... Val Loss: 0.001874\n",
      "Epoch: 89/100... Step: 9200... Loss: 0.002605... Val Loss: 0.001823\n",
      "Epoch: 89/100... Step: 9201... Loss: 0.002226... Val Loss: 0.001713\n",
      "Epoch: 89/100... Step: 9202... Loss: 0.002087... Val Loss: 0.001610\n",
      "Epoch: 89/100... Step: 9203... Loss: 0.001352... Val Loss: 0.001559\n",
      "Epoch: 89/100... Step: 9204... Loss: 0.002763... Val Loss: 0.001483\n",
      "Epoch: 89/100... Step: 9205... Loss: 0.002725... Val Loss: 0.001340\n",
      "Epoch: 89/100... Step: 9206... Loss: 0.002915... Val Loss: 0.001166\n",
      "Epoch: 89/100... Step: 9207... Loss: 0.002545... Val Loss: 0.001017\n",
      "Epoch: 89/100... Step: 9208... Loss: 0.002334... Val Loss: 0.000907\n",
      "Epoch: 89/100... Step: 9209... Loss: 0.003619... Val Loss: 0.000813\n",
      "Epoch: 89/100... Step: 9210... Loss: 0.002048... Val Loss: 0.000804\n",
      "Validation loss decreased (0.000807 --> 0.000804).  Saving model ...\n",
      "Epoch: 89/100... Step: 9211... Loss: 0.001483... Val Loss: 0.000757\n",
      "Validation loss decreased (0.000804 --> 0.000757).  Saving model ...\n",
      "Epoch: 89/100... Step: 9212... Loss: 0.002008... Val Loss: 0.000710\n",
      "Validation loss decreased (0.000757 --> 0.000710).  Saving model ...\n",
      "Epoch: 89/100... Step: 9213... Loss: 0.002180... Val Loss: 0.000649\n",
      "Validation loss decreased (0.000710 --> 0.000649).  Saving model ...\n",
      "Epoch: 89/100... Step: 9214... Loss: 0.002371... Val Loss: 0.000861\n",
      "Epoch: 89/100... Step: 9215... Loss: 0.001411... Val Loss: 0.001320\n",
      "Epoch: 89/100... Step: 9216... Loss: 0.001949... Val Loss: 0.001706\n",
      "Epoch: 89/100... Step: 9217... Loss: 0.001639... Val Loss: 0.002225\n",
      "Epoch: 89/100... Step: 9218... Loss: 0.002702... Val Loss: 0.002727\n",
      "Epoch: 89/100... Step: 9219... Loss: 0.003150... Val Loss: 0.002914\n",
      "Epoch: 89/100... Step: 9220... Loss: 0.003293... Val Loss: 0.003150\n",
      "Epoch: 89/100... Step: 9221... Loss: 0.002800... Val Loss: 0.003335\n",
      "Epoch: 89/100... Step: 9222... Loss: 0.002837... Val Loss: 0.003323\n",
      "Epoch: 89/100... Step: 9223... Loss: 0.002475... Val Loss: 0.003054\n",
      "Epoch: 89/100... Step: 9224... Loss: 0.003315... Val Loss: 0.002648\n",
      "Epoch: 89/100... Step: 9225... Loss: 0.002704... Val Loss: 0.002034\n",
      "Epoch: 89/100... Step: 9226... Loss: 0.001982... Val Loss: 0.001650\n",
      "Epoch: 89/100... Step: 9227... Loss: 0.001803... Val Loss: 0.001369\n",
      "Epoch: 89/100... Step: 9228... Loss: 0.002093... Val Loss: 0.001378\n",
      "Epoch: 89/100... Step: 9229... Loss: 0.002393... Val Loss: 0.001367\n",
      "Epoch: 89/100... Step: 9230... Loss: 0.001873... Val Loss: 0.001400\n",
      "Epoch: 89/100... Step: 9231... Loss: 0.001869... Val Loss: 0.001376\n",
      "Epoch: 89/100... Step: 9232... Loss: 0.001315... Val Loss: 0.001334\n",
      "Epoch: 89/100... Step: 9233... Loss: 0.001452... Val Loss: 0.001282\n",
      "Epoch: 89/100... Step: 9234... Loss: 0.002006... Val Loss: 0.001301\n",
      "Epoch: 89/100... Step: 9235... Loss: 0.002349... Val Loss: 0.001458\n",
      "Epoch: 89/100... Step: 9236... Loss: 0.001915... Val Loss: 0.001868\n",
      "Epoch: 89/100... Step: 9237... Loss: 0.001992... Val Loss: 0.002037\n",
      "Epoch: 89/100... Step: 9238... Loss: 0.002683... Val Loss: 0.002207\n",
      "Epoch: 89/100... Step: 9239... Loss: 0.002555... Val Loss: 0.002084\n",
      "Epoch: 89/100... Step: 9240... Loss: 0.001770... Val Loss: 0.001851\n",
      "Epoch: 89/100... Step: 9241... Loss: 0.001952... Val Loss: 0.001724\n",
      "Epoch: 89/100... Step: 9242... Loss: 0.002167... Val Loss: 0.001361\n",
      "Epoch: 89/100... Step: 9243... Loss: 0.002361... Val Loss: 0.001047\n",
      "Epoch: 89/100... Step: 9244... Loss: 0.001451... Val Loss: 0.000940\n",
      "Epoch: 89/100... Step: 9245... Loss: 0.001907... Val Loss: 0.001171\n",
      "Epoch: 89/100... Step: 9246... Loss: 0.002822... Val Loss: 0.001256\n",
      "Epoch: 89/100... Step: 9247... Loss: 0.001763... Val Loss: 0.001322\n",
      "Epoch: 89/100... Step: 9248... Loss: 0.002601... Val Loss: 0.001344\n",
      "Epoch: 89/100... Step: 9249... Loss: 0.001899... Val Loss: 0.001406\n",
      "Epoch: 89/100... Step: 9250... Loss: 0.001957... Val Loss: 0.001339\n",
      "Epoch: 89/100... Step: 9251... Loss: 0.001568... Val Loss: 0.001360\n",
      "Epoch: 89/100... Step: 9252... Loss: 0.002654... Val Loss: 0.001350\n",
      "Epoch: 89/100... Step: 9253... Loss: 0.002453... Val Loss: 0.001257\n",
      "Epoch: 89/100... Step: 9254... Loss: 0.002781... Val Loss: 0.001102\n",
      "Epoch: 89/100... Step: 9255... Loss: 0.002133... Val Loss: 0.001052\n",
      "Epoch: 89/100... Step: 9256... Loss: 0.002352... Val Loss: 0.001030\n",
      "Epoch: 90/100... Step: 9257... Loss: 0.002619... Val Loss: 0.008723\n",
      "Epoch: 90/100... Step: 9258... Loss: 0.002720... Val Loss: 0.008624\n",
      "Epoch: 90/100... Step: 9259... Loss: 0.001728... Val Loss: 0.007537\n",
      "Epoch: 90/100... Step: 9260... Loss: 0.001331... Val Loss: 0.006360\n",
      "Epoch: 90/100... Step: 9261... Loss: 0.002090... Val Loss: 0.005306\n",
      "Epoch: 90/100... Step: 9262... Loss: 0.001871... Val Loss: 0.004365\n",
      "Epoch: 90/100... Step: 9263... Loss: 0.002466... Val Loss: 0.003368\n",
      "Epoch: 90/100... Step: 9264... Loss: 0.002188... Val Loss: 0.002319\n",
      "Epoch: 90/100... Step: 9265... Loss: 0.001988... Val Loss: 0.001349\n",
      "Epoch: 90/100... Step: 9266... Loss: 0.002627... Val Loss: 0.000812\n",
      "Epoch: 90/100... Step: 9267... Loss: 0.001873... Val Loss: 0.000878\n",
      "Epoch: 90/100... Step: 9268... Loss: 0.001594... Val Loss: 0.001266\n",
      "Epoch: 90/100... Step: 9269... Loss: 0.001719... Val Loss: 0.001976\n",
      "Epoch: 90/100... Step: 9270... Loss: 0.002771... Val Loss: 0.002434\n",
      "Epoch: 90/100... Step: 9271... Loss: 0.001643... Val Loss: 0.002813\n",
      "Epoch: 90/100... Step: 9272... Loss: 0.002493... Val Loss: 0.003089\n",
      "Epoch: 90/100... Step: 9273... Loss: 0.001519... Val Loss: 0.003269\n",
      "Epoch: 90/100... Step: 9274... Loss: 0.002379... Val Loss: 0.003369\n",
      "Epoch: 90/100... Step: 9275... Loss: 0.002345... Val Loss: 0.003502\n",
      "Epoch: 90/100... Step: 9276... Loss: 0.001493... Val Loss: 0.003552\n",
      "Epoch: 90/100... Step: 9277... Loss: 0.001758... Val Loss: 0.003618\n",
      "Epoch: 90/100... Step: 9278... Loss: 0.002393... Val Loss: 0.003619\n",
      "Epoch: 90/100... Step: 9279... Loss: 0.002503... Val Loss: 0.003667\n",
      "Epoch: 90/100... Step: 9280... Loss: 0.002648... Val Loss: 0.003603\n",
      "Epoch: 90/100... Step: 9281... Loss: 0.001022... Val Loss: 0.003529\n",
      "Epoch: 90/100... Step: 9282... Loss: 0.002344... Val Loss: 0.003492\n",
      "Epoch: 90/100... Step: 9283... Loss: 0.002365... Val Loss: 0.003490\n",
      "Epoch: 90/100... Step: 9284... Loss: 0.001330... Val Loss: 0.003583\n",
      "Epoch: 90/100... Step: 9285... Loss: 0.001251... Val Loss: 0.003529\n",
      "Epoch: 90/100... Step: 9286... Loss: 0.001677... Val Loss: 0.003500\n",
      "Epoch: 90/100... Step: 9287... Loss: 0.001804... Val Loss: 0.003358\n",
      "Epoch: 90/100... Step: 9288... Loss: 0.002115... Val Loss: 0.003152\n",
      "Epoch: 90/100... Step: 9289... Loss: 0.001582... Val Loss: 0.002862\n",
      "Epoch: 90/100... Step: 9290... Loss: 0.001871... Val Loss: 0.002662\n",
      "Epoch: 90/100... Step: 9291... Loss: 0.002112... Val Loss: 0.002475\n",
      "Epoch: 90/100... Step: 9292... Loss: 0.001345... Val Loss: 0.002289\n",
      "Epoch: 90/100... Step: 9293... Loss: 0.001747... Val Loss: 0.002243\n",
      "Epoch: 90/100... Step: 9294... Loss: 0.002710... Val Loss: 0.002459\n",
      "Epoch: 90/100... Step: 9295... Loss: 0.002377... Val Loss: 0.002789\n",
      "Epoch: 90/100... Step: 9296... Loss: 0.002089... Val Loss: 0.002990\n",
      "Epoch: 90/100... Step: 9297... Loss: 0.002323... Val Loss: 0.003060\n",
      "Epoch: 90/100... Step: 9298... Loss: 0.003288... Val Loss: 0.002954\n",
      "Epoch: 90/100... Step: 9299... Loss: 0.004075... Val Loss: 0.002774\n",
      "Epoch: 90/100... Step: 9300... Loss: 0.002645... Val Loss: 0.002572\n",
      "Epoch: 90/100... Step: 9301... Loss: 0.002796... Val Loss: 0.002489\n",
      "Epoch: 90/100... Step: 9302... Loss: 0.001969... Val Loss: 0.002409\n",
      "Epoch: 90/100... Step: 9303... Loss: 0.002768... Val Loss: 0.002303\n",
      "Epoch: 90/100... Step: 9304... Loss: 0.002062... Val Loss: 0.002244\n",
      "Epoch: 90/100... Step: 9305... Loss: 0.002276... Val Loss: 0.002293\n",
      "Epoch: 90/100... Step: 9306... Loss: 0.002443... Val Loss: 0.002269\n",
      "Epoch: 90/100... Step: 9307... Loss: 0.001959... Val Loss: 0.002353\n",
      "Epoch: 90/100... Step: 9308... Loss: 0.001881... Val Loss: 0.002561\n",
      "Epoch: 90/100... Step: 9309... Loss: 0.002920... Val Loss: 0.002824\n",
      "Epoch: 90/100... Step: 9310... Loss: 0.002488... Val Loss: 0.002972\n",
      "Epoch: 90/100... Step: 9311... Loss: 0.002519... Val Loss: 0.002997\n",
      "Epoch: 90/100... Step: 9312... Loss: 0.002160... Val Loss: 0.002990\n",
      "Epoch: 90/100... Step: 9313... Loss: 0.001632... Val Loss: 0.002895\n",
      "Epoch: 90/100... Step: 9314... Loss: 0.002319... Val Loss: 0.002662\n",
      "Epoch: 90/100... Step: 9315... Loss: 0.002309... Val Loss: 0.002430\n",
      "Epoch: 90/100... Step: 9316... Loss: 0.001994... Val Loss: 0.002018\n",
      "Epoch: 90/100... Step: 9317... Loss: 0.002471... Val Loss: 0.001661\n",
      "Epoch: 90/100... Step: 9318... Loss: 0.002747... Val Loss: 0.001227\n",
      "Epoch: 90/100... Step: 9319... Loss: 0.003097... Val Loss: 0.000959\n",
      "Epoch: 90/100... Step: 9320... Loss: 0.002640... Val Loss: 0.001015\n",
      "Epoch: 90/100... Step: 9321... Loss: 0.001141... Val Loss: 0.001290\n",
      "Epoch: 90/100... Step: 9322... Loss: 0.002699... Val Loss: 0.001491\n",
      "Epoch: 90/100... Step: 9323... Loss: 0.001712... Val Loss: 0.001719\n",
      "Epoch: 90/100... Step: 9324... Loss: 0.002190... Val Loss: 0.001981\n",
      "Epoch: 90/100... Step: 9325... Loss: 0.001919... Val Loss: 0.002112\n",
      "Epoch: 90/100... Step: 9326... Loss: 0.002323... Val Loss: 0.002141\n",
      "Epoch: 90/100... Step: 9327... Loss: 0.002154... Val Loss: 0.002054\n",
      "Epoch: 90/100... Step: 9328... Loss: 0.002278... Val Loss: 0.001899\n",
      "Epoch: 90/100... Step: 9329... Loss: 0.002478... Val Loss: 0.001740\n",
      "Epoch: 90/100... Step: 9330... Loss: 0.002648... Val Loss: 0.001561\n",
      "Epoch: 90/100... Step: 9331... Loss: 0.002413... Val Loss: 0.001363\n",
      "Epoch: 90/100... Step: 9332... Loss: 0.002847... Val Loss: 0.001174\n",
      "Epoch: 90/100... Step: 9333... Loss: 0.002776... Val Loss: 0.000988\n",
      "Epoch: 90/100... Step: 9334... Loss: 0.002352... Val Loss: 0.000835\n",
      "Epoch: 90/100... Step: 9335... Loss: 0.001847... Val Loss: 0.000764\n",
      "Epoch: 90/100... Step: 9336... Loss: 0.001659... Val Loss: 0.000721\n",
      "Epoch: 90/100... Step: 9337... Loss: 0.001550... Val Loss: 0.000733\n",
      "Epoch: 90/100... Step: 9338... Loss: 0.002073... Val Loss: 0.000719\n",
      "Epoch: 90/100... Step: 9339... Loss: 0.002271... Val Loss: 0.000711\n",
      "Epoch: 90/100... Step: 9340... Loss: 0.001766... Val Loss: 0.000732\n",
      "Epoch: 90/100... Step: 9341... Loss: 0.001744... Val Loss: 0.000695\n",
      "Epoch: 90/100... Step: 9342... Loss: 0.001807... Val Loss: 0.000679\n",
      "Epoch: 90/100... Step: 9343... Loss: 0.001898... Val Loss: 0.000806\n",
      "Epoch: 90/100... Step: 9344... Loss: 0.001740... Val Loss: 0.000937\n",
      "Epoch: 90/100... Step: 9345... Loss: 0.001275... Val Loss: 0.001042\n",
      "Epoch: 90/100... Step: 9346... Loss: 0.002077... Val Loss: 0.001031\n",
      "Epoch: 90/100... Step: 9347... Loss: 0.001736... Val Loss: 0.000950\n",
      "Epoch: 90/100... Step: 9348... Loss: 0.001610... Val Loss: 0.001012\n",
      "Epoch: 90/100... Step: 9349... Loss: 0.001468... Val Loss: 0.000919\n",
      "Epoch: 90/100... Step: 9350... Loss: 0.002671... Val Loss: 0.000766\n",
      "Epoch: 90/100... Step: 9351... Loss: 0.001989... Val Loss: 0.000676\n",
      "Epoch: 90/100... Step: 9352... Loss: 0.002389... Val Loss: 0.000682\n",
      "Epoch: 90/100... Step: 9353... Loss: 0.001236... Val Loss: 0.000718\n",
      "Epoch: 90/100... Step: 9354... Loss: 0.002646... Val Loss: 0.000810\n",
      "Epoch: 90/100... Step: 9355... Loss: 0.001728... Val Loss: 0.001036\n",
      "Epoch: 90/100... Step: 9356... Loss: 0.001041... Val Loss: 0.001359\n",
      "Epoch: 90/100... Step: 9357... Loss: 0.002220... Val Loss: 0.001677\n",
      "Epoch: 90/100... Step: 9358... Loss: 0.001074... Val Loss: 0.001920\n",
      "Epoch: 90/100... Step: 9359... Loss: 0.002386... Val Loss: 0.002030\n",
      "Epoch: 90/100... Step: 9360... Loss: 0.002782... Val Loss: 0.002098\n",
      "Epoch: 91/100... Step: 9361... Loss: 0.002009... Val Loss: 0.002464\n",
      "Epoch: 91/100... Step: 9362... Loss: 0.002448... Val Loss: 0.003169\n",
      "Epoch: 91/100... Step: 9363... Loss: 0.002965... Val Loss: 0.003227\n",
      "Epoch: 91/100... Step: 9364... Loss: 0.002243... Val Loss: 0.003045\n",
      "Epoch: 91/100... Step: 9365... Loss: 0.002288... Val Loss: 0.002747\n",
      "Epoch: 91/100... Step: 9366... Loss: 0.002406... Val Loss: 0.002428\n",
      "Epoch: 91/100... Step: 9367... Loss: 0.002762... Val Loss: 0.002108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100... Step: 9368... Loss: 0.001667... Val Loss: 0.001699\n",
      "Epoch: 91/100... Step: 9369... Loss: 0.002834... Val Loss: 0.001436\n",
      "Epoch: 91/100... Step: 9370... Loss: 0.001903... Val Loss: 0.001294\n",
      "Epoch: 91/100... Step: 9371... Loss: 0.001827... Val Loss: 0.001276\n",
      "Epoch: 91/100... Step: 9372... Loss: 0.002760... Val Loss: 0.001289\n",
      "Epoch: 91/100... Step: 9373... Loss: 0.002195... Val Loss: 0.001277\n",
      "Epoch: 91/100... Step: 9374... Loss: 0.002175... Val Loss: 0.001160\n",
      "Epoch: 91/100... Step: 9375... Loss: 0.002541... Val Loss: 0.001050\n",
      "Epoch: 91/100... Step: 9376... Loss: 0.002176... Val Loss: 0.000849\n",
      "Epoch: 91/100... Step: 9377... Loss: 0.002587... Val Loss: 0.000700\n",
      "Epoch: 91/100... Step: 9378... Loss: 0.001288... Val Loss: 0.000487\n",
      "Validation loss decreased (0.000649 --> 0.000487).  Saving model ...\n",
      "Epoch: 91/100... Step: 9379... Loss: 0.002183... Val Loss: 0.000476\n",
      "Validation loss decreased (0.000487 --> 0.000476).  Saving model ...\n",
      "Epoch: 91/100... Step: 9380... Loss: 0.002022... Val Loss: 0.000608\n",
      "Epoch: 91/100... Step: 9381... Loss: 0.001745... Val Loss: 0.000778\n",
      "Epoch: 91/100... Step: 9382... Loss: 0.001664... Val Loss: 0.000935\n",
      "Epoch: 91/100... Step: 9383... Loss: 0.001670... Val Loss: 0.001085\n",
      "Epoch: 91/100... Step: 9384... Loss: 0.001332... Val Loss: 0.001098\n",
      "Epoch: 91/100... Step: 9385... Loss: 0.003050... Val Loss: 0.001036\n",
      "Epoch: 91/100... Step: 9386... Loss: 0.001535... Val Loss: 0.000855\n",
      "Epoch: 91/100... Step: 9387... Loss: 0.001464... Val Loss: 0.000647\n",
      "Epoch: 91/100... Step: 9388... Loss: 0.001774... Val Loss: 0.000654\n",
      "Epoch: 91/100... Step: 9389... Loss: 0.001574... Val Loss: 0.000846\n",
      "Epoch: 91/100... Step: 9390... Loss: 0.001557... Val Loss: 0.001045\n",
      "Epoch: 91/100... Step: 9391... Loss: 0.001664... Val Loss: 0.001278\n",
      "Epoch: 91/100... Step: 9392... Loss: 0.001249... Val Loss: 0.001416\n",
      "Epoch: 91/100... Step: 9393... Loss: 0.002480... Val Loss: 0.001416\n",
      "Epoch: 91/100... Step: 9394... Loss: 0.001866... Val Loss: 0.001350\n",
      "Epoch: 91/100... Step: 9395... Loss: 0.001329... Val Loss: 0.001160\n",
      "Epoch: 91/100... Step: 9396... Loss: 0.001342... Val Loss: 0.000827\n",
      "Epoch: 91/100... Step: 9397... Loss: 0.001619... Val Loss: 0.000587\n",
      "Epoch: 91/100... Step: 9398... Loss: 0.001270... Val Loss: 0.000696\n",
      "Epoch: 91/100... Step: 9399... Loss: 0.001470... Val Loss: 0.001019\n",
      "Epoch: 91/100... Step: 9400... Loss: 0.001260... Val Loss: 0.001303\n",
      "Epoch: 91/100... Step: 9401... Loss: 0.002125... Val Loss: 0.001568\n",
      "Epoch: 91/100... Step: 9402... Loss: 0.001638... Val Loss: 0.001797\n",
      "Epoch: 91/100... Step: 9403... Loss: 0.002482... Val Loss: 0.001937\n",
      "Epoch: 91/100... Step: 9404... Loss: 0.002778... Val Loss: 0.002024\n",
      "Epoch: 91/100... Step: 9405... Loss: 0.002780... Val Loss: 0.001983\n",
      "Epoch: 91/100... Step: 9406... Loss: 0.002161... Val Loss: 0.002004\n",
      "Epoch: 91/100... Step: 9407... Loss: 0.001942... Val Loss: 0.001991\n",
      "Epoch: 91/100... Step: 9408... Loss: 0.002457... Val Loss: 0.001836\n",
      "Epoch: 91/100... Step: 9409... Loss: 0.002342... Val Loss: 0.001670\n",
      "Epoch: 91/100... Step: 9410... Loss: 0.002544... Val Loss: 0.001486\n",
      "Epoch: 91/100... Step: 9411... Loss: 0.001679... Val Loss: 0.001392\n",
      "Epoch: 91/100... Step: 9412... Loss: 0.002102... Val Loss: 0.001258\n",
      "Epoch: 91/100... Step: 9413... Loss: 0.001563... Val Loss: 0.001218\n",
      "Epoch: 91/100... Step: 9414... Loss: 0.002118... Val Loss: 0.001213\n",
      "Epoch: 91/100... Step: 9415... Loss: 0.001936... Val Loss: 0.001139\n",
      "Epoch: 91/100... Step: 9416... Loss: 0.001901... Val Loss: 0.001198\n",
      "Epoch: 91/100... Step: 9417... Loss: 0.001915... Val Loss: 0.001135\n",
      "Epoch: 91/100... Step: 9418... Loss: 0.002972... Val Loss: 0.001131\n",
      "Epoch: 91/100... Step: 9419... Loss: 0.001701... Val Loss: 0.001072\n",
      "Epoch: 91/100... Step: 9420... Loss: 0.001862... Val Loss: 0.001093\n",
      "Epoch: 91/100... Step: 9421... Loss: 0.001636... Val Loss: 0.001115\n",
      "Epoch: 91/100... Step: 9422... Loss: 0.001276... Val Loss: 0.001188\n",
      "Epoch: 91/100... Step: 9423... Loss: 0.002685... Val Loss: 0.001208\n",
      "Epoch: 91/100... Step: 9424... Loss: 0.001150... Val Loss: 0.001285\n",
      "Epoch: 91/100... Step: 9425... Loss: 0.001451... Val Loss: 0.001247\n",
      "Epoch: 91/100... Step: 9426... Loss: 0.003311... Val Loss: 0.001142\n",
      "Epoch: 91/100... Step: 9427... Loss: 0.002362... Val Loss: 0.001015\n",
      "Epoch: 91/100... Step: 9428... Loss: 0.001502... Val Loss: 0.000937\n",
      "Epoch: 91/100... Step: 9429... Loss: 0.002358... Val Loss: 0.000938\n",
      "Epoch: 91/100... Step: 9430... Loss: 0.001836... Val Loss: 0.000993\n",
      "Epoch: 91/100... Step: 9431... Loss: 0.001302... Val Loss: 0.001030\n",
      "Epoch: 91/100... Step: 9432... Loss: 0.001681... Val Loss: 0.001069\n",
      "Epoch: 91/100... Step: 9433... Loss: 0.001409... Val Loss: 0.001126\n",
      "Epoch: 91/100... Step: 9434... Loss: 0.001827... Val Loss: 0.001149\n",
      "Epoch: 91/100... Step: 9435... Loss: 0.001937... Val Loss: 0.001147\n",
      "Epoch: 91/100... Step: 9436... Loss: 0.001882... Val Loss: 0.001086\n",
      "Epoch: 91/100... Step: 9437... Loss: 0.001649... Val Loss: 0.001043\n",
      "Epoch: 91/100... Step: 9438... Loss: 0.001066... Val Loss: 0.000986\n",
      "Epoch: 91/100... Step: 9439... Loss: 0.001984... Val Loss: 0.000931\n",
      "Epoch: 91/100... Step: 9440... Loss: 0.001244... Val Loss: 0.000930\n",
      "Epoch: 91/100... Step: 9441... Loss: 0.001581... Val Loss: 0.000937\n",
      "Epoch: 91/100... Step: 9442... Loss: 0.001847... Val Loss: 0.000930\n",
      "Epoch: 91/100... Step: 9443... Loss: 0.002069... Val Loss: 0.000950\n",
      "Epoch: 91/100... Step: 9444... Loss: 0.001535... Val Loss: 0.000964\n",
      "Epoch: 91/100... Step: 9445... Loss: 0.001184... Val Loss: 0.000939\n",
      "Epoch: 91/100... Step: 9446... Loss: 0.001221... Val Loss: 0.000955\n",
      "Epoch: 91/100... Step: 9447... Loss: 0.001582... Val Loss: 0.000992\n",
      "Epoch: 91/100... Step: 9448... Loss: 0.001504... Val Loss: 0.001023\n",
      "Epoch: 91/100... Step: 9449... Loss: 0.001611... Val Loss: 0.001036\n",
      "Epoch: 91/100... Step: 9450... Loss: 0.001791... Val Loss: 0.001036\n",
      "Epoch: 91/100... Step: 9451... Loss: 0.001837... Val Loss: 0.001083\n",
      "Epoch: 91/100... Step: 9452... Loss: 0.001812... Val Loss: 0.001075\n",
      "Epoch: 91/100... Step: 9453... Loss: 0.002048... Val Loss: 0.001044\n",
      "Epoch: 91/100... Step: 9454... Loss: 0.001766... Val Loss: 0.001016\n",
      "Epoch: 91/100... Step: 9455... Loss: 0.002065... Val Loss: 0.000973\n",
      "Epoch: 91/100... Step: 9456... Loss: 0.001119... Val Loss: 0.000949\n",
      "Epoch: 91/100... Step: 9457... Loss: 0.001145... Val Loss: 0.000972\n",
      "Epoch: 91/100... Step: 9458... Loss: 0.001488... Val Loss: 0.001047\n",
      "Epoch: 91/100... Step: 9459... Loss: 0.001876... Val Loss: 0.001091\n",
      "Epoch: 91/100... Step: 9460... Loss: 0.001619... Val Loss: 0.001086\n",
      "Epoch: 91/100... Step: 9461... Loss: 0.001390... Val Loss: 0.001140\n",
      "Epoch: 91/100... Step: 9462... Loss: 0.001045... Val Loss: 0.001144\n",
      "Epoch: 91/100... Step: 9463... Loss: 0.001627... Val Loss: 0.001083\n",
      "Epoch: 91/100... Step: 9464... Loss: 0.001576... Val Loss: 0.001024\n",
      "Epoch: 92/100... Step: 9465... Loss: 0.002558... Val Loss: 0.004895\n",
      "Epoch: 92/100... Step: 9466... Loss: 0.002347... Val Loss: 0.003690\n",
      "Epoch: 92/100... Step: 9467... Loss: 0.001538... Val Loss: 0.002616\n",
      "Epoch: 92/100... Step: 9468... Loss: 0.001712... Val Loss: 0.001718\n",
      "Epoch: 92/100... Step: 9469... Loss: 0.002190... Val Loss: 0.001087\n",
      "Epoch: 92/100... Step: 9470... Loss: 0.001734... Val Loss: 0.000744\n",
      "Epoch: 92/100... Step: 9471... Loss: 0.001571... Val Loss: 0.000664\n",
      "Epoch: 92/100... Step: 9472... Loss: 0.001412... Val Loss: 0.000796\n",
      "Epoch: 92/100... Step: 9473... Loss: 0.001677... Val Loss: 0.001123\n",
      "Epoch: 92/100... Step: 9474... Loss: 0.001458... Val Loss: 0.001586\n",
      "Epoch: 92/100... Step: 9475... Loss: 0.001938... Val Loss: 0.001992\n",
      "Epoch: 92/100... Step: 9476... Loss: 0.002357... Val Loss: 0.002351\n",
      "Epoch: 92/100... Step: 9477... Loss: 0.001423... Val Loss: 0.002592\n",
      "Epoch: 92/100... Step: 9478... Loss: 0.001672... Val Loss: 0.002784\n",
      "Epoch: 92/100... Step: 9479... Loss: 0.001750... Val Loss: 0.002896\n",
      "Epoch: 92/100... Step: 9480... Loss: 0.001902... Val Loss: 0.002898\n",
      "Epoch: 92/100... Step: 9481... Loss: 0.001795... Val Loss: 0.002863\n",
      "Epoch: 92/100... Step: 9482... Loss: 0.001994... Val Loss: 0.002886\n",
      "Epoch: 92/100... Step: 9483... Loss: 0.001271... Val Loss: 0.002884\n",
      "Epoch: 92/100... Step: 9484... Loss: 0.001522... Val Loss: 0.002812\n",
      "Epoch: 92/100... Step: 9485... Loss: 0.001905... Val Loss: 0.002727\n",
      "Epoch: 92/100... Step: 9486... Loss: 0.001606... Val Loss: 0.002699\n",
      "Epoch: 92/100... Step: 9487... Loss: 0.001600... Val Loss: 0.002509\n",
      "Epoch: 92/100... Step: 9488... Loss: 0.001450... Val Loss: 0.002444\n",
      "Epoch: 92/100... Step: 9489... Loss: 0.001547... Val Loss: 0.002412\n",
      "Epoch: 92/100... Step: 9490... Loss: 0.001333... Val Loss: 0.002269\n",
      "Epoch: 92/100... Step: 9491... Loss: 0.001076... Val Loss: 0.002165\n",
      "Epoch: 92/100... Step: 9492... Loss: 0.001142... Val Loss: 0.002130\n",
      "Epoch: 92/100... Step: 9493... Loss: 0.001686... Val Loss: 0.002033\n",
      "Epoch: 92/100... Step: 9494... Loss: 0.001570... Val Loss: 0.001869\n",
      "Epoch: 92/100... Step: 9495... Loss: 0.001057... Val Loss: 0.001860\n",
      "Epoch: 92/100... Step: 9496... Loss: 0.001959... Val Loss: 0.001787\n",
      "Epoch: 92/100... Step: 9497... Loss: 0.001482... Val Loss: 0.001679\n",
      "Epoch: 92/100... Step: 9498... Loss: 0.000933... Val Loss: 0.001596\n",
      "Epoch: 92/100... Step: 9499... Loss: 0.001074... Val Loss: 0.001528\n",
      "Epoch: 92/100... Step: 9500... Loss: 0.001951... Val Loss: 0.001423\n",
      "Epoch: 92/100... Step: 9501... Loss: 0.001294... Val Loss: 0.001333\n",
      "Epoch: 92/100... Step: 9502... Loss: 0.001411... Val Loss: 0.001217\n",
      "Epoch: 92/100... Step: 9503... Loss: 0.001763... Val Loss: 0.001120\n",
      "Epoch: 92/100... Step: 9504... Loss: 0.001870... Val Loss: 0.001112\n",
      "Epoch: 92/100... Step: 9505... Loss: 0.001738... Val Loss: 0.001064\n",
      "Epoch: 92/100... Step: 9506... Loss: 0.001942... Val Loss: 0.001044\n",
      "Epoch: 92/100... Step: 9507... Loss: 0.001949... Val Loss: 0.001018\n",
      "Epoch: 92/100... Step: 9508... Loss: 0.001882... Val Loss: 0.000961\n",
      "Epoch: 92/100... Step: 9509... Loss: 0.002454... Val Loss: 0.000913\n",
      "Epoch: 92/100... Step: 9510... Loss: 0.001846... Val Loss: 0.000847\n",
      "Epoch: 92/100... Step: 9511... Loss: 0.002044... Val Loss: 0.000798\n",
      "Epoch: 92/100... Step: 9512... Loss: 0.001759... Val Loss: 0.000762\n",
      "Epoch: 92/100... Step: 9513... Loss: 0.001898... Val Loss: 0.000744\n",
      "Epoch: 92/100... Step: 9514... Loss: 0.001604... Val Loss: 0.000683\n",
      "Epoch: 92/100... Step: 9515... Loss: 0.001097... Val Loss: 0.000651\n",
      "Epoch: 92/100... Step: 9516... Loss: 0.001448... Val Loss: 0.000600\n",
      "Epoch: 92/100... Step: 9517... Loss: 0.002082... Val Loss: 0.000594\n",
      "Epoch: 92/100... Step: 9518... Loss: 0.001541... Val Loss: 0.000590\n",
      "Epoch: 92/100... Step: 9519... Loss: 0.001307... Val Loss: 0.000583\n",
      "Epoch: 92/100... Step: 9520... Loss: 0.002340... Val Loss: 0.000589\n",
      "Epoch: 92/100... Step: 9521... Loss: 0.001623... Val Loss: 0.000581\n",
      "Epoch: 92/100... Step: 9522... Loss: 0.001160... Val Loss: 0.000579\n",
      "Epoch: 92/100... Step: 9523... Loss: 0.001672... Val Loss: 0.000597\n",
      "Epoch: 92/100... Step: 9524... Loss: 0.002157... Val Loss: 0.000596\n",
      "Epoch: 92/100... Step: 9525... Loss: 0.001956... Val Loss: 0.000581\n",
      "Epoch: 92/100... Step: 9526... Loss: 0.002402... Val Loss: 0.000582\n",
      "Epoch: 92/100... Step: 9527... Loss: 0.001310... Val Loss: 0.000595\n",
      "Epoch: 92/100... Step: 9528... Loss: 0.002041... Val Loss: 0.000639\n",
      "Epoch: 92/100... Step: 9529... Loss: 0.001168... Val Loss: 0.000716\n",
      "Epoch: 92/100... Step: 9530... Loss: 0.001880... Val Loss: 0.000859\n",
      "Epoch: 92/100... Step: 9531... Loss: 0.001573... Val Loss: 0.000924\n",
      "Epoch: 92/100... Step: 9532... Loss: 0.001343... Val Loss: 0.000930\n",
      "Epoch: 92/100... Step: 9533... Loss: 0.001946... Val Loss: 0.000859\n",
      "Epoch: 92/100... Step: 9534... Loss: 0.001247... Val Loss: 0.000798\n",
      "Epoch: 92/100... Step: 9535... Loss: 0.001296... Val Loss: 0.000680\n",
      "Epoch: 92/100... Step: 9536... Loss: 0.001766... Val Loss: 0.000572\n",
      "Epoch: 92/100... Step: 9537... Loss: 0.001340... Val Loss: 0.000517\n",
      "Epoch: 92/100... Step: 9538... Loss: 0.002179... Val Loss: 0.000511\n",
      "Epoch: 92/100... Step: 9539... Loss: 0.001443... Val Loss: 0.000606\n",
      "Epoch: 92/100... Step: 9540... Loss: 0.001415... Val Loss: 0.000781\n",
      "Epoch: 92/100... Step: 9541... Loss: 0.001438... Val Loss: 0.000933\n",
      "Epoch: 92/100... Step: 9542... Loss: 0.001406... Val Loss: 0.001063\n",
      "Epoch: 92/100... Step: 9543... Loss: 0.001710... Val Loss: 0.001127\n",
      "Epoch: 92/100... Step: 9544... Loss: 0.001604... Val Loss: 0.001181\n",
      "Epoch: 92/100... Step: 9545... Loss: 0.001520... Val Loss: 0.001128\n",
      "Epoch: 92/100... Step: 9546... Loss: 0.001365... Val Loss: 0.001061\n",
      "Epoch: 92/100... Step: 9547... Loss: 0.001051... Val Loss: 0.001000\n",
      "Epoch: 92/100... Step: 9548... Loss: 0.002079... Val Loss: 0.000886\n",
      "Epoch: 92/100... Step: 9549... Loss: 0.001383... Val Loss: 0.000769\n",
      "Epoch: 92/100... Step: 9550... Loss: 0.001607... Val Loss: 0.000655\n",
      "Epoch: 92/100... Step: 9551... Loss: 0.001898... Val Loss: 0.000575\n",
      "Epoch: 92/100... Step: 9552... Loss: 0.001699... Val Loss: 0.000485\n",
      "Epoch: 92/100... Step: 9553... Loss: 0.001407... Val Loss: 0.000445\n",
      "Validation loss decreased (0.000476 --> 0.000445).  Saving model ...\n",
      "Epoch: 92/100... Step: 9554... Loss: 0.001334... Val Loss: 0.000443\n",
      "Validation loss decreased (0.000445 --> 0.000443).  Saving model ...\n",
      "Epoch: 92/100... Step: 9555... Loss: 0.001176... Val Loss: 0.000444\n",
      "Epoch: 92/100... Step: 9556... Loss: 0.001203... Val Loss: 0.000492\n",
      "Epoch: 92/100... Step: 9557... Loss: 0.001295... Val Loss: 0.000528\n",
      "Epoch: 92/100... Step: 9558... Loss: 0.001413... Val Loss: 0.000583\n",
      "Epoch: 92/100... Step: 9559... Loss: 0.001141... Val Loss: 0.000636\n",
      "Epoch: 92/100... Step: 9560... Loss: 0.001448... Val Loss: 0.000652\n",
      "Epoch: 92/100... Step: 9561... Loss: 0.001259... Val Loss: 0.000676\n",
      "Epoch: 92/100... Step: 9562... Loss: 0.001261... Val Loss: 0.000638\n",
      "Epoch: 92/100... Step: 9563... Loss: 0.001924... Val Loss: 0.000583\n",
      "Epoch: 92/100... Step: 9564... Loss: 0.001321... Val Loss: 0.000580\n",
      "Epoch: 92/100... Step: 9565... Loss: 0.001460... Val Loss: 0.000610\n",
      "Epoch: 92/100... Step: 9566... Loss: 0.001481... Val Loss: 0.000695\n",
      "Epoch: 92/100... Step: 9567... Loss: 0.001889... Val Loss: 0.000789\n",
      "Epoch: 92/100... Step: 9568... Loss: 0.001849... Val Loss: 0.000790\n",
      "Epoch: 93/100... Step: 9569... Loss: 0.001762... Val Loss: 0.001781\n",
      "Epoch: 93/100... Step: 9570... Loss: 0.001399... Val Loss: 0.001851\n",
      "Epoch: 93/100... Step: 9571... Loss: 0.002079... Val Loss: 0.001416\n",
      "Epoch: 93/100... Step: 9572... Loss: 0.002341... Val Loss: 0.000926\n",
      "Epoch: 93/100... Step: 9573... Loss: 0.002763... Val Loss: 0.000813\n",
      "Epoch: 93/100... Step: 9574... Loss: 0.001732... Val Loss: 0.000915\n",
      "Epoch: 93/100... Step: 9575... Loss: 0.001401... Val Loss: 0.001057\n",
      "Epoch: 93/100... Step: 9576... Loss: 0.001813... Val Loss: 0.001236\n",
      "Epoch: 93/100... Step: 9577... Loss: 0.001338... Val Loss: 0.001353\n",
      "Epoch: 93/100... Step: 9578... Loss: 0.001407... Val Loss: 0.001455\n",
      "Epoch: 93/100... Step: 9579... Loss: 0.002022... Val Loss: 0.001584\n",
      "Epoch: 93/100... Step: 9580... Loss: 0.001140... Val Loss: 0.001727\n",
      "Epoch: 93/100... Step: 9581... Loss: 0.000814... Val Loss: 0.001864\n",
      "Epoch: 93/100... Step: 9582... Loss: 0.002428... Val Loss: 0.002018\n",
      "Epoch: 93/100... Step: 9583... Loss: 0.001967... Val Loss: 0.002186\n",
      "Epoch: 93/100... Step: 9584... Loss: 0.002003... Val Loss: 0.002381\n",
      "Epoch: 93/100... Step: 9585... Loss: 0.001071... Val Loss: 0.002485\n",
      "Epoch: 93/100... Step: 9586... Loss: 0.001153... Val Loss: 0.002593\n",
      "Epoch: 93/100... Step: 9587... Loss: 0.001040... Val Loss: 0.002741\n",
      "Epoch: 93/100... Step: 9588... Loss: 0.001241... Val Loss: 0.002846\n",
      "Epoch: 93/100... Step: 9589... Loss: 0.001677... Val Loss: 0.002889\n",
      "Epoch: 93/100... Step: 9590... Loss: 0.001442... Val Loss: 0.002964\n",
      "Epoch: 93/100... Step: 9591... Loss: 0.001287... Val Loss: 0.003025\n",
      "Epoch: 93/100... Step: 9592... Loss: 0.001901... Val Loss: 0.003156\n",
      "Epoch: 93/100... Step: 9593... Loss: 0.001090... Val Loss: 0.003212\n",
      "Epoch: 93/100... Step: 9594... Loss: 0.001131... Val Loss: 0.003194\n",
      "Epoch: 93/100... Step: 9595... Loss: 0.002353... Val Loss: 0.003217\n",
      "Epoch: 93/100... Step: 9596... Loss: 0.001110... Val Loss: 0.003137\n",
      "Epoch: 93/100... Step: 9597... Loss: 0.002044... Val Loss: 0.003104\n",
      "Epoch: 93/100... Step: 9598... Loss: 0.001092... Val Loss: 0.003041\n",
      "Epoch: 93/100... Step: 9599... Loss: 0.002020... Val Loss: 0.003019\n",
      "Epoch: 93/100... Step: 9600... Loss: 0.001119... Val Loss: 0.002917\n",
      "Epoch: 93/100... Step: 9601... Loss: 0.001100... Val Loss: 0.002847\n",
      "Epoch: 93/100... Step: 9602... Loss: 0.001073... Val Loss: 0.002840\n",
      "Epoch: 93/100... Step: 9603... Loss: 0.001208... Val Loss: 0.002852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100... Step: 9604... Loss: 0.001172... Val Loss: 0.002771\n",
      "Epoch: 93/100... Step: 9605... Loss: 0.001745... Val Loss: 0.002726\n",
      "Epoch: 93/100... Step: 9606... Loss: 0.000954... Val Loss: 0.002661\n",
      "Epoch: 93/100... Step: 9607... Loss: 0.001275... Val Loss: 0.002663\n",
      "Epoch: 93/100... Step: 9608... Loss: 0.001238... Val Loss: 0.002591\n",
      "Epoch: 93/100... Step: 9609... Loss: 0.001145... Val Loss: 0.002488\n",
      "Epoch: 93/100... Step: 9610... Loss: 0.001014... Val Loss: 0.002493\n",
      "Epoch: 93/100... Step: 9611... Loss: 0.002168... Val Loss: 0.002572\n",
      "Epoch: 93/100... Step: 9612... Loss: 0.001932... Val Loss: 0.002597\n",
      "Epoch: 93/100... Step: 9613... Loss: 0.002041... Val Loss: 0.002630\n",
      "Epoch: 93/100... Step: 9614... Loss: 0.002135... Val Loss: 0.002648\n",
      "Epoch: 93/100... Step: 9615... Loss: 0.002340... Val Loss: 0.002612\n",
      "Epoch: 93/100... Step: 9616... Loss: 0.002061... Val Loss: 0.002495\n",
      "Epoch: 93/100... Step: 9617... Loss: 0.001946... Val Loss: 0.002381\n",
      "Epoch: 93/100... Step: 9618... Loss: 0.001227... Val Loss: 0.002212\n",
      "Epoch: 93/100... Step: 9619... Loss: 0.001471... Val Loss: 0.002046\n",
      "Epoch: 93/100... Step: 9620... Loss: 0.000973... Val Loss: 0.001850\n",
      "Epoch: 93/100... Step: 9621... Loss: 0.001752... Val Loss: 0.001707\n",
      "Epoch: 93/100... Step: 9622... Loss: 0.001175... Val Loss: 0.001666\n",
      "Epoch: 93/100... Step: 9623... Loss: 0.001533... Val Loss: 0.001534\n",
      "Epoch: 93/100... Step: 9624... Loss: 0.002208... Val Loss: 0.001482\n",
      "Epoch: 93/100... Step: 9625... Loss: 0.002022... Val Loss: 0.001416\n",
      "Epoch: 93/100... Step: 9626... Loss: 0.001490... Val Loss: 0.001403\n",
      "Epoch: 93/100... Step: 9627... Loss: 0.001474... Val Loss: 0.001374\n",
      "Epoch: 93/100... Step: 9628... Loss: 0.001360... Val Loss: 0.001402\n",
      "Epoch: 93/100... Step: 9629... Loss: 0.001851... Val Loss: 0.001449\n",
      "Epoch: 93/100... Step: 9630... Loss: 0.001355... Val Loss: 0.001446\n",
      "Epoch: 93/100... Step: 9631... Loss: 0.001904... Val Loss: 0.001450\n",
      "Epoch: 93/100... Step: 9632... Loss: 0.002200... Val Loss: 0.001451\n",
      "Epoch: 93/100... Step: 9633... Loss: 0.001971... Val Loss: 0.001439\n",
      "Epoch: 93/100... Step: 9634... Loss: 0.001126... Val Loss: 0.001407\n",
      "Epoch: 93/100... Step: 9635... Loss: 0.001736... Val Loss: 0.001385\n",
      "Epoch: 93/100... Step: 9636... Loss: 0.001607... Val Loss: 0.001348\n",
      "Epoch: 93/100... Step: 9637... Loss: 0.002106... Val Loss: 0.001258\n",
      "Epoch: 93/100... Step: 9638... Loss: 0.001834... Val Loss: 0.001145\n",
      "Epoch: 93/100... Step: 9639... Loss: 0.001267... Val Loss: 0.001017\n",
      "Epoch: 93/100... Step: 9640... Loss: 0.001092... Val Loss: 0.000918\n",
      "Epoch: 93/100... Step: 9641... Loss: 0.001317... Val Loss: 0.000792\n",
      "Epoch: 93/100... Step: 9642... Loss: 0.001807... Val Loss: 0.000671\n",
      "Epoch: 93/100... Step: 9643... Loss: 0.000972... Val Loss: 0.000589\n",
      "Epoch: 93/100... Step: 9644... Loss: 0.001004... Val Loss: 0.000672\n",
      "Epoch: 93/100... Step: 9645... Loss: 0.001325... Val Loss: 0.000814\n",
      "Epoch: 93/100... Step: 9646... Loss: 0.001183... Val Loss: 0.000982\n",
      "Epoch: 93/100... Step: 9647... Loss: 0.001519... Val Loss: 0.001143\n",
      "Epoch: 93/100... Step: 9648... Loss: 0.000956... Val Loss: 0.001248\n",
      "Epoch: 93/100... Step: 9649... Loss: 0.001224... Val Loss: 0.001263\n",
      "Epoch: 93/100... Step: 9650... Loss: 0.001157... Val Loss: 0.001280\n",
      "Epoch: 93/100... Step: 9651... Loss: 0.001418... Val Loss: 0.001197\n",
      "Epoch: 93/100... Step: 9652... Loss: 0.001575... Val Loss: 0.001199\n",
      "Epoch: 93/100... Step: 9653... Loss: 0.001131... Val Loss: 0.001116\n",
      "Epoch: 93/100... Step: 9654... Loss: 0.001277... Val Loss: 0.000985\n",
      "Epoch: 93/100... Step: 9655... Loss: 0.001332... Val Loss: 0.000921\n",
      "Epoch: 93/100... Step: 9656... Loss: 0.001280... Val Loss: 0.000785\n",
      "Epoch: 93/100... Step: 9657... Loss: 0.001321... Val Loss: 0.000644\n",
      "Epoch: 93/100... Step: 9658... Loss: 0.001029... Val Loss: 0.000516\n",
      "Epoch: 93/100... Step: 9659... Loss: 0.001301... Val Loss: 0.000421\n",
      "Validation loss decreased (0.000443 --> 0.000421).  Saving model ...\n",
      "Epoch: 93/100... Step: 9660... Loss: 0.001204... Val Loss: 0.000415\n",
      "Validation loss decreased (0.000421 --> 0.000415).  Saving model ...\n",
      "Epoch: 93/100... Step: 9661... Loss: 0.001053... Val Loss: 0.000483\n",
      "Epoch: 93/100... Step: 9662... Loss: 0.001180... Val Loss: 0.000608\n",
      "Epoch: 93/100... Step: 9663... Loss: 0.001259... Val Loss: 0.000692\n",
      "Epoch: 93/100... Step: 9664... Loss: 0.000900... Val Loss: 0.000758\n",
      "Epoch: 93/100... Step: 9665... Loss: 0.001807... Val Loss: 0.000773\n",
      "Epoch: 93/100... Step: 9666... Loss: 0.001648... Val Loss: 0.000742\n",
      "Epoch: 93/100... Step: 9667... Loss: 0.001279... Val Loss: 0.000723\n",
      "Epoch: 93/100... Step: 9668... Loss: 0.001792... Val Loss: 0.000676\n",
      "Epoch: 93/100... Step: 9669... Loss: 0.001055... Val Loss: 0.000659\n",
      "Epoch: 93/100... Step: 9670... Loss: 0.000689... Val Loss: 0.000639\n",
      "Epoch: 93/100... Step: 9671... Loss: 0.001169... Val Loss: 0.000605\n",
      "Epoch: 93/100... Step: 9672... Loss: 0.001255... Val Loss: 0.000595\n",
      "Epoch: 94/100... Step: 9673... Loss: 0.001540... Val Loss: 0.001288\n",
      "Epoch: 94/100... Step: 9674... Loss: 0.001980... Val Loss: 0.001697\n",
      "Epoch: 94/100... Step: 9675... Loss: 0.001956... Val Loss: 0.001793\n",
      "Epoch: 94/100... Step: 9676... Loss: 0.001673... Val Loss: 0.002001\n",
      "Epoch: 94/100... Step: 9677... Loss: 0.000980... Val Loss: 0.002176\n",
      "Epoch: 94/100... Step: 9678... Loss: 0.002093... Val Loss: 0.002249\n",
      "Epoch: 94/100... Step: 9679... Loss: 0.000910... Val Loss: 0.002324\n",
      "Epoch: 94/100... Step: 9680... Loss: 0.001209... Val Loss: 0.002366\n",
      "Epoch: 94/100... Step: 9681... Loss: 0.001133... Val Loss: 0.002393\n",
      "Epoch: 94/100... Step: 9682... Loss: 0.000809... Val Loss: 0.002341\n",
      "Epoch: 94/100... Step: 9683... Loss: 0.001318... Val Loss: 0.002321\n",
      "Epoch: 94/100... Step: 9684... Loss: 0.001268... Val Loss: 0.002324\n",
      "Epoch: 94/100... Step: 9685... Loss: 0.001560... Val Loss: 0.002289\n",
      "Epoch: 94/100... Step: 9686... Loss: 0.001548... Val Loss: 0.002309\n",
      "Epoch: 94/100... Step: 9687... Loss: 0.001275... Val Loss: 0.002286\n",
      "Epoch: 94/100... Step: 9688... Loss: 0.001586... Val Loss: 0.002344\n",
      "Epoch: 94/100... Step: 9689... Loss: 0.001629... Val Loss: 0.002255\n",
      "Epoch: 94/100... Step: 9690... Loss: 0.001615... Val Loss: 0.002266\n",
      "Epoch: 94/100... Step: 9691... Loss: 0.001189... Val Loss: 0.002236\n",
      "Epoch: 94/100... Step: 9692... Loss: 0.001133... Val Loss: 0.002191\n",
      "Epoch: 94/100... Step: 9693... Loss: 0.001439... Val Loss: 0.002146\n",
      "Epoch: 94/100... Step: 9694... Loss: 0.001223... Val Loss: 0.002151\n",
      "Epoch: 94/100... Step: 9695... Loss: 0.001295... Val Loss: 0.002165\n",
      "Epoch: 94/100... Step: 9696... Loss: 0.001158... Val Loss: 0.002172\n",
      "Epoch: 94/100... Step: 9697... Loss: 0.001044... Val Loss: 0.002126\n",
      "Epoch: 94/100... Step: 9698... Loss: 0.000943... Val Loss: 0.002089\n",
      "Epoch: 94/100... Step: 9699... Loss: 0.001444... Val Loss: 0.001991\n",
      "Epoch: 94/100... Step: 9700... Loss: 0.001679... Val Loss: 0.001926\n",
      "Epoch: 94/100... Step: 9701... Loss: 0.001632... Val Loss: 0.001809\n",
      "Epoch: 94/100... Step: 9702... Loss: 0.000509... Val Loss: 0.001679\n",
      "Epoch: 94/100... Step: 9703... Loss: 0.001184... Val Loss: 0.001512\n",
      "Epoch: 94/100... Step: 9704... Loss: 0.001123... Val Loss: 0.001435\n",
      "Epoch: 94/100... Step: 9705... Loss: 0.001050... Val Loss: 0.001332\n",
      "Epoch: 94/100... Step: 9706... Loss: 0.001133... Val Loss: 0.001245\n",
      "Epoch: 94/100... Step: 9707... Loss: 0.000939... Val Loss: 0.001176\n",
      "Epoch: 94/100... Step: 9708... Loss: 0.000830... Val Loss: 0.001138\n",
      "Epoch: 94/100... Step: 9709... Loss: 0.001197... Val Loss: 0.001130\n",
      "Epoch: 94/100... Step: 9710... Loss: 0.001458... Val Loss: 0.001123\n",
      "Epoch: 94/100... Step: 9711... Loss: 0.000945... Val Loss: 0.001169\n",
      "Epoch: 94/100... Step: 9712... Loss: 0.001359... Val Loss: 0.001208\n",
      "Epoch: 94/100... Step: 9713... Loss: 0.000980... Val Loss: 0.001183\n",
      "Epoch: 94/100... Step: 9714... Loss: 0.001046... Val Loss: 0.001167\n",
      "Epoch: 94/100... Step: 9715... Loss: 0.001904... Val Loss: 0.001189\n",
      "Epoch: 94/100... Step: 9716... Loss: 0.001993... Val Loss: 0.001218\n",
      "Epoch: 94/100... Step: 9717... Loss: 0.001564... Val Loss: 0.001230\n",
      "Epoch: 94/100... Step: 9718... Loss: 0.001984... Val Loss: 0.001254\n",
      "Epoch: 94/100... Step: 9719... Loss: 0.001789... Val Loss: 0.001231\n",
      "Epoch: 94/100... Step: 9720... Loss: 0.001360... Val Loss: 0.001223\n",
      "Epoch: 94/100... Step: 9721... Loss: 0.001534... Val Loss: 0.001220\n",
      "Epoch: 94/100... Step: 9722... Loss: 0.001693... Val Loss: 0.001261\n",
      "Epoch: 94/100... Step: 9723... Loss: 0.001113... Val Loss: 0.001184\n",
      "Epoch: 94/100... Step: 9724... Loss: 0.001183... Val Loss: 0.001188\n",
      "Epoch: 94/100... Step: 9725... Loss: 0.001456... Val Loss: 0.001149\n",
      "Epoch: 94/100... Step: 9726... Loss: 0.001477... Val Loss: 0.001099\n",
      "Epoch: 94/100... Step: 9727... Loss: 0.001137... Val Loss: 0.001050\n",
      "Epoch: 94/100... Step: 9728... Loss: 0.001659... Val Loss: 0.001035\n",
      "Epoch: 94/100... Step: 9729... Loss: 0.001504... Val Loss: 0.001037\n",
      "Epoch: 94/100... Step: 9730... Loss: 0.001630... Val Loss: 0.001034\n",
      "Epoch: 94/100... Step: 9731... Loss: 0.001061... Val Loss: 0.000998\n",
      "Epoch: 94/100... Step: 9732... Loss: 0.001286... Val Loss: 0.001034\n",
      "Epoch: 94/100... Step: 9733... Loss: 0.001429... Val Loss: 0.001074\n",
      "Epoch: 94/100... Step: 9734... Loss: 0.000995... Val Loss: 0.000989\n",
      "Epoch: 94/100... Step: 9735... Loss: 0.001572... Val Loss: 0.000975\n",
      "Epoch: 94/100... Step: 9736... Loss: 0.001760... Val Loss: 0.000949\n",
      "Epoch: 94/100... Step: 9737... Loss: 0.001165... Val Loss: 0.000983\n",
      "Epoch: 94/100... Step: 9738... Loss: 0.000819... Val Loss: 0.000921\n",
      "Epoch: 94/100... Step: 9739... Loss: 0.001271... Val Loss: 0.000898\n",
      "Epoch: 94/100... Step: 9740... Loss: 0.001150... Val Loss: 0.000876\n",
      "Epoch: 94/100... Step: 9741... Loss: 0.001161... Val Loss: 0.000899\n",
      "Epoch: 94/100... Step: 9742... Loss: 0.001807... Val Loss: 0.000897\n",
      "Epoch: 94/100... Step: 9743... Loss: 0.001476... Val Loss: 0.000820\n",
      "Epoch: 94/100... Step: 9744... Loss: 0.001058... Val Loss: 0.000779\n",
      "Epoch: 94/100... Step: 9745... Loss: 0.001210... Val Loss: 0.000742\n",
      "Epoch: 94/100... Step: 9746... Loss: 0.000785... Val Loss: 0.000720\n",
      "Epoch: 94/100... Step: 9747... Loss: 0.001344... Val Loss: 0.000689\n",
      "Epoch: 94/100... Step: 9748... Loss: 0.001048... Val Loss: 0.000595\n",
      "Epoch: 94/100... Step: 9749... Loss: 0.001431... Val Loss: 0.000601\n",
      "Epoch: 94/100... Step: 9750... Loss: 0.000957... Val Loss: 0.000554\n",
      "Epoch: 94/100... Step: 9751... Loss: 0.001115... Val Loss: 0.000536\n",
      "Epoch: 94/100... Step: 9752... Loss: 0.000701... Val Loss: 0.000539\n",
      "Epoch: 94/100... Step: 9753... Loss: 0.001118... Val Loss: 0.000626\n",
      "Epoch: 94/100... Step: 9754... Loss: 0.001011... Val Loss: 0.000703\n",
      "Epoch: 94/100... Step: 9755... Loss: 0.000926... Val Loss: 0.000752\n",
      "Epoch: 94/100... Step: 9756... Loss: 0.000960... Val Loss: 0.000803\n",
      "Epoch: 94/100... Step: 9757... Loss: 0.001641... Val Loss: 0.000833\n",
      "Epoch: 94/100... Step: 9758... Loss: 0.001378... Val Loss: 0.000816\n",
      "Epoch: 94/100... Step: 9759... Loss: 0.001348... Val Loss: 0.000797\n",
      "Epoch: 94/100... Step: 9760... Loss: 0.000682... Val Loss: 0.000740\n",
      "Epoch: 94/100... Step: 9761... Loss: 0.001319... Val Loss: 0.000687\n",
      "Epoch: 94/100... Step: 9762... Loss: 0.001116... Val Loss: 0.000622\n",
      "Epoch: 94/100... Step: 9763... Loss: 0.000963... Val Loss: 0.000552\n",
      "Epoch: 94/100... Step: 9764... Loss: 0.001446... Val Loss: 0.000518\n",
      "Epoch: 94/100... Step: 9765... Loss: 0.000353... Val Loss: 0.000510\n",
      "Epoch: 94/100... Step: 9766... Loss: 0.001251... Val Loss: 0.000528\n",
      "Epoch: 94/100... Step: 9767... Loss: 0.000901... Val Loss: 0.000532\n",
      "Epoch: 94/100... Step: 9768... Loss: 0.001169... Val Loss: 0.000571\n",
      "Epoch: 94/100... Step: 9769... Loss: 0.001335... Val Loss: 0.000543\n",
      "Epoch: 94/100... Step: 9770... Loss: 0.000703... Val Loss: 0.000555\n",
      "Epoch: 94/100... Step: 9771... Loss: 0.001245... Val Loss: 0.000572\n",
      "Epoch: 94/100... Step: 9772... Loss: 0.000942... Val Loss: 0.000630\n",
      "Epoch: 94/100... Step: 9773... Loss: 0.000985... Val Loss: 0.000646\n",
      "Epoch: 94/100... Step: 9774... Loss: 0.001537... Val Loss: 0.000671\n",
      "Epoch: 94/100... Step: 9775... Loss: 0.001393... Val Loss: 0.000694\n",
      "Epoch: 94/100... Step: 9776... Loss: 0.001190... Val Loss: 0.000677\n",
      "Epoch: 95/100... Step: 9777... Loss: 0.000818... Val Loss: 0.002140\n",
      "Epoch: 95/100... Step: 9778... Loss: 0.001680... Val Loss: 0.002222\n",
      "Epoch: 95/100... Step: 9779... Loss: 0.001818... Val Loss: 0.002094\n",
      "Epoch: 95/100... Step: 9780... Loss: 0.001116... Val Loss: 0.001949\n",
      "Epoch: 95/100... Step: 9781... Loss: 0.001438... Val Loss: 0.001770\n",
      "Epoch: 95/100... Step: 9782... Loss: 0.001420... Val Loss: 0.001569\n",
      "Epoch: 95/100... Step: 9783... Loss: 0.000953... Val Loss: 0.001337\n",
      "Epoch: 95/100... Step: 9784... Loss: 0.000959... Val Loss: 0.001089\n",
      "Epoch: 95/100... Step: 9785... Loss: 0.001563... Val Loss: 0.000853\n",
      "Epoch: 95/100... Step: 9786... Loss: 0.001253... Val Loss: 0.000660\n",
      "Epoch: 95/100... Step: 9787... Loss: 0.000577... Val Loss: 0.000492\n",
      "Epoch: 95/100... Step: 9788... Loss: 0.001116... Val Loss: 0.000398\n",
      "Validation loss decreased (0.000415 --> 0.000398).  Saving model ...\n",
      "Epoch: 95/100... Step: 9789... Loss: 0.001576... Val Loss: 0.000370\n",
      "Validation loss decreased (0.000398 --> 0.000370).  Saving model ...\n",
      "Epoch: 95/100... Step: 9790... Loss: 0.000949... Val Loss: 0.000362\n",
      "Validation loss decreased (0.000370 --> 0.000362).  Saving model ...\n",
      "Epoch: 95/100... Step: 9791... Loss: 0.001593... Val Loss: 0.000373\n",
      "Epoch: 95/100... Step: 9792... Loss: 0.001177... Val Loss: 0.000384\n",
      "Epoch: 95/100... Step: 9793... Loss: 0.000776... Val Loss: 0.000393\n",
      "Epoch: 95/100... Step: 9794... Loss: 0.001022... Val Loss: 0.000403\n",
      "Epoch: 95/100... Step: 9795... Loss: 0.001026... Val Loss: 0.000414\n",
      "Epoch: 95/100... Step: 9796... Loss: 0.000815... Val Loss: 0.000420\n",
      "Epoch: 95/100... Step: 9797... Loss: 0.000970... Val Loss: 0.000419\n",
      "Epoch: 95/100... Step: 9798... Loss: 0.001018... Val Loss: 0.000422\n",
      "Epoch: 95/100... Step: 9799... Loss: 0.001034... Val Loss: 0.000432\n",
      "Epoch: 95/100... Step: 9800... Loss: 0.000956... Val Loss: 0.000446\n",
      "Epoch: 95/100... Step: 9801... Loss: 0.000906... Val Loss: 0.000469\n",
      "Epoch: 95/100... Step: 9802... Loss: 0.000664... Val Loss: 0.000458\n",
      "Epoch: 95/100... Step: 9803... Loss: 0.000899... Val Loss: 0.000460\n",
      "Epoch: 95/100... Step: 9804... Loss: 0.001132... Val Loss: 0.000456\n",
      "Epoch: 95/100... Step: 9805... Loss: 0.000942... Val Loss: 0.000464\n",
      "Epoch: 95/100... Step: 9806... Loss: 0.001069... Val Loss: 0.000476\n",
      "Epoch: 95/100... Step: 9807... Loss: 0.000985... Val Loss: 0.000490\n",
      "Epoch: 95/100... Step: 9808... Loss: 0.000700... Val Loss: 0.000506\n",
      "Epoch: 95/100... Step: 9809... Loss: 0.000786... Val Loss: 0.000526\n",
      "Epoch: 95/100... Step: 9810... Loss: 0.000917... Val Loss: 0.000550\n",
      "Epoch: 95/100... Step: 9811... Loss: 0.001145... Val Loss: 0.000610\n",
      "Epoch: 95/100... Step: 9812... Loss: 0.001072... Val Loss: 0.000657\n",
      "Epoch: 95/100... Step: 9813... Loss: 0.000823... Val Loss: 0.000700\n",
      "Epoch: 95/100... Step: 9814... Loss: 0.000874... Val Loss: 0.000735\n",
      "Epoch: 95/100... Step: 9815... Loss: 0.001226... Val Loss: 0.000728\n",
      "Epoch: 95/100... Step: 9816... Loss: 0.000772... Val Loss: 0.000717\n",
      "Epoch: 95/100... Step: 9817... Loss: 0.000836... Val Loss: 0.000629\n",
      "Epoch: 95/100... Step: 9818... Loss: 0.001253... Val Loss: 0.000571\n",
      "Epoch: 95/100... Step: 9819... Loss: 0.001629... Val Loss: 0.000510\n",
      "Epoch: 95/100... Step: 9820... Loss: 0.001650... Val Loss: 0.000484\n",
      "Epoch: 95/100... Step: 9821... Loss: 0.001516... Val Loss: 0.000458\n",
      "Epoch: 95/100... Step: 9822... Loss: 0.001860... Val Loss: 0.000479\n",
      "Epoch: 95/100... Step: 9823... Loss: 0.002572... Val Loss: 0.000546\n",
      "Epoch: 95/100... Step: 9824... Loss: 0.001666... Val Loss: 0.000597\n",
      "Epoch: 95/100... Step: 9825... Loss: 0.001596... Val Loss: 0.000644\n",
      "Epoch: 95/100... Step: 9826... Loss: 0.001496... Val Loss: 0.000718\n",
      "Epoch: 95/100... Step: 9827... Loss: 0.001320... Val Loss: 0.000783\n",
      "Epoch: 95/100... Step: 9828... Loss: 0.000878... Val Loss: 0.000812\n",
      "Epoch: 95/100... Step: 9829... Loss: 0.001302... Val Loss: 0.000859\n",
      "Epoch: 95/100... Step: 9830... Loss: 0.001518... Val Loss: 0.000870\n",
      "Epoch: 95/100... Step: 9831... Loss: 0.001800... Val Loss: 0.000881\n",
      "Epoch: 95/100... Step: 9832... Loss: 0.001587... Val Loss: 0.000897\n",
      "Epoch: 95/100... Step: 9833... Loss: 0.001307... Val Loss: 0.000896\n",
      "Epoch: 95/100... Step: 9834... Loss: 0.001964... Val Loss: 0.000887\n",
      "Epoch: 95/100... Step: 9835... Loss: 0.001648... Val Loss: 0.000878\n",
      "Epoch: 95/100... Step: 9836... Loss: 0.002001... Val Loss: 0.000878\n",
      "Epoch: 95/100... Step: 9837... Loss: 0.001520... Val Loss: 0.000867\n",
      "Epoch: 95/100... Step: 9838... Loss: 0.001806... Val Loss: 0.000873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100... Step: 9839... Loss: 0.000741... Val Loss: 0.000871\n",
      "Epoch: 95/100... Step: 9840... Loss: 0.002116... Val Loss: 0.000866\n",
      "Epoch: 95/100... Step: 9841... Loss: 0.001231... Val Loss: 0.000872\n",
      "Epoch: 95/100... Step: 9842... Loss: 0.001390... Val Loss: 0.000882\n",
      "Epoch: 95/100... Step: 9843... Loss: 0.000969... Val Loss: 0.000881\n",
      "Epoch: 95/100... Step: 9844... Loss: 0.000929... Val Loss: 0.000875\n",
      "Epoch: 95/100... Step: 9845... Loss: 0.001129... Val Loss: 0.000843\n",
      "Epoch: 95/100... Step: 9846... Loss: 0.000933... Val Loss: 0.000826\n",
      "Epoch: 95/100... Step: 9847... Loss: 0.000588... Val Loss: 0.000809\n",
      "Epoch: 95/100... Step: 9848... Loss: 0.000960... Val Loss: 0.000798\n",
      "Epoch: 95/100... Step: 9849... Loss: 0.001192... Val Loss: 0.000790\n",
      "Epoch: 95/100... Step: 9850... Loss: 0.001293... Val Loss: 0.000781\n",
      "Epoch: 95/100... Step: 9851... Loss: 0.000873... Val Loss: 0.000759\n",
      "Epoch: 95/100... Step: 9852... Loss: 0.000847... Val Loss: 0.000727\n",
      "Epoch: 95/100... Step: 9853... Loss: 0.000730... Val Loss: 0.000686\n",
      "Epoch: 95/100... Step: 9854... Loss: 0.001007... Val Loss: 0.000639\n",
      "Epoch: 95/100... Step: 9855... Loss: 0.000927... Val Loss: 0.000606\n",
      "Epoch: 95/100... Step: 9856... Loss: 0.001001... Val Loss: 0.000576\n",
      "Epoch: 95/100... Step: 9857... Loss: 0.001064... Val Loss: 0.000546\n",
      "Epoch: 95/100... Step: 9858... Loss: 0.001389... Val Loss: 0.000551\n",
      "Epoch: 95/100... Step: 9859... Loss: 0.000859... Val Loss: 0.000593\n",
      "Epoch: 95/100... Step: 9860... Loss: 0.001062... Val Loss: 0.000631\n",
      "Epoch: 95/100... Step: 9861... Loss: 0.000653... Val Loss: 0.000648\n",
      "Epoch: 95/100... Step: 9862... Loss: 0.001197... Val Loss: 0.000716\n",
      "Epoch: 95/100... Step: 9863... Loss: 0.000899... Val Loss: 0.000695\n",
      "Epoch: 95/100... Step: 9864... Loss: 0.001195... Val Loss: 0.000707\n",
      "Epoch: 95/100... Step: 9865... Loss: 0.001099... Val Loss: 0.000766\n",
      "Epoch: 95/100... Step: 9866... Loss: 0.000560... Val Loss: 0.000795\n",
      "Epoch: 95/100... Step: 9867... Loss: 0.000766... Val Loss: 0.000796\n",
      "Epoch: 95/100... Step: 9868... Loss: 0.000471... Val Loss: 0.000793\n",
      "Epoch: 95/100... Step: 9869... Loss: 0.000517... Val Loss: 0.000821\n",
      "Epoch: 95/100... Step: 9870... Loss: 0.000801... Val Loss: 0.000830\n",
      "Epoch: 95/100... Step: 9871... Loss: 0.001050... Val Loss: 0.000828\n",
      "Epoch: 95/100... Step: 9872... Loss: 0.001043... Val Loss: 0.000793\n",
      "Epoch: 95/100... Step: 9873... Loss: 0.000804... Val Loss: 0.000768\n",
      "Epoch: 95/100... Step: 9874... Loss: 0.000465... Val Loss: 0.000707\n",
      "Epoch: 95/100... Step: 9875... Loss: 0.001011... Val Loss: 0.000675\n",
      "Epoch: 95/100... Step: 9876... Loss: 0.001187... Val Loss: 0.000642\n",
      "Epoch: 95/100... Step: 9877... Loss: 0.001027... Val Loss: 0.000624\n",
      "Epoch: 95/100... Step: 9878... Loss: 0.000877... Val Loss: 0.000618\n",
      "Epoch: 95/100... Step: 9879... Loss: 0.000626... Val Loss: 0.000576\n",
      "Epoch: 95/100... Step: 9880... Loss: 0.000774... Val Loss: 0.000596\n",
      "Epoch: 96/100... Step: 9881... Loss: 0.000859... Val Loss: 0.001690\n",
      "Epoch: 96/100... Step: 9882... Loss: 0.001152... Val Loss: 0.001458\n",
      "Epoch: 96/100... Step: 9883... Loss: 0.001052... Val Loss: 0.001262\n",
      "Epoch: 96/100... Step: 9884... Loss: 0.002313... Val Loss: 0.001229\n",
      "Epoch: 96/100... Step: 9885... Loss: 0.001417... Val Loss: 0.001145\n",
      "Epoch: 96/100... Step: 9886... Loss: 0.001298... Val Loss: 0.001057\n",
      "Epoch: 96/100... Step: 9887... Loss: 0.001323... Val Loss: 0.000971\n",
      "Epoch: 96/100... Step: 9888... Loss: 0.001343... Val Loss: 0.000844\n",
      "Epoch: 96/100... Step: 9889... Loss: 0.000984... Val Loss: 0.000773\n",
      "Epoch: 96/100... Step: 9890... Loss: 0.001143... Val Loss: 0.000707\n",
      "Epoch: 96/100... Step: 9891... Loss: 0.000990... Val Loss: 0.000668\n",
      "Epoch: 96/100... Step: 9892... Loss: 0.000952... Val Loss: 0.000633\n",
      "Epoch: 96/100... Step: 9893... Loss: 0.000989... Val Loss: 0.000618\n",
      "Epoch: 96/100... Step: 9894... Loss: 0.000834... Val Loss: 0.000640\n",
      "Epoch: 96/100... Step: 9895... Loss: 0.001292... Val Loss: 0.000653\n",
      "Epoch: 96/100... Step: 9896... Loss: 0.001094... Val Loss: 0.000719\n",
      "Epoch: 96/100... Step: 9897... Loss: 0.001689... Val Loss: 0.000781\n",
      "Epoch: 96/100... Step: 9898... Loss: 0.000899... Val Loss: 0.000859\n",
      "Epoch: 96/100... Step: 9899... Loss: 0.001325... Val Loss: 0.000911\n",
      "Epoch: 96/100... Step: 9900... Loss: 0.001012... Val Loss: 0.000967\n",
      "Epoch: 96/100... Step: 9901... Loss: 0.000631... Val Loss: 0.001009\n",
      "Epoch: 96/100... Step: 9902... Loss: 0.001027... Val Loss: 0.001027\n",
      "Epoch: 96/100... Step: 9903... Loss: 0.001451... Val Loss: 0.001030\n",
      "Epoch: 96/100... Step: 9904... Loss: 0.001248... Val Loss: 0.001021\n",
      "Epoch: 96/100... Step: 9905... Loss: 0.000761... Val Loss: 0.000996\n",
      "Epoch: 96/100... Step: 9906... Loss: 0.001097... Val Loss: 0.000975\n",
      "Epoch: 96/100... Step: 9907... Loss: 0.001162... Val Loss: 0.000897\n",
      "Epoch: 96/100... Step: 9908... Loss: 0.000872... Val Loss: 0.000833\n",
      "Epoch: 96/100... Step: 9909... Loss: 0.000462... Val Loss: 0.000793\n",
      "Epoch: 96/100... Step: 9910... Loss: 0.000964... Val Loss: 0.000746\n",
      "Epoch: 96/100... Step: 9911... Loss: 0.001269... Val Loss: 0.000687\n",
      "Epoch: 96/100... Step: 9912... Loss: 0.000972... Val Loss: 0.000628\n",
      "Epoch: 96/100... Step: 9913... Loss: 0.000868... Val Loss: 0.000599\n",
      "Epoch: 96/100... Step: 9914... Loss: 0.001198... Val Loss: 0.000580\n",
      "Epoch: 96/100... Step: 9915... Loss: 0.000712... Val Loss: 0.000596\n",
      "Epoch: 96/100... Step: 9916... Loss: 0.000839... Val Loss: 0.000565\n",
      "Epoch: 96/100... Step: 9917... Loss: 0.000846... Val Loss: 0.000558\n",
      "Epoch: 96/100... Step: 9918... Loss: 0.000857... Val Loss: 0.000567\n",
      "Epoch: 96/100... Step: 9919... Loss: 0.000758... Val Loss: 0.000596\n",
      "Epoch: 96/100... Step: 9920... Loss: 0.001018... Val Loss: 0.000618\n",
      "Epoch: 96/100... Step: 9921... Loss: 0.000863... Val Loss: 0.000642\n",
      "Epoch: 96/100... Step: 9922... Loss: 0.001298... Val Loss: 0.000658\n",
      "Epoch: 96/100... Step: 9923... Loss: 0.001515... Val Loss: 0.000670\n",
      "Epoch: 96/100... Step: 9924... Loss: 0.001827... Val Loss: 0.000686\n",
      "Epoch: 96/100... Step: 9925... Loss: 0.001724... Val Loss: 0.000714\n",
      "Epoch: 96/100... Step: 9926... Loss: 0.001808... Val Loss: 0.000716\n",
      "Epoch: 96/100... Step: 9927... Loss: 0.001693... Val Loss: 0.000739\n",
      "Epoch: 96/100... Step: 9928... Loss: 0.001751... Val Loss: 0.000765\n",
      "Epoch: 96/100... Step: 9929... Loss: 0.001876... Val Loss: 0.000797\n",
      "Epoch: 96/100... Step: 9930... Loss: 0.001665... Val Loss: 0.000846\n",
      "Epoch: 96/100... Step: 9931... Loss: 0.001418... Val Loss: 0.000889\n",
      "Epoch: 96/100... Step: 9932... Loss: 0.001326... Val Loss: 0.000891\n",
      "Epoch: 96/100... Step: 9933... Loss: 0.001400... Val Loss: 0.000882\n",
      "Epoch: 96/100... Step: 9934... Loss: 0.001198... Val Loss: 0.000879\n",
      "Epoch: 96/100... Step: 9935... Loss: 0.001358... Val Loss: 0.000881\n",
      "Epoch: 96/100... Step: 9936... Loss: 0.001007... Val Loss: 0.000873\n",
      "Epoch: 96/100... Step: 9937... Loss: 0.001341... Val Loss: 0.000858\n",
      "Epoch: 96/100... Step: 9938... Loss: 0.001895... Val Loss: 0.000833\n",
      "Epoch: 96/100... Step: 9939... Loss: 0.001057... Val Loss: 0.000830\n",
      "Epoch: 96/100... Step: 9940... Loss: 0.001083... Val Loss: 0.000808\n",
      "Epoch: 96/100... Step: 9941... Loss: 0.001274... Val Loss: 0.000763\n",
      "Epoch: 96/100... Step: 9942... Loss: 0.001503... Val Loss: 0.000696\n",
      "Epoch: 96/100... Step: 9943... Loss: 0.001516... Val Loss: 0.000649\n",
      "Epoch: 96/100... Step: 9944... Loss: 0.001917... Val Loss: 0.000607\n",
      "Epoch: 96/100... Step: 9945... Loss: 0.001462... Val Loss: 0.000574\n",
      "Epoch: 96/100... Step: 9946... Loss: 0.001122... Val Loss: 0.000556\n",
      "Epoch: 96/100... Step: 9947... Loss: 0.001129... Val Loss: 0.000517\n",
      "Epoch: 96/100... Step: 9948... Loss: 0.000979... Val Loss: 0.000470\n",
      "Epoch: 96/100... Step: 9949... Loss: 0.000883... Val Loss: 0.000437\n",
      "Epoch: 96/100... Step: 9950... Loss: 0.001015... Val Loss: 0.000415\n",
      "Epoch: 96/100... Step: 9951... Loss: 0.000864... Val Loss: 0.000393\n",
      "Epoch: 96/100... Step: 9952... Loss: 0.001219... Val Loss: 0.000377\n",
      "Epoch: 96/100... Step: 9953... Loss: 0.001251... Val Loss: 0.000369\n",
      "Epoch: 96/100... Step: 9954... Loss: 0.000879... Val Loss: 0.000371\n",
      "Epoch: 96/100... Step: 9955... Loss: 0.000541... Val Loss: 0.000374\n",
      "Epoch: 96/100... Step: 9956... Loss: 0.000726... Val Loss: 0.000367\n",
      "Epoch: 96/100... Step: 9957... Loss: 0.000901... Val Loss: 0.000385\n",
      "Epoch: 96/100... Step: 9958... Loss: 0.000668... Val Loss: 0.000358\n",
      "Validation loss decreased (0.000362 --> 0.000358).  Saving model ...\n",
      "Epoch: 96/100... Step: 9959... Loss: 0.000558... Val Loss: 0.000355\n",
      "Validation loss decreased (0.000358 --> 0.000355).  Saving model ...\n",
      "Epoch: 96/100... Step: 9960... Loss: 0.000725... Val Loss: 0.000357\n",
      "Epoch: 96/100... Step: 9961... Loss: 0.000763... Val Loss: 0.000367\n",
      "Epoch: 96/100... Step: 9962... Loss: 0.000771... Val Loss: 0.000395\n",
      "Epoch: 96/100... Step: 9963... Loss: 0.001008... Val Loss: 0.000420\n",
      "Epoch: 96/100... Step: 9964... Loss: 0.001091... Val Loss: 0.000462\n",
      "Epoch: 96/100... Step: 9965... Loss: 0.000625... Val Loss: 0.000483\n",
      "Epoch: 96/100... Step: 9966... Loss: 0.000916... Val Loss: 0.000530\n",
      "Epoch: 96/100... Step: 9967... Loss: 0.000662... Val Loss: 0.000556\n",
      "Epoch: 96/100... Step: 9968... Loss: 0.000821... Val Loss: 0.000580\n",
      "Epoch: 96/100... Step: 9969... Loss: 0.000990... Val Loss: 0.000593\n",
      "Epoch: 96/100... Step: 9970... Loss: 0.000683... Val Loss: 0.000591\n",
      "Epoch: 96/100... Step: 9971... Loss: 0.000593... Val Loss: 0.000568\n",
      "Epoch: 96/100... Step: 9972... Loss: 0.000651... Val Loss: 0.000544\n",
      "Epoch: 96/100... Step: 9973... Loss: 0.000651... Val Loss: 0.000504\n",
      "Epoch: 96/100... Step: 9974... Loss: 0.000892... Val Loss: 0.000472\n",
      "Epoch: 96/100... Step: 9975... Loss: 0.000712... Val Loss: 0.000446\n",
      "Epoch: 96/100... Step: 9976... Loss: 0.000722... Val Loss: 0.000415\n",
      "Epoch: 96/100... Step: 9977... Loss: 0.001086... Val Loss: 0.000397\n",
      "Epoch: 96/100... Step: 9978... Loss: 0.000575... Val Loss: 0.000377\n",
      "Epoch: 96/100... Step: 9979... Loss: 0.000710... Val Loss: 0.000373\n",
      "Epoch: 96/100... Step: 9980... Loss: 0.000710... Val Loss: 0.000373\n",
      "Epoch: 96/100... Step: 9981... Loss: 0.001081... Val Loss: 0.000386\n",
      "Epoch: 96/100... Step: 9982... Loss: 0.000739... Val Loss: 0.000393\n",
      "Epoch: 96/100... Step: 9983... Loss: 0.000893... Val Loss: 0.000413\n",
      "Epoch: 96/100... Step: 9984... Loss: 0.000708... Val Loss: 0.000430\n",
      "Epoch: 97/100... Step: 9985... Loss: 0.000939... Val Loss: 0.001850\n",
      "Epoch: 97/100... Step: 9986... Loss: 0.001022... Val Loss: 0.001942\n",
      "Epoch: 97/100... Step: 9987... Loss: 0.001440... Val Loss: 0.001780\n",
      "Epoch: 97/100... Step: 9988... Loss: 0.001223... Val Loss: 0.001686\n",
      "Epoch: 97/100... Step: 9989... Loss: 0.000908... Val Loss: 0.001571\n",
      "Epoch: 97/100... Step: 9990... Loss: 0.001122... Val Loss: 0.001467\n",
      "Epoch: 97/100... Step: 9991... Loss: 0.001045... Val Loss: 0.001336\n",
      "Epoch: 97/100... Step: 9992... Loss: 0.001198... Val Loss: 0.001205\n",
      "Epoch: 97/100... Step: 9993... Loss: 0.000865... Val Loss: 0.001073\n",
      "Epoch: 97/100... Step: 9994... Loss: 0.001116... Val Loss: 0.000954\n",
      "Epoch: 97/100... Step: 9995... Loss: 0.000969... Val Loss: 0.000851\n",
      "Epoch: 97/100... Step: 9996... Loss: 0.000818... Val Loss: 0.000775\n",
      "Epoch: 97/100... Step: 9997... Loss: 0.001080... Val Loss: 0.000706\n",
      "Epoch: 97/100... Step: 9998... Loss: 0.001122... Val Loss: 0.000683\n",
      "Epoch: 97/100... Step: 9999... Loss: 0.001293... Val Loss: 0.000696\n",
      "Epoch: 97/100... Step: 10000... Loss: 0.001307... Val Loss: 0.000700\n",
      "Epoch: 97/100... Step: 10001... Loss: 0.001289... Val Loss: 0.000685\n",
      "Epoch: 97/100... Step: 10002... Loss: 0.000888... Val Loss: 0.000715\n",
      "Epoch: 97/100... Step: 10003... Loss: 0.000905... Val Loss: 0.000747\n",
      "Epoch: 97/100... Step: 10004... Loss: 0.000802... Val Loss: 0.000779\n",
      "Epoch: 97/100... Step: 10005... Loss: 0.000943... Val Loss: 0.000806\n",
      "Epoch: 97/100... Step: 10006... Loss: 0.000944... Val Loss: 0.000838\n",
      "Epoch: 97/100... Step: 10007... Loss: 0.001062... Val Loss: 0.000881\n",
      "Epoch: 97/100... Step: 10008... Loss: 0.001105... Val Loss: 0.000856\n",
      "Epoch: 97/100... Step: 10009... Loss: 0.000996... Val Loss: 0.000861\n",
      "Epoch: 97/100... Step: 10010... Loss: 0.000817... Val Loss: 0.000839\n",
      "Epoch: 97/100... Step: 10011... Loss: 0.000837... Val Loss: 0.000855\n",
      "Epoch: 97/100... Step: 10012... Loss: 0.000919... Val Loss: 0.000829\n",
      "Epoch: 97/100... Step: 10013... Loss: 0.000778... Val Loss: 0.000814\n",
      "Epoch: 97/100... Step: 10014... Loss: 0.000634... Val Loss: 0.000787\n",
      "Epoch: 97/100... Step: 10015... Loss: 0.000755... Val Loss: 0.000751\n",
      "Epoch: 97/100... Step: 10016... Loss: 0.000446... Val Loss: 0.000724\n",
      "Epoch: 97/100... Step: 10017... Loss: 0.000883... Val Loss: 0.000677\n",
      "Epoch: 97/100... Step: 10018... Loss: 0.000824... Val Loss: 0.000638\n",
      "Epoch: 97/100... Step: 10019... Loss: 0.000666... Val Loss: 0.000562\n",
      "Epoch: 97/100... Step: 10020... Loss: 0.000596... Val Loss: 0.000500\n",
      "Epoch: 97/100... Step: 10021... Loss: 0.000590... Val Loss: 0.000452\n",
      "Epoch: 97/100... Step: 10022... Loss: 0.000516... Val Loss: 0.000443\n",
      "Epoch: 97/100... Step: 10023... Loss: 0.001234... Val Loss: 0.000432\n",
      "Epoch: 97/100... Step: 10024... Loss: 0.000662... Val Loss: 0.000448\n",
      "Epoch: 97/100... Step: 10025... Loss: 0.001056... Val Loss: 0.000459\n",
      "Epoch: 97/100... Step: 10026... Loss: 0.001138... Val Loss: 0.000474\n",
      "Epoch: 97/100... Step: 10027... Loss: 0.001376... Val Loss: 0.000490\n",
      "Epoch: 97/100... Step: 10028... Loss: 0.001857... Val Loss: 0.000522\n",
      "Epoch: 97/100... Step: 10029... Loss: 0.001623... Val Loss: 0.000544\n",
      "Epoch: 97/100... Step: 10030... Loss: 0.002231... Val Loss: 0.000575\n",
      "Epoch: 97/100... Step: 10031... Loss: 0.001929... Val Loss: 0.000615\n",
      "Epoch: 97/100... Step: 10032... Loss: 0.001777... Val Loss: 0.000644\n",
      "Epoch: 97/100... Step: 10033... Loss: 0.002142... Val Loss: 0.000679\n",
      "Epoch: 97/100... Step: 10034... Loss: 0.001510... Val Loss: 0.000710\n",
      "Epoch: 97/100... Step: 10035... Loss: 0.001105... Val Loss: 0.000731\n",
      "Epoch: 97/100... Step: 10036... Loss: 0.000743... Val Loss: 0.000740\n",
      "Epoch: 97/100... Step: 10037... Loss: 0.001272... Val Loss: 0.000768\n",
      "Epoch: 97/100... Step: 10038... Loss: 0.001351... Val Loss: 0.000786\n",
      "Epoch: 97/100... Step: 10039... Loss: 0.001349... Val Loss: 0.000791\n",
      "Epoch: 97/100... Step: 10040... Loss: 0.001190... Val Loss: 0.000815\n",
      "Epoch: 97/100... Step: 10041... Loss: 0.001308... Val Loss: 0.000824\n",
      "Epoch: 97/100... Step: 10042... Loss: 0.001444... Val Loss: 0.000847\n",
      "Epoch: 97/100... Step: 10043... Loss: 0.001379... Val Loss: 0.000859\n",
      "Epoch: 97/100... Step: 10044... Loss: 0.001532... Val Loss: 0.000860\n",
      "Epoch: 97/100... Step: 10045... Loss: 0.001152... Val Loss: 0.000870\n",
      "Epoch: 97/100... Step: 10046... Loss: 0.001382... Val Loss: 0.000872\n",
      "Epoch: 97/100... Step: 10047... Loss: 0.001422... Val Loss: 0.000875\n",
      "Epoch: 97/100... Step: 10048... Loss: 0.001472... Val Loss: 0.000873\n",
      "Epoch: 97/100... Step: 10049... Loss: 0.001494... Val Loss: 0.000881\n",
      "Epoch: 97/100... Step: 10050... Loss: 0.001194... Val Loss: 0.000871\n",
      "Epoch: 97/100... Step: 10051... Loss: 0.001133... Val Loss: 0.000852\n",
      "Epoch: 97/100... Step: 10052... Loss: 0.001314... Val Loss: 0.000856\n",
      "Epoch: 97/100... Step: 10053... Loss: 0.001000... Val Loss: 0.000848\n",
      "Epoch: 97/100... Step: 10054... Loss: 0.000694... Val Loss: 0.000838\n",
      "Epoch: 97/100... Step: 10055... Loss: 0.000989... Val Loss: 0.000828\n",
      "Epoch: 97/100... Step: 10056... Loss: 0.000895... Val Loss: 0.000819\n",
      "Epoch: 97/100... Step: 10057... Loss: 0.001155... Val Loss: 0.000805\n",
      "Epoch: 97/100... Step: 10058... Loss: 0.001081... Val Loss: 0.000784\n",
      "Epoch: 97/100... Step: 10059... Loss: 0.000697... Val Loss: 0.000761\n",
      "Epoch: 97/100... Step: 10060... Loss: 0.000707... Val Loss: 0.000720\n",
      "Epoch: 97/100... Step: 10061... Loss: 0.000934... Val Loss: 0.000669\n",
      "Epoch: 97/100... Step: 10062... Loss: 0.000773... Val Loss: 0.000630\n",
      "Epoch: 97/100... Step: 10063... Loss: 0.000719... Val Loss: 0.000557\n",
      "Epoch: 97/100... Step: 10064... Loss: 0.000657... Val Loss: 0.000499\n",
      "Epoch: 97/100... Step: 10065... Loss: 0.000824... Val Loss: 0.000451\n",
      "Epoch: 97/100... Step: 10066... Loss: 0.000865... Val Loss: 0.000383\n",
      "Epoch: 97/100... Step: 10067... Loss: 0.000631... Val Loss: 0.000337\n",
      "Validation loss decreased (0.000355 --> 0.000337).  Saving model ...\n",
      "Epoch: 97/100... Step: 10068... Loss: 0.000693... Val Loss: 0.000310\n",
      "Validation loss decreased (0.000337 --> 0.000310).  Saving model ...\n",
      "Epoch: 97/100... Step: 10069... Loss: 0.000465... Val Loss: 0.000287\n",
      "Validation loss decreased (0.000310 --> 0.000287).  Saving model ...\n",
      "Epoch: 97/100... Step: 10070... Loss: 0.000529... Val Loss: 0.000294\n",
      "Epoch: 97/100... Step: 10071... Loss: 0.000543... Val Loss: 0.000315\n",
      "Epoch: 97/100... Step: 10072... Loss: 0.000841... Val Loss: 0.000341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Step: 10073... Loss: 0.000566... Val Loss: 0.000381\n",
      "Epoch: 97/100... Step: 10074... Loss: 0.000651... Val Loss: 0.000400\n",
      "Epoch: 97/100... Step: 10075... Loss: 0.000658... Val Loss: 0.000418\n",
      "Epoch: 97/100... Step: 10076... Loss: 0.000671... Val Loss: 0.000442\n",
      "Epoch: 97/100... Step: 10077... Loss: 0.000626... Val Loss: 0.000464\n",
      "Epoch: 97/100... Step: 10078... Loss: 0.000978... Val Loss: 0.000496\n",
      "Epoch: 97/100... Step: 10079... Loss: 0.000690... Val Loss: 0.000541\n",
      "Epoch: 97/100... Step: 10080... Loss: 0.000814... Val Loss: 0.000557\n",
      "Epoch: 97/100... Step: 10081... Loss: 0.000732... Val Loss: 0.000584\n",
      "Epoch: 97/100... Step: 10082... Loss: 0.000915... Val Loss: 0.000615\n",
      "Epoch: 97/100... Step: 10083... Loss: 0.000863... Val Loss: 0.000629\n",
      "Epoch: 97/100... Step: 10084... Loss: 0.000965... Val Loss: 0.000650\n",
      "Epoch: 97/100... Step: 10085... Loss: 0.000982... Val Loss: 0.000675\n",
      "Epoch: 97/100... Step: 10086... Loss: 0.000860... Val Loss: 0.000665\n",
      "Epoch: 97/100... Step: 10087... Loss: 0.000826... Val Loss: 0.000671\n",
      "Epoch: 97/100... Step: 10088... Loss: 0.000642... Val Loss: 0.000667\n",
      "Epoch: 98/100... Step: 10089... Loss: 0.000960... Val Loss: 0.001937\n",
      "Epoch: 98/100... Step: 10090... Loss: 0.001231... Val Loss: 0.001823\n",
      "Epoch: 98/100... Step: 10091... Loss: 0.001566... Val Loss: 0.001678\n",
      "Epoch: 98/100... Step: 10092... Loss: 0.001381... Val Loss: 0.001591\n",
      "Epoch: 98/100... Step: 10093... Loss: 0.001199... Val Loss: 0.001512\n",
      "Epoch: 98/100... Step: 10094... Loss: 0.001229... Val Loss: 0.001409\n",
      "Epoch: 98/100... Step: 10095... Loss: 0.001049... Val Loss: 0.001271\n",
      "Epoch: 98/100... Step: 10096... Loss: 0.000832... Val Loss: 0.001137\n",
      "Epoch: 98/100... Step: 10097... Loss: 0.000750... Val Loss: 0.000980\n",
      "Epoch: 98/100... Step: 10098... Loss: 0.001104... Val Loss: 0.000877\n",
      "Epoch: 98/100... Step: 10099... Loss: 0.000654... Val Loss: 0.000749\n",
      "Epoch: 98/100... Step: 10100... Loss: 0.001018... Val Loss: 0.000658\n",
      "Epoch: 98/100... Step: 10101... Loss: 0.000844... Val Loss: 0.000571\n",
      "Epoch: 98/100... Step: 10102... Loss: 0.000907... Val Loss: 0.000515\n",
      "Epoch: 98/100... Step: 10103... Loss: 0.001347... Val Loss: 0.000478\n",
      "Epoch: 98/100... Step: 10104... Loss: 0.001037... Val Loss: 0.000458\n",
      "Epoch: 98/100... Step: 10105... Loss: 0.000720... Val Loss: 0.000430\n",
      "Epoch: 98/100... Step: 10106... Loss: 0.000810... Val Loss: 0.000412\n",
      "Epoch: 98/100... Step: 10107... Loss: 0.000754... Val Loss: 0.000411\n",
      "Epoch: 98/100... Step: 10108... Loss: 0.000921... Val Loss: 0.000400\n",
      "Epoch: 98/100... Step: 10109... Loss: 0.001056... Val Loss: 0.000384\n",
      "Epoch: 98/100... Step: 10110... Loss: 0.000962... Val Loss: 0.000371\n",
      "Epoch: 98/100... Step: 10111... Loss: 0.000872... Val Loss: 0.000374\n",
      "Epoch: 98/100... Step: 10112... Loss: 0.000843... Val Loss: 0.000346\n",
      "Epoch: 98/100... Step: 10113... Loss: 0.001019... Val Loss: 0.000324\n",
      "Epoch: 98/100... Step: 10114... Loss: 0.001067... Val Loss: 0.000318\n",
      "Epoch: 98/100... Step: 10115... Loss: 0.000507... Val Loss: 0.000313\n",
      "Epoch: 98/100... Step: 10116... Loss: 0.000706... Val Loss: 0.000302\n",
      "Epoch: 98/100... Step: 10117... Loss: 0.000782... Val Loss: 0.000308\n",
      "Epoch: 98/100... Step: 10118... Loss: 0.000353... Val Loss: 0.000310\n",
      "Epoch: 98/100... Step: 10119... Loss: 0.000895... Val Loss: 0.000304\n",
      "Epoch: 98/100... Step: 10120... Loss: 0.000599... Val Loss: 0.000305\n",
      "Epoch: 98/100... Step: 10121... Loss: 0.000663... Val Loss: 0.000297\n",
      "Epoch: 98/100... Step: 10122... Loss: 0.000581... Val Loss: 0.000295\n",
      "Epoch: 98/100... Step: 10123... Loss: 0.000416... Val Loss: 0.000296\n",
      "Epoch: 98/100... Step: 10124... Loss: 0.000594... Val Loss: 0.000300\n",
      "Epoch: 98/100... Step: 10125... Loss: 0.000335... Val Loss: 0.000313\n",
      "Epoch: 98/100... Step: 10126... Loss: 0.000557... Val Loss: 0.000313\n",
      "Epoch: 98/100... Step: 10127... Loss: 0.000601... Val Loss: 0.000311\n",
      "Epoch: 98/100... Step: 10128... Loss: 0.000583... Val Loss: 0.000309\n",
      "Epoch: 98/100... Step: 10129... Loss: 0.000922... Val Loss: 0.000306\n",
      "Epoch: 98/100... Step: 10130... Loss: 0.000925... Val Loss: 0.000301\n",
      "Epoch: 98/100... Step: 10131... Loss: 0.001654... Val Loss: 0.000289\n",
      "Epoch: 98/100... Step: 10132... Loss: 0.001890... Val Loss: 0.000287\n",
      "Validation loss decreased (0.000287 --> 0.000287).  Saving model ...\n",
      "Epoch: 98/100... Step: 10133... Loss: 0.001675... Val Loss: 0.000287\n",
      "Epoch: 98/100... Step: 10134... Loss: 0.002080... Val Loss: 0.000288\n",
      "Epoch: 98/100... Step: 10135... Loss: 0.001735... Val Loss: 0.000288\n",
      "Epoch: 98/100... Step: 10136... Loss: 0.001605... Val Loss: 0.000294\n",
      "Epoch: 98/100... Step: 10137... Loss: 0.001385... Val Loss: 0.000301\n",
      "Epoch: 98/100... Step: 10138... Loss: 0.001189... Val Loss: 0.000309\n",
      "Epoch: 98/100... Step: 10139... Loss: 0.001201... Val Loss: 0.000314\n",
      "Epoch: 98/100... Step: 10140... Loss: 0.000864... Val Loss: 0.000319\n",
      "Epoch: 98/100... Step: 10141... Loss: 0.001187... Val Loss: 0.000324\n",
      "Epoch: 98/100... Step: 10142... Loss: 0.000844... Val Loss: 0.000332\n",
      "Epoch: 98/100... Step: 10143... Loss: 0.001248... Val Loss: 0.000337\n",
      "Epoch: 98/100... Step: 10144... Loss: 0.001423... Val Loss: 0.000352\n",
      "Epoch: 98/100... Step: 10145... Loss: 0.001412... Val Loss: 0.000358\n",
      "Epoch: 98/100... Step: 10146... Loss: 0.001435... Val Loss: 0.000365\n",
      "Epoch: 98/100... Step: 10147... Loss: 0.000942... Val Loss: 0.000371\n",
      "Epoch: 98/100... Step: 10148... Loss: 0.001565... Val Loss: 0.000384\n",
      "Epoch: 98/100... Step: 10149... Loss: 0.001334... Val Loss: 0.000395\n",
      "Epoch: 98/100... Step: 10150... Loss: 0.001684... Val Loss: 0.000403\n",
      "Epoch: 98/100... Step: 10151... Loss: 0.001245... Val Loss: 0.000407\n",
      "Epoch: 98/100... Step: 10152... Loss: 0.001495... Val Loss: 0.000421\n",
      "Epoch: 98/100... Step: 10153... Loss: 0.001376... Val Loss: 0.000428\n",
      "Epoch: 98/100... Step: 10154... Loss: 0.001251... Val Loss: 0.000440\n",
      "Epoch: 98/100... Step: 10155... Loss: 0.001166... Val Loss: 0.000442\n",
      "Epoch: 98/100... Step: 10156... Loss: 0.000934... Val Loss: 0.000438\n",
      "Epoch: 98/100... Step: 10157... Loss: 0.001030... Val Loss: 0.000436\n",
      "Epoch: 98/100... Step: 10158... Loss: 0.000735... Val Loss: 0.000437\n",
      "Epoch: 98/100... Step: 10159... Loss: 0.000803... Val Loss: 0.000447\n",
      "Epoch: 98/100... Step: 10160... Loss: 0.001020... Val Loss: 0.000443\n",
      "Epoch: 98/100... Step: 10161... Loss: 0.000777... Val Loss: 0.000431\n",
      "Epoch: 98/100... Step: 10162... Loss: 0.000995... Val Loss: 0.000417\n",
      "Epoch: 98/100... Step: 10163... Loss: 0.000312... Val Loss: 0.000412\n",
      "Epoch: 98/100... Step: 10164... Loss: 0.000662... Val Loss: 0.000394\n",
      "Epoch: 98/100... Step: 10165... Loss: 0.000713... Val Loss: 0.000394\n",
      "Epoch: 98/100... Step: 10166... Loss: 0.000844... Val Loss: 0.000392\n",
      "Epoch: 98/100... Step: 10167... Loss: 0.000492... Val Loss: 0.000393\n",
      "Epoch: 98/100... Step: 10168... Loss: 0.000524... Val Loss: 0.000386\n",
      "Epoch: 98/100... Step: 10169... Loss: 0.000670... Val Loss: 0.000365\n",
      "Epoch: 98/100... Step: 10170... Loss: 0.000426... Val Loss: 0.000354\n",
      "Epoch: 98/100... Step: 10171... Loss: 0.000663... Val Loss: 0.000341\n",
      "Epoch: 98/100... Step: 10172... Loss: 0.000960... Val Loss: 0.000329\n",
      "Epoch: 98/100... Step: 10173... Loss: 0.000810... Val Loss: 0.000325\n",
      "Epoch: 98/100... Step: 10174... Loss: 0.000549... Val Loss: 0.000327\n",
      "Epoch: 98/100... Step: 10175... Loss: 0.000678... Val Loss: 0.000320\n",
      "Epoch: 98/100... Step: 10176... Loss: 0.000600... Val Loss: 0.000316\n",
      "Epoch: 98/100... Step: 10177... Loss: 0.000675... Val Loss: 0.000314\n",
      "Epoch: 98/100... Step: 10178... Loss: 0.000428... Val Loss: 0.000328\n",
      "Epoch: 98/100... Step: 10179... Loss: 0.000441... Val Loss: 0.000319\n",
      "Epoch: 98/100... Step: 10180... Loss: 0.000747... Val Loss: 0.000321\n",
      "Epoch: 98/100... Step: 10181... Loss: 0.000529... Val Loss: 0.000325\n",
      "Epoch: 98/100... Step: 10182... Loss: 0.000953... Val Loss: 0.000333\n",
      "Epoch: 98/100... Step: 10183... Loss: 0.000633... Val Loss: 0.000319\n",
      "Epoch: 98/100... Step: 10184... Loss: 0.000911... Val Loss: 0.000311\n",
      "Epoch: 98/100... Step: 10185... Loss: 0.000724... Val Loss: 0.000317\n",
      "Epoch: 98/100... Step: 10186... Loss: 0.000829... Val Loss: 0.000319\n",
      "Epoch: 98/100... Step: 10187... Loss: 0.000930... Val Loss: 0.000324\n",
      "Epoch: 98/100... Step: 10188... Loss: 0.000638... Val Loss: 0.000343\n",
      "Epoch: 98/100... Step: 10189... Loss: 0.000752... Val Loss: 0.000329\n",
      "Epoch: 98/100... Step: 10190... Loss: 0.000663... Val Loss: 0.000352\n",
      "Epoch: 98/100... Step: 10191... Loss: 0.000591... Val Loss: 0.000363\n",
      "Epoch: 98/100... Step: 10192... Loss: 0.000565... Val Loss: 0.000344\n",
      "Epoch: 99/100... Step: 10193... Loss: 0.000867... Val Loss: 0.001945\n",
      "Epoch: 99/100... Step: 10194... Loss: 0.000899... Val Loss: 0.001868\n",
      "Epoch: 99/100... Step: 10195... Loss: 0.001173... Val Loss: 0.001725\n",
      "Epoch: 99/100... Step: 10196... Loss: 0.001311... Val Loss: 0.001616\n",
      "Epoch: 99/100... Step: 10197... Loss: 0.001230... Val Loss: 0.001497\n",
      "Epoch: 99/100... Step: 10198... Loss: 0.001350... Val Loss: 0.001378\n",
      "Epoch: 99/100... Step: 10199... Loss: 0.001098... Val Loss: 0.001249\n",
      "Epoch: 99/100... Step: 10200... Loss: 0.000766... Val Loss: 0.001119\n",
      "Epoch: 99/100... Step: 10201... Loss: 0.000911... Val Loss: 0.000973\n",
      "Epoch: 99/100... Step: 10202... Loss: 0.000948... Val Loss: 0.000849\n",
      "Epoch: 99/100... Step: 10203... Loss: 0.000827... Val Loss: 0.000741\n",
      "Epoch: 99/100... Step: 10204... Loss: 0.000648... Val Loss: 0.000661\n",
      "Epoch: 99/100... Step: 10205... Loss: 0.000785... Val Loss: 0.000617\n",
      "Epoch: 99/100... Step: 10206... Loss: 0.001174... Val Loss: 0.000565\n",
      "Epoch: 99/100... Step: 10207... Loss: 0.001232... Val Loss: 0.000523\n",
      "Epoch: 99/100... Step: 10208... Loss: 0.001177... Val Loss: 0.000495\n",
      "Epoch: 99/100... Step: 10209... Loss: 0.001092... Val Loss: 0.000461\n",
      "Epoch: 99/100... Step: 10210... Loss: 0.001061... Val Loss: 0.000453\n",
      "Epoch: 99/100... Step: 10211... Loss: 0.000621... Val Loss: 0.000445\n",
      "Epoch: 99/100... Step: 10212... Loss: 0.000901... Val Loss: 0.000424\n",
      "Epoch: 99/100... Step: 10213... Loss: 0.000666... Val Loss: 0.000425\n",
      "Epoch: 99/100... Step: 10214... Loss: 0.000906... Val Loss: 0.000421\n",
      "Epoch: 99/100... Step: 10215... Loss: 0.000722... Val Loss: 0.000410\n",
      "Epoch: 99/100... Step: 10216... Loss: 0.000857... Val Loss: 0.000418\n",
      "Epoch: 99/100... Step: 10217... Loss: 0.000919... Val Loss: 0.000416\n",
      "Epoch: 99/100... Step: 10218... Loss: 0.000752... Val Loss: 0.000420\n",
      "Epoch: 99/100... Step: 10219... Loss: 0.000561... Val Loss: 0.000416\n",
      "Epoch: 99/100... Step: 10220... Loss: 0.000687... Val Loss: 0.000422\n",
      "Epoch: 99/100... Step: 10221... Loss: 0.000707... Val Loss: 0.000420\n",
      "Epoch: 99/100... Step: 10222... Loss: 0.000664... Val Loss: 0.000420\n",
      "Epoch: 99/100... Step: 10223... Loss: 0.000623... Val Loss: 0.000415\n",
      "Epoch: 99/100... Step: 10224... Loss: 0.000701... Val Loss: 0.000408\n",
      "Epoch: 99/100... Step: 10225... Loss: 0.000552... Val Loss: 0.000411\n",
      "Epoch: 99/100... Step: 10226... Loss: 0.000782... Val Loss: 0.000411\n",
      "Epoch: 99/100... Step: 10227... Loss: 0.000582... Val Loss: 0.000415\n",
      "Epoch: 99/100... Step: 10228... Loss: 0.000480... Val Loss: 0.000418\n",
      "Epoch: 99/100... Step: 10229... Loss: 0.000721... Val Loss: 0.000416\n",
      "Epoch: 99/100... Step: 10230... Loss: 0.000534... Val Loss: 0.000419\n",
      "Epoch: 99/100... Step: 10231... Loss: 0.000636... Val Loss: 0.000421\n",
      "Epoch: 99/100... Step: 10232... Loss: 0.000437... Val Loss: 0.000421\n",
      "Epoch: 99/100... Step: 10233... Loss: 0.000720... Val Loss: 0.000408\n",
      "Epoch: 99/100... Step: 10234... Loss: 0.001279... Val Loss: 0.000402\n",
      "Epoch: 99/100... Step: 10235... Loss: 0.001402... Val Loss: 0.000401\n",
      "Epoch: 99/100... Step: 10236... Loss: 0.002056... Val Loss: 0.000395\n",
      "Epoch: 99/100... Step: 10237... Loss: 0.001678... Val Loss: 0.000392\n",
      "Epoch: 99/100... Step: 10238... Loss: 0.001812... Val Loss: 0.000392\n",
      "Epoch: 99/100... Step: 10239... Loss: 0.001932... Val Loss: 0.000384\n",
      "Epoch: 99/100... Step: 10240... Loss: 0.001734... Val Loss: 0.000379\n",
      "Epoch: 99/100... Step: 10241... Loss: 0.001655... Val Loss: 0.000371\n",
      "Epoch: 99/100... Step: 10242... Loss: 0.001635... Val Loss: 0.000370\n",
      "Epoch: 99/100... Step: 10243... Loss: 0.000941... Val Loss: 0.000362\n",
      "Epoch: 99/100... Step: 10244... Loss: 0.000839... Val Loss: 0.000359\n",
      "Epoch: 99/100... Step: 10245... Loss: 0.000966... Val Loss: 0.000358\n",
      "Epoch: 99/100... Step: 10246... Loss: 0.000899... Val Loss: 0.000358\n",
      "Epoch: 99/100... Step: 10247... Loss: 0.001207... Val Loss: 0.000352\n",
      "Epoch: 99/100... Step: 10248... Loss: 0.001252... Val Loss: 0.000347\n",
      "Epoch: 99/100... Step: 10249... Loss: 0.001241... Val Loss: 0.000345\n",
      "Epoch: 99/100... Step: 10250... Loss: 0.001196... Val Loss: 0.000340\n",
      "Epoch: 99/100... Step: 10251... Loss: 0.001699... Val Loss: 0.000342\n",
      "Epoch: 99/100... Step: 10252... Loss: 0.001170... Val Loss: 0.000338\n",
      "Epoch: 99/100... Step: 10253... Loss: 0.001155... Val Loss: 0.000338\n",
      "Epoch: 99/100... Step: 10254... Loss: 0.001234... Val Loss: 0.000342\n",
      "Epoch: 99/100... Step: 10255... Loss: 0.001375... Val Loss: 0.000344\n",
      "Epoch: 99/100... Step: 10256... Loss: 0.001170... Val Loss: 0.000340\n",
      "Epoch: 99/100... Step: 10257... Loss: 0.001036... Val Loss: 0.000334\n",
      "Epoch: 99/100... Step: 10258... Loss: 0.001370... Val Loss: 0.000335\n",
      "Epoch: 99/100... Step: 10259... Loss: 0.001539... Val Loss: 0.000335\n",
      "Epoch: 99/100... Step: 10260... Loss: 0.001563... Val Loss: 0.000338\n",
      "Epoch: 99/100... Step: 10261... Loss: 0.000468... Val Loss: 0.000345\n",
      "Epoch: 99/100... Step: 10262... Loss: 0.000887... Val Loss: 0.000340\n",
      "Epoch: 99/100... Step: 10263... Loss: 0.000994... Val Loss: 0.000349\n",
      "Epoch: 99/100... Step: 10264... Loss: 0.000788... Val Loss: 0.000359\n",
      "Epoch: 99/100... Step: 10265... Loss: 0.001185... Val Loss: 0.000362\n",
      "Epoch: 99/100... Step: 10266... Loss: 0.000617... Val Loss: 0.000360\n",
      "Epoch: 99/100... Step: 10267... Loss: 0.000599... Val Loss: 0.000360\n",
      "Epoch: 99/100... Step: 10268... Loss: 0.000647... Val Loss: 0.000366\n",
      "Epoch: 99/100... Step: 10269... Loss: 0.000702... Val Loss: 0.000368\n",
      "Epoch: 99/100... Step: 10270... Loss: 0.000354... Val Loss: 0.000370\n",
      "Epoch: 99/100... Step: 10271... Loss: 0.000576... Val Loss: 0.000371\n",
      "Epoch: 99/100... Step: 10272... Loss: 0.000699... Val Loss: 0.000376\n",
      "Epoch: 99/100... Step: 10273... Loss: 0.000637... Val Loss: 0.000380\n",
      "Epoch: 99/100... Step: 10274... Loss: 0.000521... Val Loss: 0.000379\n",
      "Epoch: 99/100... Step: 10275... Loss: 0.000381... Val Loss: 0.000379\n",
      "Epoch: 99/100... Step: 10276... Loss: 0.000389... Val Loss: 0.000374\n",
      "Epoch: 99/100... Step: 10277... Loss: 0.000836... Val Loss: 0.000386\n",
      "Epoch: 99/100... Step: 10278... Loss: 0.000434... Val Loss: 0.000388\n",
      "Epoch: 99/100... Step: 10279... Loss: 0.000397... Val Loss: 0.000385\n",
      "Epoch: 99/100... Step: 10280... Loss: 0.000704... Val Loss: 0.000390\n",
      "Epoch: 99/100... Step: 10281... Loss: 0.000563... Val Loss: 0.000393\n",
      "Epoch: 99/100... Step: 10282... Loss: 0.000537... Val Loss: 0.000397\n",
      "Epoch: 99/100... Step: 10283... Loss: 0.000611... Val Loss: 0.000398\n",
      "Epoch: 99/100... Step: 10284... Loss: 0.000496... Val Loss: 0.000399\n",
      "Epoch: 99/100... Step: 10285... Loss: 0.000700... Val Loss: 0.000394\n",
      "Epoch: 99/100... Step: 10286... Loss: 0.000829... Val Loss: 0.000391\n",
      "Epoch: 99/100... Step: 10287... Loss: 0.000725... Val Loss: 0.000395\n",
      "Epoch: 99/100... Step: 10288... Loss: 0.000579... Val Loss: 0.000392\n",
      "Epoch: 99/100... Step: 10289... Loss: 0.000929... Val Loss: 0.000394\n",
      "Epoch: 99/100... Step: 10290... Loss: 0.000598... Val Loss: 0.000398\n",
      "Epoch: 99/100... Step: 10291... Loss: 0.000835... Val Loss: 0.000413\n",
      "Epoch: 99/100... Step: 10292... Loss: 0.000802... Val Loss: 0.000404\n",
      "Epoch: 99/100... Step: 10293... Loss: 0.000779... Val Loss: 0.000412\n",
      "Epoch: 99/100... Step: 10294... Loss: 0.000684... Val Loss: 0.000406\n",
      "Epoch: 99/100... Step: 10295... Loss: 0.000767... Val Loss: 0.000393\n",
      "Epoch: 99/100... Step: 10296... Loss: 0.000513... Val Loss: 0.000402\n",
      "Epoch: 100/100... Step: 10297... Loss: 0.001208... Val Loss: 0.001708\n",
      "Epoch: 100/100... Step: 10298... Loss: 0.001460... Val Loss: 0.001682\n",
      "Epoch: 100/100... Step: 10299... Loss: 0.001213... Val Loss: 0.001549\n",
      "Epoch: 100/100... Step: 10300... Loss: 0.001342... Val Loss: 0.001454\n",
      "Epoch: 100/100... Step: 10301... Loss: 0.001511... Val Loss: 0.001389\n",
      "Epoch: 100/100... Step: 10302... Loss: 0.001338... Val Loss: 0.001295\n",
      "Epoch: 100/100... Step: 10303... Loss: 0.001291... Val Loss: 0.001169\n",
      "Epoch: 100/100... Step: 10304... Loss: 0.000553... Val Loss: 0.001046\n",
      "Epoch: 100/100... Step: 10305... Loss: 0.001104... Val Loss: 0.000940\n",
      "Epoch: 100/100... Step: 10306... Loss: 0.000847... Val Loss: 0.000824\n",
      "Epoch: 100/100... Step: 10307... Loss: 0.000718... Val Loss: 0.000724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100... Step: 10308... Loss: 0.001122... Val Loss: 0.000637\n",
      "Epoch: 100/100... Step: 10309... Loss: 0.000825... Val Loss: 0.000548\n",
      "Epoch: 100/100... Step: 10310... Loss: 0.000911... Val Loss: 0.000482\n",
      "Epoch: 100/100... Step: 10311... Loss: 0.001639... Val Loss: 0.000432\n",
      "Epoch: 100/100... Step: 10312... Loss: 0.001129... Val Loss: 0.000393\n",
      "Epoch: 100/100... Step: 10313... Loss: 0.000994... Val Loss: 0.000378\n",
      "Epoch: 100/100... Step: 10314... Loss: 0.000934... Val Loss: 0.000372\n",
      "Epoch: 100/100... Step: 10315... Loss: 0.000682... Val Loss: 0.000359\n",
      "Epoch: 100/100... Step: 10316... Loss: 0.000818... Val Loss: 0.000351\n",
      "Epoch: 100/100... Step: 10317... Loss: 0.000916... Val Loss: 0.000347\n",
      "Epoch: 100/100... Step: 10318... Loss: 0.000787... Val Loss: 0.000341\n",
      "Epoch: 100/100... Step: 10319... Loss: 0.000976... Val Loss: 0.000328\n",
      "Epoch: 100/100... Step: 10320... Loss: 0.000624... Val Loss: 0.000310\n",
      "Epoch: 100/100... Step: 10321... Loss: 0.000762... Val Loss: 0.000302\n",
      "Epoch: 100/100... Step: 10322... Loss: 0.000606... Val Loss: 0.000294\n",
      "Epoch: 100/100... Step: 10323... Loss: 0.000928... Val Loss: 0.000279\n",
      "Validation loss decreased (0.000287 --> 0.000279).  Saving model ...\n",
      "Epoch: 100/100... Step: 10324... Loss: 0.000577... Val Loss: 0.000262\n",
      "Validation loss decreased (0.000262 --> 0.000260).  Saving model ...\n",
      "Epoch: 100/100... Step: 10326... Loss: 0.000663... Val Loss: 0.000252\n",
      "Validation loss decreased (0.000260 --> 0.000252).  Saving model ...\n",
      "Epoch: 100/100... Step: 10327... Loss: 0.000691... Val Loss: 0.000249\n",
      "Validation loss decreased (0.000252 --> 0.000249).  Saving model ...\n",
      "Epoch: 100/100... Step: 10328... Loss: 0.000505... Val Loss: 0.000242\n",
      "Validation loss decreased (0.000249 --> 0.000242).  Saving model ...\n",
      "Epoch: 100/100... Step: 10329... Loss: 0.000446... Val Loss: 0.000235\n",
      "Validation loss decreased (0.000242 --> 0.000235).  Saving model ...\n",
      "Epoch: 100/100... Step: 10330... Loss: 0.000762... Val Loss: 0.000238\n",
      "Epoch: 100/100... Step: 10331... Loss: 0.000382... Val Loss: 0.000235\n",
      "Validation loss decreased (0.000235 --> 0.000235).  Saving model ...\n",
      "Epoch: 100/100... Step: 10332... Loss: 0.000717... Val Loss: 0.000228\n",
      "Validation loss decreased (0.000235 --> 0.000228).  Saving model ...\n",
      "Epoch: 100/100... Step: 10333... Loss: 0.000926... Val Loss: 0.000218\n",
      "Validation loss decreased (0.000228 --> 0.000218).  Saving model ...\n",
      "Epoch: 100/100... Step: 10334... Loss: 0.000754... Val Loss: 0.000213\n",
      "Validation loss decreased (0.000218 --> 0.000213).  Saving model ...\n",
      "Epoch: 100/100... Step: 10335... Loss: 0.000757... Val Loss: 0.000209\n",
      "Validation loss decreased (0.000213 --> 0.000209).  Saving model ...\n",
      "Epoch: 100/100... Step: 10336... Loss: 0.000665... Val Loss: 0.000207\n",
      "Validation loss decreased (0.000209 --> 0.000207).  Saving model ...\n",
      "Epoch: 100/100... Step: 10337... Loss: 0.000608... Val Loss: 0.000204\n",
      "Validation loss decreased (0.000207 --> 0.000204).  Saving model ...\n",
      "Epoch: 100/100... Step: 10338... Loss: 0.001349... Val Loss: 0.000209\n",
      "Epoch: 100/100... Step: 10339... Loss: 0.001531... Val Loss: 0.000209\n",
      "Epoch: 100/100... Step: 10340... Loss: 0.001756... Val Loss: 0.000211\n",
      "Epoch: 100/100... Step: 10341... Loss: 0.001829... Val Loss: 0.000216\n",
      "Epoch: 100/100... Step: 10342... Loss: 0.001743... Val Loss: 0.000208\n",
      "Epoch: 100/100... Step: 10343... Loss: 0.001575... Val Loss: 0.000210\n",
      "Epoch: 100/100... Step: 10344... Loss: 0.001558... Val Loss: 0.000214\n",
      "Epoch: 100/100... Step: 10345... Loss: 0.001731... Val Loss: 0.000214\n",
      "Epoch: 100/100... Step: 10346... Loss: 0.001537... Val Loss: 0.000216\n",
      "Epoch: 100/100... Step: 10347... Loss: 0.001349... Val Loss: 0.000219\n",
      "Epoch: 100/100... Step: 10348... Loss: 0.001082... Val Loss: 0.000217\n",
      "Epoch: 100/100... Step: 10349... Loss: 0.000612... Val Loss: 0.000213\n",
      "Epoch: 100/100... Step: 10350... Loss: 0.001015... Val Loss: 0.000217\n",
      "Epoch: 100/100... Step: 10351... Loss: 0.001554... Val Loss: 0.000220\n",
      "Epoch: 100/100... Step: 10352... Loss: 0.001219... Val Loss: 0.000233\n",
      "Epoch: 100/100... Step: 10353... Loss: 0.001353... Val Loss: 0.000243\n",
      "Epoch: 100/100... Step: 10354... Loss: 0.001331... Val Loss: 0.000244\n",
      "Epoch: 100/100... Step: 10355... Loss: 0.001534... Val Loss: 0.000255\n",
      "Epoch: 100/100... Step: 10356... Loss: 0.001695... Val Loss: 0.000256\n",
      "Epoch: 100/100... Step: 10357... Loss: 0.001458... Val Loss: 0.000249\n",
      "Epoch: 100/100... Step: 10358... Loss: 0.001199... Val Loss: 0.000242\n",
      "Epoch: 100/100... Step: 10359... Loss: 0.001216... Val Loss: 0.000247\n",
      "Epoch: 100/100... Step: 10360... Loss: 0.001315... Val Loss: 0.000251\n",
      "Epoch: 100/100... Step: 10361... Loss: 0.001436... Val Loss: 0.000260\n",
      "Epoch: 100/100... Step: 10362... Loss: 0.001314... Val Loss: 0.000255\n",
      "Epoch: 100/100... Step: 10363... Loss: 0.000962... Val Loss: 0.000257\n",
      "Epoch: 100/100... Step: 10364... Loss: 0.000873... Val Loss: 0.000243\n",
      "Epoch: 100/100... Step: 10365... Loss: 0.000866... Val Loss: 0.000239\n",
      "Epoch: 100/100... Step: 10366... Loss: 0.000968... Val Loss: 0.000242\n",
      "Epoch: 100/100... Step: 10367... Loss: 0.000976... Val Loss: 0.000241\n",
      "Epoch: 100/100... Step: 10368... Loss: 0.000870... Val Loss: 0.000251\n",
      "Epoch: 100/100... Step: 10369... Loss: 0.001003... Val Loss: 0.000248\n",
      "Epoch: 100/100... Step: 10370... Loss: 0.000556... Val Loss: 0.000255\n",
      "Epoch: 100/100... Step: 10371... Loss: 0.000614... Val Loss: 0.000251\n",
      "Epoch: 100/100... Step: 10372... Loss: 0.000784... Val Loss: 0.000263\n",
      "Epoch: 100/100... Step: 10373... Loss: 0.000538... Val Loss: 0.000261\n",
      "Epoch: 100/100... Step: 10374... Loss: 0.000513... Val Loss: 0.000273\n",
      "Epoch: 100/100... Step: 10375... Loss: 0.000454... Val Loss: 0.000276\n",
      "Epoch: 100/100... Step: 10376... Loss: 0.000606... Val Loss: 0.000277\n",
      "Epoch: 100/100... Step: 10377... Loss: 0.000639... Val Loss: 0.000272\n",
      "Epoch: 100/100... Step: 10378... Loss: 0.001032... Val Loss: 0.000277\n",
      "Epoch: 100/100... Step: 10379... Loss: 0.000357... Val Loss: 0.000270\n",
      "Epoch: 100/100... Step: 10380... Loss: 0.000425... Val Loss: 0.000275\n",
      "Epoch: 100/100... Step: 10381... Loss: 0.000699... Val Loss: 0.000287\n",
      "Epoch: 100/100... Step: 10382... Loss: 0.000744... Val Loss: 0.000283\n",
      "Epoch: 100/100... Step: 10383... Loss: 0.000419... Val Loss: 0.000292\n",
      "Epoch: 100/100... Step: 10384... Loss: 0.000534... Val Loss: 0.000290\n",
      "Epoch: 100/100... Step: 10385... Loss: 0.000519... Val Loss: 0.000283\n",
      "Epoch: 100/100... Step: 10386... Loss: 0.000477... Val Loss: 0.000285\n",
      "Epoch: 100/100... Step: 10387... Loss: 0.000382... Val Loss: 0.000300\n",
      "Epoch: 100/100... Step: 10388... Loss: 0.000601... Val Loss: 0.000302\n",
      "Epoch: 100/100... Step: 10389... Loss: 0.000591... Val Loss: 0.000295\n",
      "Epoch: 100/100... Step: 10390... Loss: 0.000565... Val Loss: 0.000285\n",
      "Epoch: 100/100... Step: 10391... Loss: 0.000632... Val Loss: 0.000303\n",
      "Epoch: 100/100... Step: 10392... Loss: 0.000714... Val Loss: 0.000305\n",
      "Epoch: 100/100... Step: 10393... Loss: 0.000860... Val Loss: 0.000318\n",
      "Epoch: 100/100... Step: 10394... Loss: 0.000611... Val Loss: 0.000332\n",
      "Epoch: 100/100... Step: 10395... Loss: 0.000709... Val Loss: 0.000332\n",
      "Epoch: 100/100... Step: 10396... Loss: 0.000836... Val Loss: 0.000342\n",
      "Epoch: 100/100... Step: 10397... Loss: 0.000583... Val Loss: 0.000345\n",
      "Epoch: 100/100... Step: 10398... Loss: 0.000632... Val Loss: 0.000353\n",
      "Epoch: 100/100... Step: 10399... Loss: 0.000976... Val Loss: 0.000353\n",
      "Epoch: 100/100... Step: 10400... Loss: 0.000513... Val Loss: 0.000353\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "counter = 0\n",
    "print_every = 1\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr,\n",
    "                                                   steps_per_epoch=len(train_loader),\n",
    "                                                   epochs=epochs)\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(BATCH_SIZE)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        h = tuple([e.data for e in h])\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = tuple([each.data for each in h])#model.init_hidden(BATCH_SIZE)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(DEVICE), lab.to(DEVICE)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) < valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Visualizer:\n",
    "    colors=['blue','black', 'red']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.date_pred_targ_dict: dict = dict()\n",
    "        \n",
    "    def add(self, timestamp, pred, targ, color='red'):\n",
    "        self.date_pred_targ_dict[color] = pd.concat([self.date_pred_targ_dict.get(color, pd.DataFrame()),\n",
    "                                                     pd.concat([pd.DataFrame(timestamp),\n",
    "                                                       pd.DataFrame(pred),\n",
    "                                                       pd.DataFrame(targ)], axis=1)])\n",
    "    \n",
    "    def plot(self):\n",
    "        for color in self.colors:\n",
    "            color_df = visualizer.date_pred_targ_dict.get(color, pd.DataFrame())\n",
    "            plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "            plt.plot(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "            plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "            plt.plot(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:02<00:00, 32.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 88.13it/s]\n",
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]C:\\Users\\octav\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\octav\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\octav\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 58.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: 0.00000031\n",
      "MAE loss: 0.00052199\n",
      "KLDiv loss: -0.07917054\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "visualizer = Visualizer()\n",
    "\n",
    "mse_losses = []\n",
    "mae_losses = []\n",
    "kldiv_losses = []\n",
    "num_correct = 0\n",
    "custom_batch = BATCH_SIZE\n",
    "index_of_elapsed = train_data.columns.tolist().index(ELAPSED)\n",
    "\n",
    "h = model.init_hidden(custom_batch)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in tqdm(train_loader):\n",
    "    if inputs.shape[0] != custom_batch:\n",
    "        continue\n",
    "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "    output, h = model(inputs, h)\n",
    "    visualizer.add(inputs[:,index_of_elapsed], output, labels[:,-1], color='black')\n",
    "    \n",
    "for inputs, labels in tqdm(val_loader):\n",
    "    if inputs.shape[0] != custom_batch:\n",
    "        continue\n",
    "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "    output, h = model(inputs, h)\n",
    "    visualizer.add(inputs[:,index_of_elapsed], output, labels[:,-1], color='blue')\n",
    "    \n",
    "for inputs, labels in tqdm(test_loader):\n",
    "    if inputs.shape[0] != custom_batch:\n",
    "        continue\n",
    "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "    output, h = model(inputs, h)\n",
    "    visualizer.add(inputs[:,index_of_elapsed], output, labels[:,-1])\n",
    "    mse_losses.append(nn.MSELoss()(output.squeeze(), labels.float()).item())\n",
    "    mae_losses.append(nn.L1Loss()(output.squeeze(), labels.float()).item())\n",
    "    kldiv_losses.append(nn.KLDivLoss()(output.squeeze(), labels.float()).item())\n",
    "    \n",
    "\n",
    "print(\"MSE loss: {:.8f}\".format(np.mean(mse_losses)))\n",
    "print(\"MAE loss: {:.8f}\".format(np.mean(mae_losses)))\n",
    "print(\"KLDiv loss: {:.8f}\".format(np.mean(kldiv_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS10 maxLR==lr 2lstms\n",
    "lr=0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# visualizer.plot()\n",
    "# for color in ['blue', 'red']:\n",
    "for color in ['red']:\n",
    "    color_df = visualizer.date_pred_targ_dict.get(color, pd.DataFrame())\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS10 maxLR==0.01 3lstms\n",
    "Epoch: 85/100... Step: 8738... Loss: 0.000911... Val Loss: 0.000262\n",
    "Validation loss decreased (0.000265 --> 0.000262).  Saving model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# visualizer.plot()\n",
    "# for color in ['blue', 'red']:\n",
    "for color in ['red']:\n",
    "    color_df = visualizer.date_pred_targ_dict.get(color, pd.DataFrame())\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS10 maxLR==0.01 2lstms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# visualizer.plot()\n",
    "for color in ['blue', 'red']:\n",
    "# for color in ['red']:\n",
    "    color_df = visualizer.date_pred_targ_dict.get(color, pd.DataFrame())\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BS10 maxLR==0.001 2lstms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# visualizer.plot()\n",
    "for color in ['blue', 'red']:\n",
    "# for color in ['red']:\n",
    "    color_df = visualizer.date_pred_targ_dict.get(color, pd.DataFrame())\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJCCAYAAABAuEcoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3X90XHd95//XZ0YjW2M5SjzKpoSgUVoCbUAEiApls9+2YLanib+BxN8ettuR49qAYqldnOX0y7ZMG8eB4dsGusR0KxvtaVzHc0sWWichxCkFL116+Lbbyl82EYFCKCuZAC2xAoplydaP+Xz/kO94ftx7545mRjOSno9zdOy5c++dz9yZuT/e9/15f4y1VgAAAAAAAIAkRZrdAAAAAAAAALQOgkUAAAAAAADII1gEAAAAAACAPIJFAAAAAAAAyCNYBAAAAAAAgDyCRQAAAAAAAMgjWAQAAAAAAIA8gkUAAAAAAADII1gEAAAAAACAvLZmN6BUd3e37e3tbXYzAAAAAAAA1o3Tp0+ftdZeHWbelgsW9fb2amxsrNnNAAAAAAAAWDeMMZNh56UbGgAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2ARAAAAAAAA8ggWAQAAAAAAII9gEQAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2ARAAAAAAAA8ggWAQAAAAAAII9gEQAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2ARAAAAAAAA8ggWAQAAAAAAII9gEQAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2ARAAAAAAAA8ggWAQAAAAAAII9gEQAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2ARAAAAAAAA8ggWAQAAAAAAII9gEQAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2ARAAAAAAAA8ggWAQAAAAAAII9gEQAAAAAAAPJCBYuMMb9sjPmmMebbxpjf9nj+/caYrxtjnjHGnDLGJC9NTxpjThtj/pcx5lljzL56vwEAAAAAAADUT8VgkTEmKumPJd0q6UZJ/94Yc2PJbF+V1G+tfZ2kP5f0wKXpP5D0r621r5f0Zkm/bYy5tl6NBwAAAAAAQH2FySx6k6RvW2u/Y62dl/SIpHcWzmCt/ZK1dvbSw7+TdN2l6fPW2ouXpm8K+XoAAAAAAABokjDBm5dL+m7B4+cvTfPzbklPuQ+MMa8wxjxzaR1/YK39fukCxphBY8yYMWbshRdeCNdyAAAAAAAA1F2YYJHxmGY9ZzRmQFK/pI/mZ7T2u5e6p71S0m5jzDVlK7N21Frbb63tv/rqq8O1HAAAAAAAAHUXJlj0vKRXFDy+TpJXdtDbJaUlvaOg61nepYyiZyX9HytrKgAAAAAAABotTLDoHyTdYIy53hjTLulXJX22cAZjzBskfVLLgaIfFky/zhjTcen/V0m6RdI369V4AAAAAAAA1FdbpRmstYvGmN+U9HlJUUkPWWufNcbcL2nMWvtZLXc765T0GWOMJJ2x1r5D0s9I+kNjjNVyd7aPWWvHG/ReAAAAAAAAUCNjrWf5oabp7++3Y2NjzW4GAAAAAADAumGMOW2t7Q8zL0PZAwAAAAAAII9gEQAAAAAAAPIIFgEAAAAAACCPYBEAAAAAAADyCBYBAAAAAAAgj2BRi3LGHfU+2KvIwYh6H+yVM+40u0kAAAAAAGADaGt2A1DOGXc0+MSgZhdmJUmT05MafGJQkpTqSzWzaQAAAAAAYJ0js6gFpU+l84Ei1+zCrNKn0k1qEQAAAAAA2CgIFrWgM9NnqpoOAAAAAABQLwSLWlBPV09V0wEAAAAAAOqFYFELymzPKB6LF02Lx+LKbM80qUUAAAAAAGCjIFjUglJ9KY3ePpp/nOxKavT2UYpbAwAAAACAhiNY1KIKA0MT90wQKAIAAAAAAKuCYNEaYK1tdhMAAAAAAMAGQbBoDbiweKHZTQAAAAAAABsEwaImcRxHvb29ikQi6u3tleM4vvO+dPGlVWwZAAAAAADYyNqa3YCNyHEcDQ4OanZ2VpI0OTmpwcFBSVIqVV6b6KWLL+mazmtWtY0AAAAAAGBjIrOoCdLpdD5Q5JqdnVU6nfac/9z8udVoFgAAAAAAAMGiZjhz5kzF6Tmby/+fbmgAAAAAAGC1ECxqgp6enorTF5YW8v9/67G3qvfBXjnj/nWNAAAAAAAA6oFgURNkMhnF4/GiafF4XJlMJv84O54ten5yelKDTwwSMAIAAAAAAA1FsKgJUqmURkdH84+TyaRGR0eLilvf99f3lS03uzCr9KniukbOuKPeB3sVORgh+wgAAAAAANTMWGub3YYi/f39dmxsrNnNWBXGGEmS12dgDhrvZWSUO7Bcz8gZdzT4xKBmF2aLnt/Xv08jO0Ya0GIAAAAAALAWGWNOW2v7w8xLZlGLevnWl3tO7+m6XNcofSpdFCiSJCurI2NHyDACAAAAAAArQrCoRf3Wv/6tsmnxWFyZ7ZfrGp2Z9h5Vzcrmu6vRTQ0AAAAAAFSDYFGL2nHDjqLHya6kRm8fVarvcl2jwiyjUmemz2j4yWHtOrFLk9OTsrIUyQYAAAAAABURLGpRC7mF/P/3v3m/Ju6ZKAoUSdJtN9zmu/y2jm06MnZEVsX1kLyKZAMAAAAAALjamt0AeFtYuhwsurB4If9/Z9zR/qf2a2puyndZI6OLSxfLAkUuv+5rAAAAAAAAZBa1qMXcYv7/F5cuSloOFO15bE9goEharlk0Mz/j+/y2jm3UMQIAAAAAAJ7ILGpRhd3Q3Myi9Kl00fSVOjd/Lh9wcusYfeXMV3TyuZM6M31GPV09ymzPlHV7AwAAAAAA6x/BohZV2A3t4uJyZlE9uo8ZGc0vzRdNm12YLapv5AaQJBEwAgAAAABgg6EbWovyyiwKGv3MS6Ijoc1tm4um+dUxohA2AAAAAACQCBa1LDezKGIi+ZpFme0ZxSKx0Ot412vepbbIypPHKIQNAAAAAMDGQ7CoRbmZRVvbt+Yzi1J9KR2946g62jpCrePkcycDC127jIzn9GozmQAAAAAAwNpHsKhFFWYWjX1/LD9ymSS9783vUywSUzwWD1zHmekzoQJLP9P9M57Tb7vhtuoaDQAAAAAA1jwKXLeY4SeHNXp6VEt2SZL0ows/yj83OT2pXSd2ycoqYiJ6z03v0cnnTmpyetJzXT1dPeqIdegfz/5j4Gt+c+qbntNPPndyhe9i7XHGHe1/an9+lLhER0KHbj1EgW8AAAAAwIZDZlELGX5yWIfHDucDRV7cQtQ5m9Oxp48psz2j7M5sWZZRPBZXZntGHW0dFesc+b3eRqlZ5Iw72vPYnnygSJKm5qa09/G9csadJrYMAAAAAIDVR7CohYyeHq1qfnfEslRfSqO3j+plnS+TJF0dv1qjt48q1ZfSuflz6r+2f0Xt2Sg1i9Kn0kWjz7nml+a1+9Hd+S6ABI4AAAAAABsBwaIWEpRR5MfN/kn1pfS37/5bSdLvv/33892nXrr4kl53zeuU6EhUtd72aLsy2zNVt2ctCsqgWrJLsrKanJ7U4BODBIwAAAAAAOsewaIWEjXRqpcpzP7Z1rFNkjQ1u9ydyhl39ML5F/TJ05/Mj6gW1mJuseq2rFXudqvEzeQCAAAAAGA9I1jUQgZvHqxqfiNTNGJZZ3unYpGYXpx7Uc64o/d+9r35GkfnF85Xte6czW2ITJrhJ4eLahVVslHqOAEAAAAANi6CRS1kZMeIbntl8XD1r7vmdfn//9JP/VLRc1ZWx54+lg/o/NnX/kxLdkm//5Xf1+5Hd2tuca6m9qz3TBpn3NGRsSNVLbNR6jgBAAAAADYugkUt5s6fubPo8Vt735r//xf+6Qtl87sBHWfc0eATg8rZnKSV1T/ysp4zadKn0vnMqzCMzIap4wQAAAAA2LgIFrUQZ9zRb/3VbxVN+8T//ET+/36BjTPTZ5Q+ldbswmzd27SeM2mqDYRZ2XzhcAAAAAAA1iuCRS3CzQyavjhdND1M5ktPV09DMoDisfi6zqSpNhBW7YhyAAAAAACsRQSLWsRKM4PcgE6lwEeiI6FER0JGRsmuZMX1Xrf1Oo3ePrquM2ky2zPqaOsIPf+5+XPrvuA3AAAAAABtzW4Alk1OT1a9TNREiwI6g08MFgWc2qPtml+a18T+CSWvLA4Qtd3f5lnXyMjIyuoLd31Bp39wWr0P9mpyelJRE9WSXVKyK6nM9sy6CCKl+lKavjCt3zj5G6Hmn1+a1+5Hd+eXBQAAAABgPSKzqAU4446MTNXLHbvzWD5okepLafT20XxXqWs7r9Wv3PgrkqQrN19ZtuzgzYOe69xxww5J0pv/65s1cGIgH8RyA0uT05MafGJwXWTYOOOOPvTlD1W1zJJd0p7H9qyL9w8AAAAAgBeCRS2g2lG5pOVuZaXZLam+VD4I9P2Z7+vJbz0pI6Otm7aWLT+yY0RD/UOKmqik5Sylof4hdcSWu2W9NP+S72u7I7CtZW6NqH+e+eeql13ILWj/U/sb0CoAAAAAAJqPYFELCCpO7ZVxFI/FdejWQ2XTnXFHH/+7j+cfT1+clpXVb578Tc91j+wY0eK9i7IHrBbvXdQtPbfoM1//TM1tXguCakSFyfKampuqd5MAAAAAAGgJBItagF9x6mRXUrkDOWV3ZnXFpiskSZ3tnb6Fp9On0rqweKFs+uGxwxp+crhiO6rJFqp2JLFW4xfsMjI6vvN4qCLgAAAAAACsRwSLWkBme0bxWLxoWuGw9am+lN7x6ndIkmbmZ5Q+lfasmROU7XNk7EjFOjths4UK27ZW+QW7erp6lOpLaeKeicCAkVsbCgAAAACA9YZg0Spzxh31Ptgrc/ByV6f9T+0v6vqU6EgUZQ85444+/eyn88/7FZkOyvaxshUzh7Z1bAv1HnbftHvNjwZWKUAnVQ6eRQ5G1PtgL8WuAQAAAADrCsGiVeQWVXZHGHNNzU7p/ML5/OO5xbmi59On0ppfmi+a5lVkulK2T73qDJ187mRd1tNM7uhxW2JbJC13+Svt3hcUfJuam5KVXVejwwEAAAAAIBEsWlVlRZV/QtIVUulAaLMLs0WjbfkFebymu6ObealUZ+jFuRcDn3dNTk+GqoHU6lJ9Ke141Q69OvFqTdwzUZYt5ZV95GU9jA4HAAAAAICLYNEqKgvu7JM0pLJgkbScueJmqwTV1ymUPpXWkl3ynDdMnaFqilaHLZrdityugJGDET3xzSfKsrZcbvZRUADOtdZHhwMAAAAAwEWwaBV5BmM6JL+R2t1slTD1daTggIXfCGqFwmbS5Nd5ejT0vK2isCugldXc4pwmpyd9u5Gl+lLK2VzF9UZMpGgdhQEp6hoBAAAAANYSgkWryDezxydY5AZ/3AyXZFdSRsazvo7knxmU7EqGKkhd+jqJjkS+po8XvyymVlbWFVBSzuYCu5GFybhaskv52kWlASnqGgEAAAAA1hJjrUcfqCbq7++3Y2NjzW5GQzjjjgZODFye8KikO/3nT3YlNXHPRFXrH3xisCgYEo/FQ2UVBWm7v80zMBQ1US3eu7ji9a4mZ9xR+lS6rLi4y8god8A7g8hru/pJdiUlyfN1qv08AQAAAACoF2PMaWttf5h5ySxaRYVFqyVJ3/efN0yNoVJhM5CqNXjzYFXTW43fKHSFtnVs833O3a4dbR0VX+vM9Bnf7oBBrw8AAAAAQKsgWLRKnHFHU3NTxROnJH1N0sXiybUEeVJ9KU3cM6HcgZznCF8rMbJjREP9QzKX+stFFNFQ/5BGdoyUzduKtXq8up6VOjd/LrCtqb5UqGBRT1ePb7c1I9MS2wMAAAAAgCAEi1aJZ02cnKQ/v/TvJYmORN2CPPU0smNEj/zKI5KkZ4ae8Q0U7X18b1Gtnr2P721agMQNXIXJ6Jlfmg+sW+SMO3rxwosV1zM5PamZ+RnP56xs4GsAAAAAANAKCBatksCh1S8Fi2KRmA7demh1GrQCbmbN3OKc5/P7n9pfNgz9/NJ8efe7VRCm61mpoHmrCfKUZZAVCPweAAAAAADQAggWrZLAEbXsctezo3ccbbmMokKb2zZLkuYWvINFfkGSqbkpRe+PavjJ4Ya1rVSYrmelgrqJ1SvIEzERuqIBAAAAAFpaqGCRMeaXjTHfNMZ82xjz2x7Pv98Y83VjzDPGmFPGmOSl6a83xvytMebZS8/9u3q/gbUisz2jeCzu+dx1j1ynM+8/o/TtaTlO6wYSOmLLmUUXFi+UPVcpAJKzOR0eO7wqASNn3FlRMemgbmKBwb4qLNkl7Tqxa1UDZwAAAAAAVKNisMgYE5X0x5JulXSjpH9vjLmxZLavSuq31r5Oy1V4Hrg0fVbSXdba10j6ZUkPGmOurFfj1xJ3RK2IWd7k7hDrkvT888/LWqvJyUkNDg62bMDIrxua2+UrjMNjhxta+LqatnjxyyAKCvZVy8rq8NhhmYNG3Q90k2kEAAAAAGgpYTKL3iTp29ba71hr5yU9IumdhTNYa79krXX7/PydpOsuTf+Wtfa5S///vqQfSrq6Xo1fa37ttb8mI6MP/psPauKeCc95ZmdnlU63ZhFkN7OotBtatV2+JqcnNXBioCGBkpV0Pyvkl0HkBvuSXcn8qHD1MDU3pYETA3XNNGrFEekAAAAAAGtHmGDRyyV9t+Dx85em+Xm3pKdKJxpj3iSpXdI/VdPA9WRmfkZLdklXdVwVON+ZM61ZBNkvs2glXb6k5UDJ4BODdQ1mrLQtkhSPxZXZnvF9PtWX0sQ9E8odyBVlhtXDkbEjddkOhYW93RHpSrcxwSQAAAAAQJAwwSKvNArrOaMxA5L6JX20ZPrLJB2XtMdam/NYbtAYM2aMGXvhhRdCNGlt+tGFH0mSrtocHCzq6alPfZx6cwtcl9Ysiproitc5uzBbt9HSnHGnqqyfWCSmREdCRkbJrqRGbx8NXWC8nt3SpOB6SWE5447uevSussyq2YXZ/Lq9gknUUAIAAAAAFGoLMc/zkl5R8Pg6Sd8vnckY83ZJaUm/YK29WDD9CklPSvpda+3feb2AtXZU0qgk9ff3ewai1oMfzV0KFgVkFsXjcWUy/tktzeTXDW3JLtW03qm5KTnjTs0jwaVPpWW945h5URPVkl1SsiupzPbMil/TXe7uJ+7W+YXzK1pHqZWOuOaMOxXbMTk9qcjBiCImUvZ5WVkdGTuiW3puaenR+AAAAAAAqyNMZtE/SLrBGHO9MaZd0q9K+mzhDMaYN0j6pKR3WGt/WDC9XdKjkh621n6mfs1eG5xxR90PdMscNDIHjd7wyTdIkoafHPbs+pNMJjU6OqpUqjUv2P26oSU6EjWvu9asGik42BKPxZXdmdXivYuyB6wm7pmoOTCS6ktp5oMzGuofqim7yrWtY1vVyzjjjvY8tidUwMrK+gb26pHZBAAAAABYHyoGi6y1i5J+U9LnJX1D0qettc8aY+43xrzj0mwfldQp6TPGmP9ljHGDSe+S9POSfv3S9P9ljHl9/d9G63Ev4qfmpvLT3KyXfzn/L54jdk1MTLRsoEiS2qPtMjJFmUXOuKOXLr7kOX/UREMHUVaaVVPYDnekOa92VNPFrFojO0a0eO+ihvqHalrPuflzoesHuXWHBk4MaCG3UNPrurw+A+obAQAAAMDGE6Ybmqy1JyWdLJl2b8H/3+6zXFZStpYGrlXpU+nAi/haRuxqFmOMOmIdRTWL/N5nxER07M5jkqS7Hr1LufJSVUX8RiELwxl3tPfxvZ5ZM/FYvKGBokKjp0drWn5+aV7pU+mKbXXrDtX7O1T6GZS+jlssWxLd1QAAAABgHQvTDQ0rsJJMGWtbv1zT5rbNRd3Q/N6ntVapvpRSfSk9fOfDgYWnK41CVsn+p/Zrfmne87ndN+1etcBGUO2msKOnhfnepE+l6x4o8voM9j+1P7BYNgAAAABgfSJY1CAryZRZWqqtUPRq6GjrKOqG5vc+C6en+lKBhadrzfwp7OpX6tjTx1at65Rfl7uoiYYOHob53kxOT1bVLi+xSKzosVuPyuWMO77btfS90FUNAAAAANYXgkUNktmeKbsgL9QebS+btrBQn9ozjdQR6yjKLMpsz2hTdFPRPF5ZKn6ZNVduurLqQFFhcKL7ge7AeVczE2bw5vI6VO70MEGgMBlWzrgTmKUVVmnXwam5KQ0+MZgP9Ox/ar/vsoXvxe2qNjk9KSub76pGwAgAAAAA1i6CRQ2S6kvp6B1HfYsuewWSFhcXG92smjjjjiZ/PKlPfe1TRRkkhe8l0ZHwzBTyC56dXzgfKrDgBojMQaNdJ3blgxNBWUWuWotnhzWyY6RoZLSoiWqof0gjO0aU2Z5RPBYvmj8WieUDP8mupG+GVWFwbPejuwOztKTloFNne2fV7S8MrAVt19tuuC3/WQycGKCrGgAAAACsM6bV6uT09/fbsbGxZjejbiIHI/4X9/cVP5yamtK2bdUPn74avIoqxyIxGWOK6gUFFZTufqDbMwiR7Epq4p4JOeOO7n7i7vww8BET0d03361bem6pqaCzu/5mc8YdpU+ldWb6jHq6epTZntHBvz6oN77sjXrkVx7xnH//U/tDBcQKDfUP6ZaeW7TrxK6KgaVSRka5AzmZg8E1pip9Fu56AAAAAACtwRhz2lrbH2ZeMosarJraRa2cWeRVVHkht1BWWDooq+TFuRc9p5+ZPiNn3NFdJ+7KB4okKWdzOjx2WPs+t2/FgSIjU1Px7HpK9aU0cc+EcgdymrhnQqm+lBLxRFkwyBl31PmRTg2cGKg6UCRJJ587qVRfSm+7/m1VL+t+XxMdCc/nIyYS6rPY1tGaQc+NjvpSAAAAAMIgWNRg1QQqWrlmUTVdufzmDSqGnT6VVk7emSgz8zOhX7uQkdG+/n0tPcx7oiOhqdkpOeOOuh/oznftKgyaVcsNvv3t839b1XJuzaSgAELOhssWmpqb0vCTw1W9PiqrJdhDfSkAAAAAYREsarBUX8o3S6NUK2cWVZMh5TevV92e9mi7Mtszdasr5NaISnYldXzncY3sGKnLehvBGXf0xe98UV/956+uOIvIixt8qyYby62ZJEmDTwzWpS1Hxo4QiKgjr2DPwIkBdT/QHWo7e30nqC8FAAAAwAvBolVw6NZDZUGS0sdSa2cWVRrdzeUGf7yk+lIavX20aGS0d7/h3Ur1paoKRgV5xRWvkD1g8928WpUz7mjPY3t0celiXdfrZgdVE3yLt8Xz26vaIFMQK0sgoo78PpvSkez8+H0nVqsAPAAAzURXbACoDsGiVVAYJDEyRVkchVo5WJTqS+mKTVdUnG9r+9bAII1bt+f5//i8JOkNP/EGScvBqHoMCb9WLnzTp9Jlw9evVMREir5X1QbfZhcvByAmpyfr0ibXWvk81oKgbRmUIeR2cfQrdk59KQBAMxV2xTcHTeiM2Wpfwys7d+v/s5WgEQD4aGt2AzaKVF+qLIgyoIGix63cDU0KHk7d5VfEupSbWeXW5kn1pTS7MKvBJwZX3kBV112umeoZRLHWlo08ltmeqXoEOWfckZGpegS1IGvl81gLerp6AoN5Xs+5GWxBgckfXfiRnHGnpTPxAADrk9dxampuSnsf3ytJdTs2+WXnzszP1P21AGC9ILOohbRyZpEkRU204jxhgwNusKjwwP3W3reurGEFbrvhtprXsRrqGUTxWldpNluiI+GbubUpuknS8olUNYGi9mh74PNulzjUh1fNr0Jev88wGWw5m6PQNQCgKfyOU/NL8/m6fN0PdBd1HVtJd7Kgm3TzS/N0mwcADwSLWkirZxYt2aXA54PqFXnNGzXRomDRD8//sKb2ScvDxq8FYWtAhV2XF7fLX+5ATmc/cFbHdx73DPAsLC3IHDRVd0Fzg1DS5UCFG5Aq7BKH+nADgH68fp9hP1MKXQMAmqFSpvXU3JSm5qbyXcf2PLZHex/fW/XInpVu0tFtHgDKESxqIa2eWVRYmNqLW6w6jD/72p8pZ3PK/E1G3Q90q/MjnbrloVtCLRuU4VTvmjuNkupL6egdR/OjtwVJdiV9R9RLdCRCb/NUX0oPvfOhomwjScopV2FJbxeXLurc/Dlld2a1eO+i7AGr977xvbpmyzUtX2C8lYS9Q+qMO4EBHff3Wbi+anCiDABYbdVmWi/kFjS/NF80LcwNj0o3MyMmQuFrAChBsKiFtHpmUaUi1MeePhbqAOsWGXS7PE3NTeVrF1WS7Epq8d5F38CVkVkzB/lUX0oP3/lwYNcityuX34h6h249VPVrutlGne2dK2p3ofmlee1/an/+cdfmLk1fnK55vRuFV8FNrzukhfN5cbP6StdXDepLAQBWW70yrcPc8Ag6h12yS1VlKgHARkCwqIW0emZRqi+lff37fA+2YbuyhB2evfR1Cmvg+AWu1tpw7V61hdz6QoVdufxG1KsleydsJkmlWlWFhc+v2HSFLixeKLvrB29ev4XZhVkNnBhQ2/1tMgeNeh/s1f6n9gf+ZtygXaX5/BgZ6ksBABoiKIPWzbSuVaUbHtXUZaRrNgAsM9bWb+Sjeujv77djY2PNbsaqMKY42HHy5EndeuutTWpNeM64o4ETA57PGZmykblKRQ5GQh+wk11JnZk+o56uHmW2Z4qCI+agd9AqTBsg9T7YG7rbXqVR0uyB5ef+6H/+kd73l+/TdVuv0/fOfc/zc8Nl1fwWGsXIaF//Po3sGGlqOwAAa4/bRdrvXM3NeC28kRGPxctuePmd04WV3Zn1PNdw27eSMgV+6wSAtcwYc9pa2x9mXjKLWkird0NzpfpSvt3AwnRlCdvdJdmVzHeZ8qqBU0sbULn/vivZlQwMaBTWU3r2hWclSc+fez6fzr3rxC4NPzlcW2PXqWZ/V42Mju88TqAIAFC1MF2p/TJo65m541e/sVIX7kqCuqOtZEQ2AFhrCBa1kFbvhlbIaxjvsEOlVxoC3HXbDbc1rA1Y1hZpC3zerYUTVNy8sG7SsaePlT1vZXVk7EjVJ1Ib4UQs7G/Z1PG1AAAgAElEQVShUX7pp36Ju6YAgBXxCwTtfnS3hp8cDsxgLu0KH1RPKAyvc4SwZQ/8uN3Cux/oVvcD3fnzkeEnh0PVGwSAtY5gUZN4df9bK5lFUnmtnWpq6FQaAtx18rmTDWvDRufebVvMBX/ntrZvVaov5RnUMDIa6h/Kb+/hJ4d1YfGC53rC1pJyA0TmoNGuE7vW/YmY+x3e2r51VV832ZVUZ3unfuqqn1rV1wUArF2FN3G6H+j2DQQt2SUdHjscmNGzrWNb0eP2aHuoEWK9TM1Nae/je8vOEeo1Qu7U3JSm5qby5yNHxo40PFsKAFpBcFoBGsYrWLSWMosk5QsvN0qYAsyNbsN6FfZu24tzL0pSfhsH1SUYPR0cAKz0eZbWNSjt+uaeiK23zzvVl9KHv/xh/ePZf1yV13O7d77sD1+mhdza2ucAAJqj9BhdOLjFSkzNTeXrFG3bvE0Xly5q58/s1Onvn15RkGd+aV53PXqXpOXjaiO7v/t1za9XcAoAWgWZRU2y1jOLalU43LqfZtdzWc/CjoRW+Bmk+lKBNaSW7FLguqyszEGT/2u7v63oZC5MACtsu9cSZ9xZUaBoqH+oqF5UWG43zVgkRrAIADa4sF2+a+3SFeTFC8s3pja3bdbEPROBXd+D5GxOg08MavjJYR0ZO1LPJoZiZNZdBjSAjY1gUQtZa5lFtah0R4raQ40VJhBX7WcQNdGq2uCmqbsBozB35NZjAHElaetbYls0smOkqF5UGIVFQGPRmBaWNs4+BwBQLEyBatdqZM385bf/UlJt9fxmF2Y1enq0KSONWtlQN0MBYK0gWNQkGz2zKAi1hxrP60QsFokp0ZFYcf2nwZsHV9SW0dOjcsadUMUtKxU9X4tWki21uW2zpOoCTfFYvCi4RGYRAGxs1YxUVu0NoZUo7PpeWpNyqH8o/7jS+UKlTOdGmpqbIrsIwLpBzaImWQ81i2qR6Eh4ZhclOhKauGdi9Ru0wYSpQVQtd/j10dOjVZ2oLdklpU+lQ90F/JOv/olu6bllXQUSe7p6qr5j655Qhw00JbuSZZ8vmUUAsLH5HUO8pq9GACaiiJxxJ1+P0u9Y74w7GjgxUNNrGZmGZR+tx/qKADYmMotayEYKFh269ZBikVjRtFgkVnW3GqxcpRpEKzGyY0SL9y5WVW8gaqKhgyXzS/PrbrSRzPZM1UMGu93xwnTLcwOwpZ8vmUUAsHE5447v6GNex5aV1hGqRk65UCOfpvpSK6rZJy2/j+zOrI7vPF62jkRHQu95w3tWtN5C67G+IoCNiWBRk2z0bmipvpSO3nG0KMX46B1HuROzTqwkABLWejsJS/WltK1jW+jt1R5tz9eSqlTXoT3a7huAJbMIADYmt1aRV7aQX73CSjUM69VNLewQ9Cu5ueiOBupmLZ39wFnZAzb/d/YDZ3XiGydW0uwi67G+IoCNiWBRk2z0bmhSYzJb0DrCpndXm9q+Xk/C3v6Tb69Y0DNiInronQ/lfytuXQc3Sy/eFi+qO1U4bykyiwBgYwoa2Wz3Tbt9jxttkfLqFUZGQ/1Duu6K6wJf0y+LyUuYbONqs4vCDtrhjsy2UgzQAmA9IVjUQj760Y8qEomot7dXjkNxPKxdjeoqVphVs57MzM/oDT/xhnxBT0llmUbxWFwP3/lwYFC1I9ahQ7ceChWAJbMIADamoAzdT57+pCIHI+p9sDffHczNRFrMFWfAJzoSOr7zuEZ2jPiu08jIHrB6+M6HQ2fQhs1SqpRdFDGRFQ/asRIM0AJgvSFY1CRemUXT09Oy1mpyclIDAwPq7u4maIQ1qVFdxba2b23Iepvp4acf1sWli3rg/31A6VNpZbZnZA9YHd95vKibptcJqHsC72YITc1Nhar3IC3fISazCADqyxl31Ptgb1nApRU44466H+gOzPzN2ZysrCanJ7X38b1yxh3fTKTO9s78cckv69ednupLaV//vlABo7AZx5Wyi3I2V9UAHrV8Vq9OvJoseQDrDsGiJvnUpz5VcZ6pqSkNDg4SMMKaU6+uYrFITJGC3dTU3JT2PLanpU6+V8K9mDAHjXY/tjs/fXJ6Mh/sCdNNs5phj0vFImQWAUA9uQH8yenJfMBl4MSAzEHT9MCRM+5oz2N7PEei9TO/NK/9T+0PNWqaVw290i5ZIztGdHzn8YqZQ9UU066UXVR4XK0k6NiZ3Zn1bZeRUd81fRXXDwBrDcGiJjlw4ECo+WZnZ5VOr6/Rn7D+VSq8HEayK6n2aLtyyhVNX8gtaP9T+2tadzMVXkx4CRvskaob9rhULErNIgCop6BaQNUELRohfSq9on3+1NyUtnVs83yu8MaQW0OvUkZsqi+lY3ceC3zNarqbh6ldFPa4GnTsTPWlfANi1191vWbmZ8I1GADWEIJFTfLd73439LyTk+GGFQdahXvSuNLRUdwRS84vnPd8vpo7o60m6GLCFbYbX6W0/yCxSKys/gQANEMrd92Swrev0r57dmG2aTc7auke7nXM9aohGHbgkqAAT6IjUXVXrkO3HirKQvYS5v37HTvdjCK/gFiyK0mwCMC6RLCoSSKR8Js+Gq3PcKTAakr1pZSzucozlljvI4nUcsJaKkzavx8KXANoBV5dt5qZgVOqmvaF2XdPzU015b3VeyTRre1ba6rPc+jWQ57Hr0rdyryk+lKqVAopzPsPc0z1Coh1tncSLAKwLhEsapJcLvxF9NJSdUOLA62i2pPTREeiKG096M5jkFa+S11pmxiZ0MGysGn/XmIRuqEBaL5aaq+tBr/23f3E3WXHmcz2TKgCzoXvbTWOV864o7OzZ+u6zhfnahtivpbjl5egm1Nhj6srbRPBIgDrlfEalauZ+vv77djYWLOb0XA9PT2hu6Ilk0lNTEw0tkFAA7h3ZAtPtOOxuHbftFuffvbT+dT2REdCh2495Dna197H92p+aT4/rT3arofe+ZDvyZtbxLMwEBKLxHT0jqMtMUqJ1zZxGRnt69+nkR0jDW/Hux9/tz7/T5/X8+9/vuGvBQB+IgcjnqNzGRnlDlSfnVpvfu2rhfve/I6R9Rh+3R3FbHJ6cnn4+grvYVN0ky4uXQy9fre7eKtou78tcBQ1e6Bx1ztvO/Y2fXnyy1WPvgYAzWCMOW2t7Q8zL5lFTXLvvfeGmi8ejyuTWb9dcrC++d2lG9kxorMfOCt7wMoesDr7gbOeJ1apvpQeeudDunbrtZKWg0pBgSJJ2v/U/rKMmVYqiu1uk/Zoe9H0REdCx3ceX5VAkUSBawCtwa94spVV9wPdTc8MrXf3Lenye25UVlXpQAqVAkXZnVld+N0Lyu7MKhaJhXqNVusuPnjzoO9z1YyuVi1n3NHfnPkbLdmlluxGCQC1IFjUJO9617skLQeD/Fx55ZUaHR1VKsXdCaxdYQteBi0/PjQuSfrdn//disv7Fb9upaLYXznzlaJsKUmaW5xb1TbEItQsAtDapuamtPfxvU298L7thtsatm6/UTFrKUYthRtIwZXsSuaPq6m+lK7YdEWo5Votc2Zkx4i2X7+9bHqj6yCmT6XLBotoZiFzAKgngkVN9qEPfUjZbFbJZFLGGCWTST388MOSpPe9730EigApf/I6fWE6cL5KFxStcKfPGXd0ZOxI2fTVrtFBZhGAVlCp9s380nxT6xd9+tlP132dL869KGfc8a1vVGs2U9hgk1ctnzC1iBqZqVOLL971RWV3ZutWBykMv4BfswqZA0A9ESxqksJaUalUShMTE8rlcpqYmNCuXbvU0dGh2dlwd4WA9a4t0qbO9k5NXwwOFlW6oGiFgqnpU2nfLgG13k2uBplFAFpBmMBINfvGehaMdsadhmSlbuvYpv1P7fc9FtSazRQ22GRlywIplZZt9RFLa81mrkZQwE9qjXMOAKgFwaImcYNFxngfZLZs2UKwCCjQtalLP77w48B5Kl1Q+N0BXE1BbWhEbQw/ZBYBaAWZ7RlFTPDpaNh9YzXD3Aetww027X50d+jlqvHjCz8ODEKdfO5kTUGvsKOyeWUIVQoE7b5pd8t1QWuWoJs/0ureAAKARiBY1GR+waJ4PE6wCChw5eYr9bUffi3w5DnMsPTNSAt3T/rNQf+T97BD+9ZLLBJTzuYChxsGgEZL9aW0KbopcJ6w+8ZaC0aXBpuCRtcKyysQVmm9k9OTGjgxUFPQq1JRa78MoUqBoJPPnQzdhvWuUjBoNW8AAUAjECxqksJuaF4IFgGXOeOOvjn1Tf3D9/8h8OQ5sz2jeMy/aLyVLbtoqOXubZhlS0el8bOvf9+q3q2NRZdHvKErGoBmCyrwP9Q/FHrf6HfxHjbDo5rC0GHEY/G6BeTDBr2GnxzWrhO7AufpbO8MrOWT6Ej4Lku2zGVBwaBW764HAGEQLGqSSt3Q4vG4zp8/v5pNAlqSG2wpHW1EKh9xxB2WPmqivusrPNGtpcuC17K7TuzS8JPDRfOFvfgY2TFScZ56Gv/h8ghzmzOba67rAQC16Ix1+j53eOywuh/oDrWP8rt4D5vhESYQYmQ01D+kLbEtgfMlOhIavX20rsWgg246OOOONn1okw6PHQ7MKtp+/Xad+51zgQG4Q7ce8n2ObJnL/G5QuZ893fUArHUEi5okTLCIzCKgcrCldMSRVF9KW9q3aGv7Vs/5C090a+my4LWsldXhscNFAaMwFx+rPbKMM+7oL77+F/nHK+niAAD18tprXhtYY2dqbkoDJwZkDhpF74+WBeVdXhfvRiZ0wegwgRArq5EdI5r54Ex+5C1J+ZsUya6ksjuzOvuBs0r1peqaXeJ3I8QZd3TXibs0n5sPXD67M6sv3vXFiq+T6ktpqH+o7DMhW6aYe4PKHX2to61DvVf25j97AFjrCBY1GcEiIFiYYEthcMdaq5n5Gb3t+reVXTSUnuj63aWt1GXMGXcC5zkydiQfeAlz8bHaJ9/pU+my4tbV1PUAgHra1rFNvVf2hgqc52xOh8cO6+0Pv11ScXfg9Km03nLdW4rmt7I69vQxOeNOxa7DYfbFhW10R96yB6wW712UPWDLRuBK9aUCu3VVw6/WUfpUWjkFd3cLU/C60MiOER3feXxVh6FfiwpHX3vHq9+h9mh7s5sEAHVDsKhJqFkEhFPtsMqzC7PK2Zzect1bNHr7qOJtywEjrxPdoO5qflk2bvezIIW1kTLbM4pFYoHzr/bJd611PQCgnmbmZ9TT1aOJeyZCBzVO/e9TGn5yuKw78Kn/fapsXrfLclC3Y2fcKerW7KUt0rai4P6hWw8pUodTbr9gWpiRPr1q9lWymsPQrwdbYlt0fp4SEgDWD4JFTRLUDc1xHP3VX/2VxsfH1dvbK8ehawg2rkpFq6XigNLM/IwkaeumrUr1pfQrr/kVJbuSnie6QSPS+J1Uh61B5AZeUn0pXbHpCt/5ggJWjbKtY5vndGpRAFgthaNEfnnyy/ofk/9DvQ/2+u6fvBweOxy6IPXU3JRnt2O3e9vAiYHA4ew72zv1p3f86YoCJqm+lK7quKrq5Qq1R9s9A1V+XfK8cEOgsba0b9H5BYJFANYPgkVNVhoschxHg4OD+ayiyclJDQ4OEjDChpXqS2n3TbsD5ymsR3Fu/pyk5RN7SYq3xT0vJiqdYPvdqQ17sl0YeAm6ABm8OThLqd6ccUcvXXypbLrfhQgAhBV2dEm/USInpyf10sWXqu4y1UiJjoTsAVuxKHQlL869uOJljYzml+aVPpUu2qbOuKPDY4dDr4cbAo1FZhGA9YZgUZP4dUNLp9Nl3c9mZ2eVTlNLBBvXyedOBj5/eOywOj7cIWfc0bmLy8Eit8D1lvYtRcEiZ9xR50c6K55gGxnPC50wJ9tGJh94ccYd3+4HW2JbVn0UNK96RdLy9qKLAYBK/AJC1YwuGZShuZBb8K3n2AxBwf5qrCRQE9Vy5qk7ulnpNt33uX2h10Vx6sbb0r5FC7kFzS8FFxoHgLWCYFGT+HVDO3PGp5aIz3RgIwiTzXNh6YJ+/bFf14l/PCFpuRuatHyCPLswK2utnHFHex7bEypN3K++Q2Z7JrCApZHRvv59SvWl8hdPXoVH47G4Pnn7Jyu2o978tmUtd70BbAxBAaFqRpestE/P2eBizWtRmPp1pZZU3lXa7TrX+ZHOfLdrL4mOBMWpV9mW2BZJIrsIwLpBsKjJSoNFPT3ed578pgMbQdg7sou5RY2OjUoq6IYWi8vK6k+f/lPtfnS3Z1aNH7+uaItLi77LHN95PJ8t5Hf3PGqiTTtx99uWdE8AUElQQKiawvmV9jfNqOXmp14jmQXVr4uY6k/HK930OHTrIYpTr7It7ZeCRdQtArBOECxqEr9uaJlMRvF4yXDf8bgyGVKHsXGFKXLt+uHsDyVJO//bTjnjTn6533jyNwILWnvx6opWaYjiX3vtr+X/73fxlLO5pp24e23LTdFNdE8AUJHfPm1yetI34OEVGArKsmmPtmvw5sGWqFsUi8R06NZDdVufXwZnzuZCH+PC2BLbQnCoCcgsArDeECxqEr9uaKlUSqOjo0oklu9kvfzlL9fo6KhSKQ762LhSfSmN3j7qO2ywlx/M/EB7H9+rZ/7lGUnS3OJc1a/r1RWtUveJwoBUK2bxeG3L9735fVxYAKgoaN/lFYz3q5OT6ktpU9smz/Vsbd+qkR0j2te/r6kBo2RXUkfvOFrXfaPf9nO7iRV2G6slo6kZXZwhnf7BaUnST//xT3sWeA9bAB4AWgXBoibxCxZJywGjkZHlbiyf//znCRQBWr64mLhnQvaA1fbrt4daZn5pXv/ta/+tptctDQ5VCvRcXLyY/79XFk8rFBl1t+X40Lgk6U0vf1NT2wNgbchsz4QO4BgZ7b5pt2ewxRl3fOvtuNk3IztGdHzn8XwAxc3aaLTszqzsAduQrltBxwR3v+x2Gzt066EVBcuG+ocI/jeBM+7oE//zE/nHk9OT2vPYnqIC8Hse21NU76vweQBoRQSLmsxvxI/OzuV6KzMz/sULgY3qi3d9UUP9Q6HmnVkI9xvyq5FRGhzKbM+ozbT5Ln9x6XKwyM3iuXLTlcvruqKnpYqMunWd3BHkACBIqi+VH5mrEiurY08f8x0NzU/hPrcwgNId766+wVVKdCQaun8uzOysVHg61ZfSvv7wo525VnuETSzb/9T+suy6hdyC9j+1X5J09xN3l9VMLHweAFoRwaIm8atZ5CJYBAQb2TFSVbe0IPFYXIM3D3rW0LjthtuKHqf6Unr/v35/0bRER0J33XSXJJUNmZvqS+k/vPk/SFLLFRl1g0VBI+oAQKFq9rsrGQ3NL/MyaJlkV1JD/UP5IMxKCmS3R9vrWp/IT2kGUdAxgcDP2jE1N+U73Rl3fIte+y0HAK2AYFGTBHVDkwgWAWGUBnJWavT2Ud3Sc4vncM1/8tU/Kbsz/tqrXytJ+tZvfkv2gNXZD5zVv+n5N5KKu6G5Li5e1KboJt/fe7Nsbd8qiWARgPCq7UZbzWhoQZk9QfV+Ju6Z0MiOkXwQ5tidxyoWjC7s4pXoSOihdz7UUsF8VzXBuXqN3Ib6CsqkA4BWRrCoyQgWASt38rmTFedpj7QHPu/Wd0ifSnsWaJ1fmi870fuX8/8iSbqm85r8tE3R5WKthd3QXBeXLmpz2+aKbV1tn/n6ZyRJH/zvH6TYJoBQqg2o+I2G1h4t3jfHY/HAzJ5qasCFHRTBHrD5gH8rBoqk8KOBRk10VTKj4M0vUJfoSGhyejJwWY69AFoVwaImCdsN7fx5ht8E/FQamezG7hs1n5v3fC5iIhrqH8qn+Qeta3J6Mj+CSfcD3fq9L/2eJKlvpC9/kueO7OOVWXRh8YLvyD/N4ow7uvtzd+cfT05PauDEgLof6ObEFUCgsMWmjYxvMOddr3lX/nFQ7Z7CZcLW+3Hnn7hnwjdg1MxRKavhvu+grnWJjoSO3XmsZQNeG8GhWw+VBUAl6Zot13jMXYzMIwCtqrxKK1YF3dCA2vV09XjesYuYiB6+82HtfnS353JGRkv3FmcR+a3Lnd99rrC+wJmXzmjwiUFJl7t0ldYskpYzi9zMo1aRPpXW7MJs2fSpuan8e+LCA4CX9mi7rr/qen3jhW94ZmS6trR7B5WccUef/cfPSlou/O+OBlZJqi9V9X4psz2jwScGi/Z3rTAqZTXc9+z1Plpp0ISNLNWX0lfOfEWHxw4XTf/62a9XXLZS5hEANAuZRU3mFyzasmX5BItgEeDPr1vCw3c+rFRfyvcixms0n8z2jGeBa7/5XW4B18BuaIsXWy6zKCiTyq8oLQBI0vmF89pxww4t3ruo7M6sbzepmfkZDT4xWJSt6Iw7GnxiUC/NvyTpctC9URmN1WYktar18j7WszBd4/2Q0QugFREsapJK3dCi0aja29v1h3/4hzLGqK2tTcYY9fb2ynE4oABS5ZNnv7R9r+mpvpSO3nF0RQVCz0yfCeyG1oo1iyp1wajUxQ/AxrSYW9T80ny+K1ql+kClwWevrMZGB6irGYGsla2X97Fe1XLc3P/U/jq2BADqg2BRk1TqhjY8PKz5+Xm99NLynbelpeUMicnJSQ0MDKi7u5ugEaDgk+fBmwc9l/GbnupL6dCth6oO7PR09eRrFXh1Q7uweKHluqFVKpq6Vup5AGgcZ9zJ12tzi+Cfn1+updjZ3pmfz90PF44wVqjwItrvgpoANda6Wo6bhV3cAaBVECxqkqBgkeM4Onz4cNn0QlNTUxocHCRgBAQY2TGiof6hfCZR1ESLilp7SZ9K68LihapeJ7M9s+a6obnZAJuj5YGxtVbPA0D9ud3FJqcnZWU1OT2pwScGdfyZ45K86xH5XSxHTCTfzcZvHgLUWOvCjlwHAGtFqGCRMeaXjTHfNMZ82xjz2x7Pv98Y83VjzDPGmFPGmGTBc39pjPmxMeZz9Wz4euEVLEqnw6Viz87Ohp4X2KhGdoxo8d5F2QNWi/cuBgaKpOrvbhsZpfpSFbuhtVpmkbQcMPq9X/i9omkv63wZdTAA+HYXc7vLeI2I5nexvGSX8nWJMtsz6mjrKHqeADXWA/cmTLzNO2AUMRHPGzQuN3uvXrwyAwGgGhWDRcaYqKQ/lnSrpBsl/XtjzI0ls31VUr+19nWS/lzSAwXPfVTSrvo0d/0Iqll05kz4i9Vq5gVQWbV3t/f175OkNZdZ5PrOj75T9PgHMz9Q+lSak0pgHfO7iHTGHXU/0C1z0PiO0JRTTpI09ORQ2X7CvViOeJxeunWJUn0pffhtH85Pp1Az1pNUX0qbY94BoZzNackuqS3iPRi1m71Xj+OvX2Ygx3YA1QiTWfQmSd+21n7HWjsv6RFJ7yycwVr7JWute/vp7yRdV/DcKUnn6tTedSOoG1pPT/iL1WrmBVBZZnvG80LHy5bYlnymUlDNolYscC0tn0y6XUoKcVIJrF9+F5HDTw5rz2N7QtdOOTd/znM/kepL5QNKpdwA1M9e+7OSpM8PfJ5CzVh3Xpx70fe5hdyCujZ16drOaz2fr1ex92YUkgew/oS5Inq5pO8WPH7+0jQ/75b0VC2N2ki8gkWZTEaxmPcQ3qVmZmYUiUTU29ur4eFh9fb25h9TzwhYGb8LnULxWFyfvP2T+cdB3dBascC1tHwy6RXckjipBNYax3E8zwFKs4j2P7Xf8yLyyNgRLeQWqnpNr/1EpSBz9wPd+vk//XlJ0rs+8y6C0iji9z1eS67Zck3g8y/Ovah/GPwH3+frUeydQvIA6iFMsMhraAvPPlTGmAFJ/VruehaaMWbQGDNmjBl74YUXqll0zQrqhpZKpXT06FElEsFDeLe1tWlqakrWWk1OTurw4cOanJzMP252AexmHPCHh4fV1tYmY4wikYg2b94sY4yMMYpGozLGeLbFcRx1d3eHmrfVFG7n7u5udXZ25t+HMaZuI+etxRO4lbQ5bIDE7TbhvsbLrn6ZJGn4L4Zl7jPqznTnL4LcbmjuvO73s/BzKv1bjREPK500+nVDqaQZ35VGvuZa/O5Xsh7fU7XWwzYo3Kfs2rWr6BxgYGBAsTfGtPfRvUVZRH6ZQ9b71K6iyR9PFm3DSvvQwtefvjitvY/vvdwNbg18JtW0sVXej1c7WqVtpe0cHBws+h7v2rVLw8PDDXmtRr3/X+j9hcDne7p6PGt+uaxs6BpDjiP19krGSG1ty//29krb2rx7Htgf96i3d3m51eC2LxKRuruX/yIR1b0Nha+zmu+vJVXaGEHPr9YH1kx8WapjrQ38k/QWSZ8vePw7kn7HY763S/qGpH/l8dwvSvpcpdey1urmm2+2G8G3vvUtK8keP37cd55sNmvj8bjVcnCu6C8SiXhOL/1LJpOB7chmszaZTFpjjE0mkzabzdbl/WWzWRuLxXzbPjQ0FPjaK2nX0NBQqG3i/iUSCZvNZgPbKskaY+zQ0FBdtku9BX1HSv86OzvLtmOY7ZzNZu2WLVvK1hePx1e0vtXitW3CfJbmPmN1nwL/kh9P5l+jvb19ef2vL5+v/WC7zT6TtT/xsZ+wb/3Pbw39WXl9Txsh+fFk4Ps09xmbfSbca7ufvdd78Pqu1JPXZ+33mtV+R6tZ91qx1t9TPfYzXseL9vb2NbMNrA2x/++T1e8F78vq8vd7xd+jlawj8eGETSQSq77vCLONC79rN954Y+g2+h2D3HOz1XpfYc8T2tvb7dDQUOjfViOO937HEGNMXbfX0NBQ/rOo97le9pms3fzhzb7f9XgmbrPPZO3C0oLVfbLRg9HAeYdGsjaZtNYYaxOJ5T9jrE0mrR0asjYet1Yq/4vdnLWx+zqK1/nBuFVf1krLyzX6K5jN+revnm3wep3VeH8rlc3a/GeaTNaxndns8hckaEMHbazV+sCaaa19WRpE0pgNEZexy1uoYrCoTdJ3JF0vqV3S05JeUzLPGyT9k6QbfNbxiyJYVMQNFgUd/PwOmtX8GQfm8K8AACAASURBVGN81+91sKzHiVk2mw3VttKAl/vaXic2sVjMJhIJa4yxiUSi7P8r3T7RaDR04G2lJxGNDKBU+96j0WjRtssHOnw+/0qBtMJgZKMuQFe6/VZ60lkpgNL+ofZ8AKVo+99+aZ57iudPfjxpr/r9q+zWd21d8fe0UYG5oc8NhQ6MBQlzMVIpcF0Lv8+69Pu5kovRMOtea9bye6rHcSvoGJVIJBrY+voKPEfYLKufk9XvBv++6/L30yXHmd/yv/j1/Tvgv+9o1mdSzc0Yr99OpXO41QqE1XIuWU0grB7vp/S3XXr+Uo/tlc1mfV+nHkGpoHOIxB8kim7AtN3fZiP3RYJv2vzHpJXPtbv6slb3JK3Sm63+r1+1+lfPFD3f8QufuLyu/b1WsZeKnm/0Lj+Z9I87uH/1+Hn7vU4rHtIaFquoFOhxN4ZXMMl93u+5Vt+o1VhLX5YGUhXBIrM8fzBjzG2SHpQUlfSQtTZjjLn/0gt91hjzRUl9kn5waZEz1tp3XFr2byT9tKROSVOS3m2t/bzfa/X399uxsbGKbVrrvvWtb+nVr361stmsUinvwo6RSERhPp8giURCZ8+eLZvuOI527drluf5oNKqlpaX8v8lkUplMxredhYaHh3X48OEVtzeZTEqSJidX1v2lkYwxOn78eKjt4HJTqmdnL9eHiMfjGh0drWo9fuseGBioaR1eksmkJiYmJEm9vb2Bn4UxRrlcLnDewvVVq5btF/T7CWqTW/y1tKaHJCU6Ejp066F8MdaymmP3yrNzb0dbh+a+PCf9VWCTA0WjUR07dkypVKrm75XjOEqn05q8c1K6MnheI6PcgeAaTpW+J65a92d+/D5r9/vptb0KBX0fKq17LVqr7ynouFXNfqbS9zXouNxKyj7HeyQ9JmlC0mZJF7Q8RMltDW7IfSWP+6T4r8Y996G+fqzls0wfiURChw4dqvpzcfd1Z86cUU9PT+hzGSn8fk3y/u2EOYer5fgYVq3nkl5tbMTxPmi9rnqcP1V6jVrfQ+RgRH5dOuOxeNHIf9H7o8rZCvtca6SDHvP0OdLtg1L7rPTZUen/e2/5PNc8LQ29fvn/9+VUWlnEGKmRu/xIZPlKvJJsVqpll+v3Oo1+fyvR2yt5ff2SSammXYHfigsNDUk1XKNJas2NWo219GVpIGPMaWttf5h5Qw35Y609aa19lbX2p6y1mUvT7rXWfvbS/99urb3GWvv6S3/vKFj2/7DWXm2t7bDWXhcUKNpI3AO3V4FrVz1GOjt37pxn3/T9+/f7njwsLS0V/Ru2/pHjODpy5EhN7T1z5ozOnGnN4nvWWqXT1RX8TafTZReos7OzVa/Hb92NULj9K30Whd9Rv3lr+Txr2X5Bvx+/NjmOo/Ttac0+MqvoTFTS8rDO2Z1Z2QNWZz9wNnjUHp896tzi3PJFW1/FZvtaWlrK/w5r2S6FNSHUVfl1e7oq74fCfMbRaLTyi62Q32ftTvfaXoWC2l9p3WvRWn1P6XTa97hVzX6m0rxex7tWrO9S9nldKSknqVfSf5KU0nKBgDpIdCQUNR6/4cXyScmXkhq9fVRbzBb5XDMXs5JOBc8yNTVVdR1Gr/o31ayjmu+U128nzO9pNc53av1de7XRr92Tk5M1/U4ymUzgeXE9zp8qbfNab1Zu69jm+1xpQfiKgSJJen555EC98b9Kb/vg5enb08uBIkm6/r8XL7NpevnfeEF9sk0vla260bv8sOuv9XR2m88mb8VDmt/Xr+ZdQZjvbVCgKOw5Witu1Gr4tT8SoXaRj3DjQ6PuwgSLMpmM4vF4qPUZY9TZ2Vk2fX5+Xvv37y87YZqaCjc0rivMATroRD6snp6elr5gqfbErhEBlHquw0vh9g/6LIwxuu222/InhpGI9+6kls+zlu0XdNLp1aaiIMq4tPSxJcUfiCtzdcY3QFSpCH2RNknvlHR1+EVKub/DWrZLUeDk2eB547G4MtszFdcZ5jNeWlpq2EV2JpPRpk3Fo83F43FlMsttrybo6bXu0v1w4brXorX6noI+x0gkEvq7Ven7Wnq8qzXo0Cie5whXafnMzki6QcvFA0Lafv32slEb47G4sjuzOvuBszp25zElOi7v8zojnYo9VTxya/579Ixk/8BKf6+KASNz0UjjldtXbaCg1ps11Ry7vH47Yc7hVuN8p5pzSS/VBMKMMTX9TlKplPbt2xc4T63nPpW2uTGmob/twoElIsbnMuzUh6VcZPm3k7v0G/vn118O/lz1nNRVsB36HpH+3U4pemk01ouX7gR1FJzrJ7+0/O+V38lP8trll46eWMtohZmMFOarV8tH6jjSS+VxMLW3e7+/ZvP7+tW0K3Cc5cyYWlxKEAgUj7fmRq1GJiN5jTi+tCQNDhIw8hK2v9pq/W2UmkXf+MY3rCT7qU99KnC+oKKxq/0XVP/I2uC+5mH+gmoWtcpftTU9GlkbpBHfi2pqFm3fvr3i51RrDYNat59XEVu/Nq3ktbLZrG1ra7s8/y/L6o2y+k/yr0Fwc+2/w1q2S9nvNOXdzlf851fY7DPZirWR/GoBNeo74Wd4eLhoOxS+RtBvJUx7CmvcNLtwu9ueWutVrfZ7qkeb61UDplItNvd3Vul1W6HGU1H9pQOXfr83FfyWf1NWPyGr/QH7pEt/pYV2kx9PVixw7/c9KtpmOwraVvJn7jN2aGQo9DG/0nlIoaC6NGG3bZh2bd++PdT2aUSNyLDC1pIM+5sqGtyhwt9Kfie9vb11XV9p2xtZY6/SIBn5ATKeyQacJ3zS6reutvqdTqv39Fvd/l6rn/5zq/9z0ErWqveU1Z5bype75unl52WtfvovrH5ny+Xnrv375ek3ftqqL+tZKyj7TNbGM8VF6t2C3CuVzS4XcpYu/1v6V0vdIr8SNO46G1ZMeoUaUrMoTHGooL9EovI6Eonmb7x62b3b/322wHF9NaieBa5X+2+jBIu+/vWvW6lysMj1ve99r+hAVnSBukp/lQ6etQQvrr766rIgxWq/v5WeNAXJZrO2o6Oj5vX4rbv0hCcajVb1ngovmPwu4EpHQ2trawsVxKz1AnSlBYlLFbY9qE1B7yXIfffdV77MsM8J4H2y6pdVtLbfYS3FRcs+t1douSj3ARWdJF73h9d5XsQVvs5KA7thTsSrCS5ks1l71VVXWUm2o6PDM6Dl1c5qRpoL812ol6D3Xs/Csqv1nurVZq/96Ur3PdlsNnBwg8LvaK1Bh0bLt8kNyOws2N8MXHruvQH7JI+/zR/eHPoC0X39XC6Xn1a2zXyCVUOfWx44Iuwxv5qL+HoE+Sq16+677w69fY4fP1634+NKVLufvuKKKwLb+G//7b8NtZ6V/E5e85rXWKn8nKZuI5Zls/bqq6+ua5tdQQWuCwMvgYNpvOkTVr/4QasDxurum5an/YdXXg4WuX+lQdif/KvLz939uuLn7hywUs7q1Y9a/d8Jz+t+vzYFDXRRGowZGrI28YuXCm8fMDbx4aRt37xgJWszGe+AUXv7yuMQfgEoY1p34Ktsdvk9S9Zec00d2uO3EcL8bd5ceSS0q66qy/tuGf/lv/hvjxY5rjeaCBa1vmeffdZKso888kio+X/wgx8UHche9apXhTpIx+Pxqu/6+01fyRDT0uUh24Ne13GcsvWFPQnxmn7TTTeVPReLxTyHgA/zd+211674xG5kZCS/nnqfIJaO6nHFFVeEfk/uhbL7OMjHP/5xK8nefPPN9i1veYu1NjiT7A/+4A9qfl9e36WtW7dWvf3c9bz3ve8NnM8v0BaNRgOX+9KXvlS+3IDPCeB9snqDbOSKSFEwoHC4Yvf32tXVFfg7LPzsenp6Qm8Xvwv3oZEhG7s/VtzWtKxeW75N3Istv4sxY0zFIFJQEKia4ELYebPZrN26tXhEumqsZJmVqPR+6pnl4i5beJHfCPVs89GjR0Pt38IcsxKJhP25n/u5isu2dGbRMwXH1ns99jdusGhvwD7J5y/MSIjWXv4ezc/P56eVbTOf1y9UKRC4klHv6hGk9DsuSLIzMzOhl5+ZmVm1/UhQO0r/SoOm7s3IL3zhC77ranRm0Stf+Uoryf7kT/5kzd8DP5/+9Kfr2maXV3aO7isfCS0wA+ktH7O6623LAZf3/Ozl6e95k1VQsOimY5efG3xj+Xq7v2H1ypNWB7y/g0Ft8nyvXvGFvqzVB0vef2Q5WPT3f2/tpk3e1+gr3eRBg1u18sBXP/uzy2156qk6rKyWzKJ77728nmy2+ANy1/uqV9WhkS3kj/7If3u0wpdjFaiKYBE1i5osqGZRodJ6MN/+9rcrLpNMJjU6OqpDhw6F6q/uzl9a+8idXmn0iVQqpdHRUV155fLwSq94xSuUzWZ17tw5pVKpwPou09PTRY/Djshz/Pjx/P8Lt9HHPvYxHT9+XMlkUsYYJZNJHT16VDMzM/rud78rSWpvD1/M4a//+q9XPPrGO96Rr/euiYmJuo+ys/ybX/bSpY7bV1xxRcXl5ubmQr/GxYvL/eC7urry/w/q9/+Rj3ykpkKwfgWJN2/eXPX2c9t7/vz5wPmWfPpr+00vXX+RFwMWWJRy0ZwmJiaUyy3/OzIykn/8iU98wnO9pb/Dwu3w9NNPh94u7u+0o6NDknT11VdrdHRUJy+e1EJuoXjmmCSPn61bM8KvdoS1VnfffXdgO6z1r2lRTa2RsPOmUin9+q//emCbWkGl99OIOmgXLlyoOE8tBZ7r2eY77rgj1HxhatPMzc2pv794MBCv410r13jKF8vtkncVyrZL/3oUoq5kcrq6Qr+F+6wwdXI8C2Zf8trXvrbocdjzkELuvq6WdRQqPF+75ZZbJPns/33MzMys6HUbrfR8y30cdOxLp9Oan5+vuO6V/k7c7fq9732v7Ll6DRKysLB8vNu8eXPR9Fp/2/8/e18fH0dVtn3NbnaTbDZJ201bKiUbPuXDgEqRL0GglY8iCgiITtrSYkMTxRZB9CVKn/ISFJ4HbVATiNgSkkGoiiJQeJTyPuAjCBREgsiXkk0LpW22bdp87mZ33j9mz+yZmXPma2ezadnr98svu7PzcebMOWfuc53rvm+xXkTnRZ2IVkchQFCTZOgTZJgFwkbJOBDcB7yyGNh6Snb73BfZ+7/YpPyv/CC7LZGx5RPlwL8+r3yueROYKAUEaOIRkThFMmSwIEBgxi5qaQEMptr8FmDHJ4APqYweaWUgSiYBXpdx+wpjxUUioXXyFkzaQ3Bzb0iSkuHM51P+m71zecGhbMwF8LnPZT+LInD88cBZZynfycMaH7dflv0B5L70sVYPhJhMeUCRLCoQ6Am+HejJIisy5dvf/rZKTBCDiZxj+vTpTKKEpJS9/PLL1W3HHnusI4JDFEV885vfhM/nQywW0xzX1taGgC6oGCnTXl10OtoIIZNaFr72ta+pn2lDrrS0FKIoaibkpCzEgD3ppJNs3RMATEy4sLQzcGJMOsVNN93E/c3KUHdicJHJZGVlpfpsWJMB8jwHBwdNyQAr8CaRO3fudHSeiYkJ1eC1Ioui0aij7QTMibbZnCAFBIKM4HoZkD6iP69ZP3TaxkRRxOc/rxiPZPJEB93UgMFLE6LQjDAMh8MIhUIoKSnh7gOw26ETciGfQeRZcDp2O4XV/eQjk5kVcZxrgGde2WbMmOGYgLJDbBGYtQFZljE6Oorqam1KwPfee8/Qz8g7lPTNOXPm5Jy+2yuo/ZZws08BeIHagfAxNmKXsuAkuC39bEidqYHnGd2m8cRG7rkqKyvVz+eee67rhRb6GNazdQK6rRD7wcnYu2/fPtfXzgWE6LULYl+akUF2M2Cy+okd4pnUK69+vRjfCVl02223qfZjroQigVgvom9VH9Kr0+hb1WdIkiH1Stg7zojKTOBPAGPVwF9uAj4wsVWJ2TsSAcaqgPC27G+ELEpWAA/9Vvlc8yaQUvpkbDCGxkcbseD+BVj08CJTcliGrMniRsB8DNX9wL0vAM/ebPgpkeAHvHbzCpN6JbTsrMPIjT713oNBoLNT4T3yEkzaIxBTgkkWSZISbDkWU3aMxcyDL4uictOZxXoV9PyJR4Lo+9jICEDGug8/VP7HYvbLsj+A2DxHHJHdFo1mG04RGhTJogKBTDjsKouc7qdfERJFETNnKmmYXnvtNaxbt07zeyAQUF+ONBHlRH1CMDQ0hHA4bCizKIpYv349DjroIACKouGcc84BYFQW0QbCnXfeqflt7ty56meaxKEJNX1mJBqE4HjxRc4KDQPEqHCDfJJFPINp79696OzstCQ67BpcY2NjCAQCKC8vV++HtWqrX6ED3K0C8iaXjrKPQVv3ZqnTAeuMWjwwJ6/PAvgpe39/2o+PTf8Y93zPPfccc7vZRNpNGyNjBElpX1vNsZ52GDeROjFTD5SVlWH27Nk49NBDLcuib4dOCBEn+9odR/Wgx5lciGM7sLqf1tZWA9nvZiWcJr2s+kauWaVYfSsQCGDfvn2OCSgnZJEZgZZMJiHLsmExgkcqi6KIY445BgDwyCOPTAmiCKD6bQgKIfNPANR8MVeyiDVB5EE/DomiiBNPPBEAcNHhF6lKIr/gR9O8JrRf2M49F00W8TJtOoWTtsMC3YZnZHJ1T3VlkSbLp0OY3ZudjGJdXV1MosgO8Uyu7SSjqVOQsfyyyy7DtGnTcO211+ZF/c1Cy6YWo5KXIFWiZDWbKAdSZUA5R6o89/ns52QIGJoDVFKdf3S68j8RBhKVwN6DFbLIl73uSHIEm97bxFUU0WCRSczHMJjZWGLsb4kE8PGPGxN3uRF0SL0SGh9tzJRLBiYU+/Ogut3qfN9MdZQvOBEEARyyiCXZGhlRtvMgioA+kyBNUNMKIhr6cXFkBBgY4F/HTlmmOkjdksXMOXOAvr4iUcRBkSwqMNy6obHg9/sxZ84cAGz5MLnWxMSE6cuQJovcGFeELGJBFEU88cQTAIB77rlHXe0yI4suvPBCzW8VFRXqZ3riRk9+zMgi8psTAmiqkkUHH3wwc/ucOXNUZdXSpUtVQkAPuwbX+Pg4ysrKUFpaqrkfuh319fVxJ51OVwFbW1sNKjTAvgsKAV1WK2URUcURHHTQQbZWGLnPl8pYS+ywaHUUx844FrOrZnPP98ADDzC3m03M3bQx0s+ffvpp1NXVIbYuBmFCNx4lYHBfiUQiGle4zs5OpnrojTfewPvvv4933nnHsiz6dujE7cfJvnbdW/Wg6zfXCacVrEhLURSxfPly9Te3K+H02GlFFvH6bywWs6UMEkUR119/vabMVVVVBuWCHQLKbv1bEWhkIURPFg1YGcnI75juFK3zWwHSXPYCGIfGsiME/rl150KAtn+HAiHMP3S+6flpxaGVIsSsXpYfvxwTN09AXi1j4uYJU6IIgMaG4L2/nMKqnVuBHufIwoVVW6D7WSGURTyXbjswu7fW1lZT1ajP52OOSXaJZ3JtlpLTKxdQYtcFAgGUlpbmfWynwVXyAkAqqLihhQaAqq1AKA7IAvDaV4E01bnrKVth78HAvjlaZVGyTLE9xjIqkYGjFbJoAV+Rbgb9+AFwvJ82ZZ6Nz2g3J5PArFnAYYcBpFu7FXS0bGrBSDLTlmSoSqoPdu9W9yGCGzLVOuig/IpHnAqCAA5Z5NZ/Tj/G0CfnkdX6fj48DPz97+bXsVOWqQxSLzsyq6EevWMOVBTJogIhVzc0FsnU1dWlGlisSRFNFunBI11yURbxQEiAZDKpThbMyCJ9GWjihv5M34MZWWRF0JE4R7RKZqqSRd/61reY27/97W+rn0tKSlBZWZlTzI2xsTGUlpYiGAyaStPp1WAaTlcBRVHEJZdcon4nbeaEE05wdB7a+LMiiwDglFOysQF+85vf2JqAmxqYMoA9QOSZCOTVMvpW9SESjJi2zx07GFIemBNuuSiL2tvblVXnXkB+RAYy1VTtr0bgvwMa95FQKIS2tjbNeURRxOGHH244/4YNG1zHtNCr1mpra7mECNmXTCgDgQB3Xzfjmf64fE8oRFHU9GsWGfTJT34SgOKG63YlnL4nq3rh9V9BEGwrg0499VQAwBFHHIG+vj7s2sVeLbcilun65y2i2HET45FFhx56qKVL3FQii8R6UVEVAQqxm4KqJoqUR3Dr528FACz+xGJ0X9qtiaPSeVEnnlr8FJrmNXHPT5RLPEVIT0+Pui+rbxB7wg5hQb+bvVIWOVHQsUAvvNHlmz5dUW1YtQW6TgpBFtlZqNEvzJD7NLs3URRx3nnncX/nxTuy4zYsyzL32pFIxDMXUGLXlZSUoKysbFL7NU/JG62OKvF9gvuA2ueBpWcoyqLR6cB4NeBLA0KmblOUHbH7SGDoICD8YXZbOqC4qY1mYiMRsuhjL7kqswzZ4JZKyBjShGbNAlacnnk2fuX9X+HLxmZKJBTCaM4c4NBDga9+1b2gQ0O4yT7lfgFMjAc06p6WliwX8Otf51c84kYQxByW3PrPmY0xPBuYpSyyo4KcCr58bkFsHrI4ZBEu4aOOIllUIDh1Q9MbS8SljIC4kZEXtJWyiFUeQjDlU1lEygooL+q3334bQHbFkhjo9EtbH8+IRxDRMJuMA3zjs7S0VI1z9DlKsnnxxRe7DthsZ8LsFqSMJJYCIYS+/OUvq/sEAgF1Ak0QDofR2dmpiflkhrGxMaaySA/ickDD7Srgpz/9aQDAd77zHVWB5rQ9OlEW6c9v97mZlmkNEOoMoe3rWYJlfHzctH3Ons1WHZkRbrmQRZr77AXwB+XjpmWb8Itrf6H+VFlZyTXSWeOYHYLVTBVDb3vttddMJweiKKqT/traWu6+bski+hlPxuoziYdy1llnMcmgPXv2AIBlPCgz0HXhxkVTEATDooeZMohcgxzjNvYSXf9ESQsoY+CsWbMAAH/4wx8sJ5M8sgiAJfE1lciiiYkJlSyq9lUDaaCyrFINqHtZ/WUAlDLz4qi0X9iOpnlNTOVR63xl7LajCGHVC3neTvsebUPkQhbR45AbsoguNz3OkXZj1Rbo4/WLYpMBXn+qqalRP9MLMwDUJCVW92bmYsxSBpuVh96eSqW4C6rhcNgzN7FCKota57ciFNAt4JH+lg4AZcoYj+l9GbJoBpDMjFXEvWuCGpMTYWBsOlCeVdXAl7Hl+89Q/g8cDZQNAn73rtQst1RRBI48Uvl8113Aj3+c+cGv1O/3Pnedum8yqRBGgQBQUWGPk+BBQ7jJ2TFCmKgwqHvIVMGlCWAbTgRBpEzMYcmt/5xZhfJsYLqfy7JSIKvA2Pt7IGh9pReVRaYokkUFQq5kkX6SQM5jlsWCJovM1EX0sWNjY45VUHbJomeffRYvvZRd4aANdNpI0a9A05Nbt2TR9OnTDXXv8/lwJHnjQWvsbN++3XXA5nxOLEgMhB/+8IcAshla6JgmJSUlSCaTuOKKK9RtX/nKVyCKou34K4Tg0CuL9MfTkzcgt2CRdJsm13Fal2T/cDhsiyyiz2/3Wmb7se7fiiziZREzI9xyIYuMPyj/JtIT+NKXvqRubmho8DyWg11VjNUkL51Oq33BzOD3gixyew4nIPfCG3sJWZQL6Huyql9RFLFq1Sr1ezQa5ZaNpxwg/Y+8o1pbW11lIeIRus3NzWq/skP0mpFFgDnxNZXIorGxMZUs+sGpP0DIH0LjZxpVIshunbRf2M5UHpHz2FGEeNn3aGVRLm5o9Ljvhizi3ROpVyfKIruLM16C1c8A4Oqrr1Y/E9UfAbEfnNybHjQZpS+PlcrZ7LpeJi6gyaLJVhaxMqaR/hYQyrNkEQCUxxWyiASsDoxq/wNKTKLR6ZnjZMUdbV5mgfBDRYmKgY/nXG5T9zkAg4PKHwDVDW1gJOuTn0gof8GgQhbZMMu4aJ3fivIS3fhdthvyWBU3w1iOnqiWcCIIIkMis0xEskVw8MFa/zleYKRclUWJBJBOAyaqwQMiELS+0ovKIlMUyaICwy1ZxHtJ21UWsQxHcozehc3paotdsug3v/mNoZzEQKdf2vF4XLMPzw2NhhVZNHPmTEN6+Wg0ikMOOUT9zlu1dxqwOZ8GCJG1E8OMfNeTRRMTExpjndSbE/UMS1mknwDoA3jmEiySbo+kDbpVFk2fPh0jIyOWMTfo89t9bmZlYmXfsSKLvvCFLzC3m9Wjp2RRpvtPpCc0Ey2zyZ5XAWh5sCL66HZn9jz0k0W7MYwmW1lkFQiXKBRyicHixA0NyCr9jj76aPT19XGD5/OUA3qyiBXHyA6xTNc/nR1xeHhYHdfsqNrIPb/wwgvcfXgT03yqRZ1idHRUJYuCE0FMTExoFjrsTvwB8wxOvOdKx80zu4bTtuqVsoi+rp0FAz3ovsFydbeq14ceeoi53alC2S1EUcTq1asN2+mst/r3Eek/TlRTekLKLG6llYux2XXdZFDkwUtlkdOgxgC/vwXkkI4s2gWMRhQ3NAAoydR7GaUiGq9UlEW+FHBSO3BDJonG89cBHyhjNwaOdn1/BNxEGBns3av8AVDd0F7szS74rloFbN+ukEXhcG5kkVgv4vbP3658EZT3ykGz/Yob31EZifS094BVdeox+V7raW0F9NwsT4RDhibu0EiTy48/riWKeIGR9u0zRg8nsBOziBTm9NOBGTPY+3sRCNpNh/ES+oZQVBaZokgWFQhO1Tp6Ukn/UtNnQbOKWcR6GRNDaLLIIrOYFXbJIt4kx4osCoVC6n2dddZZEAQBVVVVGiPbzMXDyeqWVVYPt5AkCV//+tcBANdeey0A+2QRmey4IYsmJibUNqJvG15meyHl/cc//oEPM+k7f/rTnzoyDkn5ZsyYgaGhIcssLF67od13332GbVZkEU++b4ZcyCL99UqDmQDw6aTtVXlW2+bdI0/JYQarSR5xVa2srHSkbnBDCE4GWUTu10pZxKoXO2mpAWduaECWoCLP2o5CgC7LD37wAwDa98u8j9EYYAAAIABJREFUefMAKGSAnljm3Qcptz4+2sjIiClZpD/fI488AkCJ2cUDjyCZSsqiX736K5UsWv3kaiSTSc27y4naygy8500Tfmb1kouyyCuyKFc3tN1U4Nwrr7wSgHVb+LHqk6OF0wyhueCss84ybHv22WfVz6RvEtgli+ixkGQKJOAuRkC78PHyyy8zF1R4cJNBkQdi85KYRW7HdjdBjU2RKtWSRZF3gMFDsoGqiaKIdjkjyiIAuDCbqAPPtgDDSgZi7J2rDZBtgkh5BEG/Lusm5ZaqBxnWb71VyXYGQHVDe37vg+p+8bjikvXhh7kriwBgwaELlA++NBAcwm4hk1Dj1Ey/S1QA07JZ3PKtLBJF4Hvfy36vreWLcCzJIvqH885TSKCSEqChgR0YqaEBePllgBM7FLqQHiro/kYeSCgEZMJbeA7PO4wL6OvPZfKTjwqKZFGBkKsbmv6lRs6Xi7KIRxY5MfIkScI777yDDRs2cCcqhMggASL1qK2tNXVDoycCvEmkHbKIXKOiokINqGiXLHISsDkfEwsSbJQQadu3bwcAlVTxWllEu6HRx9HnlCQJf/nLX9zekgHEsP/jH/+otu+9e/c6Mg5J3UciEaRSKcuYG26URePj49z08d/4xjeYGYOckkVWbhi5kEWXX365es3Zs2fjxutvBOBMWcTC9ddfr8bSIhAEAT//+c/V73ZXh4eHhzWT/ZqaGtTU1KjHkwxys2bNckQWuSEEJ1NZxCqfJEn47W9/C0DJZEfXnd201IAzNzTA6PpGFAIkvokgCGp/kiTJUBZyPE0ok7Fd/x40uw9SbnJdQBnvR0ZG1PrSk0Ws891xxx0A+H3HzCVuqpBFUq+E7z7xXYUsSilkhizL+Oeuf6r7OFEWmUEURdx9993qd6IIOf/889VtrL5BnoWd8YNuB/lQFuVKFtH3R961f/zjH02P37ZtG3O7l+5UVmDZSfR7T78gR+rJaqwbHR1VyX99YgYzsogmwVlxnFhttaKiAj6fz1UGRR4IsUoSmrjtI26CGpshlQhqyaKyQWDLaVmyiCiLyinbOBVUlEV6jEaoQNgC8MBjwH1PMa8bCoTQc2kP5NUyBm4cwLovrUNVaVaB70uVY+W32GKQjAkKzeMk2dBkanyf8xJkGfjHPxSyaPv2rMCk5mwJNa118K3xoW5tHZo7JNTVZTkSQTBet+VXG7Jfwh9ivHSr8nlsuqK8+tR6bXVkqs6usIXer6ZG+TM7RpKAn/0s+/3zn1faAesYS7KIfueSCjbpVwCUoFA8UohS4mpA93NSmFBIkX/lA046jJMH4EStpL/+JMYr2x9RJIsKDLdkEc99wm7MItZLMVc3NGKQk/PwJipkYnreeecZ7osY6HZjFvHIIjOiR5IkbN68Wf1OXBlGRkY0E3WewsNpwOZ8uCzw0uGSlU8WWUTvzyKLzNRutLIIyBpztCG9fPlyw73mIhH/Oyd1pxPjkJRzBk9OC63RTrc7p6orFkZHRw1lTSQSpmRRkPGCtiI/cyGL6uvrcdRRRwFQMiouPH8hAIUsotuM2WSPNY5ddNFFuOmmbIre888/X22LBHZXh//whz9oJvvxeBzxeFw9/uabbwaguJemUiluLC59n5mqyiJCqOizJ5ExljyL8fFxTd3ZTUsNaJ/n0qVLLUk7Mqmj3y2iKKpB9sn4QZ7nypUrmWPUnj17VNLvhhtuYF7L7D5YZNFBBx1k6obGOp/Vs2e5xNnJEjWZaNnUgrHRTMyiEQCZIWtT3yZ1HzIZ9uI9tHDhQvUzCTpPtyNWvZB6d0rU0MqiXFS5ucYssiK5rN5xbhIWeA2WnWR2X6SP23FDi0QiALQuofQ5WKDPa4csqqurw9KlS7l2r1viLZlMqnZeLm5ovMvHYsp81ckcVpKA8WGdsggAtpwOTFQonwM6N7R9GeXQKEUW7a4D3vyi8QKjM4C++QaFUaQ8gs6LOoHXRLWsK78FjI5nx9KhdBzx0xohf0JCLKYIWQRBmb8zw+hllEVIUTbNkU8CUObqH3yg8BexGCB/QkL8tEbEJ2KQISM2GEPH1kbEqpTKIs2JXDccVv5+t4VShoa3AaFMO9w3BzizFfj891TXegC49lqlzA0NWmELuRdCSvl8xv3iceWPPqa5WXlmNTXZ/UmCLQD45S+111m0SDkmnc4SV+++qxz/NUHCTqEGsiBAFgTguOMYlZoDKLJfA5YbWiiUTXGXC+jKIY0lFmPvG4tl9yN/Vg/guOPYD4t+qKy/l14yXpsmohYsyDaGkhLloX2EUSSLCgSnbmh2V9bMlEUE+VIW2Z2okJdzfX29xmCiY1aYuaHR5eORRTzjkky2aKPg5ZdfBqBMAvUkCwFRdkybNs1xwOZ8TCx4xlE6nYYgCBolCrkPekWftQJvFuyaECJ6ZZFV4N9cpPbPP/889ze7xiEp35NPPsndh26DbmMW8cgiwFjW8fFxJiFEwCIpx8bGDJMSegxxY+SSMYJuA0NDQyjxKe0lmcq6oZWXlxv6Nq30eeuttwznLysr07icTZs2DclkEmvWrDHsa0UArlu3znSiR54VaZe8ZzeV3dAkSUJNTQ0EQUBbm5I9j6gXCMzGWEmSEOMYYbFYzNB+Nm7caNhn0aJFaM4YRXq3rRdffBEA8O6770IQBJWE+MMf/mC43sjIiGHcJiAEnyzLKrmdSqXQ3d2tXs/sPpYtWwYAGKAs8lmzZmnc0DZt2qQpO+98PESjUc9jhOlBP29BEBAOhxEOh9Xvfr8fgiCoJB55HuR3QRAQ2xMDJgAEoBBFmWLtSWZnboIgIBgMelJm+pkSpZjVmEnaay7Z0OwmYgCgqaeSkhI16QNdFr1Kka73mpoaTV+xKjfdDllYvHgx9zjWNfXtgrQNss3n82l+Y/3V1NSgublZvUe3cQPtuKGRhRi9TWkWD47OcEvIIvqZnH322QCyiyTBYNA0tIFd4k0/pvX29qr2kR1lkX7eS/7MzPnFi9lz2HCYLZJoaYGS2YvOWJYIAbsOp7KhjQJntAKzXwdeWQbcmVGv0cqizpeABx8xFogQTCSTmgwcO9KEcPsAGo4XtXPzT7YgCar9pwXgj/8JHKl9d5D5uwGZmEUQAAQy9mdA6YPhsHG+TuIOqQiOAHX/j3FixVtqeBiAQM11KrcBs18DSvcCQ3OyAcEHs/H15JnsRUgCMnWyO0Xr6FCeJ+d1Z4AsK8fQYvG//x1YEH8A63AVZiIOAUqVYbKyJ/7sZ9mG/alPKdsuu0zxFQTYpBFhQHlkDE320JVjt6Ls4o037D8sMxAyinTSTZuyjSGVUh5aZeXkx1aaIiiSRQWCUzc0u/vZjVnkhCyyOzmyky0FyE6Gk8kkKioq1LLRwYDpl7bZyp3TgJWsyRaps9HRUa4bGgkg/d3vftex4ZWPmEVmxpGeiCD3QasUWMoiM4OcuE6ZKYtYcDpJo2H2bO0ah089pcitebGU9CqxfJBF+rK6cUNLp9MG9Q397NxMBFltYHh4GAGfcn3aDW3mzJkGl0Na6cOKEcMiiwDg/fffZ5YnFotpDHn6XvWr1jy88sorAJQYXoTM8Pl8qKysZJIQtbW1Bpc2emJOtv3pT39Sj/GSLJIkSZ2oNjQ0GAiWeDyuIWbMSJSGhgbTazU0NEAQBFRWVqK5uRk/+clPDPvIsoyOjg61PLTbFqkDvXrV6cIHD4sXL1avZwfEvae8vBxVVVUYGRlRy3T33Xdryu4Efr+fqxwlZWP1N1aMJdbEn/zpn/fw8LBmzCP1TJ4teR4a7AKQBFAChTTKdOXpFVp3lNLSUk+URXqySJIkTdr1Z555xnAMGTd6enrg8/k0xIz+j75/mhywE7Cc1DVdT/pFs+XLlxvadjwe11w3Ho+rfaWmpgZPPPGE6XXNVKsAcNpppzG3s665YMECLF261DAODA8Pq9vs9I94PI6Ojg71Ht3GEuS1c9Kmn3/+ebzxxhvMY80WLGk10Re/+EXDMyF9m1y/tLRUbQ/6d6f+Hd7c3Kwh1MrKyjRjLD0uPPnkk2q/IMoiVj9WztmAhoYxx3NdHmc2PKydmy5apMytYzFo0sADAPrOBiAAyYy7e2AUmP995XMp5XJEK4uOeRj4JiP7GVElJcLA3oOAh3vwxh3tbLFHgGo3MoAXvwlsbgZeauLfMA3ihhYYBj6eIa5GFFv65JN1ibt6ReCH+7SKp/7TgEfvNb/Gph9lP894Bzjlp8BXv6goi9IZRmbPodl9dpxgr+yTjIfwNdyG7xfm4uPjRhInnc5KpCgVLwBtzKGPEoaGJj+20hRBkSwqMPJFFnnphmZ3RZA3gddv9/l88Pl8SCaT6otalmWNMfv000/buqZTsshMkWJGFpGyuYmdkA9lESvYKIEVWRQIBJgBru0oi/TBUq3aRi5Se7NAyENDQ7Zc3Mz2YWVfGhsbU90fnMZzYqG0tNQw8bQii3iqI736JleyiDy7RCKhTkCam5vxyeOVNLuLly5W43FEIhHNs+a5QdLQk0UkRtlBBx3E3J+QIcSQp8kPp0Tr+vXrNWTG0NAQZFlmjot6lzZ6Yk623XXXXer+X/nKV1TyRk9q6VUNZMLJmiCHw2EsWrTI1hhmNvFyiqGhIXR0dNjOBDfVUVlZiVAopKlHt8SI3++Hz+fDokWLDM8WyE7Uyfnpiam+zZB2xFNYeYIOAINQyKIUVGXRcUGt+4JdZRFNXurbajgc1hAf8+bNQ0NDgyZWzfr16w11RlQkw8PDkGXZ9jtbTxZZkXH5qOt4PM4kVWnwslcCSn0uX75c/c7LIEiwadMmW8SYF7AzpurbTHNzs6GeeXaD2ZhFK4vsEFkffvgh7rzzTgDaxRT9O7y5uRkdHR0aQm18fNy0zY2Pj6O5uRlbt25FX1+foR8vXrw4c87/C+DflmV1Cw0HmNLZAM9l3HUnKGURAZ3hTB+zKPI2UK5Tvr2ZIXf/awfw420KScPDPX8DXl0MjMwA+j8LPJl5D+rJLB6CmXr3pYHP/BxAGnj3XAgCoAtxpaBiu7LveKbvb2ETrRqUUuqbox5T/tc9A/zt61kibdbr9spbYNyKH1jvVAjoY2auXJn/SOFTFbkEI9uPUSSLCgQ3q7F2iAq7MYvMlEX6Y8844wym4axHa2urYYLPi+8TCAQ0ZBGgJR5+/etfm16LwClZZEZe6FMO05+nGllEgssS0iEajarqFiuyqKqqypWyiHZDYymLWOqaoaEh1yluDz/8cO5v8XjcVqBrs8mDPvsSoNwXCcpM7rG5uVmd+JeUlKhuOgR6ZdHcuXPVz83NzZprkExybrOh8eIruWljRCGTTCbVld7h4WHVv39oZAi/+MUvACjKOvpZ23EDLC8v14wH7733HgCjaxWB2ZjolXrFK+jjsjU3N6O0tJSpatArFwjI5LmI3LBjxw489thjePXVV3M+F1HJqYTP7Q3wX++HsEZA3do6xIeU8eT222+HIAiGiemkYwLA75FVFmXm3S/87gXN2GhHWUSIAF5b1W9nvS/S6TRWrlypfpdl2bUSj14weu2117Bo0SLNJH7p0qVYsmRJfsk4GO+zqqoKgiDgkEMOAaC407NA1Je0m9pkBrW2gizLiEajEASBS+DrFd5382KeMKC3I2kinWRBtIudO3eqLquEXJozZw4AYNGiRSoh39HR4ei8BB0dHXj22WeZfTlLqvcAOAGaADj5QpKyo+96B5j5OrB4PhRGGFkS5OXlwLMZguH024FLdOpSAVklkRvsPQT4fRew/Xjl+9nfByL/BLbaIHEAoHJL9nN1DBBkYGc9/H6gt5e1f8adbu/Byv8BhjJKj/oHFNXTWBVwyF+z26e9l62nigGgus9emQsIGT4kwY+3WjCQ4NoEeR5zpzym0Dg+WSiSRQWCUzc0wB5RkYuyiOeGBvCDVdMQRRE/+lFWEspSbhAQsogux+joqGpQ2DUAnZJFLEUOjyBiKYvcrPCTe0yn09yJhd101zREUcSRRx6Jiy++GH19fepKrBVZVF1dzVQWma1ojo2NMd3Q6InA6tWrDcft2rVLs9JOYjOwFBh1dXWaOAtvvvmm6f2PjIxoJiYsmLkIsOp5bGwM4XAYPp8P4+PjWLBgATo6OjT9irjpEPelxx57TCPFf+ONN9Syd3d3a+7xsMMOA2AesNqMLKLJTjOyyMz9hZSdEESJREKbyYZ0f1+2vQ8NDWH37t3qM7MzQT7ppJPw179mjbeHH37Y8pj9ESMjI+jo6MhLIPsi7MErwkbz7qsHcBGQrsq4gw3G8MGeDwBMTpBzRyBkUSZrdDKZ1KgQrZRFkiS5nmjrEY/H1XEilyxma9euVT9v2bLF8IyTyaSniju7OPLII5FOp/HOO0pl8+qVpb6cSuRwNBpFX18f0um0xs2Wxvj4uPqubmhosCw/vThA9yXabdkrbNu2jetK6AbWSsubATRgUqZNCSr1+egM4HO3AHP/mo3pM61P+R95M6tCWvA94OhHgdFpwKZWhZgBtDF93KB8JzBerWRkO75Hya5mF8MUCfnQ7wHZj7IygLsuOe1fyv9UENgTBd6+0Poas19TSLEyXQawmf/UuuitPBQGzHwdWFmnVWoVCL4METgxFcmiKTRuTQlMYnKCqYIiWVRgeBXHhrzEvYhZxDPAyOScRWoQg4JM3puampjKDYJgMIhEIoFEIqGSHA8++KBjg8KpgUAUOXRK76997WuachHQZBEhUtxMEui6JnVHx0mpqanBsmXLDKum+jgqBDQR8Prrr+OJJ56AJEmaYJA0WGSRU2URL8A1rTY59dRTLesiHo9jyZIl6v0CWpUGHWfBTlBTfUwX/Z8+kx4NQmCRGC51dXXYsGED/vWvf0EQBNxxxx3YtGkT93jivgRoJwzBYFBV05FVZXKPW7YoK229zGU1BWZZ+BYuXKi2oc985jPqb7QKyufzWbpkxONxdYX23nvv1RKFFFlE8Pzzz2Pv3r2O+uaWLVs07ltFMqWI/QrHQAkcTcN+nOXJhR+GstEqFp6yiCYCvIQXpMDWrVs9KIn3IHHRaJUta7FnKqmIWKAV37zFi/fee8+RTUa3sVQqpWlfbjLRTT18b3Iuk6KeRzIETISARzuBwTpl2/SMO1x5HPjGx4EvXAOMZEic168E/pzNQooxXbwZpxidCYxVK+5ebX3AyCz7x/opu6JcscU++1mT/cszgfkFGVjbBwzPsXENzqAc/lBLFvkAfPUihTwLZoIl1T0DTI8BlR9YX8cFnEzv0lBcvVJupuUVFUAmK6HBZawIbxEMAg6yYR8oKJJFBYKbFSazVTQ9WZRLzCIzhUk8HteQGsQFQ29Q/PKXvzRVx9BuaIS4+c///E9Lg0K/Uskji8zUOaIo4gc/yPoGn3nmmZpyEdBkEYEVWUS7LJGV1dtvv139vb+/35D6Ox6PGwz5ZDJpiKPCC4w6Pj6OZcuWqc9NTzaYKYvoZ33wwQcjHA6rWXiIy5UkSdi3bx/Wrl2rZiJ69NFH1WCiBL/73e9M64YglUp5ThzkssJMYriQ9ktWrN3Gjli1ahW6u7tN99FnoqJBP7+DDz5Y/bx48WJ0dXWp/e+DD7IGDom74MYtxjAWMMgit5gqKcaLKMIKfr2RvQHAX3U7TVWyiCiLKNAqxJGRETz66KOGeD9eqz28xGSmlncCWhUeDAbxt7/9TRPsn7yvp5KKCDAuTNILebQbNW33vPXWW45IHvo9TOySqdq+3MEBUZIL1ExlgvJ5bZ8SW2h6RnlDyCJfCqjeCsTOBJ5sU7KmUQgFQsB4Ve7lCX8IVG8BVvuAo4zZL7nwJ9Qg0+GZu1BdDVAmjRFzMwNu+S7gCL6NpOLqU8zLXLpXcVEj+PhjQMUOoPbPwMw3gNMznhAeKosiEaCnR/kjXamiQuEY7GA8PNP85NGowkJFo8pFZFkJvDwwoHyemPBO+ZKDMtT19RYtyn5nZUCMRICmJqVSaYTD2YrX19E55yj7XHGFUkc9PQAn5qslKisBl9kl92cUyaICwY0bmpnxQZREXsQscjKRJy4YeoMikUiYpsKm3dBIliSSAcMMesUUjyyycpsjrmiBQECjxOG5pBGwyCLapYp2WQImT3aeSCRUAslJzKL//u//1uw7PDysaUMdHR0aQoi4K916660G5QqtIvkog8T5McOuXbu4hCY9JvT29uKWW24BoBBMPMN9fHwc99xzj8sS60Cab/HtUMQUgVnabC8QDAbR2NhoXCB4CwDhZJPI9o0pApXg0pFFtLpRkiRs3boVo6OjGuXq4sWLp7Ta47bbbit0EZgg47MkSUgmk3jsscemdD0SyLLMJeAeffRR9bOe8HELfUzKqYxAIGDDFo8C4Kt0yLy9pycr8nAN4lqWLEcmibqCYzKxPGdkSCMhraSXn98C9IoI/HcnKnzKxcPBMJZM70TOL/J6CTj0aUXtI8jZuELhbaqIheYt6L8vXpLE9JBCVg2d/zUMyv3oekm5B9/Br2SvMWdz5pyZeIblu4CdxzKLo3L6Nf8EDnmBX+5p7ymKIf1jLd8NXHwV8I3jgGkZ9WImrpPfr32OLF5GloHvMQRmoZCyDwlR1tgIkPXG4WGFOGpqYp+zpyerQto1ys+si127gL4+JVNZXx+ftNiyhb3dKbxOgiEIxkZC/6VSwM9/nt3/t7817jMwALS3KwQZvX3fPqU+RNFYR1UZwpR4lIgi0NnpToVl4q1wIKM4HSgQ3JBFZvvKsqwhUqzc0MxiFnn1gjdbUSIZuZLJpKosmj17tuNrmLmh6bNH0SBkUWlpqWaCYKUs0gd81KfqLSSIkccji375y18CUDKu7NmjyH3vv/9+z64/1VZSCwW7Kic7ccBKS0vVNmnm1rB27VrvsluR03isZjaL01SEggr9aplDTJs2DRHOTKWiooIZQ6aiogKRSASCICAajXKPB7LkRCQS4cajiUajnowFfr8fPT09kGUZ+/bt88xlOxKJaO4xEolg3bp1OP30043qojgAYnf7oaamd3tdcj9u/np6etSAxNFoFD09PZiYmIAsy4jMjsBPdVg6sH5LS4thbEgmk1M+Gx7Phd0uIpEImpqa1Axk+vbDyzpphTPPPFNVZU3GO4/cA/3cee3BrO8C7HeIJEm44YYb1O+Feo/nEt/KCfRJWILBIL7+9a/bOHIRjMyDgmg0O28XxazI4zSLONCVlZwfiBtayZhC1gDK/+l9itIovB1IVAC+DENc3Y9oFFh/nYg7zr8VAHBySETXDbn1IUEAIl9p0bp6ZVy7Qke8jIkJ5T55vEVsTwy7x3ZnN/gTSrkBpOu7INxUCdRLEE74lfJ7xlUNgTFgeDZQpSU9olHgUBJ6aHimQUmlwafvzSqwaBz2RyC8U7stoyw6/HDtc+TxMl/+svbwaFThHsg+LS3GZGEjI8DGjcZzkiz0pNsNp0zIIruKId5+Tt+hZIz0yrXNTvlpG6jKA1UckCWJqPAjEEV3ZNgUVbzmG0WyqMBwYgCbTbb0aaHdKIvIMV6RRQbDm0IgEFBX46oyA4Kb1bkHH3zQ9HfeBJuQRcFg0BFZRJRFzc3NWLRoUd4zsbiB3ggmQYYJsTY8PIxdu3ZBkiTs3LnTcHwRkwczQhPQkpkk+07e4aEbGt2fbrzxxtxPSEE/dgYCAQ3pQVItTyWYTYiampowNDTEnARaEQcEt99+O9ra2gxB/EOhEO655x5NHLDnnnsOsixjaGgIAwMDSKfT6Ovr48b5EgRBJScGBgZw//33M6/Dyn7JAk086cesUCiErq4uDWHghVuSIAhoa2vDwMCAWpckrlhjY6NxEWUftP3BIb9AgsGT6+RCgIiiqAYk1scD9AV9iB6cbQfz589XP+cSO4f1DpwsOM2eSUDqfGBgAO3t7ejr62MSmG7tnKVLlzKDV+cL5B70z53VHtra2hyfv6WlRRN7sBCIRqNIpVKeEcL6c9Nj58UXX2z4vaurywZJxs56FwrxQ5gQMkhvCodCisqEayITZZEvDVzUqBAqC1qA8A4gQaWV9yttOBKaoZIP5DZeeCH37Oa1tcCuCd34kclwNiJsZxyhxVsDb2k3fPZHwIx3lc/+BOTgEIJXLINcnVFKlVP29IIbgS9/FfhOjUqYtbYCxAwqTdcocZyccpsXXGfYJAQUCRAjoS8TNOewZ4+RTOINuaztemJpFAqZOaFfrTNraHosXGjcRlQ9NiDVA3XXAS/MVNrXn5fOz50wslt+2kbisqkurg1oHxzgnPhx8gwOMBTJogLBzeqNnizSkzH0RCCXbGhekUVmCotAIKAG2CUqF+Im5QRWBhtvgkFWl0pLSzX1aIcsIilkp6qSRj/x2rBhA3O/lpYWy5VIN9BPIIswh9lkzu/3q+3w+9///uTUrYdkEd1HLrroIlfnYE0gQqEQVqxYoSFM1q9fryE96MD1ucDpBCYYDHIVJKlUypB+mhBC7e3tAMxJAQL9PgTV1dVqEH+6bkhWSvpeampqmOXnjZn67WbXAfjEGJm80cTTunXruOchYGWyBBSy6corr2Rei4YgCFixYgWzPrmT/xIAdFZxynb1+XyWaqzJirszNjGGspLsTId+j7ktQyQSwX333ad5Lk1NTabZRK1A2gRNcPLQ2NjorMAZsO7XDmF29NFHcxe46D57ww03TJqSuNKryZIJCh2IWxAElWDmtVW3JBKLvNYri/r7+20Sf+w07rSiRA/y+E49Vet+tGQJ0NWlEA0GVG3JxiwCgOAIhAtXQq7uV+LtvHe2sn378YryCAAdHeGll5T/GfM6J7S2ArXVumdSqbiKhcutlcJjKV3YhhN/CSxcqQSaDioKpUQqAVWxVU6pkE75GRD9C1ARB760DBWnSBDFLKFz9tmA/JqIqrIqlPgYpLYAnhAMSGXfTZGSKD51yFEA3JFFLPELb8hlbdd3vzEohXgRn9E2GrOGRkOSlMZFwyEJSR3jAAAgAElEQVRR1PhFIFYN+DKH3DX2P5COdeiDrY+vZLf8NLxSFpHxQz+etrYaYxf5/ewAU5GIu3s4QFAkiwoEN25oeuP7YF2kOCuyiN6PRQg9+eSTAIwBrqtcdlgzgzAYDKqTHDq9thWcSJXNVrl5bmi8+EUEY2NjaGlpmbJEEWAki8jKuR79/f245JJLPL++3hgrwhxWk7lXX30VAHDNNddMTt16SBbRY5JbNzTSP0OhkIZM4K24E3gR5yYYDKqklF1YxWujg8k+99xzplkjnYLEf+MRTrRa45xzzmGqN1ikDG8sNSO2WG3VzXnoffTkVE9PDwYGBnDWWWcx64NM/qPRKLq7u1VCTg/uhHkCAH0bVJOqrq5Gd3c3+vr6uGouuyqrXDGeGkdZgB2keCFrldkCwWAQbW1thufS3t5ueAbr169HU1OT5TkFQUAqlYIsy6raxwxulDt0rCYadgizs88+WyUwZVnGS2TWDeC667JqBN77NB84++yzHe1vNu7wUMhA4noCl0cIH3XUUY4XSniks/489uMyHcm4hvnckbyCTjhB6360caOJ6ic0AAwdpNkkl8UR9s0AKrYDT90O7DgO+NtSNdvYcFpRg0oS8MADNm/HApGIcm+t81u1ZExQYaGG3jwJdXXKNXko9eve+Sk/EDtDCTQ9vS+7vXxAyVJGk0U0ShIo+4LStgcSylj9ZN/DqFtbh9HkKM4/4nxEq22+o8dDmPGXTvXrQEsfjpytyJXckEWsKRyLg+CJUvTdj5BFWyqOsRefSA+WD5ws85VBfr8miFLLsihGMlOfHZl7GEQCLec5UBaFQkBbm7vy0/CCLJIkgITbWLNG22BJ7KK5c7PbvvMdYN06Y3CpgYGPLFEEFMmigiMXskivfKEnZlYxi55//nnD73feeSckSTIQSaeccorjlZ2ysjJTQ3nv3r149913HZ0TAA477DBb+/n9fqahQJCLG1qhV+J4IM/o6aef1gRPnjmTnV1BlmU8/PDDnl9/D3O5LDf4/f6cVFC5xILJh/qKgF5VZUGSJDxAWX9u3R7JsyFExWc+8xk+4ekhWUSjzK4lpgMhr+fNm2dKJuhBTwrsEFW8WDa0K4tdmI0RdD14Tf4RsogFEmeFYOvWrcyYWVaKIbsgdU67Bro5j75selJJkiTNZJ7g6quvVif/Vm2GO2GuB1CDrKsDtTC5++Ddav15VWdukJbTSKQSKA9k2xJ5j0mShC79KrMFfD4f1q1bxy076xm0t7ejo6PD9Lz6OuYRA25B+iur3Kxr6ccj/RhBK++8cNNijUG0OykZfwRBUMt28sknO7qGE9uE2AhePwe7iEQiBgJX34+mT58OADj99NPR2dmJGTNm2Dp3U1MTt8+7U8bNg97fyY5HCiGL9IIG7mP6xK+AI54EXjcqJYdHAJQNArsPA9pfB3YeBwQypMCg0rdaWrJBlVkIBJQ/K5C5PoHGViDXFGTEYkq8HR5h9LHKj0Gg5T27jgLu+x9grFohvghm/lPJsibwF2F3TfSj+fFmvLTjz5lyjCI2GEMynUR5STn6VvVpr8XBzZ+/Aa//Xkugk6HAronym99kP7MIM8JB2BHW6IklQhZ96lR39hK3caVSbAarq0tD6PQPZo9vyMRmGi8B+sMptuImHDZG7s5FgUNX5vHHm7ORds7V2JiV2e3ebWywogi88072+0UXmQes+oiiSBYVCG6UKXqySC+ZphVBVm5ojz/+uOH38fFxtLS0GMiiaDSKFStWOCrrl7/8ZVNDmaSZdYo5c+bY2i+VSpleP5cA13YNlnxCEARN4EtiZBLQwZOvuuoq7nl48UnclgnILY09C5FIBF1dXWqcETur2IA2VsGQTpNNVAnVeh9mBkZHR20F/dXDDsHKc4shaGlpMSj93ECWZUSjUdUVjKhuuEq9FDx/O5xD0pdyYEZ0AMArr7xi+rse9L2tXr1a01dYMXJYsWzoZ9Pa2orAiQFgFYDVAK7lX9tstd5rsogmey699FJurBeWqxUvZpYdpY8VSPu/++67czqPFXgxVx555BHb5+BOmC+C4opGujItVvsiMHJ4tv68qDM3GJ9QlBGhYLb85D3mJraOLMuuyr5kyRIAwJFHGhUYLJWVnhjIhdAXBME0JhSLzNPH99GTOZs2bbJ1XQCYNcs8pbogCMwgynSbGRgYUN1ozzjjDADOXbqtVEIsGwEAOjs7TWNMWoG8a3/2s58xfxdFUa3fGTNmqIpAKxdb0mZ8Ph9EUcRPfvITW+Xp6uqyzIRLMHPmTBv1vBnAcgB9ANK258PkNaMni7iPSUgDZbuARCXw8jLNT3LpLuClaxRS5eIlwH8ISuDpRAiRV5V6MuMKo1Fg/Xrlj4A2a6ZPZ8/1Wza1ICVTNl0wk1Tm0KcBKCIWnqCtsrQSn57zaQR8Gbt6Ty0g+4CtJwMVlELPPwZ8oZlf+Aw6NncAJSPAnJeB6j51+6Z/K33V4DKngw8+7B7bjb3je9VtYxNjIK9hO69jwj8Q8Agzu3yDnljyhZRCHHWCS9uA17jIg7UgdWaUZ+c3ezJFGPcrVGnTpZTdVFurKG727VOyk3lBrugrt7/fnI20Ai/SuL7B0ixhMYwGE0WyqEDwIhuansywSxZt3ryZq/7o7+83kEWjo6Nob2/HiSeeaDs+wTPPPMP9TZIkjQrKDPrJrN3rC4JgGiDTLVn07LPP2lbO2HGZ0xtodGYiM+Nt7ty5GjccwKgmIxPBc88911Z5rXDllVcyXS2++tWvMq/vBPSqqj6or96obG9vtySMzBQ7f/nLX9TJ3Ny5cy37IJlssdoeSbnNqpfu7m709PQwJ0GE7OO5xRB4qWLr7+9XSSISC4PbxtJAWUUZl1xxg/fff9/0d6t+NTQ0pFHMOcGVV16pmZTZiZFjwPGA8EVByZ4sAODwh1buR16SRXq10AcffMDNsMdrS/lWSuZbtcArvxN3IZpM0EDf7D8PoJT6bX7hY76MpxSyqKI0O86Qd5ebsrl1SyLtuq6uDoBCoFj1L5oYIGQTgZN2Y6fMejJPryx6++231c+SJOHaa03Y4AxkWYbP58OOHTssy+fGDdcpgWamEiKBv2kQG0EURXR1ddmqcxbRTsY7YgsQkHZIq9Pd2LzElrIbw8kscYR+zA2FQhoikW93/Qqh0HHo6fmV4/mw3nRobeUofHpF1bUMO4/T/OQfrgWeaAdK9wF1zwCyAOyJAo92ou3rSmHMeAJSZrrc992X/fzDH7Ln+rTSBAAwqxc4+AUlWPXNfqBhAWJX1EBYI0BYI6DmjhpIvcr7J5lKwu/zI53OPHM5U7fbTlSzqgEASofVWEg8yETZNedvwDXzgLPXqL/tGlMWPVvnt2aJKR38gh8QgJ+++FOcdd9Z6va943tVksiOssgu/+AENLH0pStK7ReGBTMfOAsGa8H9CxAfzarXidBrLDMVeh/Uomss5r3ixuvKdRJpnKBIFjFRJIsKjFzc0PSTV7sBrq1cj/SBpsmq7fTp03HSSSfZcsfYunUr9zcnfvV6AsIuWSTLsul1aDc0XoBr1rUmJiZsK2euueYa0+d70kknGYw3WZbR1taGdDrNNN5ImWiJvCRJXPek/v5+Vxltenp6VPKRxMa688470dnZqTHcOjs78eyzzzo+P41oNKpZVbWzKt/e3o6enh7u72ar42QVWJIkvPvuu+ozMGtbu3btwvr167luSjwXFFEUmRmuzOKn0HA6cbMKtkvIIvKfPGNaYRWJRFAWLEPTN5o05IqTMliRnbzyWYFWzDmBPn6RGxVIy6YWJGR28H9COtohnrwki5yohewGrvYKZOzLN1nEK7+V2kMP0ib+/ve/83fyA7gewP/JfK9mX1/qlVC3tg6+NT7Ura1TJ0/5wNiEEkSWJovIWGYVMFj/fsolzpIgCAiFQipx8vDDDzvqX3rypry8XDOW8cYTN2WWJMmw4PDYY4+p44qTDGF6G4VXp24Id6d9h0t6gq9mJ4QiOdaKkDEj2ul3KMmeCADf/va31Uyy8Xjc9hiuX1R98cUXLY/R35cepE5Je0skEpr3AY80i0QijlxLJQn4xS+Uz7fdZvR84YZj2XoycMpPgM/dkt2WCKHxsFZlHtsrAmv7gDVpCG19aPqsqM7ZncTKARQ1EQGPlzSodQLjwPJTgGlblGxth29SglBnEB+NY9kjyyD1SkikEnh9x+tIIfPeJOzD0EFalzMnUS4OeU75T0g1KIohqVeCWC9i/cXrESnX2kAVgQqFtJKVvvrhcJaY2ju+15Ebmhv+wRHIOOfWNnDiA0eh+fFmbHpPq6aMZEyL4Uy3TlJDsNQroeYONknoGl5XrpNI4wRFsoiJIllUILhxwdIbIWbZ0MxiFpm5tbDK9a9/KWkt9+3bh3A4bMswM0vznctKrJPMK2bX4SmLLr/8clW9kEva4Egkgvb2dqxYscLw3AjZ8sYbb3DVQABbOk8MFfqcZqRYbW2t5j7srm62tLTgoYceQjAYxIcfKi/WyspKiKKorhyvWrUKoihaKkas4HZyIooil7jUb9cH9m1ubjakyiarxCzU1tZCFEWum5IV+eCEnKDLqnefs0IsFsPevXu5q7+0soi+TjgcVtVcAwMDKC8tx0Q6O56Y1TUrkHR3d7djpdltt91ma3JktmrMgxfBrg0rrBTefvtt2xNjL8kiJ2ohJ4GrvUQu7kV2wFNTOHWdJrBsK0Fk1UWDxvFL6pWw7JFliA3GIENGbDCmTp7yAUIWhcuy5SZjPq9uLrroIsiyjO7ubk/jLNFkkdPnro9hGI/HMTo6qgYvb2hoUMcgOnC5mzKzSNZkMqmOK3ZsFN5CUCAQYNbpW2+9xdzf7Nxu+g5519iNtUcTiqIo4oYbbuDuS2wQ3ruMts9oW1Jvc9odw8k7hLyX76OlMBbgEaWkP5C61ZfNLJC+E6KosVHx0AGUrGd6bxpuBIB/fBUYngWMT1PVQ5HnOtHeJBo4gO5uxQMoW3ZnPAHdvHjDXut8i/cDoxskUgm0bGpBMp3ESJLqZ+U7geMeBEZyiAM56w1g+yc0m9JIq2OsWC9i4MYByKtl9a8mVJPJumbE4NigysvYMfnd8A+ukItt4CLmTufLnYZtw0GFKHo3szadoKacS363RKNCoklC1/C6cp2ypwCfNf2Io0gWFQhu3ND0MAtwzVK/uI0l8+abbwJQyCK7MmCzCYiblWxiHLIIHF7gXLPr0GTRU089pfmNqBdYQcDtgMQ/ARQFjN4gP/bYYwEAw8PDzONpQ1VvmM2fP990fz1aW1s1dWY3/g2pg0AggFQqpYkpQc6nJxzMwCNhIpFITpMTOxNgvavOli1bcPfddxsmCxMTE5g+fXpBsxrpyxqPxx2PEclkEpWVlcwJC3mG7733nuY677//vma1t8RXgmRK21Z4da0POk/ajtPYXsRI56V0p2FnMke3zaOPPtqV+xoNs3gITs7vJVnkRC00mUGYJUlS46F96UtfyrnuzaC/L4KLL77Y1flIVlAASjY0HmRgvjDfUH8rn1hpmJgkUgmsfGKlq/KwQCuXTv/l6QCALe9tUX8/77zzDIG3aZx66qkAvI+zFAqFsHPnTgDOCdo//elPhm0jIyNqVrKzzz4bfX19kGXZduByHqxIVl6/8vv9at/hLfglEglmEPbHHnvMsK9Vv3CbQRKwlwyB9W4jKlO9rWXnPejVYh4BIYuI/UcWrqxgVlYy5pJ3GSszcK79wo43Dc88FQRo1EOhzj7VzcwOB+CEJ6Bf57w5slgvGpQ6dtA/2I9kKolwgBoH5m4GLv8q8IVG/oFW8CeBNy43bDYbY80Weub9Yh5+vFlpK3bW8N3wDwSOFKdu3dBcQhOXKoPRAPDYUdnvSZ/5/jm/53KpXBbssqf0OPzJT+YWVPsARZEsKhAKEbPILVlE5MNDQ0PYsWOHZpIJKAaCfhVr0aJF3PO1trY6ngCTFzxLyv3pT3/a8QR/w4YNAJSJwZo1awy/j4yM4MEHH3RURgL9BExveFhldDMjuaoY2mXe/oSIoduJE7XHyMiI+uzD4bBK+JBnV1lZaWt1UJZl3H///cxnpA8y6hR2JsCsVWSeob9r166CZTUCnJXVDLt27WIau6QfPffcc6buSwF/QKMsAvh13dfXZ7g+ObcbNwp6AsVTM1kRznrSrb+/35X7Go3W+a0IBdj34+T8NFmUS1BZwLlaaDKCMJO6J2PNtm3bcq57K9D3ReBGlSFJklZZwVsvkIH5VfPx1I+f0kwAau6o0ay20uBtd1zGXgmNjzaqyqUPhj4AADy5OUty0bGrSN10dmZXjr1Q2rEQCoXURSsn15Akiev2RRZVvMwcaEWy8vpVV1eX2nd4YxNrQY2XqID1/pQkSXXtvuqqq/LSb8zebW+88QYAZfHEqYLLyXhmZ9GQ9GdicxCXeD0ikYjtdzYh4Mjz9SKBhB52vGl48+IVK7xLLMUC3ZzonBNmw2XbBW3cWEA8zCifgUQqgVMOOQVBQXejQWdB9w3YfjyQNI4HvDHWKvD1nuQ2AMBz/c9ZkjkuvbwM43ZsMIaGhxtQ+cNKNmnkgHj1An6B3XfvPyH7OWGje8dH4xDWCO7cr91WrtU5zdhTr4NqH6AokkUFhhPSRD9pNHNDMyOL9CSTVUprQtDs27cPr776KlO+HQ6HsXv3bos7UCCKIpP0YIHcI3mxs2IhPffcc2p8AzvGgiRJuOaaa9TvPALFSYBUAtpVjAcz9zarVOovvPACACUzlFnqW5qIycWdjrSZffv2qdcjpFFVVZVtl8J8qhqsJsBO3B6Ju1khshoB3gXLtTLE9XHJ9Ncv8ZVgQjbKKlh1s3fvXsN+gJZ4swMyKaLHBreuU05i+diFWC9iyQlL2D/W2z+/1XjrqEyTqBayi3zUvRu4iZVkiFWTiVs87cVpiFYr7bispAw9X+7BU99+Cs2PN2PRw4vUCYBXhJBpGTe1aF07MkgfwXdpBrT9yq5C2CnoOndCFpm1DUISedlvWONKMBhUxxU7/WrhQm36bQKWotKuuyghWskiDVmcc0MY8dzQIpEI990mSZLG1SuVSqnjrZdjil21rt4N7eabb2aeq62tzfY7mxBxxC3QbmwqJ7DjTcObF3uVWIoF/byYjiBgRhaJ9SKqSu3Z7DSS6SSOm3kc1l3SiUhJNBuUezxH4nfvXGDHcdb7ZWAW+BoAUKL0tzcH3tKQOY2PNnIJI6fPiDduDyWG8uqmbBeNJ7LVXhup5JYkZtGYjSmFWf2Zwk3l5oJ8RCw/AFEkiwoEN2oBPczc0FgECJn4L1iwQDXAotEofvSjHwHgrwoRN6Tdu3ebTjLtruRKkoTBwUEASrpsvVqIEGjRaBQnnngigKzBSMgSPUh8g+7ubktjwW464ZkzZ1rfDAW7BpDZszcLzCxJEu688071uz71Lc+wzYUsokGuR8iByspKLinBWgEsFAljFeSVYDLdzXhw46Lp5D5efvllW9dnuaHxMJ2Okqk7F3nmPT09lpN3MmGkg227JUPylflr4zsbtRu+BuALAObbP7+Xk16gcP2Kh0JlXdPDDVlkKGPmFHv+Zw/6VvVh4ZELcezMYyHWi5B6Jdy9+e5slh4LVAQqPAl6zXWpYMzl6Puh+/53vvOdvChW6Dp3Uv9mbYPYNcuXL/eszCz3vMbGRlNFsL5fbdyoGwsyiMVihnLadRf1kmhta2sz2FbBYNBUzdvS0mJwy/KC6CXqc6eE9ubNmwEo91JXV4dXXnlF87vzoNMSOjo6NNuSySRqamo87Q92vWmmwryYwMp83zXKC7LE3z+ZSiLgCyhxhFr6IP9HGvJP+nDvFT91dC4D9s4F3rnAsJnnLmdJdgnsMXwkOeLarUrvchYbjHH3JTGeAGR94XIIUeIG7Re246y6szJloH6gikGURUdZJ4oEoNSfel9TFXmPWH5goEgWFQj5iFlE5LTBYNBUWXTEEUfgjDPOwMknn4y+vj5cdtllAIAlS5YYyiMIgi33tdraWlv+6nr3kD179kCWZY0h0d3drcYjOOooxWGWkEVmZbFr1NiZtNAp4c1QVlbm2AAyI4vMVBgtLS2agMyANvUtz7B94oknLMvEAqttjoyMqAGtly9fjoULFxqeeyAQwE033eTqmvkAT52yYsUKTJs2Td3mpZuDW7DKyotbEQqF0NPTYztIrSRJ+PWvf829Nk0yBXxGNzQejj/+eNNzAeZZegjIJEuvOnRDhuQr85dhon4UgHkAqu2f32uyaKphsrOu8eCGLDKUMQQgDdTOqoXUK+GZvmfwyrZXULe2DiufWGmbKBIgYDw17knQa65LBUPIQ1QukiThrrvuUrfv3LkzL66BpM5DoRA3Th0LZm2D2DW5qGxYIOPK0UcfDQDMeIBmMLMj9HYILxuantT3kmgVRdGQuWzdunWm46eX1yfvVr/fj/Xr1zvKdgoY31exWAz33HOPZh+nqiAWGQY4y9BmB/nwpvECZo/RiiyycuVi7Z9IJRD0G9t9qd99LC6kfUoAcB38gh9tF/CJUFtkl2y0eeOjccfjNMvlTLBI+dY/2K9Ivx56SNnw3e9OqiuU1Cvh1W2vKl84RR33AX86DNhSzf6dBWIzTWaGUEeYtIjl+zeKZFGBkQtZpFcCWZFFZIVuYmICIyMjqmFHSKcTTzwRgiBoDB07CignigxeFpJwOMw0JMhEmciyrWDHqLGatJAJ95lnnml5rvHxcVtqJhrk2fAyVvHgxpCTJMkg3SZtjrQfWgVEG5ZWz3779u249957DfsJguCZmskL8NQpp59+uoZ889pg9KqsN954IwDlebFIIbtkCi9uBqCNSSH1Svj37n/joX88ZPlSlyTJEAheEAQsWbKEmxHOjDBqbGzUBhh2iXxl/jqkipPlcdD++Q90sqhQWdf0cBMcWC17PYDvADgTgABsv2o7lj2yDMNJJX5ObDDm2OVMT766DQZqmp3oaPZms4UGL0Geu9OYSKw2w1usyJc7o9P2YmZH6NVFoigaYj0CynOh9/OaaHVKtOd6ffpeCFnoNomF2fuKwGl7MLOVvG5bk60asgOzx2hFFpnF7NMjFAjhgiMuQEpO4bb/vU1jR0i9Eq557BqLM5ggGQLkzNQ1Y3pGyiPouqQLYj2/ks3JLvNYnk7VMSyXM6uFhW++M0PxESSJb3btmrTYOYTc2jO+x3S/d2uAcxc7O3dtda3BXTs2GMPS3y9FzR01hSePvA6qfYCiSBYVCPl0QyMZrPQg2yYmJjA6OqoqKch59u7di3Q6bSueAe0q5kQG7JTwIAac3ZUtO0YNL50woKxUEaOK+LabQZZlxwYGcRH8xje+4ci9xo0h19LSYiDaZFlGNBpVM8q8+OKL6m+0YWkn1kwymdS4PwJKdpFbb73V8tjJBMtoNsQnQWFiq+ihL+uFF14IQJmI5eJuxOtDgiCo5yNGQzKtGOlWfueslVpZlrkuGoB5/xsZGcEtt9xi53ZMka9YPj/43A+MGxNA5FX77hAshcGBhELGUaInq4ceeqhj4lcURSz5ryXAxQAqoKywCsA4xrmpl+2AN1FwE+PINDvR5QCasl9JRrrJcg3csWOH+p/EuLMDVpvh2Uhel5nYMk7JIqtEHfTCgyRJzIQZxLWb7FdoojWX6+tV46TtDQ0NuSqL3efsNCahV+faH8GaFxPU15vzEmK9iM6LOhGtjkKAgEh5hKmWqSqtwpITlqDr713qNtqO4MXusY3dh1NfBETXyxi4ccCUKAKAhUeyY4wBAI77LSCkwZPUxAZjjlQxZi5nPKz+43jBYufYfSYM4ZUpQoEQFh65kOmunUwnER+Nq+TRoocXofnxZmcX8AJTVQY4xVAkiwqEfGRDo8kis5hFemURUZjs2aOwynbIIkI40JNW2jDkGYpOCQ9iwNnJ4mXXqNEbprSyhjYYH3jgActzAc4MDEmSsGnTJgBAT08PWltbbU/+3RhydiYJPBVQa2ur62xNW7Zssd6pwJgqsVWsQJ5ProoUO32PZTSY+Z27qUPS/3igj3Uy4WRdx4tYPkQ+LawRcM2j2hXRaHUUPVf2YOD/Ddg+fy5q0v0FhYijpJ+s6ifidrFxfCOQW5K6vIPrbuEHQHlokL7NCrpstt0NJEnSxBR0Wv/6NuM2E6JbOCWLRFHEihUruP2ZLDyQdslLmEEvUBQ6YH0u1+fFgnQbQNruc3bSHswWKpyea38EPS8GtGFx7CSBEutF9K3qQ3p1GuFgmEmCl5WUYeM7GzE6oVuIy9gRZmnsaUTKI2pSAQ0Cw8pf/QPAYK3t0DKGeIM0SvcBR27ksiECBFuBrwGYEkmR8ghOmXsKk2SbvpNDqk6CPWr3mRBc+oa9/ZacsAQb39loy11bhoyOzR2FI4ymmgxwiqFIFhUYuWRD45FFVjGLeMoiJ2QRoJ3U2TXUnRIedifITgMd0oYpHfiTfh52s6E5kWjTmU6cxo1wY8jZIQh+97vfqZ/1k3O6PpzEoKAnIblM+POJqRJbxQpekUV2+h7PaOBtd1uHoihyJ4N0m3M74fcKdOwBAEjr5Oqt81stVzQN57RBqhfhHF4FB3ZqOOeCioC57wdNVJbcUqKmJDZFpolOtuvfypUrDXZHLkrNyVbZuHFbbG9vR3d3N/f3/v5+Wwk1aFuq0AHr3V6ft0DgVkVvRewAztsDsaFYmeKmQoKLyQCZF0ej2VjKBE6ELLxxcsfwDlM7wk7so1AghLYL2tC3qs+oooy8C7SEgRn/Aja12g4tYzmuH/MwcOxvmT/pyQ7eAprUK2HJ7zgZU6EoSV/+4GX4fcbViH5eHKBJsEftxqOKDAPDrcC571IbTbr3xnc2On6f3r357qkTz6gIFUWyqEDIhxua3QDXvJhFu3fvBmA/3oBGkWDTUHdKeNg14HJJf8pSz9idwOUar8mpMe3UkGttbTUEbqbLLKehQdIAACAASURBVEkSrrvuOvU3Mjlvbm5GY2OjxsXM7/cbXGgCgQBzGy09L/SEn4dCS/7tgsTw2bJlS85KG6u+xzMaeNtzqUNenBL92Fgo10Bi+JnJs53GMvBK/VKEEW5Ubs2PN6skDPmzG7TaCyTTSdMVapqoTMnK+5usbJeVMMhjGcBmo3s4cQnSg7fdKSRJQjzOdqlzq9ScbJWNG7IIMCe+a2trPYmjuD/A63tgPf+mpqac24MoihgYGEBPT0/BFFxTAbkmgeLZBDXlNaZ2hFXso0h5BJ0XdaqLMGaBqUP/Em2HlrEkRD65Hjj6D/ZOBiP5RMZrMk7zkEwnmclDbpoPDOtzBE1S7By78ajiFcD5IvDt86iNJnoHu+QgDRny1M+g9hFEkSwqEPKRDc1tzCJClhCyyG7MIo0iwYGhbpfwkCQJa9eutSwLkNuEkuWGZXYuNylggcK4PYmiqMnq5vf7NcGHeXF7Ojs7mYHIKysrNQbW+vXrDRlXqqqq8pJ+12sUWvJvB5Ik4T/+4z/U77mSC1Z9j2U0hAIhblDdXOqwkHFKrGDX8HMam8DL1NhFaOFU5bbg/gXo2Nxh+YzzCU3KZB3M4kiMJEeQSCXwiVmfgF9Q3t9+wY+mk5ogb5QNfTvfKkqz9pvLNfKtspEkCe++qyyTn3feea7HVTPS3Or+p+IChRuYKYHcLnLon397e7tn7aHQCq5CI9ckUK3zW9Wxh8Ylx1yC1vmtBjKb2BF07CMA6jmi1VH0XNpjiD/EIxv8w1FHoWUsCRGHUzF9uXKNxfSr44H/c0WkILFzxHoRd3/hbvV7tDqKpnlNanyqikAFfGkAMvDnKDBik1evra7FwiMXWmaC02My1b1F2MPUSVn0EYMXZJFeEeMkZhGLLLLrhiYIAlasWGEwRmMx48TJraFIVuDpiRVLdUDD7YSSRRaZncuue5oeXteRHUiShF/96lfq91Qqha6uLpx++ukQRZF7nyyyEVBWoln3T7cFnrvaVIsFBEDNJjZVwQpQTsiFfJSbGGlXP3I1xlPjiFZHLV2tcqlD/bF1dXWT3kdYsGv4cbOjcbC/xMnaH9Ha2mp4Z/Am4lKvhE3vbXJ0fp/gQ1q2jp3nFLHBGHxrfOqqO+lrVkRkWk7ji0d9Eb1NvZbXcFI3bmDWfqcqEUJsDKLI3rZtm6r6c6NWAZTxur+/H7W1tWhtbVW382yZaDSq2W9/Bl0H+jGcLHLQ+xVRWLS2KjGK6LULJ0IWsV7EPZvvwZ/7/wwAmFs5F1v3bUX9rHqI9SLejr+NW55RklXo7QixXrTtvt06vxWNjzZq3sehQAidi1sh1tsrK7kmoLzbSSr7XFSk+oDZuRIcoUAIJ3+3DegpTP9YeIRyP2vPW4uVpzCydEoS0NgI33dGbNVaKBDCETOOYAa3tsKM8hmoW1unKpPcuPsX4S2KyqICw8sA13bd0EZHRzExMaGuAvl8PgiCgJdeegkAcNppp5mWo7u7G+3t7ZptXrv0sFbgiXHldeBLFlnEO5edDGE8FMLtySrjF+8+eYGt7dTx/hILaH9AQdRo9SJOO+Q0fLb2s+hb1TepL+mp4hpo1/C7/rTrHZ232DfyBycqtxWPrXB8/rScRsCn9xPwBqzAqaxVez2qSqtsnT/fKkpe+3WbNn0y4LXKj6dUYdV9d3c3ZNmoANvfQeqAZScVFZRTC14kgaqfpbA1X//U1/HWtW8BgErqnDZXmUf879L/zcmO0Gdhi1ZHNW5qTs/Vt6oP8moZ3Zd2swNo24Q+YLZTdysaudyTV9gxrGSynFUxi71DpsHUDrPfS5HyiCa+1EhyBJve2+SKkBscH7QdULyIyUGRLCoQChmzaN++fQCgKouam5s15THLPBaNRpnGjdfGqNkk2esJ5YYNG9TPRC6dj0lrIdyerMgG3n02NjZ6GovmQJHaTzYKRS74ff68qCisMFVcA+0afmMTY2oQYjtpdYt9I7+w41rS/HgzhhLO03lHq6NYf/F6y6DUuYAETpV6JVvucXf85Q7bRnQ+3W547bqtjZO1bQpgMon4j5rLU1FBuX8g1yRQxK1revl0lJco84m/vv9X1K2tw/nS+QCAZ/ufzb2cVBY2rxawyDndEkZ65SfPVd8K4WB40hflWCBk0ezwbP5OoojWxV3MUAVXHHcF9o7v9aQs+phOI8kRrHyCoXYqYtJQJIsKBDduaHqCycwNjSaLJElCNBpVtz333HMAgNdffx0AcM8999i6vtWkxkuDyGyS7OWEUpIkrFiRXWWm5dL5mLROttFoRTbw6rK9vd3TWDRTLRbQ/oJCkQv5crmxg6kwsWqd32rLz/62P9+mBiG2swpW7BuFR+fLnY6PoeNtDN00hJ5Le4xZeiwQKY+gaV6T5X6xwRiWPbLM1jl3je2aEquu+2O7Lqr88odi3X404BOUKWR1aTUEQUCpvxSPvf2Yhki55ZlbCj4+mcGt+5gAQXNfYr3o+J0AAMfPPt7V9d2At7Al9Uq47NeXAQAaHm4wfV48pdfGdzYimU7mrezx0XjO7cjJwl4RWgheKFy8xLx58+TNmzcXuhh5x5NPPokLLrgAzz//PE455RRbx3zsYx/Dtm3b1O/XXnstfvrTn6rf29vb0dzcjHPOOQdPP/000uk0HnjgAYO/PEEwGMTVV1+Njo4O7jX9fj9SqdSk+9azYhaFQiHPDVBejJRoNIq+vj7PrlMoTFY9FpE/SJLEjYWRL1wgXYD4SBwvLn8xr9eZyhDWuI8nF62Oom9Vn3eFKcIzuHmuPZf2MFd+pV5JjYHBgr4dSL0SGh5ucHx9KxTbm3MU3435Q7FuPxq47snrsPaFtfivz/8Xrj/tevhvYSuSp/L4VLe2znGiCj3I4lqkPII9Y3s0qtBQIIQlJyzBhn9sQHw0mzEyUh5BRbACnzroU/j9lb/P6fp2QJJ26GM/LTlhCbr+3mWMCeXQLc63xpf3TKJm7Yh+F/sFP1JyShMri3f/hXb/KyQEQXhZluV5dvYtKosKhHy4oRFlEUllXldXh4aGBiZRBACJRMJSVZRKpVQlw2S+5CdrpfJAl0vvjyu+RWhRCKWNXyiMG9pUQi7xDIrZPKYu7MQComGmMCOuDD2X9tjKIpivlMDF9uYcxXdj/lCs2wMfUq+Ee/92LwCg9c+tkHolrs0wlcen1vmtOceiI/cdH41nvUYo1U37he0YuHEA8mpZ/Ru4cQBzq+a6col2A1bSjpHkCDpf7mRud/quyiVmk13QpJ7UK6HmjhoIawQIawQ0PNyg/k7IOlrpzbv/fL2TDzQUyaICwY0bmn5fvRsaiVm0Y4fie2qH8DCLT0RQqMCEkzFJ/ijIpaeCW08R+xd8gq+gKcWnAtzGIAAmx3Aqwh0aT2x0tL8M2dKgtBuENV+TpmJ7c4fiuzF/KNbtgQui0iBEx+6x3Wh8tFF1S9NjRvmMySyeI4j1ItZfvF7jQuY01TuNNNIQINiKr1QZrJw0soj37uHZeU7fVV6QblYQIKD58WbU3FGDhocbNEotHki8I979xAZjRXc0GyiSRQWGE7JID56y6M0338ypTCwcKEobPYoBZ4sowohCBbieShDrRccqFAJ9Wt0ipg7aL2zHcTOPc3SMHcPZThDWfJE6xfZWRBFFTBZ4Ko391WYQ60WN8qf70m6DUtQJZMi2CIhwMIx9iX2ur+MEPMKOZ+M4fVexSDevIUNGx+YOWyQRjfho3JSwnApx/6Y6imRRgeCFGxovwDXP7SwXHEhKGxpFuXQRRRhRyADXUwlu1VX6tLpFTB1IvRL+vfvfjo7xiuRpnd+a0ySEh2J7K6KIIiYLTlUnu0Z35akk+QFLKRoOhh2dw457UzgYnhRlkdQrMTOVBf1BNJ7YaMuF2g4I6eZ2kS3f4JWr6I5mjSJZVCB4kQ1NfyxxQ6uocJ7al5AlkUhEjXlEcKArbYpy6SKK0MIn+JBKf7Td0ADn8W0Icg2YWUR+QNwnRidGbR/j1nBmgZ6EeImpHBOkiCKKOLDglDyfym5oPOiVoouOX+ToeDs2wGSRRS2bWpiZyhKpBDb8YwOWnLAEJT7FU4XnQu0EThbZnJJwbhEfjZvOt4s2mzmKZFGB4IYs0sPn0z4+QhaddNJJjs4TiURUsmRgYADr1q0rKm2KKOIjjGKAawXlgXLViCII+AKWMQ30aXWLmBpguU+wQGJveGE460EmIfJq2TPJfjFmURFFFDFZcKqQ3JfYt9+/D52qN60WmqReCd2vdWPX6K68p3E3W0yIj8bRsbkDPsGHb33mW5ZxluyAtxhSEahQ68Uv+NE0rwl3f+HunK5lF37Bj4n0hOk+zY83T0pZ9kcUyaICw0uyiLihHXPMMbaPCQaDaGtr02wrKm2KKOKjjaIbmgJZlnHu4edq5OjrL15vuVJqJyhyEZMPM6OZPN+eS3uQujkFebXsieFsBjvuGT7BZ0oqBf1Bz5RPRRRRRBFW0LtpWREjiVRiv38fOlVvmqlriMKVuIbFBmNY9PCinMkKqVdC3do6+Nb4VAJK6pW4gcdpJFIJ3PXiXZ4QVywyMRQI4Z6L7sHEzROQV8uYuHkC7Re2Q6wX8xrniFzbjtqp8+XOvJZjf0aRLCoQ3MQs0hNL+u+ELAoEtBHpP/7xj6ufr7rqKo1qaN26dUUyqIgiitCgmA1NwXhqHJ+c/UlD4GI7k/yia9DUA0+BE62O2speM1nloXH/Jfej7YI25kp+OBjGui+tm9QyF1FEEUXQblpdl3RZqm339/ehU/WmmasxS+EqQ8bdm+92TdQQAio2GIMMGbHBGJb+fimWPbLMkS1Hp5t3C7vZQQnaLmhjbvcCkfKIbdfvos3LR5EsKhD+f3t3HyRXfd/5/vOdJ2lGAoFGipcA02KvuangHce7mTjedW12N/IDgouxVTG2qyXL9t4akOJYbLKhnHQqBG66spdU3UU3awFdFbAsnQ1FNiKGiwiJZd/4lhNnGRzYMWa9sM5oUNnGmgEE0sxoHvp3/xj1UT+c0326p/uc7un3q4qqmdOnu38aMZozn/P9fn+taEMrhEXlM4fOnz/vf/yLv/iLVA0BqIrd0KS8y2s5v6wNfRsqHoty4RhUfRR05w/xye7MakNv6d9nM2cSNbKeau0cm/o3KT2aDrz4Prb7mN7+rbcJigAkKj2a1h1jd1QNjDq9VTasWmb/2P7Af8PPLZ4L/fkeFpytpSI5KIBayi9pcWWx7tdqxsDnKLuDFp+787qda3q/chv7NuqdW9+pmbtmlB5NR/oZ366DudsBYVHCWjHgulpY1Iqd0gCsLwy4li4sX5CkinBBijaz4c2FN0suFoPu/LFla/yKZ1AV7jomFbgUQqCgMvz+nn49dMtDJedGvfgGgDgdvvmwju4+GvhvWZKBfLOEVcscvvmwcrfkdMWGK0rOn52fDf35Xi04a7QCq9mVW3FXgn3t01/T/rH9JTONdl63s2bFWhCT6cZ33qiNfRv9Y1F+Xo7//Hjd79UtCIsS0kgbWrmwAdflbWhvv/22/zFhEYBaGHC92oImKbCyqPzCMciKW9HBpw/6nwfd+WPL1sY0UqFVCOvOL126eVLPrmitUthu+NjuYxWzsQiEAHSKsH/LkgzkmykssE+PpnXZhssqzg/7+Z7dmQ29bmi0AqvZlVtJVIIdvvlwyUyjr336a4EVaybTzut2hlYCjWwZ0eaBzTq/eL7k+JYNW0Lfe//Yfh2++fDa/xDrFGFRQlrZhlYeFi0vL6uvb/VuaiaT0Y4dO+R53M0GEIwB19Uri6TSC8cws/Oz/sdhd+o6fZZD3IIqtPYc36Nt922rGhq1e1hH5RCA9aAb/y179a1XA48H/XwPa9szmW66/qa639ub9DQzN1P388KYrG0qwQoVa8Xh49HdR/W1T39NRz52JLA1MLszq039m3Ru8VzJY/8y9S8D32NT/yY9OPEgowGq6Kt9ClqpnrAo6oDr8jY0SVpZudRScurUKY2Pr5bbMbMIQDkGXFevLGrEyJYRnTp7KvA4ogsKfaRLZf9ScMk5YR0AoNm8SU8mk1Nlx0jYz/dCFcsDEw/4x5ycjrxwRO8feX/kgK1w8yToZ2KjnFxbBXyFuX1Bx6XVa4Lps9Ma2TKi7M6s0qNp/f2P/r6kiliSrrviOg31D2n70HZNn53WlRuv1OsLr/vnFUYDFL82VlFZlJBWtqEFhUXl7zc3N6dMpj3uqAJoL7Sh1a4sKha29eum/k3+x2Fzjk6dPVWzKgaXBAVuBdUqhcIu2gnrAACNypzMBAZFtSp0Trx8ouJYvdWuYTdP1iLKzmHtIqyKbVP/Js0tzZVcx84tzemKjVdUrQhvp2rjdkJYlJBWtKE98cQTkqR777030vOnp7mjCqASbWjSwvKCpGiVRYd2HQrsnz+/dF4HnjogafWiZt/P7Qt8/uz8bKRWqrXq9N3Yoqw3rFIouzOrwb7BkmPrYfAqACA51XY3q1ah0oxq12o3Txq1Hn4mbh7YLEklQdrc0px/w86b9PT6wuuBz23F17TTERYlrJm7oRWGV7/+evA3QLmREe6oAqjEbmiX2tCKd9QIkx5N64qNVwQ+9sDEA35gFHQnsVi1HVTWaj3sxhbljl+1SqHiv8ukd0IDAHS+sJ85tSp0mlHt2uzt3ocHh9fFz8RNA6tV3V954Sv+DbI//+9/rsWVRUnVryWa/TVdDwiLEtKKNrRqNmwovTs+NDSkbLbz02MAzdfbQxtaPW1okvT6fHhI/+DEg/ImvUh3rFpVBt3uA55rifL1Cyv7LwRlbyy84R9rh53QAACdLajFPErVaqPPK9bobMnhweHA9z6061BDr9duCpVFv/GXv+HfIJtfntf02Wltu29b1WuJbp/XGSRS2mBmN5rZ983sFTP7YsDjv25m3zOz/2ZmJ80sVfTYPjN7+eJ/wTX4XagVbWjVXLhwQZs3b5aZKZVKKZfLMdwaQKBuH3DtTXra/dhuSdLex/dGqr6pdjfQyWnf4/u0dePWSO/fijLoTh7w7E162vd47cuHO8buCLwr2ulBGQCgPaVH08rdkivZsStK1Wrhef09l3awXlhe0LemvxX5vWtVL/X39Gugt3SObSEUamTNneK5Hz0n6dI4gWKz87MVO9EV66SZTXGpuRuamfVK+pKkD0o6LelZM3vCOfe9otP+XtKYc27OzPZLuk/SJ8xsq6S7JY1JcpKeu/jcN9TlGgmLau2GVsu5c+e0f/9+HT58uK7nAegu3Tzgunx3kdfOvxZph4zszqz2Ht8bOOhSWr1bFdYjX64VZdCdvBvbwacP1gwv94/t93eYKdfJQRkAoL2F7dhVy7emv6Wl/JL/ed7l/R3Swn6eFcvuzGrP8T2Bj/Varx756COSgncMK6x7vfEmPT008VDVc8Ku0wZ6B/zKLm/SC/26dZsopSnvlfSKc+4HzrlFSY9KurX4BOfcN5xzhdt235Z0zcWPPyzpr5xzr18MiP5K0o3NWfr6EFdlUUEul2v4/QB0h24ecN1oFUp6NK07xu5oyhpqBSONDKpuRsl7UmbnZ6s+/r5r3lf1wpqd0AAA7Sb3XPDvZA9MPBB5nmDQzaWh/iEd+dgRP8QK2jFsvcqczPgzJ2sp3sl2Y+9GPXzrw0qPptfFjMdmipI2XC3p1aLPT188FubfSnq6nuea2biZTZjZxJkzZyIsqfPFPbOoYGWle1tLAETTzQOuw1rAorSGHb75sN8rvxbFFzDlGr2IKZS8F1xz2TXrouy8v6dfV22+quo579z6zsDjN11/UyuWBABATdVuDH3uq58r+blefpPowFMHNP7keMVrdPvmDVErhlNbUpq5a0bubqdtQ9vU29Orvcf3asf9O3Tw6YOBNw0PPn2wFUtue1HShqDSl8Ckw8z2aLXl7A/rea5zLuecG3POjW3fvj3CkjpfI21otXZDi6K3lynvAKrr5gHXYS1gUVvDzi+eX/Ma3l58OzT8Cat8inIRU3zx+PV9X++Yi8lq4dm1W64NnEtQ4E16+vo/fD3wsVq70wEA0CrVrisWVxa15/ge9d3bpw985QMVN4kemHig4lpAWh3u3Ck/21shasVwcbvZ7Nyszi+d97+2YdXMs/OzXVldFCUsOi3p2qLPr5H0w/KTzOwDkjKSPuKcu1DPc7tZ3G1o4+PjDb8fgO7QYz1yck2pgOwUhbt2YXf6og78bkZr0+LKYmjbW9hds3ovYt668FZDa0vCbe+6LfD4/rH9uvqyq6uGRZmTmdD5BMwsAgAkZfzna/9OtuJWdPIfTgYGQ0G6/edalIrh4cFhP1A7+PTB0GuEIN24MUaUtOFZSdeb2XVmNiDpk5KeKD7BzP6ppIe0GhT9pOihZyR9yMyuNLMrJX3o4rGu18gvYeXBUj1hUW9vL8OtAUTSY6v/tnRLdVFxa1eYqDtkZHdmq+60UVDrnLALvk0Dm0Kfs+/xfZEDo7cX3450XtK8SU9HXjhScsxk/kDrDX0bQucTeJNe1b9TZhYBAJLSrNb1Yt3+c61WxbDJdGjXIUkXq4pqzEQs141hXM20wTm3LOnzWg15XpL0mHPuRTO718w+cvG0P5S0WdKfmtnzZvbExee+Lun/0Grg9Kykey8e63qNtKGVi/Lc3//935dzTsvLywRFACIplEZ3S1gU1J9erHiHjFoKg66rhUE91qM7xu6oGDhdLOiCz5v0dG7xXOhzVtyK9hzfo233basZGnVKZVFQ252T8y8IN/ZtDKwsKgSAYUzWEcO9AQDr14P/24PqiVS7EU23/1yrFebcMXaHX1XUSJVQN4Zxkf7vdM6dcM79r865/8U5l7147Hedc4VQ6APOuXc4595z8b+PFD33YefcOy/+90hr/hidq9VtaB/96Ecbfn0A3alQWRS19aqTHXjqQM07S5cNXFbXDIDDNx/W0d1HQx/Pu7wO33xYuVtygfN4gnYp8yY9ffrxT0d6/9n52ZpDrzslLKq17f3Gvo26sFxZWRQUMhWYrOSCEQCAJKRH07py8MqmvFZxe1W3qhXmFO+cWm+VUKfsINtszYsyUZdm7oZWHhqNjFz6RhkYGFjz+wDoLr093VFZ5E16emDigZrnvT5ff0FsrQs2b9JTejStmbtmdGz3MV02cJmk1Xa38p1MvElPn/3zz9b19zG3NFf1rtnbFzqjDa3WtvcbejcEVhZVuwg8uvtoyQUjAABJaeQaI0ihvaqbVRsFUD5OoJ4qoV7r7dpd5giLEtLM3dCKX+Mb3/iGTp26NKOBsAhAvdbjzKLybWe9SS/yNqiNlh1X28WruPInPZrWb/6L35QkvfxrL1dcjGROZrSUX6r7/U+dPRVaXXTgxAH/69DOsjuz2ti3seRY8d29sDa0sL+zKPOkAACISzNam/aP7e/KIKNc2CiAoKqg7M5s1XEAxcZ/frxrv76ERQlpxsyiQkVR8Wv09fWVnENYBKBefhtafn20oRUPsC5sjTr+5HjkwYaNlh0f2nUodGvc8sqfKzZeIUk6e+FsxbnVhjTX8rmvfs4PhL7ywlcqXnfv8b068NSBhl+/mqCArt7nH3z6YEkYNDw4XHJ3b0Nv8IDrsLuLTq4rdzMBALSnekKLIMODw1TLFimMAkhtSclkgRXb0mqwlLslF3qdVqzW4Oz1jLAoYfWERWG7oRW3oREWAVir9TbgOmiAddRtaNcyAyA9mvZDoCDFrVKF895ceLPkHG/SW1M1zOLKovYc36Md9+/Qv/uLf1fxuJPTgxMPNr3CKCigqyeYKrTelQd65bu4hVUWpUfTodvhduNuJgCA9lQILbZu3Fr3c4f6h2g/C5AeTWvqzinl785r6s6p0Ou49GhaRz52pGZY183XDYRFCWnGzKJCeFQtLOrv71/z+wDoLuupDa2RrVELBnoH1nwRVm0WQXHp+fOvPS9Juv6Pri+pwsmczISGHvU4dfaUXl8IXksrqm3CdjGLGkyFtd4triyWrDUsLJIq5xMUdONuJgCA9pUeTeuyDZfV9ZywihnUpxDWhV0zSN193UBYlBDa0AC0q/W0G1q1EGR4cDi0/Hh4cFgP3/rwmi/Cqs3OKbS3eZOevvRfv+Q/VmiT8ya9qi1o+8f2V52LVI9TZ09p233btO2+bQ21jZW3nIWtO2owVe0uXvFjG/o2aDm/XNEy6U16Ord4ruK53bqbCQCgvdVTvZLakqpaMYP6FCqRju0+VlFl1O3XDYRFCVvLgOuwNjTPu3SB/zM/8zMlnwNALetpN7RqF1+Hdh3Sbe+6zf88tSWlY7uPyd3tNHPXTFMuwoJmEZRv3Z45mamYuzO3NKeDTx+suqvH4ZsPa+aumTWvsWB2flaz87Mlc50KgdGBpw6o554e2T0mu8d02R9c5j8W1HJWTdjfSXHgVAgsgxQHcIXh1xdWLvjPt3tMe47vqago2zywmbuwAIC2VE/1Sje3RbVScZVRtXlH3aSv9ilohWa2oRUHTk8//bR+7/d+z/98enpa4+PjkqR0unv/RwcQ3XoacD2yZSQwvNjUv0np0bS++9p31dfTp8XfWVxTpWeY4kBo+uy0RraMKLszW3LhERauhLXPFVclSavB0VqGYIeZW5rTvsf36ZG/f0Qn/+FkyWPnFs/pM3/+GUnBLWfVFC6IvUnP/7r09/RrMb/onxNW1dbX01fyZy+ERZ8/8Xl9+fkvV23ZO794PvIaAQCI003X36QHJh6IdG43t0W1Wno03dXhUDkqixLSSBtalAHX999/v+bmyga5zs0pk2H3FwDRrKcB19mdWfX3VM5uW8ov+fOMtg5ubUlQVFBr0GKUnTiKObmS14i6k8qG3g11vY+0GtqUB0UFy/llP+ypR3ZntqIaqTgoqmbLhi0lf/bCn+mR5x+pOduJndAAAO3Im/R05IUjkc4tv2EEtBJhUcKaPbPohz/8YeC509OUKwKIZj0NuE6PX3sgswAAIABJREFUpnXZQOXQyMKg5Nn52abN/WlUvbOhysOlKMMZ+6yvobColkK1VFQ91qO9x/dq3+P76qpGKigeGO5Nesp8vb7wh9J9AEC7CavQLW9FL29jB1qNsCghrdoN7eqrrw48d2SEckUA0aynAdfepBe6C9ips6f01P94Si/NvFT3QOdmqhbyBAn6eylUL4W91rJb1luLbzW0vmoKbXVhs5XK5V1eTq7h/7eKW9jGnxyve6c7SvcBAO0m7EaGkyuZn3N091EdvvlwzKtDNyMsSkirdkP74he/qKGhsinuQ0PKZilXBBDNehlwXQgUqikMli4f6BynesIWqXq4FHflzE3X36T0aFp3jN0Ry/sVSu/rnZMksaMJAKA9hd3IKOx6FtbGDrQaYVFCGgmLwnZDK36NT3ziE8rlckqlUjIzpVIp5XI5hlsDiGy9DLiuN1CYW5pLZKZNvWFLtcAj7sqZIy8ckTfp6f0j72/5ew0PDvsXyvWGYr3W2/U7mgAA2lPQ7EFucKAdEBYlbC2VRYXn9vZeml/R19endDqtqakp5fN5TU1NERQBqEu1mUXF25sn2boVRSNVNknNtDl88+FIs5N6rKdq4FFvldJazS3Nac/xPdpzfE/L3+vQrkP+x/WGYnmXJygCALQltmxHuyIsSkgjM4vCdkMrPt7X17e2hQHoemG7oZXvYHXq7CntPb5Xdo+1ZXDUSJVNkjNtioc3h9k+tL3q44UqpTgDozgUVxVJ4bvchWFWEQCgndXaORVIAmFRQlo1s4iwCMBahQ24DmrrKmxXnsTMn1pVTjddf1Ndr5f0drRRAo3NA5trnnP45sM6uvto1UqlsNcZHhxu6u5w9QQ6BeVB11D/UElVkbR6UX35hssjvd5A7wCl/AAAAHUiLEpYM9rQindDIywCsFZhA65rtWjFOfMnqMqpPKw68fKJul4z6e1og2YWFBS2vY86dDw9mtbMXTOhwY9zLnA+wqFdhzRz10xTKpN6rVePfPSRusKnwrbAUUrxo1RiDQ8O6+FbH+YOLQAAQJ1IFhJSbxua53l67bXXSo4FVRYVzy8CgEaEzSzaOri15lblcc38CapyKoRVjQxBHh4cTnw72sK6MyczOnX2lHqtVytuRaktKe17zz7d+9f3+pVcUYX9fZ1fOq/9Y/t14uUTmj47rZEtI8ruzPprGNkyolNnTzX8ZzGZjnzsiP9640+O1xw2XgiKov49hK2xsHsMAAAAGkdYlJB62tA8z9P4+LhWVkpbQk6ePCmptLKo+GMAaETQbmjepKe3LrxV87lxzYYJC4KKj0cNPPp6+iranJKSHk0HVsE8/+PnV8OiOm40eJOeTBYaMJ14+URoqJLdmV3T0Gon5/85ykOwIL3WWxIuRZHdma0Iodg9BgAAoDlIFhIWJSzKZDKam6u8I/vHf/zHkV8DAKIKGnCdOZnRUn6p6vPi/EU9LJQqPh51CHInDIM++Q+rNwdOnT0VeZh45mSmaiVSK6vAUltSJZ+nR9PK7syqzyrvUQ30DtQdFBVek91jAAAAWoOwKCH13B2eng6+oC+0pREWAWimoAHXUYIFk2nP8T2ye0zb7tvW0mHX2Z1ZDfYNlhwrD6vSo2nd9q7bStYXZCm/FNuspUZ4k55+5+u/438edZh4rb+zalVga/l6hIWGmZMZLbvliuOXDVzWcMDD7jEAAACtQViUkHra0EZGgi/o3/GOd0ii9QxAc5XPLPImPf9YNeeXzvsfz87P6nNf/VzLAqP0aFp/8IE/8D8fuXwksKrkXdvfJUmaz8zr6O6joa8X16ylRmROZrSwvFByLMow8WphUK0qsEa/HtWqe8JeM8qgagAAAMSLlCEh9YRF2WxWQ0OVO+TcfvvtkgiLADRXYTe0Z/7nM9p23zbtOb6npMooqsWVxZZW7Pzr1L/2P55+a1qZk5mKcGp+eV7S6m5i6dF0RXtUQVyzlhoRZT5TkLDd1YYHh2u2a4V9PcJCw+HBYbm7XdXqniitgwAAAGgPpAwJixIWpdNp5XI5pVKlv+Ts2rUr8msAQFSFQOAPv/WHNXc/q6WVFTt/+r0/Lfk8qD1rYXlBG/s2+v9OBgUo7T4UudGQJWimz7HdxzRz10zNdq2wr9PtP3974PEoA8I78WsPAADQrQiLElLPzCJpNTCamprSzMyMf6zwyw+VRQCaqTDg+sLKhTW/ViHQ8CY97bh/h+weU9+9fbJ7LPKg5jC553IVx8rbsxaWF0pmG3XiUOS1hCyNzvQJ+zodvvlww1+/TvzaAwAAdKvKbUkQi3ra0IoVB0OFjwmLADRTlPlEUQz0Dii7M6sDTx3QgxMP+jtzFVraCpVAkhoKDM7MnQk8Xrw9+/zSvDb2bSx5PGx7+nZVvPX89NlpjWwZUXZntuV/hrCv01q+fp32tQcAAOhWhEUJqzcsKj6/EBLRhgagmRoJi0xWsU374sqi9hzfU/V5hUqgRgKEoPeULlVGSdLCykJFWNSJCFkAAAAQJ0pSElJvG1pBcRVRISQiLALQTIUB1/UoDm3CtqgPM3122m9T67mnJ1J7mjfpBQZFkkqGcc8vzWuwfzDwPAAAAADBqCxKCG1oANrVWtvQwkKcMFsHt2r8yXHNLc1Jqt2e5k16/uNBeqxHB546oBMvn9Cps6c00DMgb9KjMgcAAACIiJQhYWtpQ6OyCEArFNq4igdDt0phcHMhKCooH1RdLHMyU3F+sbzL64GJB/zZRYv5xYpd0gAAAACEIyxKSDPa0ACgFQqVRY3+O1WPfT+3T6/Pvx742PTZ6cDjxQOso6oWPgEAAAAoRfKQkEbb0KgiAtBqhbBoYWUh9JzUllRT3uvEyyc0smUk8LGg42upDgoLnwAAAACUIixKSDNmFhEcAWiFwoDrsF3EUltSmrpzSsd2H1N/T/+a3mv67LSyO7N+O1rBUP+QsjuzFecffPpgw++1dXBrw88FAAAAuglhUcKoLALQbp56+SlJ0sJycGVRIcRJj6b1yEcfqRiIXc+A7JEtI0qPppW7JafNA5slSVs3blXullzgQOrZ+dnIr13u7cW3mVsEAAAAREBYlJBGZ4E8+uij/sc33nhjs5YDAJJW27x++2u/XfWczMmMH7qkR9P6x1f+Y0nSf9r1n9RjPcq7fOT3O7d4zt+p7LYbbls9aNLe43u14/4dTQ13FlcWmVsEAAAARNCX9AK6VSNtaJ7n6fbbb/c//9GPfiRJevPNN5u7OABdK3Myo2W3XPWcsK3ttw1tqysoklYrhQqv9f3Z70uSP/A66H029W/S+aXzdb1HMeYWAQAAALURFiWsnrAok8lofn6+4viPf/zjZi4JQBeLGqYU7y429eaUJOkLf/GFuiuLCq+15/gemSr/PSy8T3o0rQNPHQgMikym/t5+La4s1nyvsGHaAAAAAC6hDS0hjbShTU8H/xK3tLS01uUAgKT6wpRC5c9yfrUS6Sfnf1J3UFTMKfjfxemz0/ImPT048WDg41sHt+rhWx/WlRuvrPr6YUOzAQAAAJQiLEpII21oIyPBv8T1969tNyIAKMjuzKrPohWd9lqv5pbmqp4zPDis4cFhmUypLSkNDw7XvaaRLSPKnMyEhkmvz7+u9GjaH5Adto6wodkAAAAAShEWJayesCibzWpoaKji+Dve8Y5mLglAF0uPpvUfb/yPJcc29W/SQO9AybGh/iGtuJWqrzVy+YgO7TqkmbtmlL87r6k7p3Ro1yEN9Vf+OxamUA1UrT2uUA316luvhp4zc9cMQREAAAAQEWFRQhppQ0un08rlckqlUjIzXXXVVZKkK664otnLA9DFPn7Dx/2P3d1O5377nB6+9WGltqT8CqHcLTmltqSqvs70W9Maf3K8ZEez9Gha+35uX+B8onIjl4/41UBh7XEm81vLwtZTa50AAAAAShEWJaSRNjRpNTCamppSPp/XF77wBUnSd7/73aavD0D36rHKHw3p0bSm7pzyK4TSo2lld2ZrVgkVD8KWJG/S05EXjoS2lBWbfmtamZMZeZNe4HuZTHeM3eFXDAXNI2JOEQAAAFA/wqKE1RsWFXiep3vuuafi+LZt2+R5XsAzACCaP3vpz/yPd9y/o6QyqFh6NO1XGFWrFCpuIcuczNScc1SsMERbknK35DTYNyhptVro6O6jOnzz4ZL19PdcmuFWqICi/QwAAACoT7Qppmi6RtrQimUyGS0sLFQcn52d1fj46i9W6TS/IAGojzfp6def+XX/8+KwJih0SY+m/eM77t+hU2dPVZxT3EJWbfZQmEJ10tSdUzr6wlG9sfCG/u5//7vAc5fyq7tD/kX6L/Thd3647vcCAAAAQGVRYhptQyuYng7/hWtubk6ZTCb0cQAIkzmZ0fzyfMmx8layMNmd2YoWtvI2sLDZQ7UUQqj55Xm/uqhccQXUZ776mdCKKAAAAADVERYlZK1h0chI9V+4qoVJABAmrPInakVQcTta0Hb1a5kf5E16mluaC5yT5E16fgWUJP343I8rhmsDAAAAiIawKGGNhkXZbFZDQ+GDZWuFSQAQJKzyp1ZFUCGsWXEr/rHyCiVptW1teHC4obUdfPpgaFgUNAspakUUAAAAgFKERQlZ68yidDqtXC6n4eHKX7qGhoaUzbL7D4D6Be06FmVHsXrCmkO7DtXcRS3I7Pyszpw/o8H+yja0tVZEAQAAALiEsCgha21Dk1YDo5mZGR07dkypVEpmplQqpVwux3BrAA0p3+Es6o5i9YQ1hfdoxOz8rIb6KoOmRiuiAAAAAFRiN7SErSUsKkin04RDAJqmeIezqEa2jNTcCa0Z8i4fWJWU3ZnV+JPjJdVNUSqiAAAAAFSisigha21DA4B2Um/7Wq1ZQsWDsssFtaE1WhEFAAAAoBJhUUKa0YYGAO2i3rCm1iyh//CB/xA61+jws4cDdzlLj6Y1deeU8nfnNXXnFEERAAAA0CDa0BJGWARgvainfS2sba3gtnfdpqk3p/TAxAMVj529cFbjT4777wkAAACguagsSghtaAC6WVDbWrHBvkGdePlE6ONhO60BAAAAWDsqixJCGxqAblaoCDr49EHNzs9WPP6zX/pZvbHwRtXXqNXKBgAAAKAxVBYlhMoiAN0uPZrW5oHNgY+9sfBG1SHXUvN3WgMAAACwirAoQVQVAeh21aqDnKqH6jddf1OzlwMAAABAhEWJobIIANZWHVRtphEAAACAxhEWJcQ5R2URgK5Xa9B1tVY0ZhYBAAAArUFYlCDCIgDdLj2aVu6WnIYHhyse6+/prxoWMbMIAAAAaA3CogR4nqc/+qM/0srKinbs2CHP85JeEgAkJj2a1sxdMzq2+5hSW1IymVJbUrp8w+XKKx/4nKH+IWV3ZmNeKQAAANAdrN1m54yNjbmJiYmkl9EynudpfHxcc3Nz/rGhoSHlcjml0+kEVwYA7aXnnp7QIdfHdh9TepR/MwEAAICozOw559xYlHOpLIpZJpMpCYokaW5uTplMJqEVAUB7CmszS21JERQBAAAALURYFLPp6eCBrGHHAaBbBQ2/pv0MAAAAaD3CopiNjATfKQ87DgDdqjD8uniOUe6WHFVFAAAAQItFCovM7EYz+76ZvWJmXwx4/JfM7Dtmtmxmv1L22P9pZt+9+N8nmrXwTpXNZjU0VHanfGhI2Sx3ygGgXHo0rak7p5S/O6+pO6cIigAAAIAY1AyLzKxX0pck7ZJ0g6RPmdkNZadNS/qMpP9c9tybJf0zSe+R9IuSftPMLl/7sjtXOp1WLpfT5ZevfhlSqRTDrQEAAAAAQNvoi3DOeyW94pz7gSSZ2aOSbpX0vcIJzrmpi4+V73F8g6S/ds4tS1o2sxck3SjpsbUvvXOl02l95zvf0UMPPaSpqamklwMAAAAAAOCL0oZ2taRXiz4/ffFYFC9I2mVmQ2a2TdK/kXRt+UlmNm5mE2Y2cebMmYgv3dmcc+rpYWQUAAAAAABoL1HSCgs45qK8uHPuLyWdkPQ3kv5E0t9KWg44L+ecG3POjW3fvj3KS3e8fD4vs6AvLQAAAAAAQHKihEWnVVoNdI2kH0Z9A+dc1jn3HufcB7UaPL1c3xLXJ+ccYREAAAAAAGg7UcKiZyVdb2bXmdmApE9KeiLKi5tZr5kNX/z43ZLeLekvG13sekIbGgAAAAAAaEc1B1w755bN7POSnpHUK+lh59yLZnavpAnn3BNm9guSHpd0paRbzOwe59y7JPVL+v8uVtC8JWnPxWHXXY82NAAAAAAA0I6i7IYm59wJrc4eKj72u0UfP6vV9rTy5y1odUc0lKENDQAAAAAAtCP6oBJCGxoAAAAAAGhHpBUJoQ0NAAAAAAC0I8KihNCGBgAAAAAA2hFhUUJoQwMAAAAAAO2ItCIhtKEBAAAAAIB2RFiUENrQAAAAAABAOyIsSkg+n6cNDQAAAAAAtB3SioRQWQQAAAAAANoRYVFCGHANAAAAAADaEWlFTDzP07Zt22RmMjM9+uijOn/+fNLLAgAAAAAAKEFYFAPP8/TZz35Ws7Oz/rHFxUWdOXNGnucluDIAAAAAAIBShEUxyGQyWlpaCn0MAAAAAACgXRAWxWB6erqhxwAAAAAAAOJGWBSDkZGRhh4DAAAAAACIG2FRDLLZrMws9DEAAAAAAIB2QVgUk97e3opjV155pdLpdAKrAQAAAAAACEZYFINMJqPl5eWK4+fOnUtgNQAAAAAAAOEIi2IQNsQ6bIc0AAAAAACApBAWxSBsiHV/f3/MKwEAAAAAAKiOsCgG2WxWGzZsKDnW29urq666KqEVAQAAAAAABCMsikE6ndZv/dZv+Z/39fXp3e9+t7Zu3ZrgqgAAAAAAACoRFsXkwx/+sCRpeHhYqVRKV199tcws4VUBAAAAAACUIiyKST6fl7RaVZTP5+WcU08PX34AAAAAANBeSCtiUgiLent7lc/nlc/nqSwCAAAAAABth7AoJs45SZfCIuccYREAAAAAAGg7hEUxKW5Dc87RhgYAAAAAANoSaUVMaEMDAAAAAACdgLAoJoU2tOIB14RFAAAAAACg3RAWxaS8sog2NAAAAAAA0I5IK2JSPuCaNjQAAAAAANCOCItiEjTgmrAIAAAAAAC0G8KimNCGBgAAAAAAOgFpRUzKB1zThgYAAAAAANoRYVFMqCwCAAAAAACdgLQiJgy4BgAAAAAAnYCwKCYMuAYAAAAAAJ2AsCgmtKEBAAAAAIBOQFoREwZcAwAAAACATkBYFJOgyiLCIgAAAAAA0G4Ii2JSPuCaNjQAAAAAANCOSCtiUj7gmjY0AAAAAADQjgiLYlLchsZuaAAAAAAAoF0RFsWkeMC1JK2srNCGBgAAAAAA2g5pRUyK29AkaXl5mcoiAAAAAADQdgiLYlLchiatVhYRFgEAAAAAgHZDWBST4t3QJNrQAAAAAABAeyKtiAmVRQAAAAAAoBMQFsWEAdcAAAAAAKATkFbEhAHXAAAAAACgExAWxYQ2NAAAAAAA0AkIi2LCgGsAAAAAANAJSCtiQmURAAAAAADoBIRFMQkacE1YBAAAAAAA2g1hUUzKB1zThgYAAAAAANoRaUVMytvQ2A0NAAAAAAC0I8KimJQPuM7n84RFAAAAAACg7RAWxSRowDVtaAAAAAAAoN2QVsSkfMA1lUUAAAAAAKAdERbFpHzAtSTCIgAAAAAA0HYIi2JS3oYmiTY0AAAAAADQdkgrYlI+4FqisggAAAAAALQfwqKYBLWhUVkEAAAAAADaDWlFTILa0KgsAgAAAAAA7YawKCblu6FJhEUAAAAAAKD9RAqLzOxGM/u+mb1iZl8MePyXzOw7ZrZsZr9S9th9Zvaimb1kZv+3dWlCwoBrAAAAAADQCWqmFWbWK+lLknZJukHSp8zshrLTpiV9RtJ/Lnvuv5D0fknvlvRPJP2CpH+15lV3IAZcAwAAAACATtBX+xS9V9IrzrkfSJKZPSrpVknfK5zgnJu6+Fi+7LlO0kZJA5JMUr+k19a86g7EzCIAAAAAANAJovRBXS3p1aLPT188VpNz7m8lfUPSjy7+94xz7qV6F7ke5PN5mVlJ6xltaAAAAAAAoN1ESSuCyl9clBc3s3dK+llJ12g1YPplM/ulgPPGzWzCzCbOnDkT5aU7jnNOPT09JQERlUUAAAAAAKDdRAmLTku6tujzayT9MOLrf0zSt51z55xz5yQ9Lel95Sc553LOuTHn3Nj27dsjvnRnCaosIiwCAAAAAADtJkpY9Kyk683sOjMbkPRJSU9EfP1pSf/KzPrMrF+rw627sg2tUFlUHBDRhgYAAAAAANpNzbTCObcs6fOSntFq0POYc+5FM7vXzD4iSWb2C2Z2WtLHJT1kZi9efPp/kfQ/JU1KekHSC865J1vw52h7+XyeNjQAAAAAAND2ouyGJufcCUknyo79btHHz2q1Pa38eSuSbl/jGtcFBlwDAAAAAIBOQFoREwZcAwAAAACATkBYFBMGXAMAAAAAgE5AWBQTBlwDAAAAAIBOQFoREwZcAwAAAACATkBYFBPa0AAAAAAAQCcgLIpJ0IBr2tAAAAAAAEC7Ia2ICW1oAAAAAACgExAWxaTQhlYcEBEWAQAAAACAdkNYFBPa0AAAAAAAQCcgrYgJA64BAAAAAEAnICyKSVBlEWERAAAAAABoN4RFMQkacE0bGgAAAAAAaDekFTFhwDUAAAAAAOgEhEUxYcA1AAAAAADoBKQVMWHANQAAAAAA6ASERTFhwDUAAAAAAOgEhEUxYcA1AAAAAADoBKQVMWHANQAAAAAA6ASERTGhDQ0AAAAAAHQCwqKYBA24pg0NAAAAAAC0G9KKmFBZBAAAAAAAOgFhUUyCBlwTFgEAAAAAgHZDWBSToAHXtKEBAAAAAIB2Q1oRE9rQAAAAAABAJyAsigltaAAAAAAAoBMQFsWE3dAAAAAAAEAnIK2ICW1oAAAAAACgExAWxYQB1wAAAAAAoBOQVsSEyiIAAAAAANAJCItiwoBrAAAAAADQCQiLYsKAawAAAAAA0AlIK2JCGxoAAAAAAOgEhEUxCRpwTVgEAAAAAADaDWFRTIIqi2hDAwAAAAAA7Ya0osU8z9OOHTv0zW9+U9/+9rf12GOP+Y9RWQQAAAAAANpNX9ILWM88z9P4+Ljm5uYkSQsLC/rVX/1V/3HCIgAAAAAA0G6oLGqhTCbjB0UF8/Pz/se0oQEAAAAAgHZDWtFC09PTVR+nsggAAAAAALQbwqIWGhkZqfo4lUUAAAAAAKDdkFa0UDab1dDQUMmxvr5LY6L2798vz/PiXhYAAAAAAEAoBly3UDqdliTt2bNH0mpQVFxNdObMGY2Pj5ecCwAAAAAAkCRzziW9hhJjY2NuYmIi6WU0VWE20cDAgBYXFyseT6VSmpqainlVAAAAAACgW5jZc865sSjn0oYWo6CgSKo9CBsAAAAAACAuhEUxKp5XVKzWIGwAAAAAAIC4EBbFaMuWLRUDr4eGhpTNZhNaEQAAAAAAQCnCohiZmXK5nP/5T/3UTymXyzHcGgAAAAAAtA3CohjNzc0pnU5r27ZtkqQvf/nLBEUAAAAAAKCtEBbFaH5+XpJ0xRVXSJJ6evjyAwAAAACA9kJaESPnnKRLYZGZJbkcAAAAAACACoRFCSiERfl8PuGVAAAAAAAAlCIsarFCNVGB53n6m7/5G0nS3r175XleEssCAAAAAAAI1Jf0Ata7xcXFks/37t3rB0gzMzMaHx+XJAZdAwAAAACAtkBlUYt95StfKfm8vNJobm5OmUwmziUBAAAAAACEIixqsXvvvbfmOdPT0zGsBAAAAAAAoDbCohY7ffp0zXNGRkZiWAkAAAAAAEBthEUt9tM//dNVHx8aGlI2m41pNQAAAAAAANURFrXYr/3ar1UcMzNJUiqVUi6XY7g1AAAAAABoG4RFLfbBD35QkrR9+3aZmVKplI4ePSrnnKampgiKAAAAAABAW+lLegHr3cLCgiTp2LFj+tCHPpTwagAAAAAAAKqjsqiFPM/T7t27JUmf/vSn5XlewisCAAAAAACojsqiFvE8T+Pj45qbm5MkvfbaaxofH5ckWs8AAAAAAEDborKoRTKZjB8UFczNzSmTySS0IgAAAAAAgNoIi1pkenq6ruMAAAAAAADtgLCoRUZGRuo6DgAAAAAA0A4Ii1okm81qaGio5NjQ0JCy2WxCKwIAAAAAAKgtUlhkZjea2ffN7BUz+2LA479kZt8xs2Uz+5Wi4//GzJ4v+m/BzD7azD9Au0qn08rlckqlUjIzpVIp5XI5hlsDAAAAAIC2Zs656ieY9Ur6H5I+KOm0pGclfco5972ic3ZIulzSv5f0hHPuvwS8zlZJr0i6xjk3V/54wdjYmJuYmKj7DwIAAAAAAIBgZvacc24syrl9Ec55r6RXnHM/uPjij0q6VZIfFjnnpi4+lq/yOr8i6elqQREAAAAAAACSFaUN7WpJrxZ9fvrisXp9UtKfBD1gZuNmNmFmE2fOnGngpQEAAAAAANAMUcIiCzhWvXet/AXMrpI0KumZoMedcznn3Jhzbmz79u31vDQAAAAAAACaKEpYdFrStUWfXyPph3W+z22SHnfOLdX5PAAAAAAAAMQoSlj0rKTrzew6MxvQajvZE3W+z6cU0oIGAAAAAACA9lEzLHLOLUv6vFZbyF6S9Jhz7kUzu9fMPiJJZvYLZnZa0sclPWRmLxaef3GntGsl/XXzlw8AAAAAAIBmMufqGj/UcmNjY25iYiLpZQAAAAAAAKwbZvacc24syrlR2tAAAAAAAADQJQiLAAAAAAAA4CMsAgAAAAAAgI+wCAAAAAAAAD7CIgAAAAAAAPgIiwAAAAAAAOAjLAIAAAAAAICPsAgAAAAAAAA+wiIAAAAAAAD4CIsAAAAAAADgIywCAAAAAACAj7AIAAAAAAAAPsIiAAAAAAAA+AiLAAAL01xRAAAEpElEQVQAAAAA4CMsAgAAAAAAgI+wCAAAAAAAAD7CIgAAAAAAAPgIiwAAAAAAAOAjLAIAAAAAAICPsAgAAAAAAAA+wiIAAAAAAAD4CIsAAAAAAADgIywCAAAAAACAj7AIAAAAAAAAPsIiAAAAAAAA+AiLAAAAAAAA4CMsAgAAAAAAgI+wCAAAAAAAAD7CIgAAAAAAAPgIiwAAAAAAAOAjLAIAAAAAAICPsAgAAAAAAAA+wiIAAAAAAAD4CIsAAAAAAADgIywCAAAAAACAj7AIAAAAAAAAPsIiAAAAAAAA+AiLAAAAAAAA4CMsAgAAAAAAgI+wCAAAAAAAAD7CIgAAAAAAAPgIiwAAAAAAAOAjLAIAAAAAAICPsAgAAAAAAAA+wiIAAAAAAAD4CIsAAAAAAADgIywCAAAAAACAj7AIAAAAAAAAPsIiAAAAAAAA+AiLAAAAAAAA4CMsAgAAAAAAgI+wCAAAAAAAAD7CIgAAAAAAAPgIiwAAAAAAAOAz51zSayhhZmcknUp6HcA6sk3STNKLANY5vs+A1uP7DGg9vs+A1kvy+yzlnNse5cS2C4sANJeZTTjnxpJeB7Ce8X0GtB7fZ0Dr8X0GtF6nfJ/RhgYAAAAAAAAfYREAAAAAAAB8hEXA+pdLegFAF+D7DGg9vs+A1uP7DGi9jvg+Y2YRAAAAAAAAfFQWAQAAAAAAwEdYBKxzZvZxM3vRzPJm1vZT94FOYmY3mtn3zewVM/ti0usB1iMze9jMfmJm3016LcB6ZWbXmtk3zOyli9eNB5NeE7DemNlGM/uvZvbCxe+ze5JeUzWERcD6911JuyV9M+mFAOuJmfVK+pKkXZJukPQpM7sh2VUB69KXJd2Y9CKAdW5Z0m84535W0vsk/So/04CmuyDpl51zPyfpPZJuNLP3JbymUIRFwDrnnHvJOff9pNcBrEPvlfSKc+4HzrlFSY9KujXhNQHrjnPum5JeT3odwHrmnPuRc+47Fz9+W9JLkq5OdlXA+uJWnbv4af/F/9p2iDRhEQAAjbla0qtFn58WF9YAgA5nZjsk/VNJf5fsSoD1x8x6zex5ST+R9FfOubb9PutLegEA1s7MvibpHwU8lHHOfTXu9QBdwgKOte3dIQAAajGzzZL+TNKdzrm3kl4PsN4451YkvcfMrpD0uJn9E+dcW87kIywC1gHn3AeSXgPQhU5Lurbo82sk/TChtQAAsCZm1q/VoMhzzh1Pej3Aeuace9PM/l+tzuRry7CINjQAABrzrKTrzew6MxuQ9ElJTyS8JgAA6mZmJumPJb3knPu/kl4PsB6Z2faLFUUys0FJH5D035NdVTjCImCdM7OPmdlpSf9c0lNm9kzSawLWA+fcsqTPS3pGq4NAH3POvZjsqoD1x8z+RNLfSvoZMzttZv826TUB69D7Je2V9Mtm9vzF/25KelHAOnOVpG+Y2X/T6k3Hv3LO/T8JrymUOcd4BQAAAAAAAKyisggAAAAAAAA+wiIAAAAAAAD4CIsAAAAAAADgIywCAAAAAACAj7AIAAAAAAAAPsIiAAAAAAAA+AiLAAAAAAAA4CMsAgAAAAAAgO//B0VNft4lo9XdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# visualizer.plot()\n",
    "for color in ['black', 'blue', 'red']:\n",
    "# for color in ['red']:\n",
    "    color_df = visualizer.date_pred_targ_dict.get(color, pd.DataFrame())\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -2]*10, color=color)\n",
    "    plt.scatter(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "    plt.plot(color_df.iloc[:,0], color_df.iloc[:, -1]*10, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:\n",
    "\n",
    "- model:\n",
    "    - embedding_dim=features*2   ✓\n",
    "    - hidden_dim=features*16  ✓\n",
    "- learning rate  \n",
    "- batch size (window size?)\n",
    "- DONE - DID IMPROVE criterion = nn.MSELoss()   ✓\n",
    "    - try a loss which scales through time. ✓\n",
    "- optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "- add polynomial features ✓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
